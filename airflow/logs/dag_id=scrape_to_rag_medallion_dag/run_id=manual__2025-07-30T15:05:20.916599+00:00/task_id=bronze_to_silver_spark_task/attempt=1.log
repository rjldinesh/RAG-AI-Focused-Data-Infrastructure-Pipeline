{"timestamp":"2025-07-30T15:06:00.834010","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-30T15:06:00.834297","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-30T15:06:04.641411","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-30T15:06:04.642031","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name bronze_to_silver_job --verbose /opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.535815","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.578918","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579010","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579047","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579071","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579090","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579110","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579127","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579145","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579163","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579180","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579197","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579238","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579261","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579278","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579298","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579328","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579345","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579361","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579398","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579437","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579459","level":"info","event":"primaryResource         file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579477","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579495","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579513","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579529","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579548","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579580","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579601","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579619","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579636","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579653","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579671","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579688","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579704","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579719","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579769","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579794","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579812","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579828","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579845","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579862","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579879","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.579897","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.646817","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.686412","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.686494","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.686525","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.686549","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.686570","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.686589","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.686613","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-a15de9e2-1320-4055-ad57-68743b988c49;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.686632","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.771977","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.785542","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.793686","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.807853","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.816945","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.823388","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.829395","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:05.836280","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:06:07.395269","level":"info","event":"downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.520/aws-java-sdk-bundle-1.12.520.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:01.769519","level":"info","event":"[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.12.520!aws-java-sdk-bundle.jar (235912ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:02.053481","level":"info","event":"downloading https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.12/3.5.0/spark-avro_2.12-3.5.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:02.698030","level":"info","event":"[SUCCESSFUL ] org.apache.spark#spark-avro_2.12;3.5.0!spark-avro_2.12.jar (924ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:02.982182","level":"info","event":"downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.1.0/delta-spark_2.12-3.1.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:17.371302","level":"info","event":"[SUCCESSFUL ] io.delta#delta-spark_2.12;3.1.0!delta-spark_2.12.jar (14666ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:17.651696","level":"info","event":"downloading https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:19.216559","level":"info","event":"[SUCCESSFUL ] org.wildfly.openssl#wildfly-openssl;1.0.7.Final!wildfly-openssl.jar (1841ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:19.497603","level":"info","event":"downloading https://repo1.maven.org/maven2/org/tukaani/xz/1.9/xz-1.9.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:20.112896","level":"info","event":"[SUCCESSFUL ] org.tukaani#xz;1.9!xz.jar (891ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:20.406918","level":"info","event":"downloading https://repo1.maven.org/maven2/io/delta/delta-storage/3.1.0/delta-storage-3.1.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:20.780906","level":"info","event":"[SUCCESSFUL ] io.delta#delta-storage;3.1.0!delta-storage.jar (665ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:21.066153","level":"info","event":"downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.9.3/antlr4-runtime-4.9.3.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.354800","level":"info","event":"[SUCCESSFUL ] org.antlr#antlr4-runtime;4.9.3!antlr4-runtime.jar (1569ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.355324","level":"info","event":":: resolution report :: resolve 164ms :: artifacts dl 256505ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.355846","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356380","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356494","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356579","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356649","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356712","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356789","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356859","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356893","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.356927","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.357013","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.357094","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.357130","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.357171","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.357249","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.357298","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   7   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.357384","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.371946","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-a15de9e2-1320-4055-ad57-68743b988c49","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.372054","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.740263","level":"info","event":"8 artifacts copied, 0 already retrieved (337604kB/368ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.877837","level":"info","event":"25/07/30 15:10:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.976343","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.976446","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.976514","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.976552","level":"info","event":"file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.976608","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978359","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978413","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978433","level":"info","event":"(spark.app.submitTime,1753888222968)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978452","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978469","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978487","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978505","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978556","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978576","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978593","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978611","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978628","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978645","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978671","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978693","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978711","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978759","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978780","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978829","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978850","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978876","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978900","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978918","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978934","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978951","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978969","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.978986","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.979018","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:22.979069","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.624112","level":"info","event":"INFO:__main__:Starting Spark job...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.750977","level":"info","event":"25/07/30 15:10:23 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.751059","level":"info","event":"25/07/30 15:10:23 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.751185","level":"info","event":"25/07/30 15:10:23 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.771511","level":"info","event":"25/07/30 15:10:23 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.771598","level":"info","event":"25/07/30 15:10:23 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.771671","level":"info","event":"25/07/30 15:10:23 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.771886","level":"info","event":"25/07/30 15:10:23 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.796692","level":"info","event":"25/07/30 15:10:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.801783","level":"info","event":"25/07/30 15:10:23 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.802267","level":"info","event":"25/07/30 15:10:23 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.883619","level":"info","event":"25/07/30 15:10:23 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.883710","level":"info","event":"25/07/30 15:10:23 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.883843","level":"info","event":"25/07/30 15:10:23 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.883952","level":"info","event":"25/07/30 15:10:23 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.884053","level":"info","event":"25/07/30 15:10:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:23.998911","level":"info","event":"25/07/30 15:10:23 INFO Utils: Successfully started service 'sparkDriver' on port 38061.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.014888","level":"info","event":"25/07/30 15:10:24 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.031082","level":"info","event":"25/07/30 15:10:24 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.038929","level":"info","event":"25/07/30 15:10:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.039122","level":"info","event":"25/07/30 15:10:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.040764","level":"info","event":"25/07/30 15:10:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.052166","level":"info","event":"25/07/30 15:10:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bb07dc70-6bed-498c-b5ad-4bfa8d29209d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.058791","level":"info","event":"25/07/30 15:10:24 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.065589","level":"info","event":"25/07/30 15:10:24 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.128973","level":"info","event":"25/07/30 15:10:24 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.156134","level":"info","event":"25/07/30 15:10:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.172219","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://d4662ffe8e33:38061/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.172349","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://d4662ffe8e33:38061/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.172384","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://d4662ffe8e33:38061/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.172544","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://d4662ffe8e33:38061/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.172611","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://d4662ffe8e33:38061/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.172659","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://d4662ffe8e33:38061/jars/org.tukaani_xz-1.9.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.172727","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://d4662ffe8e33:38061/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.172769","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://d4662ffe8e33:38061/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.173900","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://d4662ffe8e33:38061/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.174400","level":"info","event":"25/07/30 15:10:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-3d08dc70-cbb8-42b5-9902-5062578c9bc6/userFiles-c769fda0-119f-4774-ad25-a76e2dadbfe7/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.185407","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://d4662ffe8e33:38061/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.185491","level":"info","event":"25/07/30 15:10:24 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-3d08dc70-cbb8-42b5-9902-5062578c9bc6/userFiles-c769fda0-119f-4774-ad25-a76e2dadbfe7/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.348566","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://d4662ffe8e33:38061/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.348671","level":"info","event":"25/07/30 15:10:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-3d08dc70-cbb8-42b5-9902-5062578c9bc6/userFiles-c769fda0-119f-4774-ad25-a76e2dadbfe7/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.351412","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://d4662ffe8e33:38061/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.351523","level":"info","event":"25/07/30 15:10:24 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-3d08dc70-cbb8-42b5-9902-5062578c9bc6/userFiles-c769fda0-119f-4774-ad25-a76e2dadbfe7/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.356074","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://d4662ffe8e33:38061/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.356167","level":"info","event":"25/07/30 15:10:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-3d08dc70-cbb8-42b5-9902-5062578c9bc6/userFiles-c769fda0-119f-4774-ad25-a76e2dadbfe7/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.358595","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://d4662ffe8e33:38061/files/org.tukaani_xz-1.9.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.358648","level":"info","event":"25/07/30 15:10:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-3d08dc70-cbb8-42b5-9902-5062578c9bc6/userFiles-c769fda0-119f-4774-ad25-a76e2dadbfe7/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.440394","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://d4662ffe8e33:38061/files/io.delta_delta-storage-3.1.0.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.440463","level":"info","event":"25/07/30 15:10:24 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-3d08dc70-cbb8-42b5-9902-5062578c9bc6/userFiles-c769fda0-119f-4774-ad25-a76e2dadbfe7/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.442545","level":"info","event":"25/07/30 15:10:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://d4662ffe8e33:38061/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753888223739","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.442595","level":"info","event":"25/07/30 15:10:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-3d08dc70-cbb8-42b5-9902-5062578c9bc6/userFiles-c769fda0-119f-4774-ad25-a76e2dadbfe7/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.493105","level":"info","event":"25/07/30 15:10:24 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.519701","level":"info","event":"25/07/30 15:10:24 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.7:7077 after 14 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.664277","level":"info","event":"25/07/30 15:10:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250730151024-0000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.671104","level":"info","event":"25/07/30 15:10:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37357.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.671315","level":"info","event":"25/07/30 15:10:24 INFO NettyBlockTransferService: Server created on d4662ffe8e33:37357","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.673019","level":"info","event":"25/07/30 15:10:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.674078","level":"info","event":"25/07/30 15:10:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250730151024-0000/0 on worker-20250730134024-172.18.0.9-43519 (172.18.0.9:43519) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.675011","level":"info","event":"25/07/30 15:10:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20250730151024-0000/0 on hostPort 172.18.0.9:43519 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.678380","level":"info","event":"25/07/30 15:10:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d4662ffe8e33, 37357, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.680609","level":"info","event":"25/07/30 15:10:24 INFO BlockManagerMasterEndpoint: Registering block manager d4662ffe8e33:37357 with 434.4 MiB RAM, BlockManagerId(driver, d4662ffe8e33, 37357, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.682146","level":"info","event":"25/07/30 15:10:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d4662ffe8e33, 37357, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.683013","level":"info","event":"25/07/30 15:10:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d4662ffe8e33, 37357, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.797821","level":"info","event":"25/07/30 15:10:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250730151024-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.812593","level":"info","event":"25/07/30 15:10:24 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.985788","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.985926","level":"info","event":"INFO:__main__:Reading parquet data from s3a://activefence-bucket/bbc_tech/bronze","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.992397","level":"info","event":"25/07/30 15:10:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:24.993696","level":"info","event":"25/07/30 15:10:24 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:25.584827","level":"info","event":"25/07/30 15:10:25 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:25.590972","level":"info","event":"25/07/30 15:10:25 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:25.591048","level":"info","event":"25/07/30 15:10:25 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.157063","level":"info","event":"25/07/30 15:10:26 INFO InMemoryFileIndex: It took 53 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.422129","level":"info","event":"25/07/30 15:10:26 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.430456","level":"info","event":"25/07/30 15:10:26 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.430548","level":"info","event":"25/07/30 15:10:26 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.430655","level":"info","event":"25/07/30 15:10:26 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.431322","level":"info","event":"25/07/30 15:10:26 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.432942","level":"info","event":"25/07/30 15:10:26 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.459144","level":"info","event":"25/07/30 15:10:26 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.9:59792) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.465655","level":"info","event":"25/07/30 15:10:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 108.3 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.498055","level":"info","event":"25/07/30 15:10:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.499560","level":"info","event":"25/07/30 15:10:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on d4662ffe8e33:37357 (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.502489","level":"info","event":"25/07/30 15:10:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.505582","level":"info","event":"25/07/30 15:10:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.9:33767 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.9, 33767, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.516464","level":"info","event":"25/07/30 15:10:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:26.517286","level":"info","event":"25/07/30 15:10:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:28.486139","level":"info","event":"25/07/30 15:10:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 10672 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:28.713769","level":"info","event":"25/07/30 15:10:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.9:33767 (size: 39.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:31.983982","level":"info","event":"25/07/30 15:10:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3512 ms on 172.18.0.9 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:31.987053","level":"info","event":"25/07/30 15:10:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:31.996933","level":"info","event":"25/07/30 15:10:31 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 5.553 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:31.998912","level":"info","event":"25/07/30 15:10:31 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:31.999078","level":"info","event":"25/07/30 15:10:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.001567","level":"info","event":"25/07/30 15:10:32 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 5.579176 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.228834","level":"info","event":"25/07/30 15:10:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on d4662ffe8e33:37357 in memory (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.242570","level":"info","event":"25/07/30 15:10:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.9:33767 in memory (size: 39.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397138","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397231","level":"info","event":"|-- article_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397259","level":"info","event":"|-- title: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397281","level":"info","event":"|-- pub_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397301","level":"info","event":"|-- summary: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397320","level":"info","event":"|-- load_timestamp: timestamp_ntz (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397351","level":"info","event":"|-- year_month: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397389","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397416","level":"info","event":"INFO:__main__:Input dataframe schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.397434","level":"info","event":"None","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.642256","level":"info","event":"25/07/30 15:10:32 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.642777","level":"info","event":"25/07/30 15:10:32 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.643163","level":"info","event":"25/07/30 15:10:32 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.814910","level":"info","event":"25/07/30 15:10:32 INFO CodeGenerator: Code generated in 82.089958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.831370","level":"info","event":"25/07/30 15:10:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.835827","level":"info","event":"25/07/30 15:10:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.836132","level":"info","event":"25/07/30 15:10:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on d4662ffe8e33:37357 (size: 36.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.836716","level":"info","event":"25/07/30 15:10:32 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.841877","level":"info","event":"25/07/30 15:10:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23169830 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.865897","level":"info","event":"25/07/30 15:10:32 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.867916","level":"info","event":"25/07/30 15:10:32 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.868138","level":"info","event":"25/07/30 15:10:32 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.868206","level":"info","event":"25/07/30 15:10:32 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.868382","level":"info","event":"25/07/30 15:10:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.868818","level":"info","event":"25/07/30 15:10:32 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.883685","level":"info","event":"25/07/30 15:10:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.884192","level":"info","event":"25/07/30 15:10:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.884595","level":"info","event":"25/07/30 15:10:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on d4662ffe8e33:37357 (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.884879","level":"info","event":"25/07/30 15:10:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.885551","level":"info","event":"25/07/30 15:10:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.885745","level":"info","event":"25/07/30 15:10:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.890380","level":"info","event":"25/07/30 15:10:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 12032 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.890660","level":"info","event":"25/07/30 15:10:32 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 11873 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:32.926141","level":"info","event":"25/07/30 15:10:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.9:33767 (size: 7.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.166145","level":"info","event":"25/07/30 15:10:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.9:33767 (size: 36.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.384129","level":"info","event":"25/07/30 15:10:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 493 ms on 172.18.0.9 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.384265","level":"info","event":"25/07/30 15:10:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 498 ms on 172.18.0.9 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.384324","level":"info","event":"25/07/30 15:10:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.385920","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.515 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.386247","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.386498","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.386562","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.386819","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.403990","level":"info","event":"25/07/30 15:10:33 INFO CodeGenerator: Code generated in 5.372167 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.416948","level":"info","event":"25/07/30 15:10:33 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.421022","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.421085","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.421114","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.421182","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.421568","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.425971","level":"info","event":"25/07/30 15:10:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.426784","level":"info","event":"25/07/30 15:10:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.426957","level":"info","event":"25/07/30 15:10:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on d4662ffe8e33:37357 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.427307","level":"info","event":"25/07/30 15:10:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.427673","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.427871","level":"info","event":"25/07/30 15:10:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.430117","level":"info","event":"25/07/30 15:10:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.9, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.440222","level":"info","event":"25/07/30 15:10:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.9:33767 (size: 5.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.450756","level":"info","event":"25/07/30 15:10:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.9:59792","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.505389","level":"info","event":"25/07/30 15:10:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 76 ms on 172.18.0.9 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.505464","level":"info","event":"25/07/30 15:10:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.506051","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.081 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.506165","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.506204","level":"info","event":"25/07/30 15:10:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.506425","level":"info","event":"25/07/30 15:10:33 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.089395 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.510320","level":"info","event":"INFO:__main__:Number of rows read from bronze layer: 4774","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.942721","level":"info","event":"25/07/30 15:10:33 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:33.998572","level":"info","event":"25/07/30 15:10:33 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.718322","level":"info","event":"25/07/30 15:10:34 INFO BlockManagerInfo: Removed broadcast_1_piece0 on d4662ffe8e33:37357 in memory (size: 36.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.723005","level":"info","event":"25/07/30 15:10:34 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.9:33767 in memory (size: 36.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.730778","level":"info","event":"25/07/30 15:10:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on d4662ffe8e33:37357 in memory (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.733871","level":"info","event":"25/07/30 15:10:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.9:33767 in memory (size: 7.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.743324","level":"info","event":"25/07/30 15:10:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on d4662ffe8e33:37357 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.744615","level":"info","event":"25/07/30 15:10:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.9:33767 in memory (size: 5.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.745771","level":"info","event":"25/07/30 15:10:34 INFO InitialSnapshot: [tableId=90019950-ee35-4b5d-b8ab-1724de9b3c37] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(3ca01dce-1097-4327-99c7-4ab1e080023b,null,null,Format(parquet,Map()),null,List(),Map(),Some(1753888234736)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@42572c8d,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.789547","level":"info","event":"25/07/30 15:10:34 INFO DeltaLog: No delta log found for the Delta table at s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.789896","level":"info","event":"25/07/30 15:10:34 INFO InitialSnapshot: [tableId=3ca01dce-1097-4327-99c7-4ab1e080023b] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(9e7ace87-2b05-4867-b87e-3ec2b2a6d4e9,null,null,Format(parquet,Map()),null,List(),Map(),Some(1753888234789)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@42572c8d,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:34.831567","level":"info","event":"25/07/30 15:10:34 INFO OptimisticTransaction: [tableId=9e7ace87,txnId=d7980d4e] Updated metadata from - to Metadata(5f38ac8f-9f93-4ee3-b4f5-2171e0f3f65d,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753888234819))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.021356","level":"info","event":"25/07/30 15:10:35 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.024584","level":"info","event":"25/07/30 15:10:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(article_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.024665","level":"info","event":"25/07/30 15:10:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(article_id#0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.047655","level":"info","event":"25/07/30 15:10:35 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.093093","level":"info","event":"25/07/30 15:10:35 INFO CodeGenerator: Code generated in 28.248083 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.096066","level":"info","event":"25/07/30 15:10:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 208.0 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.100959","level":"info","event":"25/07/30 15:10:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.101290","level":"info","event":"25/07/30 15:10:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on d4662ffe8e33:37357 (size: 37.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.101750","level":"info","event":"25/07/30 15:10:35 INFO SparkContext: Created broadcast 4 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.102624","level":"info","event":"25/07/30 15:10:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23169830 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.140055","level":"info","event":"25/07/30 15:10:35 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.140887","level":"info","event":"25/07/30 15:10:35 INFO DAGScheduler: Got job 3 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.140957","level":"info","event":"25/07/30 15:10:35 INFO DAGScheduler: Final stage: ResultStage 4 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.141012","level":"info","event":"25/07/30 15:10:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.141177","level":"info","event":"25/07/30 15:10:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.141452","level":"info","event":"25/07/30 15:10:35 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.153672","level":"info","event":"25/07/30 15:10:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 358.2 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.155586","level":"info","event":"25/07/30 15:10:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 127.7 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.155921","level":"info","event":"25/07/30 15:10:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on d4662ffe8e33:37357 (size: 127.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.156189","level":"info","event":"25/07/30 15:10:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.156494","level":"info","event":"25/07/30 15:10:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.156555","level":"info","event":"25/07/30 15:10:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.157437","level":"info","event":"25/07/30 15:10:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 12043 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.157863","level":"info","event":"25/07/30 15:10:35 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 11884 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.171323","level":"info","event":"25/07/30 15:10:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.9:33767 (size: 127.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:35.512492","level":"info","event":"25/07/30 15:10:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.9:33767 (size: 37.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.121584","level":"info","event":"25/07/30 15:10:37 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 1964 ms on 172.18.0.9 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.121726","level":"info","event":"25/07/30 15:10:37 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 1964 ms on 172.18.0.9 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.121791","level":"info","event":"25/07/30 15:10:37 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.123876","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: ResultStage 4 (save at NativeMethodAccessorImpl.java:0) finished in 1.982 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.124073","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.124148","level":"info","event":"25/07/30 15:10:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.124629","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Job 3 finished: save at NativeMethodAccessorImpl.java:0, took 1.984396 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.126089","level":"info","event":"25/07/30 15:10:37 INFO DeltaFileFormatWriter: Start to commit write Job 8e534b38-8b85-4c3c-956c-2d6e0b7d4f26.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.127244","level":"info","event":"25/07/30 15:10:37 INFO DeltaFileFormatWriter: Write Job 8e534b38-8b85-4c3c-956c-2d6e0b7d4f26 committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.129942","level":"info","event":"25/07/30 15:10:37 INFO DeltaFileFormatWriter: Finished processing stats for write job 8e534b38-8b85-4c3c-956c-2d6e0b7d4f26.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.555887","level":"info","event":"25/07/30 15:10:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on d4662ffe8e33:37357 in memory (size: 127.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.556957","level":"info","event":"25/07/30 15:10:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.9:33767 in memory (size: 127.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.705016","level":"info","event":"25/07/30 15:10:37 INFO CodeGenerator: Code generated in 116.278084 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.720762","level":"info","event":"25/07/30 15:10:37 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.721896","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Job 4 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000172 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.755532","level":"info","event":"25/07/30 15:10:37 INFO OptimisticTransaction: [tableId=9e7ace87,txnId=d7980d4e] Attempting to commit version 0 with 5 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.871184","level":"info","event":"25/07/30 15:10:37 INFO DeltaLog: Creating a new snapshot v0 for commit version 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.871274","level":"info","event":"25/07/30 15:10:37 INFO DeltaLog: Loading version 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.876531","level":"info","event":"25/07/30 15:10:37 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 2812)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.912515","level":"info","event":"25/07/30 15:10:37 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.912801","level":"info","event":"25/07/30 15:10:37 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.912995","level":"info","event":"25/07/30 15:10:37 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#336.minReaderVersion) OR isnotnull(metaData#335.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.934231","level":"info","event":"25/07/30 15:10:37 INFO CodeGenerator: Code generated in 14.902959 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.935941","level":"info","event":"25/07/30 15:10:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 206.2 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.939271","level":"info","event":"25/07/30 15:10:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.939576","level":"info","event":"25/07/30 15:10:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on d4662ffe8e33:37357 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.940073","level":"info","event":"25/07/30 15:10:37 INFO SparkContext: Created broadcast 6 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.946728","level":"info","event":"25/07/30 15:10:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.963460","level":"info","event":"25/07/30 15:10:37 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.963968","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Got job 5 (toString at String.java:4220) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.964009","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Final stage: ResultStage 5 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.964032","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.964087","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.964349","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[19] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.965247","level":"info","event":"25/07/30 15:10:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.966405","level":"info","event":"25/07/30 15:10:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.966726","level":"info","event":"25/07/30 15:10:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on d4662ffe8e33:37357 (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.966992","level":"info","event":"25/07/30 15:10:37 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.967256","level":"info","event":"25/07/30 15:10:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.967310","level":"info","event":"25/07/30 15:10:37 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.967982","level":"info","event":"25/07/30 15:10:37 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 11166 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:37.974666","level":"info","event":"25/07/30 15:10:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.9:33767 (size: 13.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.036465","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.9:33767 (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.064798","level":"info","event":"25/07/30 15:10:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 97 ms on 172.18.0.9 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.064893","level":"info","event":"25/07/30 15:10:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.065180","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: ResultStage 5 (toString at String.java:4220) finished in 0.100 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.065356","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.065422","level":"info","event":"25/07/30 15:10:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.065647","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Job 5 finished: toString at String.java:4220, took 0.102064 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.084230","level":"info","event":"25/07/30 15:10:38 INFO CodeGenerator: Code generated in 11.306 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.088128","level":"info","event":"25/07/30 15:10:38 INFO Snapshot: [tableId=9e7ace87-2b05-4867-b87e-3ec2b2a6d4e9] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(5f38ac8f-9f93-4ee3-b4f5-2171e0f3f65d,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753888234819)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=2812; replication=1; blocksize=33554432; modification_time=1753888237850; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=8e856b28e8c8b9d670e152b6c299325b versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@42572c8d,1753888237850), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.089517","level":"info","event":"25/07/30 15:10:38 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(5f38ac8f-9f93-4ee3-b4f5-2171e0f3f65d,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753888234819)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=2812; replication=1; blocksize=33554432; modification_time=1753888237850; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=8e856b28e8c8b9d670e152b6c299325b versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@42572c8d,1753888237850), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.093010","level":"info","event":"25/07/30 15:10:38 INFO Snapshot: [tableId=5f38ac8f-9f93-4ee3-b4f5-2171e0f3f65d] DELTA: Compute snapshot for version: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.098609","level":"info","event":"25/07/30 15:10:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 205.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.102343","level":"info","event":"25/07/30 15:10:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.102637","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on d4662ffe8e33:37357 (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.103004","level":"info","event":"25/07/30 15:10:38 INFO SparkContext: Created broadcast 8 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.227093","level":"info","event":"25/07/30 15:10:38 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.227187","level":"info","event":"25/07/30 15:10:38 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.227289","level":"info","event":"25/07/30 15:10:38 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.236637","level":"info","event":"25/07/30 15:10:38 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.282055","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Removed broadcast_6_piece0 on d4662ffe8e33:37357 in memory (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.283296","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.9:33767 in memory (size: 36.5 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.287419","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Removed broadcast_7_piece0 on d4662ffe8e33:37357 in memory (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.288035","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.9:33767 in memory (size: 13.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.296469","level":"info","event":"25/07/30 15:10:38 INFO CodeGenerator: Code generated in 34.378625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.298021","level":"info","event":"25/07/30 15:10:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 206.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.301376","level":"info","event":"25/07/30 15:10:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.302013","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on d4662ffe8e33:37357 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.302696","level":"info","event":"25/07/30 15:10:38 INFO SparkContext: Created broadcast 9 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.303232","level":"info","event":"25/07/30 15:10:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.311011","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Registering RDD 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.311108","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Got map stage job 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.311134","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Final stage: ShuffleMapStage 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.311156","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.311178","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.311468","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.314185","level":"info","event":"25/07/30 15:10:38 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 105.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.315325","level":"info","event":"25/07/30 15:10:38 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.316107","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on d4662ffe8e33:37357 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.316782","level":"info","event":"25/07/30 15:10:38 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.317202","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.317279","level":"info","event":"25/07/30 15:10:38 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.318823","level":"info","event":"25/07/30 15:10:38 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 11155 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.342048","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.9:33767 (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.512393","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.9:33767 (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.534433","level":"info","event":"25/07/30 15:10:38 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 216 ms on 172.18.0.9 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.534540","level":"info","event":"25/07/30 15:10:38 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.535383","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: ShuffleMapStage 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.223 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.535485","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.535518","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.535562","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.535611","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.596721","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Removed broadcast_10_piece0 on d4662ffe8e33:37357 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.598144","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.9:33767 in memory (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.701622","level":"info","event":"25/07/30 15:10:38 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.701730","level":"info","event":"25/07/30 15:10:38 INFO CodeGenerator: Code generated in 110.438167 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.729782","level":"info","event":"25/07/30 15:10:38 INFO CodeGenerator: Code generated in 18.757375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.814463","level":"info","event":"25/07/30 15:10:38 INFO CodeGenerator: Code generated in 21.659375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.817790","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Registering RDD 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.817955","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Got map stage job 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.818019","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Final stage: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.818047","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.819177","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.819450","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.832209","level":"info","event":"25/07/30 15:10:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 603.4 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.833388","level":"info","event":"25/07/30 15:10:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 138.1 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.833782","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on d4662ffe8e33:37357 (size: 138.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.834047","level":"info","event":"25/07/30 15:10:38 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.838248","level":"info","event":"25/07/30 15:10:38 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.838325","level":"info","event":"25/07/30 15:10:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.839194","level":"info","event":"25/07/30 15:10:38 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 8) (172.18.0.9, executor 0, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.839363","level":"info","event":"25/07/30 15:10:38 INFO TaskSetManager: Starting task 42.0 in stage 8.0 (TID 9) (172.18.0.9, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.847688","level":"info","event":"25/07/30 15:10:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.9:33767 (size: 138.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:38.917435","level":"info","event":"25/07/30 15:10:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.9:59792","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.166867","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_10 in memory on 172.18.0.9:33767 (size: 698.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.167043","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_42 in memory on 172.18.0.9:33767 (size: 562.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.241948","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 45.0 in stage 8.0 (TID 10) (172.18.0.9, executor 0, partition 45, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.242552","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 8) in 404 ms on 172.18.0.9 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.243215","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.243592","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 42.0 in stage 8.0 (TID 9) in 404 ms on 172.18.0.9 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.300396","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_0 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.300594","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_45 in memory on 172.18.0.9:33767 (size: 701.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.323963","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 12) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.324194","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 45.0 in stage 8.0 (TID 10) in 83 ms on 172.18.0.9 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.324726","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 13) (172.18.0.9, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.325012","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 82 ms on 172.18.0.9 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.382075","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_1 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.382211","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_2 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.405299","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 14) (172.18.0.9, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.405547","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 12) in 82 ms on 172.18.0.9 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.405604","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 15) (172.18.0.9, executor 0, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.406314","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 13) in 81 ms on 172.18.0.9 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.457825","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_4 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.457928","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_3 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.480926","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 16) (172.18.0.9, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.481261","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 14) in 77 ms on 172.18.0.9 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.481691","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 17) (172.18.0.9, executor 0, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.481906","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 15) in 76 ms on 172.18.0.9 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.537281","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_6 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.537464","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_5 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.556285","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 18) (172.18.0.9, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.556617","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 17) in 75 ms on 172.18.0.9 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.557112","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 19) (172.18.0.9, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.557470","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 16) in 77 ms on 172.18.0.9 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.616054","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_8 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.616181","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_7 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.641216","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 20) (172.18.0.9, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.641609","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 19) in 85 ms on 172.18.0.9 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.645972","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 21) (172.18.0.9, executor 0, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.646592","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 18) in 91 ms on 172.18.0.9 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.670794","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_9 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.674827","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_11 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.686026","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 22) (172.18.0.9, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.686495","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 20) in 46 ms on 172.18.0.9 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.689509","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 23) (172.18.0.9, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.690010","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 21) in 44 ms on 172.18.0.9 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.718987","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_12 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.719170","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_13 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.744846","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 24) (172.18.0.9, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.745287","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 25) (172.18.0.9, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.745748","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 23) in 56 ms on 172.18.0.9 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.746523","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 22) in 61 ms on 172.18.0.9 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.780994","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_15 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.781088","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_14 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.801972","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 26) (172.18.0.9, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.802720","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 25) in 56 ms on 172.18.0.9 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.802762","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 27) (172.18.0.9, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.802787","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 24) in 57 ms on 172.18.0.9 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.865426","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_16 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.868642","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_17 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.897689","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 28) (172.18.0.9, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.898496","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 29) (172.18.0.9, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.898555","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 26) in 96 ms on 172.18.0.9 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.898582","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 27) in 95 ms on 172.18.0.9 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.962208","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_19 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.962781","level":"info","event":"25/07/30 15:10:39 INFO BlockManagerInfo: Added rdd_30_18 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.992119","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 20.0 in stage 8.0 (TID 30) (172.18.0.9, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.993009","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 29) in 95 ms on 172.18.0.9 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.993061","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 31) (172.18.0.9, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:39.993086","level":"info","event":"25/07/30 15:10:39 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 28) in 97 ms on 172.18.0.9 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.029347","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_21 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.029475","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_20 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.042404","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 22.0 in stage 8.0 (TID 32) (172.18.0.9, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.042783","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 20.0 in stage 8.0 (TID 30) in 53 ms on 172.18.0.9 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.043271","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 23.0 in stage 8.0 (TID 33) (172.18.0.9, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.043622","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 31) in 52 ms on 172.18.0.9 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.068164","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_23 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.068255","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_22 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.083210","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 24.0 in stage 8.0 (TID 34) (172.18.0.9, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.083537","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 23.0 in stage 8.0 (TID 33) in 40 ms on 172.18.0.9 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.084122","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 25.0 in stage 8.0 (TID 35) (172.18.0.9, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.084414","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 22.0 in stage 8.0 (TID 32) in 42 ms on 172.18.0.9 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.122391","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_25 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.123773","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_24 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.145642","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 26.0 in stage 8.0 (TID 36) (172.18.0.9, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.145883","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 24.0 in stage 8.0 (TID 34) in 63 ms on 172.18.0.9 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.146357","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 27.0 in stage 8.0 (TID 37) (172.18.0.9, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.146744","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 25.0 in stage 8.0 (TID 35) in 63 ms on 172.18.0.9 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.178442","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_26 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.179010","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_27 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.194295","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 28.0 in stage 8.0 (TID 38) (172.18.0.9, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.194548","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 27.0 in stage 8.0 (TID 37) in 48 ms on 172.18.0.9 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.195593","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 29.0 in stage 8.0 (TID 39) (172.18.0.9, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.195916","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 26.0 in stage 8.0 (TID 36) in 50 ms on 172.18.0.9 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.213694","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_29 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.213777","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_28 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.225512","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 30.0 in stage 8.0 (TID 40) (172.18.0.9, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.225631","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 28.0 in stage 8.0 (TID 38) in 32 ms on 172.18.0.9 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.226285","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 31.0 in stage 8.0 (TID 41) (172.18.0.9, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.226629","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 29.0 in stage 8.0 (TID 39) in 32 ms on 172.18.0.9 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.250664","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_31 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.251757","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_30 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.263479","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 32.0 in stage 8.0 (TID 42) (172.18.0.9, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.263626","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 30.0 in stage 8.0 (TID 40) in 38 ms on 172.18.0.9 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.264511","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 33.0 in stage 8.0 (TID 43) (172.18.0.9, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.264589","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 31.0 in stage 8.0 (TID 41) in 38 ms on 172.18.0.9 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.310400","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_33 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.311213","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_32 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.337687","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 34.0 in stage 8.0 (TID 44) (172.18.0.9, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.337818","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 33.0 in stage 8.0 (TID 43) in 74 ms on 172.18.0.9 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.337852","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 35.0 in stage 8.0 (TID 45) (172.18.0.9, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.338086","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 32.0 in stage 8.0 (TID 42) in 75 ms on 172.18.0.9 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.461949","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_35 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.463324","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_34 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.482108","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 36.0 in stage 8.0 (TID 46) (172.18.0.9, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.483045","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 35.0 in stage 8.0 (TID 45) in 144 ms on 172.18.0.9 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.483107","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 37.0 in stage 8.0 (TID 47) (172.18.0.9, executor 0, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.483133","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 34.0 in stage 8.0 (TID 44) in 146 ms on 172.18.0.9 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.533196","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_36 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.534043","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_37 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.546744","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 38.0 in stage 8.0 (TID 48) (172.18.0.9, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.547294","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 37.0 in stage 8.0 (TID 47) in 64 ms on 172.18.0.9 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.547870","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 39.0 in stage 8.0 (TID 49) (172.18.0.9, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.548012","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 36.0 in stage 8.0 (TID 46) in 67 ms on 172.18.0.9 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.612266","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_38 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.613121","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_39 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.642223","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 40.0 in stage 8.0 (TID 50) (172.18.0.9, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.643237","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 38.0 in stage 8.0 (TID 48) in 96 ms on 172.18.0.9 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.644098","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 41.0 in stage 8.0 (TID 51) (172.18.0.9, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.644493","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 39.0 in stage 8.0 (TID 49) in 97 ms on 172.18.0.9 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.789954","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_41 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.791229","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_40 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.849262","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 43.0 in stage 8.0 (TID 52) (172.18.0.9, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.851293","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 40.0 in stage 8.0 (TID 50) in 204 ms on 172.18.0.9 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.851370","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 44.0 in stage 8.0 (TID 53) (172.18.0.9, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.851395","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 41.0 in stage 8.0 (TID 51) in 201 ms on 172.18.0.9 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.939346","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_43 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.949462","level":"info","event":"25/07/30 15:10:40 INFO BlockManagerInfo: Added rdd_30_44 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.979150","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 46.0 in stage 8.0 (TID 54) (172.18.0.9, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.980270","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 43.0 in stage 8.0 (TID 52) in 134 ms on 172.18.0.9 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.980321","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Starting task 47.0 in stage 8.0 (TID 55) (172.18.0.9, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:40.980363","level":"info","event":"25/07/30 15:10:40 INFO TaskSetManager: Finished task 44.0 in stage 8.0 (TID 53) in 134 ms on 172.18.0.9 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:41.275789","level":"info","event":"25/07/30 15:10:41 INFO BlockManagerInfo: Added rdd_30_47 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:41.303685","level":"info","event":"25/07/30 15:10:41 INFO BlockManagerInfo: Added rdd_30_46 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:41.637276","level":"info","event":"25/07/30 15:10:41 INFO TaskSetManager: Starting task 48.0 in stage 8.0 (TID 56) (172.18.0.9, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:41.643606","level":"info","event":"25/07/30 15:10:41 INFO TaskSetManager: Starting task 49.0 in stage 8.0 (TID 57) (172.18.0.9, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:41.649265","level":"info","event":"25/07/30 15:10:41 INFO TaskSetManager: Finished task 47.0 in stage 8.0 (TID 55) in 659 ms on 172.18.0.9 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:41.651723","level":"info","event":"25/07/30 15:10:41 INFO TaskSetManager: Finished task 46.0 in stage 8.0 (TID 54) in 662 ms on 172.18.0.9 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:42.051194","level":"info","event":"25/07/30 15:10:42 INFO BlockManagerInfo: Added rdd_30_49 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:42.069950","level":"info","event":"25/07/30 15:10:42 INFO BlockManagerInfo: Added rdd_30_48 in memory on 172.18.0.9:33767 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:43.164660","level":"info","event":"25/07/30 15:10:43 INFO TaskSetManager: Finished task 49.0 in stage 8.0 (TID 57) in 1524 ms on 172.18.0.9 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:43.183141","level":"info","event":"25/07/30 15:10:43 INFO TaskSetManager: Finished task 48.0 in stage 8.0 (TID 56) in 1538 ms on 172.18.0.9 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:43.188705","level":"info","event":"25/07/30 15:10:43 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:43.198189","level":"info","event":"25/07/30 15:10:43 INFO DAGScheduler: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 4.351 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:43.202010","level":"info","event":"25/07/30 15:10:43 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:43.202080","level":"info","event":"25/07/30 15:10:43 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:43.202106","level":"info","event":"25/07/30 15:10:43 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:43.202128","level":"info","event":"25/07/30 15:10:43 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.529716","level":"info","event":"25/07/30 15:10:44 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.545782","level":"info","event":"25/07/30 15:10:44 INFO DAGScheduler: Got job 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.554172","level":"info","event":"25/07/30 15:10:44 INFO DAGScheduler: Final stage: ResultStage 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.558300","level":"info","event":"25/07/30 15:10:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.564374","level":"info","event":"25/07/30 15:10:44 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.575655","level":"info","event":"25/07/30 15:10:44 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[36] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.810228","level":"info","event":"25/07/30 15:10:44 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 534.7 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.842714","level":"info","event":"25/07/30 15:10:44 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 124.7 KiB, free 432.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.854534","level":"info","event":"25/07/30 15:10:44 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on d4662ffe8e33:37357 (size: 124.7 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.860859","level":"info","event":"25/07/30 15:10:44 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.881110","level":"info","event":"25/07/30 15:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[36] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.896672","level":"info","event":"25/07/30 15:10:44 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:44.917535","level":"info","event":"25/07/30 15:10:44 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 58) (172.18.0.9, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:45.190702","level":"info","event":"25/07/30 15:10:45 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.9:33767 (size: 124.7 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:47.234475","level":"info","event":"25/07/30 15:10:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.9:59792","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:47.470755","level":"info","event":"25/07/30 15:10:47 INFO BlockManagerInfo: Removed broadcast_11_piece0 on d4662ffe8e33:37357 in memory (size: 138.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:10:47.671343","level":"info","event":"25/07/30 15:10:47 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.9:33767 in memory (size: 138.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.914164","level":"info","event":"25/07/30 15:11:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250730151024-0000/0 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.916247","level":"info","event":"25/07/30 15:11:04 INFO StandaloneSchedulerBackend: Executor app-20250730151024-0000/0 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.920731","level":"info","event":"25/07/30 15:11:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250730151024-0000/1 on worker-20250730134024-172.18.0.9-43519 (172.18.0.9:43519) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.921024","level":"info","event":"25/07/30 15:11:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20250730151024-0000/1 on hostPort 172.18.0.9:43519 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.931282","level":"info","event":"25/07/30 15:11:04 ERROR TaskSchedulerImpl: Lost executor 0 on 172.18.0.9: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.964731","level":"info","event":"25/07/30 15:11:04 WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 58) (172.18.0.9 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.976132","level":"info","event":"25/07/30 15:11:04 INFO DAGScheduler: Executor lost: 0 (epoch 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.978500","level":"info","event":"25/07/30 15:11:04 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.979682","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_27 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.979815","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_26 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980001","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_23 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980065","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980111","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_6 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980172","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_36 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980221","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_17 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980266","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_40 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980309","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_35 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980370","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_42 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980402","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_49 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980458","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_38 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980504","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_44 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.980540","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_20 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.981918","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_15 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982068","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_22 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982130","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_32 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982184","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_39 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982246","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_19 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982310","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_45 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982366","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_1 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982435","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982474","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_25 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982511","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982561","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_16 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982610","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.982661","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_31 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.984642","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_46 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.986857","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_24 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.987742","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_47 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.987892","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.987961","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_7 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988005","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_34 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988036","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_29 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988100","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_3 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988122","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_21 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988139","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_28 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988156","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988184","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_4 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988242","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_30 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988287","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_43 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988331","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988376","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988416","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_8 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988440","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_33 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988475","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_37 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988505","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988528","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_41 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988552","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_9 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.988589","level":"info","event":"25/07/30 15:11:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_30_48 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.989076","level":"info","event":"25/07/30 15:11:04 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.18.0.9, 33767, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.989745","level":"info","event":"25/07/30 15:11:04 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:04.990635","level":"info","event":"25/07/30 15:11:04 INFO DAGScheduler: Shuffle files lost for executor: 0 (epoch 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:05.012450","level":"info","event":"25/07/30 15:11:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250730151024-0000/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:06.819974","level":"info","event":"25/07/30 15:11:06 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.9:50676) with ID 1,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:06.860467","level":"info","event":"25/07/30 15:11:06 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.9:45261 with 1048.8 MiB RAM, BlockManagerId(1, 172.18.0.9, 45261, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T15:11:18.236458","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name bronze_to_silver_job --verbose /opt/spark-jobs/bronze_to_silver.py. Error code is: -9.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":867,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1159,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":570,"name":"submit"}],"is_group":false,"exceptions":[]}]}
