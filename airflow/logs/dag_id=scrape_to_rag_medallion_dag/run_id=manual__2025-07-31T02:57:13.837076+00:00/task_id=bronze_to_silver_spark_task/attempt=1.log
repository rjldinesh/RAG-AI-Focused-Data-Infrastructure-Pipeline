{"timestamp":"2025-07-31T02:57:41.910189","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-31T02:57:41.910420","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-31T02:57:44.224138","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-31T02:57:44.224722","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 1 --executor-memory 1g --driver-memory 512m --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.018345","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.058889","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.058965","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.058991","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059011","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059031","level":"info","event":"executorMemory          1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059050","level":"info","event":"executorCores           1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059068","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059085","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059103","level":"info","event":"driverMemory            512m","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059119","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059136","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059153","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059169","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059185","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059226","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059243","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059260","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059276","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059292","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059308","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059324","level":"info","event":"primaryResource         file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059341","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059371","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059392","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059408","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059426","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059443","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059459","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059475","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059492","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059509","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059525","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059539","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059555","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059571","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059586","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059602","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059620","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059636","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059651","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059666","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059683","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.059716","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.135278","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.178777","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.178855","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.181170","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.181238","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.181269","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.181293","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.181566","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-4c105cd1-4233-4b94-b584-07c39301a47a;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:45.181608","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:49.562485","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:51.549482","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:53.501207","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:56.000343","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:56.415241","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:56.841992","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:57:57.257264","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:01.850729","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:02.065700","level":"info","event":"downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:02.712399","level":"info","event":"[SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.3.4!hadoop-aws.jar (851ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:02.920969","level":"info","event":"downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.520/aws-java-sdk-bundle-1.12.520.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:25.000991","level":"info","event":"[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.12.520!aws-java-sdk-bundle.jar (22287ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:25.206059","level":"info","event":"downloading https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.12/3.5.0/spark-avro_2.12-3.5.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:25.422902","level":"info","event":"[SUCCESSFUL ] org.apache.spark#spark-avro_2.12;3.5.0!spark-avro_2.12.jar (421ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:25.627926","level":"info","event":"downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.1.0/delta-spark_2.12-3.1.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:26.143946","level":"info","event":"[SUCCESSFUL ] io.delta#delta-spark_2.12;3.1.0!delta-spark_2.12.jar (720ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:26.350043","level":"info","event":"downloading https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:26.576948","level":"info","event":"[SUCCESSFUL ] org.wildfly.openssl#wildfly-openssl;1.0.7.Final!wildfly-openssl.jar (432ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:26.783003","level":"info","event":"downloading https://repo1.maven.org/maven2/org/tukaani/xz/1.9/xz-1.9.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:26.997959","level":"info","event":"[SUCCESSFUL ] org.tukaani#xz;1.9!xz.jar (420ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.202300","level":"info","event":"downloading https://repo1.maven.org/maven2/io/delta/delta-storage/3.1.0/delta-storage-3.1.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.408610","level":"info","event":"[SUCCESSFUL ] io.delta#delta-storage;3.1.0!delta-storage.jar (410ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.612877","level":"info","event":"downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.9.3/antlr4-runtime-4.9.3.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.837970","level":"info","event":"[SUCCESSFUL ] org.antlr#antlr4-runtime;4.9.3!antlr4-runtime.jar (428ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838160","level":"info","event":":: resolution report :: resolve 16679ms :: artifacts dl 25978ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838228","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838259","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838282","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838301","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838319","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838338","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838362","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838385","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838403","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838420","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838451","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838471","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838487","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838502","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838518","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838536","level":"info","event":"|      default     |   9   |   8   |   8   |   1   ||   8   |   8   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.838553","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.840633","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-4c105cd1-4233-4b94-b584-07c39301a47a","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:27.840707","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.180232","level":"info","event":"8 artifacts copied, 0 already retrieved (337604kB/339ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.494353","level":"info","event":"25/07/31 02:58:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.613049","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.613136","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.613191","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.613219","level":"info","event":"file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.613262","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614415","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614459","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614483","level":"info","event":"(spark.app.submitTime,1753930708605)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614524","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614563","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614601","level":"info","event":"(spark.executor.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614642","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614686","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614720","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614743","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614760","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614798","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614829","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614848","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614866","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614883","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614901","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614936","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.614983","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615016","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615039","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615056","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615072","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615089","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615121","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615149","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615166","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615196","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:28.615216","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.386073","level":"info","event":"INFO:__main__:Starting Spark job...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.452721","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.452828","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.452978","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.464325","level":"info","event":"25/07/31 02:58:29 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.464426","level":"info","event":"25/07/31 02:58:29 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.464482","level":"info","event":"25/07/31 02:58:29 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.464636","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.478325","level":"info","event":"25/07/31 02:58:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.482181","level":"info","event":"25/07/31 02:58:29 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.482853","level":"info","event":"25/07/31 02:58:29 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.521119","level":"info","event":"25/07/31 02:58:29 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.521228","level":"info","event":"25/07/31 02:58:29 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.521264","level":"info","event":"25/07/31 02:58:29 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.521408","level":"info","event":"25/07/31 02:58:29 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.521603","level":"info","event":"25/07/31 02:58:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.641656","level":"info","event":"25/07/31 02:58:29 INFO Utils: Successfully started service 'sparkDriver' on port 40435.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.664133","level":"info","event":"25/07/31 02:58:29 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.684621","level":"info","event":"25/07/31 02:58:29 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.692272","level":"info","event":"25/07/31 02:58:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.692417","level":"info","event":"25/07/31 02:58:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.694302","level":"info","event":"25/07/31 02:58:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.705467","level":"info","event":"25/07/31 02:58:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b084ada8-55b3-47b7-a25a-724e6f7a4b69","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.711761","level":"info","event":"25/07/31 02:58:29 INFO MemoryStore: MemoryStore started with capacity 127.2 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.719077","level":"info","event":"25/07/31 02:58:29 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.785802","level":"info","event":"25/07/31 02:58:29 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.817037","level":"info","event":"25/07/31 02:58:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.839963","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://05a2169a22bf:40435/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.840068","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://05a2169a22bf:40435/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.840096","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://05a2169a22bf:40435/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.840116","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://05a2169a22bf:40435/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.840136","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://05a2169a22bf:40435/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.840195","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://05a2169a22bf:40435/jars/org.tukaani_xz-1.9.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.840290","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://05a2169a22bf:40435/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.840393","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://05a2169a22bf:40435/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.842098","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://05a2169a22bf:40435/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.842639","level":"info","event":"25/07/31 02:58:29 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/userFiles-b6a29402-4c5e-4fb7-92b7-9dd87e26dbc9/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.853181","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://05a2169a22bf:40435/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.853304","level":"info","event":"25/07/31 02:58:29 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/userFiles-b6a29402-4c5e-4fb7-92b7-9dd87e26dbc9/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.990879","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://05a2169a22bf:40435/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.990967","level":"info","event":"25/07/31 02:58:29 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/userFiles-b6a29402-4c5e-4fb7-92b7-9dd87e26dbc9/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.993811","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://05a2169a22bf:40435/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.993895","level":"info","event":"25/07/31 02:58:29 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/userFiles-b6a29402-4c5e-4fb7-92b7-9dd87e26dbc9/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.997537","level":"info","event":"25/07/31 02:58:29 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://05a2169a22bf:40435/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:29.997626","level":"info","event":"25/07/31 02:58:29 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/userFiles-b6a29402-4c5e-4fb7-92b7-9dd87e26dbc9/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.000349","level":"info","event":"25/07/31 02:58:30 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://05a2169a22bf:40435/files/org.tukaani_xz-1.9.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.000412","level":"info","event":"25/07/31 02:58:30 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/userFiles-b6a29402-4c5e-4fb7-92b7-9dd87e26dbc9/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.002345","level":"info","event":"25/07/31 02:58:30 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://05a2169a22bf:40435/files/io.delta_delta-storage-3.1.0.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.002417","level":"info","event":"25/07/31 02:58:30 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/userFiles-b6a29402-4c5e-4fb7-92b7-9dd87e26dbc9/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.004386","level":"info","event":"25/07/31 02:58:30 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://05a2169a22bf:40435/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753930709448","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.004449","level":"info","event":"25/07/31 02:58:30 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/userFiles-b6a29402-4c5e-4fb7-92b7-9dd87e26dbc9/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.046860","level":"info","event":"25/07/31 02:58:30 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.076596","level":"info","event":"25/07/31 02:58:30 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.6:7077 after 13 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.372545","level":"info","event":"25/07/31 02:58:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250731025830-0000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.377407","level":"info","event":"25/07/31 02:58:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32947.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.377480","level":"info","event":"25/07/31 02:58:30 INFO NettyBlockTransferService: Server created on 05a2169a22bf:32947","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.378841","level":"info","event":"25/07/31 02:58:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.382351","level":"info","event":"25/07/31 02:58:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 05a2169a22bf, 32947, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.384033","level":"info","event":"25/07/31 02:58:30 INFO BlockManagerMasterEndpoint: Registering block manager 05a2169a22bf:32947 with 127.2 MiB RAM, BlockManagerId(driver, 05a2169a22bf, 32947, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.385140","level":"info","event":"25/07/31 02:58:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 05a2169a22bf, 32947, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.385750","level":"info","event":"25/07/31 02:58:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 05a2169a22bf, 32947, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.404384","level":"info","event":"25/07/31 02:58:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250731025830-0000/0 on worker-20250731025506-172.18.0.8-40691 (172.18.0.8:40691) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.405138","level":"info","event":"25/07/31 02:58:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250731025830-0000/0 on hostPort 172.18.0.8:40691 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.405224","level":"info","event":"25/07/31 02:58:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250731025830-0000/1 on worker-20250731025506-172.18.0.8-40691 (172.18.0.8:40691) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.405470","level":"info","event":"25/07/31 02:58:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250731025830-0000/1 on hostPort 172.18.0.8:40691 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.502380","level":"info","event":"25/07/31 02:58:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.533293","level":"info","event":"25/07/31 02:58:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731025830-0000/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.533504","level":"info","event":"25/07/31 02:58:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731025830-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.682077","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.682163","level":"info","event":"INFO:__main__:Reading parquet data from s3a://activefence-bucket/bbc_tech/bronze","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.686019","level":"info","event":"25/07/31 02:58:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:30.687032","level":"info","event":"25/07/31 02:58:30 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:31.293400","level":"info","event":"25/07/31 02:58:31 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:31.300012","level":"info","event":"25/07/31 02:58:31 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:31.300111","level":"info","event":"25/07/31 02:58:31 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:31.749539","level":"info","event":"25/07/31 02:58:31 INFO InMemoryFileIndex: It took 38 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.019088","level":"info","event":"25/07/31 02:58:32 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.030458","level":"info","event":"25/07/31 02:58:32 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.030534","level":"info","event":"25/07/31 02:58:32 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.030559","level":"info","event":"25/07/31 02:58:32 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.030580","level":"info","event":"25/07/31 02:58:32 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.033097","level":"info","event":"25/07/31 02:58:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.034290","level":"info","event":"25/07/31 02:58:32 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:46094) with ID 1,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.035196","level":"info","event":"25/07/31 02:58:32 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:46106) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.073915","level":"info","event":"25/07/31 02:58:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42051 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.8, 42051, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.074711","level":"info","event":"25/07/31 02:58:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:33079 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.8, 33079, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.076874","level":"info","event":"25/07/31 02:58:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 108.3 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.111021","level":"info","event":"25/07/31 02:58:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.112210","level":"info","event":"25/07/31 02:58:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 05a2169a22bf:32947 (size: 39.3 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.114545","level":"info","event":"25/07/31 02:58:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.125378","level":"info","event":"25/07/31 02:58:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:32.126077","level":"info","event":"25/07/31 02:58:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:34.797906","level":"info","event":"25/07/31 02:58:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 10672 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:34.957308","level":"info","event":"25/07/31 02:58:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:33079 (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:35.821901","level":"info","event":"25/07/31 02:58:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1038 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:35.823086","level":"info","event":"25/07/31 02:58:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:35.826764","level":"info","event":"25/07/31 02:58:35 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 3.777 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:35.827963","level":"info","event":"25/07/31 02:58:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:35.828148","level":"info","event":"25/07/31 02:58:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:35.829024","level":"info","event":"25/07/31 02:58:35 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 3.810982 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.001014","level":"info","event":"25/07/31 02:58:36 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 05a2169a22bf:32947 in memory (size: 39.3 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.004264","level":"info","event":"25/07/31 02:58:36 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.8:33079 in memory (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.220763","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.220855","level":"info","event":"|-- article_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.220883","level":"info","event":"|-- title: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.220904","level":"info","event":"|-- pub_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.220923","level":"info","event":"|-- summary: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.220940","level":"info","event":"|-- load_timestamp: timestamp_ntz (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.220957","level":"info","event":"|-- year_month: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.220977","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.221000","level":"info","event":"INFO:__main__:Input dataframe schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.221019","level":"info","event":"None","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.465204","level":"info","event":"25/07/31 02:58:36 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.465791","level":"info","event":"25/07/31 02:58:36 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.466165","level":"info","event":"25/07/31 02:58:36 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.620781","level":"info","event":"25/07/31 02:58:36 INFO CodeGenerator: Code generated in 73.474417 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.636893","level":"info","event":"25/07/31 02:58:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.4 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.642930","level":"info","event":"25/07/31 02:58:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.643350","level":"info","event":"25/07/31 02:58:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 05a2169a22bf:32947 (size: 36.8 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.643946","level":"info","event":"25/07/31 02:58:36 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.651443","level":"info","event":"25/07/31 02:58:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.681279","level":"info","event":"25/07/31 02:58:36 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.683797","level":"info","event":"25/07/31 02:58:36 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.683916","level":"info","event":"25/07/31 02:58:36 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.684037","level":"info","event":"25/07/31 02:58:36 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.684267","level":"info","event":"25/07/31 02:58:36 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.684723","level":"info","event":"25/07/31 02:58:36 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.699761","level":"info","event":"25/07/31 02:58:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.700768","level":"info","event":"25/07/31 02:58:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.701163","level":"info","event":"25/07/31 02:58:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 05a2169a22bf:32947 (size: 7.9 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.701511","level":"info","event":"25/07/31 02:58:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.702357","level":"info","event":"25/07/31 02:58:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.702423","level":"info","event":"25/07/31 02:58:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.705725","level":"info","event":"25/07/31 02:58:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11237 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.728378","level":"info","event":"25/07/31 02:58:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.8:33079 (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:36.941552","level":"info","event":"25/07/31 02:58:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:33079 (size: 36.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.059359","level":"info","event":"25/07/31 02:58:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 357 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.059443","level":"info","event":"25/07/31 02:58:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.061104","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.374 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.061297","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.061499","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.061586","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.061671","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.080450","level":"info","event":"25/07/31 02:58:37 INFO CodeGenerator: Code generated in 6.175958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.099802","level":"info","event":"25/07/31 02:58:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.100890","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.100950","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.100976","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.101055","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.101349","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.104897","level":"info","event":"25/07/31 02:58:37 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.105842","level":"info","event":"25/07/31 02:58:37 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.106107","level":"info","event":"25/07/31 02:58:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 05a2169a22bf:32947 (size: 5.9 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.106409","level":"info","event":"25/07/31 02:58:37 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.106682","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.106741","level":"info","event":"25/07/31 02:58:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.108777","level":"info","event":"25/07/31 02:58:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.195585","level":"info","event":"25/07/31 02:58:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:42051 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.294453","level":"info","event":"25/07/31 02:58:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:46106","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.514317","level":"info","event":"25/07/31 02:58:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 406 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.514416","level":"info","event":"25/07/31 02:58:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.514857","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.410 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.514993","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.515024","level":"info","event":"25/07/31 02:58:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.515295","level":"info","event":"25/07/31 02:58:37 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.415419 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.519266","level":"info","event":"INFO:__main__:Number of rows read from bronze layer: 61","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.673179","level":"info","event":"25/07/31 02:58:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 05a2169a22bf:32947 in memory (size: 7.9 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.676693","level":"info","event":"25/07/31 02:58:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.8:33079 in memory (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.680494","level":"info","event":"25/07/31 02:58:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 05a2169a22bf:32947 in memory (size: 5.9 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.684533","level":"info","event":"25/07/31 02:58:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:42051 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.687507","level":"info","event":"25/07/31 02:58:37 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:37.702202","level":"info","event":"25/07/31 02:58:37 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.132205","level":"info","event":"25/07/31 02:58:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 05a2169a22bf:32947 in memory (size: 36.8 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.132367","level":"info","event":"25/07/31 02:58:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:33079 in memory (size: 36.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.183971","level":"info","event":"25/07/31 02:58:38 INFO InitialSnapshot: [tableId=02d87b46-6f06-4eee-9e45-e117e551eaae] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(e74acac4-80b8-4080-b3e9-05eeeb388fbe,null,null,Format(parquet,Map()),null,List(),Map(),Some(1753930718181)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@784b98f,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.218964","level":"info","event":"25/07/31 02:58:38 INFO DeltaLog: No delta log found for the Delta table at s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.219309","level":"info","event":"25/07/31 02:58:38 INFO InitialSnapshot: [tableId=e74acac4-80b8-4080-b3e9-05eeeb388fbe] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(ae0736e2-9e0b-437c-a3b7-88bb39be67a3,null,null,Format(parquet,Map()),null,List(),Map(),Some(1753930718219)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@784b98f,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.257397","level":"info","event":"25/07/31 02:58:38 INFO OptimisticTransaction: [tableId=ae0736e2,txnId=6385e4a4] Updated metadata from - to Metadata(934fe67a-3cdb-4bd9-9244-c2df2ca4d973,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930718246))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.443232","level":"info","event":"25/07/31 02:58:38 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.445557","level":"info","event":"25/07/31 02:58:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(article_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.445614","level":"info","event":"25/07/31 02:58:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(article_id#0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.473415","level":"info","event":"25/07/31 02:58:38 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.511493","level":"info","event":"25/07/31 02:58:38 INFO CodeGenerator: Code generated in 23.454959 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.513855","level":"info","event":"25/07/31 02:58:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 208.0 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.520845","level":"info","event":"25/07/31 02:58:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.521290","level":"info","event":"25/07/31 02:58:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 05a2169a22bf:32947 (size: 37.0 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.521842","level":"info","event":"25/07/31 02:58:38 INFO SparkContext: Created broadcast 4 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.522638","level":"info","event":"25/07/31 02:58:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.572450","level":"info","event":"25/07/31 02:58:38 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.572999","level":"info","event":"25/07/31 02:58:38 INFO DAGScheduler: Got job 3 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.573051","level":"info","event":"25/07/31 02:58:38 INFO DAGScheduler: Final stage: ResultStage 4 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.573077","level":"info","event":"25/07/31 02:58:38 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.573117","level":"info","event":"25/07/31 02:58:38 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.573415","level":"info","event":"25/07/31 02:58:38 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.583173","level":"info","event":"25/07/31 02:58:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 358.2 KiB, free 126.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.584248","level":"info","event":"25/07/31 02:58:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 127.8 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.584618","level":"info","event":"25/07/31 02:58:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 05a2169a22bf:32947 (size: 127.8 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.584918","level":"info","event":"25/07/31 02:58:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.585168","level":"info","event":"25/07/31 02:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.585227","level":"info","event":"25/07/31 02:58:38 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.585936","level":"info","event":"25/07/31 02:58:38 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11248 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:38.598224","level":"info","event":"25/07/31 02:58:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:33079 (size: 127.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:39.266119","level":"info","event":"25/07/31 02:58:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:33079 (size: 37.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.022321","level":"info","event":"25/07/31 02:58:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 1436 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.022460","level":"info","event":"25/07/31 02:58:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.023070","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: ResultStage 4 (save at NativeMethodAccessorImpl.java:0) finished in 1.449 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.023263","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.023350","level":"info","event":"25/07/31 02:58:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.024433","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Job 3 finished: save at NativeMethodAccessorImpl.java:0, took 1.451724 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.025296","level":"info","event":"25/07/31 02:58:40 INFO DeltaFileFormatWriter: Start to commit write Job 03b55962-05c5-4dea-9efb-f47b3d382191.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.026062","level":"info","event":"25/07/31 02:58:40 INFO DeltaFileFormatWriter: Write Job 03b55962-05c5-4dea-9efb-f47b3d382191 committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.027761","level":"info","event":"25/07/31 02:58:40 INFO DeltaFileFormatWriter: Finished processing stats for write job 03b55962-05c5-4dea-9efb-f47b3d382191.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.410577","level":"info","event":"25/07/31 02:58:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 05a2169a22bf:32947 in memory (size: 127.8 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.415096","level":"info","event":"25/07/31 02:58:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:33079 in memory (size: 127.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.547280","level":"info","event":"25/07/31 02:58:40 INFO CodeGenerator: Code generated in 108.188875 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.563079","level":"info","event":"25/07/31 02:58:40 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.563426","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Job 4 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000197 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.596402","level":"info","event":"25/07/31 02:58:40 INFO OptimisticTransaction: [tableId=ae0736e2,txnId=6385e4a4] Attempting to commit version 0 with 4 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.720108","level":"info","event":"25/07/31 02:58:40 INFO DeltaLog: Creating a new snapshot v0 for commit version 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.720196","level":"info","event":"25/07/31 02:58:40 INFO DeltaLog: Loading version 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.726158","level":"info","event":"25/07/31 02:58:40 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1995)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.770190","level":"info","event":"25/07/31 02:58:40 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.770447","level":"info","event":"25/07/31 02:58:40 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.770606","level":"info","event":"25/07/31 02:58:40 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#336.minReaderVersion) OR isnotnull(metaData#335.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.785538","level":"info","event":"25/07/31 02:58:40 INFO CodeGenerator: Code generated in 9.116042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.788442","level":"info","event":"25/07/31 02:58:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 206.2 KiB, free 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.791614","level":"info","event":"25/07/31 02:58:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.791902","level":"info","event":"25/07/31 02:58:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 05a2169a22bf:32947 (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.792428","level":"info","event":"25/07/31 02:58:40 INFO SparkContext: Created broadcast 6 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.800282","level":"info","event":"25/07/31 02:58:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.824597","level":"info","event":"25/07/31 02:58:40 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.825097","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Got job 5 (toString at String.java:4220) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.825153","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Final stage: ResultStage 5 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.825181","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.825204","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.825503","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[19] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.826582","level":"info","event":"25/07/31 02:58:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.0 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.827244","level":"info","event":"25/07/31 02:58:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.827604","level":"info","event":"25/07/31 02:58:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 05a2169a22bf:32947 (size: 13.7 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.827906","level":"info","event":"25/07/31 02:58:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.828125","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.828163","level":"info","event":"25/07/31 02:58:40 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.828948","level":"info","event":"25/07/31 02:58:40 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11166 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.836056","level":"info","event":"25/07/31 02:58:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:33079 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.907989","level":"info","event":"25/07/31 02:58:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:33079 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.939513","level":"info","event":"25/07/31 02:58:40 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 111 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.939606","level":"info","event":"25/07/31 02:58:40 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.940038","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: ResultStage 5 (toString at String.java:4220) finished in 0.114 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.940109","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.940139","level":"info","event":"25/07/31 02:58:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.940323","level":"info","event":"25/07/31 02:58:40 INFO DAGScheduler: Job 5 finished: toString at String.java:4220, took 0.115707 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.961868","level":"info","event":"25/07/31 02:58:40 INFO CodeGenerator: Code generated in 12.059625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.965170","level":"info","event":"25/07/31 02:58:40 INFO Snapshot: [tableId=ae0736e2-9e0b-437c-a3b7-88bb39be67a3] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(934fe67a-3cdb-4bd9-9244-c2df2ca4d973,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930718246)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1753930720698; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=d47aaa5e0705bd3da0aee32518e8b6b8 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@784b98f,1753930720698), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.966197","level":"info","event":"25/07/31 02:58:40 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(934fe67a-3cdb-4bd9-9244-c2df2ca4d973,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930718246)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1753930720698; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=d47aaa5e0705bd3da0aee32518e8b6b8 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@784b98f,1753930720698), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.969290","level":"info","event":"25/07/31 02:58:40 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Compute snapshot for version: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.974899","level":"info","event":"25/07/31 02:58:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 205.9 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.978292","level":"info","event":"25/07/31 02:58:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 126.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.978596","level":"info","event":"25/07/31 02:58:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 05a2169a22bf:32947 (size: 36.4 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:40.979087","level":"info","event":"25/07/31 02:58:40 INFO SparkContext: Created broadcast 8 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.003566","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 05a2169a22bf:32947 in memory (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.005308","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.8:33079 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.008648","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 05a2169a22bf:32947 in memory (size: 13.7 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.010100","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.8:33079 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.153735","level":"info","event":"25/07/31 02:58:41 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.153864","level":"info","event":"25/07/31 02:58:41 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.153896","level":"info","event":"25/07/31 02:58:41 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.161603","level":"info","event":"25/07/31 02:58:41 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.214717","level":"info","event":"25/07/31 02:58:41 INFO CodeGenerator: Code generated in 31.038541 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.215992","level":"info","event":"25/07/31 02:58:41 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 206.2 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.218939","level":"info","event":"25/07/31 02:58:41 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.219263","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 05a2169a22bf:32947 (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.219789","level":"info","event":"25/07/31 02:58:41 INFO SparkContext: Created broadcast 9 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.220248","level":"info","event":"25/07/31 02:58:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.224719","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Registering RDD 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.224875","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Got map stage job 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.224908","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Final stage: ShuffleMapStage 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.224928","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.225005","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.225263","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.227254","level":"info","event":"25/07/31 02:58:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 105.6 KiB, free 126.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.227968","level":"info","event":"25/07/31 02:58:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 126.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.228237","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 05a2169a22bf:32947 (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.228458","level":"info","event":"25/07/31 02:58:41 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.228663","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.228691","level":"info","event":"25/07/31 02:58:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.229302","level":"info","event":"25/07/31 02:58:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11155 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.235625","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:33079 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.362649","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:33079 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.383561","level":"info","event":"25/07/31 02:58:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 154 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.383629","level":"info","event":"25/07/31 02:58:41 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.384374","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: ShuffleMapStage 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.159 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.384448","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.384476","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.384496","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.384517","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.417644","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 05a2169a22bf:32947 in memory (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.421529","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.8:33079 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.527548","level":"info","event":"25/07/31 02:58:41 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.527642","level":"info","event":"25/07/31 02:58:41 INFO CodeGenerator: Code generated in 93.172625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.556934","level":"info","event":"25/07/31 02:58:41 INFO CodeGenerator: Code generated in 19.069333 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.650557","level":"info","event":"25/07/31 02:58:41 INFO CodeGenerator: Code generated in 17.599833 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.653516","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Registering RDD 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.653588","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Got map stage job 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.653618","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Final stage: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.653641","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.654761","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.655012","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.676817","level":"info","event":"25/07/31 02:58:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 603.4 KiB, free 125.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.678231","level":"info","event":"25/07/31 02:58:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 125.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.678652","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 05a2169a22bf:32947 (size: 138.2 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.679035","level":"info","event":"25/07/31 02:58:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.679360","level":"info","event":"25/07/31 02:58:41 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.679412","level":"info","event":"25/07/31 02:58:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.680425","level":"info","event":"25/07/31 02:58:41 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 6) (172.18.0.8, executor 1, partition 6, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.680819","level":"info","event":"25/07/31 02:58:41 INFO TaskSetManager: Starting task 42.0 in stage 8.0 (TID 7) (172.18.0.8, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.696177","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:33079 (size: 138.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.698652","level":"info","event":"25/07/31 02:58:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:42051 (size: 138.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.771865","level":"info","event":"25/07/31 02:58:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:46094","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:41.960389","level":"info","event":"25/07/31 02:58:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:46106","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.021377","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_6 in memory on 172.18.0.8:33079 (size: 691.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.108451","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.108974","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 6) in 428 ms on 172.18.0.8 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.150521","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_0 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.168610","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 9) (172.18.0.8, executor 1, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.169000","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 61 ms on 172.18.0.8 (executor 1) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.197694","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_1 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.216849","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 10) (172.18.0.8, executor 1, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.217315","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 9) in 49 ms on 172.18.0.8 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.250992","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_2 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.269796","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 11) (172.18.0.8, executor 1, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.270113","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 10) in 53 ms on 172.18.0.8 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.320430","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_3 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.337898","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 12) (172.18.0.8, executor 1, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.338409","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 11) in 69 ms on 172.18.0.8 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.366272","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_4 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.383806","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 13) (172.18.0.8, executor 1, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.384463","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 12) in 47 ms on 172.18.0.8 (executor 1) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.420319","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_5 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.436935","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 14) (172.18.0.8, executor 1, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.437366","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 13) in 54 ms on 172.18.0.8 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.471618","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_7 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.487523","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 15) (172.18.0.8, executor 1, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.487941","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 14) in 51 ms on 172.18.0.8 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.511074","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_8 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.524441","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 16) (172.18.0.8, executor 1, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.524793","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 15) in 37 ms on 172.18.0.8 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.548398","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_9 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.560752","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 17) (172.18.0.8, executor 1, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.560996","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 16) in 36 ms on 172.18.0.8 (executor 1) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.594954","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_10 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.607940","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 18) (172.18.0.8, executor 1, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.608349","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 17) in 48 ms on 172.18.0.8 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.633799","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_11 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.646488","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 19) (172.18.0.8, executor 1, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.646693","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 18) in 39 ms on 172.18.0.8 (executor 1) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.667596","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_12 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.680160","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 20) (172.18.0.8, executor 1, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.680481","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 19) in 34 ms on 172.18.0.8 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.699642","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_13 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.710142","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 21) (172.18.0.8, executor 1, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.710490","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 20) in 31 ms on 172.18.0.8 (executor 1) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.732196","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_14 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.746536","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 22) (172.18.0.8, executor 1, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.746889","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 21) in 37 ms on 172.18.0.8 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.773999","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_15 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.787299","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 23) (172.18.0.8, executor 1, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.787864","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 22) in 41 ms on 172.18.0.8 (executor 1) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.813080","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_16 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.824615","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 24) (172.18.0.8, executor 1, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.825148","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 23) in 38 ms on 172.18.0.8 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.847923","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_17 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.860831","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 25) (172.18.0.8, executor 1, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.861132","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 24) in 36 ms on 172.18.0.8 (executor 1) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.884987","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_18 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.896518","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 26) (172.18.0.8, executor 1, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.896999","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 25) in 36 ms on 172.18.0.8 (executor 1) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.920925","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_19 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.934896","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 20.0 in stage 8.0 (TID 27) (172.18.0.8, executor 1, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.935002","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 26) in 39 ms on 172.18.0.8 (executor 1) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.965425","level":"info","event":"25/07/31 02:58:42 INFO BlockManagerInfo: Added rdd_30_20 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.979117","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 28) (172.18.0.8, executor 1, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:42.979437","level":"info","event":"25/07/31 02:58:42 INFO TaskSetManager: Finished task 20.0 in stage 8.0 (TID 27) in 45 ms on 172.18.0.8 (executor 1) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.004862","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_21 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.015285","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 22.0 in stage 8.0 (TID 29) (172.18.0.8, executor 1, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.015731","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 28) in 37 ms on 172.18.0.8 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.028797","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_42 in memory on 172.18.0.8:42051 (size: 562.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.039383","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_22 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.050551","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 23.0 in stage 8.0 (TID 30) (172.18.0.8, executor 1, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.050853","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 22.0 in stage 8.0 (TID 29) in 36 ms on 172.18.0.8 (executor 1) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.070955","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_23 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.081829","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 24.0 in stage 8.0 (TID 31) (172.18.0.8, executor 1, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.082260","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 23.0 in stage 8.0 (TID 30) in 31 ms on 172.18.0.8 (executor 1) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.103059","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_24 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.112305","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 25.0 in stage 8.0 (TID 32) (172.18.0.8, executor 1, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.112509","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 24.0 in stage 8.0 (TID 31) in 31 ms on 172.18.0.8 (executor 1) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.133580","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_25 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.144196","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 26.0 in stage 8.0 (TID 33) (172.18.0.8, executor 1, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.144839","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 25.0 in stage 8.0 (TID 32) in 33 ms on 172.18.0.8 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.163806","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_26 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.172406","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 27.0 in stage 8.0 (TID 34) (172.18.0.8, executor 1, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.172661","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 26.0 in stage 8.0 (TID 33) in 29 ms on 172.18.0.8 (executor 1) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.188437","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_27 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.196212","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 28.0 in stage 8.0 (TID 35) (172.18.0.8, executor 1, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.196460","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 27.0 in stage 8.0 (TID 34) in 24 ms on 172.18.0.8 (executor 1) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.212998","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_28 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.223408","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 29.0 in stage 8.0 (TID 36) (172.18.0.8, executor 1, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.223971","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 28.0 in stage 8.0 (TID 35) in 28 ms on 172.18.0.8 (executor 1) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.238903","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_29 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.246015","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 30.0 in stage 8.0 (TID 37) (172.18.0.8, executor 1, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.246460","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 29.0 in stage 8.0 (TID 36) in 24 ms on 172.18.0.8 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.261252","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_30 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.269314","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 31.0 in stage 8.0 (TID 38) (172.18.0.8, executor 1, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.269562","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 30.0 in stage 8.0 (TID 37) in 24 ms on 172.18.0.8 (executor 1) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.284556","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_31 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.293356","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 32.0 in stage 8.0 (TID 39) (172.18.0.8, executor 1, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.293677","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 31.0 in stage 8.0 (TID 38) in 25 ms on 172.18.0.8 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.309373","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_32 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.317873","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 33.0 in stage 8.0 (TID 40) (172.18.0.8, executor 1, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.318369","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 32.0 in stage 8.0 (TID 39) in 26 ms on 172.18.0.8 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.334054","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_33 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.344205","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 34.0 in stage 8.0 (TID 41) (172.18.0.8, executor 1, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.344443","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 33.0 in stage 8.0 (TID 40) in 27 ms on 172.18.0.8 (executor 1) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.360620","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_34 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.361228","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 35.0 in stage 8.0 (TID 42) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.361618","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 42.0 in stage 8.0 (TID 7) in 1681 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.370242","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 36.0 in stage 8.0 (TID 43) (172.18.0.8, executor 1, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.370640","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 34.0 in stage 8.0 (TID 41) in 27 ms on 172.18.0.8 (executor 1) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.387115","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_36 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.394553","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 37.0 in stage 8.0 (TID 44) (172.18.0.8, executor 1, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.394820","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 36.0 in stage 8.0 (TID 43) in 25 ms on 172.18.0.8 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.408987","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_37 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.413206","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_35 in memory on 172.18.0.8:42051 (size: 46.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.418229","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 38.0 in stage 8.0 (TID 45) (172.18.0.8, executor 1, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.418595","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 37.0 in stage 8.0 (TID 44) in 24 ms on 172.18.0.8 (executor 1) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.438819","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_38 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.439785","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 39.0 in stage 8.0 (TID 46) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.442784","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 35.0 in stage 8.0 (TID 42) in 82 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.455263","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 40.0 in stage 8.0 (TID 47) (172.18.0.8, executor 1, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.456111","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 38.0 in stage 8.0 (TID 45) in 38 ms on 172.18.0.8 (executor 1) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.470681","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_40 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.477470","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_39 in memory on 172.18.0.8:42051 (size: 46.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.478530","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 41.0 in stage 8.0 (TID 48) (172.18.0.8, executor 1, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.478893","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 40.0 in stage 8.0 (TID 47) in 24 ms on 172.18.0.8 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.493569","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_41 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.501479","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 43.0 in stage 8.0 (TID 49) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.501808","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 39.0 in stage 8.0 (TID 46) in 62 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.502205","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 44.0 in stage 8.0 (TID 50) (172.18.0.8, executor 1, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.502515","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 41.0 in stage 8.0 (TID 48) in 24 ms on 172.18.0.8 (executor 1) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.516614","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_44 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.527053","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 45.0 in stage 8.0 (TID 51) (172.18.0.8, executor 1, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.527317","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 44.0 in stage 8.0 (TID 50) in 25 ms on 172.18.0.8 (executor 1) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.533649","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_43 in memory on 172.18.0.8:42051 (size: 46.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.542051","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_45 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.550324","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 46.0 in stage 8.0 (TID 52) (172.18.0.8, executor 1, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.550652","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 45.0 in stage 8.0 (TID 51) in 24 ms on 172.18.0.8 (executor 1) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.553431","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 47.0 in stage 8.0 (TID 53) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.553896","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 43.0 in stage 8.0 (TID 49) in 52 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.565211","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_46 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.572666","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 48.0 in stage 8.0 (TID 54) (172.18.0.8, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.573028","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 46.0 in stage 8.0 (TID 52) in 23 ms on 172.18.0.8 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.586249","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_48 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.587406","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_47 in memory on 172.18.0.8:42051 (size: 46.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.593926","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 49.0 in stage 8.0 (TID 55) (172.18.0.8, executor 1, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.594289","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 48.0 in stage 8.0 (TID 54) in 22 ms on 172.18.0.8 (executor 1) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.605590","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 47.0 in stage 8.0 (TID 53) in 52 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.607077","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added rdd_30_49 in memory on 172.18.0.8:33079 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.613898","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 49.0 in stage 8.0 (TID 55) in 20 ms on 172.18.0.8 (executor 1) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.613972","level":"info","event":"25/07/31 02:58:43 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.614225","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.956 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.614259","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.614281","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.614302","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.614320","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.629836","level":"info","event":"25/07/31 02:58:43 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.630630","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: Got job 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.630685","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: Final stage: ResultStage 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.630709","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.630730","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.630958","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[36] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.633907","level":"info","event":"25/07/31 02:58:43 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 534.7 KiB, free 125.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.635132","level":"info","event":"25/07/31 02:58:43 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 124.6 KiB, free 125.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.635423","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 05a2169a22bf:32947 (size: 124.6 KiB, free: 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.635770","level":"info","event":"25/07/31 02:58:43 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.636100","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[36] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.636155","level":"info","event":"25/07/31 02:58:43 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.636879","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 56) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.643918","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:42051 (size: 124.6 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.654000","level":"info","event":"25/07/31 02:58:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:46106","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.694620","level":"info","event":"25/07/31 02:58:43 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 56) in 58 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.694706","level":"info","event":"25/07/31 02:58:43 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.694969","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: ResultStage 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.063 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.695085","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.695114","level":"info","event":"25/07/31 02:58:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.695270","level":"info","event":"25/07/31 02:58:43 INFO DAGScheduler: Job 8 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.065460 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.720609","level":"info","event":"25/07/31 02:58:43 INFO CodeGenerator: Code generated in 16.65075 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.721746","level":"info","event":"25/07/31 02:58:43 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.733408","level":"info","event":"25/07/31 02:58:43 INFO OptimisticTransaction: [tableId=ae0736e2,txnId=6385e4a4] Committed delta #0 to s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.736463","level":"info","event":"INFO:__main__:Data cleaned and loaded to silver layer!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.736762","level":"info","event":"25/07/31 02:58:43 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.754664","level":"info","event":"25/07/31 02:58:43 INFO SparkUI: Stopped Spark web UI at http://05a2169a22bf:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.756356","level":"info","event":"25/07/31 02:58:43 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.756528","level":"info","event":"25/07/31 02:58:43 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.769743","level":"info","event":"25/07/31 02:58:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.785446","level":"info","event":"25/07/31 02:58:43 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.785542","level":"info","event":"25/07/31 02:58:43 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.789808","level":"info","event":"25/07/31 02:58:43 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.791529","level":"info","event":"25/07/31 02:58:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:43.803715","level":"info","event":"25/07/31 02:58:43 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.058669","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.058801","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.099720","level":"info","event":"25/07/31 02:58:44 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.099922","level":"info","event":"25/07/31 02:58:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a/pyspark-0fe71ffc-619b-49fa-bebd-b1c16c32a7ed","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.101770","level":"info","event":"25/07/31 02:58:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-85400d16-b752-42d9-81e7-d2a95402c6ca","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.103309","level":"info","event":"25/07/31 02:58:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-ff64ae65-ebe3-446d-8e48-43284cda697a","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.109506","level":"info","event":"25/07/31 02:58:44 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.109649","level":"info","event":"25/07/31 02:58:44 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:44.109730","level":"info","event":"25/07/31 02:58:44 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
