{"timestamp":"2025-07-31T02:58:44.526510","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-31T02:58:44.526953","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-31T02:58:48.802060","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-31T02:58:48.802835","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 1 --executor-memory 1g --driver-memory 512m --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.613884","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658020","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658098","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658127","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658150","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658170","level":"info","event":"executorMemory          1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658188","level":"info","event":"executorCores           1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658206","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658225","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658242","level":"info","event":"driverMemory            512m","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658260","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658277","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658296","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658313","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658359","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658383","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658400","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658417","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658434","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658451","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658468","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658483","level":"info","event":"primaryResource         file:/opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658501","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658518","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658534","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658551","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658583","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658600","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658617","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658634","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658652","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658668","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658685","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658702","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658719","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658735","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658751","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658767","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658784","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658800","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658817","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658834","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658851","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.658868","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.736849","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.773158","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.773242","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.775010","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.775063","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.775089","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.775222","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.775665","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-72f2cabf-ac5f-4843-8c44-0f540217995e;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.775710","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.854356","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.868519","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.876997","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.892461","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.899255","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.908386","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.914884","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.923405","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934400","level":"info","event":":: resolution report :: resolve 154ms :: artifacts dl 5ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934467","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934491","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934515","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934534","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934555","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934574","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934616","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934635","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934653","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934821","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934848","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934866","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934884","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934901","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934919","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934954","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.934977","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.937485","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-72f2cabf-ac5f-4843-8c44-0f540217995e","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.937536","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:49.940708","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/3ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.050173","level":"info","event":"25/07/31 02:58:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.137496","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.137574","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.137599","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.137619","level":"info","event":"file:/opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.137638","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.138913","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.138989","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139032","level":"info","event":"(spark.app.submitTime,1753930730131)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139060","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139080","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139098","level":"info","event":"(spark.executor.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139116","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139136","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139153","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139171","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139188","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139204","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139221","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139237","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139255","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139272","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139313","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139380","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139404","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139422","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139465","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139484","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139500","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139516","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139533","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139549","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139565","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139613","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.139633","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.776094","level":"info","event":"25/07/31 02:58:50 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.776180","level":"info","event":"25/07/31 02:58:50 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.776310","level":"info","event":"25/07/31 02:58:50 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.786227","level":"info","event":"25/07/31 02:58:50 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.786326","level":"info","event":"25/07/31 02:58:50 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.786368","level":"info","event":"25/07/31 02:58:50 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.786503","level":"info","event":"25/07/31 02:58:50 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.797370","level":"info","event":"25/07/31 02:58:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.800638","level":"info","event":"25/07/31 02:58:50 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.801159","level":"info","event":"25/07/31 02:58:50 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.829545","level":"info","event":"25/07/31 02:58:50 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.829640","level":"info","event":"25/07/31 02:58:50 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.829873","level":"info","event":"25/07/31 02:58:50 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.829938","level":"info","event":"25/07/31 02:58:50 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.830056","level":"info","event":"25/07/31 02:58:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.935356","level":"info","event":"25/07/31 02:58:50 INFO Utils: Successfully started service 'sparkDriver' on port 46411.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.966710","level":"info","event":"25/07/31 02:58:50 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.980661","level":"info","event":"25/07/31 02:58:50 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.987943","level":"info","event":"25/07/31 02:58:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.988168","level":"info","event":"25/07/31 02:58:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:50.989860","level":"info","event":"25/07/31 02:58:50 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.000993","level":"info","event":"25/07/31 02:58:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-749a951e-ab00-491f-bc11-5868403e67d0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.007521","level":"info","event":"25/07/31 02:58:51 INFO MemoryStore: MemoryStore started with capacity 127.2 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.014671","level":"info","event":"25/07/31 02:58:51 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.078564","level":"info","event":"25/07/31 02:58:51 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.108319","level":"info","event":"25/07/31 02:58:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.124824","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://05a2169a22bf:46411/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.124913","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://05a2169a22bf:46411/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.125014","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://05a2169a22bf:46411/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.125164","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://05a2169a22bf:46411/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.125223","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://05a2169a22bf:46411/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.125249","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://05a2169a22bf:46411/jars/org.tukaani_xz-1.9.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.125371","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://05a2169a22bf:46411/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.125463","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://05a2169a22bf:46411/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.126405","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://05a2169a22bf:46411/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.126809","level":"info","event":"25/07/31 02:58:51 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/userFiles-9978a7c4-b7a3-46e1-a740-6b13d881b9d8/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.134097","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://05a2169a22bf:46411/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.134162","level":"info","event":"25/07/31 02:58:51 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/userFiles-9978a7c4-b7a3-46e1-a740-6b13d881b9d8/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.418815","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://05a2169a22bf:46411/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.418960","level":"info","event":"25/07/31 02:58:51 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/userFiles-9978a7c4-b7a3-46e1-a740-6b13d881b9d8/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.421120","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://05a2169a22bf:46411/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.421192","level":"info","event":"25/07/31 02:58:51 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/userFiles-9978a7c4-b7a3-46e1-a740-6b13d881b9d8/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.427648","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://05a2169a22bf:46411/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.427740","level":"info","event":"25/07/31 02:58:51 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/userFiles-9978a7c4-b7a3-46e1-a740-6b13d881b9d8/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.430040","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://05a2169a22bf:46411/files/org.tukaani_xz-1.9.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.430099","level":"info","event":"25/07/31 02:58:51 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/userFiles-9978a7c4-b7a3-46e1-a740-6b13d881b9d8/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.432083","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://05a2169a22bf:46411/files/io.delta_delta-storage-3.1.0.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.432173","level":"info","event":"25/07/31 02:58:51 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/userFiles-9978a7c4-b7a3-46e1-a740-6b13d881b9d8/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.433857","level":"info","event":"25/07/31 02:58:51 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://05a2169a22bf:46411/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753930730772","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.433948","level":"info","event":"25/07/31 02:58:51 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/userFiles-9978a7c4-b7a3-46e1-a740-6b13d881b9d8/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.476293","level":"info","event":"25/07/31 02:58:51 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.497013","level":"info","event":"25/07/31 02:58:51 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.6:7077 after 11 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.545415","level":"info","event":"25/07/31 02:58:51 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250731025851-0001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.546220","level":"info","event":"25/07/31 02:58:51 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250731025851-0001/0 on worker-20250731025506-172.18.0.8-40691 (172.18.0.8:40691) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.547379","level":"info","event":"25/07/31 02:58:51 INFO StandaloneSchedulerBackend: Granted executor ID app-20250731025851-0001/0 on hostPort 172.18.0.8:40691 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.547623","level":"info","event":"25/07/31 02:58:51 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250731025851-0001/1 on worker-20250731025506-172.18.0.8-40691 (172.18.0.8:40691) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.547696","level":"info","event":"25/07/31 02:58:51 INFO StandaloneSchedulerBackend: Granted executor ID app-20250731025851-0001/1 on hostPort 172.18.0.8:40691 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.550863","level":"info","event":"25/07/31 02:58:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44145.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.550974","level":"info","event":"25/07/31 02:58:51 INFO NettyBlockTransferService: Server created on 05a2169a22bf:44145","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.552087","level":"info","event":"25/07/31 02:58:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.556256","level":"info","event":"25/07/31 02:58:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 05a2169a22bf, 44145, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.557962","level":"info","event":"25/07/31 02:58:51 INFO BlockManagerMasterEndpoint: Registering block manager 05a2169a22bf:44145 with 127.2 MiB RAM, BlockManagerId(driver, 05a2169a22bf, 44145, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.559032","level":"info","event":"25/07/31 02:58:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 05a2169a22bf, 44145, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.559633","level":"info","event":"25/07/31 02:58:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 05a2169a22bf, 44145, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.583752","level":"info","event":"25/07/31 02:58:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731025851-0001/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.583853","level":"info","event":"25/07/31 02:58:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731025851-0001/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.669411","level":"info","event":"25/07/31 02:58:51 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.820452","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.823917","level":"info","event":"25/07/31 02:58:51 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:51.824928","level":"info","event":"25/07/31 02:58:51 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:52.509521","level":"info","event":"25/07/31 02:58:52 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:52.515605","level":"info","event":"25/07/31 02:58:52 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:52.515706","level":"info","event":"25/07/31 02:58:52 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:53.016528","level":"info","event":"25/07/31 02:58:53 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:53.030375","level":"info","event":"25/07/31 02:58:53 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:42888) with ID 1,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:53.035092","level":"info","event":"25/07/31 02:58:53 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:42886) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:53.054362","level":"info","event":"25/07/31 02:58:53 INFO DeltaLog: Loading version 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:53.068121","level":"info","event":"25/07/31 02:58:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:43243 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.8, 43243, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:53.068993","level":"info","event":"25/07/31 02:58:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:43615 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.8, 43615, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:54.168079","level":"info","event":"25/07/31 02:58:54 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1995)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:54.958073","level":"info","event":"25/07/31 02:58:54 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:54.963145","level":"info","event":"25/07/31 02:58:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:54.964432","level":"info","event":"25/07/31 02:58:54 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#11.minReaderVersion) OR isnotnull(metaData#10.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.335926","level":"info","event":"25/07/31 02:58:55 INFO CodeGenerator: Code generated in 169.426709 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.380691","level":"info","event":"25/07/31 02:58:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 206.0 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.408630","level":"info","event":"25/07/31 02:58:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.409897","level":"info","event":"25/07/31 02:58:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 05a2169a22bf:44145 (size: 36.5 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.412412","level":"info","event":"25/07/31 02:58:55 INFO SparkContext: Created broadcast 0 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.421144","level":"info","event":"25/07/31 02:58:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.510405","level":"info","event":"25/07/31 02:58:55 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.517089","level":"info","event":"25/07/31 02:58:55 INFO DAGScheduler: Got job 0 (toString at String.java:4220) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.517177","level":"info","event":"25/07/31 02:58:55 INFO DAGScheduler: Final stage: ResultStage 0 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.517358","level":"info","event":"25/07/31 02:58:55 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.517921","level":"info","event":"25/07/31 02:58:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.519291","level":"info","event":"25/07/31 02:58:55 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.530118","level":"info","event":"25/07/31 02:58:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.0 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.532913","level":"info","event":"25/07/31 02:58:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.533318","level":"info","event":"25/07/31 02:58:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 05a2169a22bf:44145 (size: 13.7 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.533741","level":"info","event":"25/07/31 02:58:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.543169","level":"info","event":"25/07/31 02:58:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.546301","level":"info","event":"25/07/31 02:58:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.677892","level":"info","event":"25/07/31 02:58:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11166 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:55.802428","level":"info","event":"25/07/31 02:58:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:43615 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.298299","level":"info","event":"25/07/31 02:58:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:43615 (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.825669","level":"info","event":"25/07/31 02:58:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1157 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.826216","level":"info","event":"25/07/31 02:58:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.828805","level":"info","event":"25/07/31 02:58:56 INFO DAGScheduler: ResultStage 0 (toString at String.java:4220) finished in 1.301 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.829753","level":"info","event":"25/07/31 02:58:56 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.829810","level":"info","event":"25/07/31 02:58:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.830659","level":"info","event":"25/07/31 02:58:56 INFO DAGScheduler: Job 0 finished: toString at String.java:4220, took 1.320129 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.874892","level":"info","event":"25/07/31 02:58:56 INFO CodeGenerator: Code generated in 29.335875 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.877971","level":"info","event":"25/07/31 02:58:56 INFO Snapshot: [tableId=53c33d89-35e0-4f0a-b26e-ecd8905a4d2e] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(934fe67a-3cdb-4bd9-9244-c2df2ca4d973,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930718246)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1753930720698; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=d47aaa5e0705bd3da0aee32518e8b6b8 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@33db5ecc,1753930720698), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.980011","level":"info","event":"25/07/31 02:58:56 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.986255","level":"info","event":"25/07/31 02:58:56 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:56.987290","level":"info","event":"25/07/31 02:58:56 INFO InitialSnapshot: [tableId=8d14067e-64cb-418b-b070-9a4f0127d5b6] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=-1, metadata=Metadata(3a242cf4-0d14-48d8-a9e6-63cdade0f10b,null,null,Format(parquet,Map()),null,List(),Map(),Some(1753930736987)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@33db5ecc,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.014176","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 05a2169a22bf:44145 in memory (size: 13.7 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.018615","level":"info","event":"25/07/31 02:58:57 INFO DeltaLog: No delta log found for the Delta table at s3a://activefence-bucket/bbc_tech/gold/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.019100","level":"info","event":"25/07/31 02:58:57 INFO InitialSnapshot: [tableId=3a242cf4-0d14-48d8-a9e6-63cdade0f10b] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=-1, metadata=Metadata(b9cb3af6-5c4e-4be0-9a84-2067d689cea2,null,null,Format(parquet,Map()),null,List(),Map(),Some(1753930737018)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@33db5ecc,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.020980","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:43615 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.035448","level":"info","event":"25/07/31 02:58:57 INFO OptimisticTransaction: [tableId=b9cb3af6,txnId=670e12a8] Updated metadata from - to Metadata(d7996a00-d6f7-4e29-b869-bb695b5b86be,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930737028))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.131977","level":"info","event":"25/07/31 02:58:57 INFO PrepareDeltaScan: DELTA: Filtering files for query","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.132716","level":"info","event":"25/07/31 02:58:57 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Compute snapshot for version: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.138875","level":"info","event":"25/07/31 02:58:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 205.7 KiB, free 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.144468","level":"info","event":"25/07/31 02:58:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.144978","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 05a2169a22bf:44145 (size: 36.4 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.145489","level":"info","event":"25/07/31 02:58:57 INFO SparkContext: Created broadcast 2 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.164309","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 05a2169a22bf:44145 in memory (size: 36.5 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.165596","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.8:43615 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.390956","level":"info","event":"25/07/31 02:58:57 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.391041","level":"info","event":"25/07/31 02:58:57 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.391154","level":"info","event":"25/07/31 02:58:57 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.410451","level":"info","event":"25/07/31 02:58:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.496788","level":"info","event":"25/07/31 02:58:57 INFO CodeGenerator: Code generated in 50.227625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.498631","level":"info","event":"25/07/31 02:58:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 206.0 KiB, free 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.501936","level":"info","event":"25/07/31 02:58:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.502263","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 05a2169a22bf:44145 (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.502886","level":"info","event":"25/07/31 02:58:57 INFO SparkContext: Created broadcast 3 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.503469","level":"info","event":"25/07/31 02:58:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.541281","level":"info","event":"25/07/31 02:58:57 INFO DAGScheduler: Registering RDD 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.542726","level":"info","event":"25/07/31 02:58:57 INFO DAGScheduler: Got map stage job 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.542852","level":"info","event":"25/07/31 02:58:57 INFO DAGScheduler: Final stage: ShuffleMapStage 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.542921","level":"info","event":"25/07/31 02:58:57 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.543111","level":"info","event":"25/07/31 02:58:57 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.543799","level":"info","event":"25/07/31 02:58:57 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.549929","level":"info","event":"25/07/31 02:58:57 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 105.6 KiB, free 126.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.550563","level":"info","event":"25/07/31 02:58:57 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 126.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.550932","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 05a2169a22bf:44145 (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.551254","level":"info","event":"25/07/31 02:58:57 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.551989","level":"info","event":"25/07/31 02:58:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.552035","level":"info","event":"25/07/31 02:58:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.552995","level":"info","event":"25/07/31 02:58:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11155 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.566274","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:43615 (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:57.792651","level":"info","event":"25/07/31 02:58:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:43615 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.225915","level":"info","event":"25/07/31 02:58:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 673 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.225998","level":"info","event":"25/07/31 02:58:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.226917","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: ShuffleMapStage 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.682 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.227068","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.227123","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.227229","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.227310","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.246183","level":"info","event":"25/07/31 02:58:58 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 05a2169a22bf:44145 in memory (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.247822","level":"info","event":"25/07/31 02:58:58 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:43615 in memory (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.385747","level":"info","event":"25/07/31 02:58:58 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.385967","level":"info","event":"25/07/31 02:58:58 INFO CodeGenerator: Code generated in 98.697042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.418597","level":"info","event":"25/07/31 02:58:58 INFO CodeGenerator: Code generated in 22.298875 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.549657","level":"info","event":"25/07/31 02:58:58 INFO CodeGenerator: Code generated in 20.685042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.555219","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: Registering RDD 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.555318","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: Got map stage job 2 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.555362","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: Final stage: ShuffleMapStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.555387","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.556284","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.556536","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.573105","level":"info","event":"25/07/31 02:58:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 603.3 KiB, free 126.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.574211","level":"info","event":"25/07/31 02:58:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.574588","level":"info","event":"25/07/31 02:58:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 05a2169a22bf:44145 (size: 138.2 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.574881","level":"info","event":"25/07/31 02:58:58 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.575244","level":"info","event":"25/07/31 02:58:58 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.575297","level":"info","event":"25/07/31 02:58:58 INFO TaskSchedulerImpl: Adding task set 3.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.577566","level":"info","event":"25/07/31 02:58:58 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 2) (172.18.0.8, executor 0, partition 6, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.577696","level":"info","event":"25/07/31 02:58:58 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 3) (172.18.0.8, executor 1, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.588160","level":"info","event":"25/07/31 02:58:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:43615 (size: 138.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.688830","level":"info","event":"25/07/31 02:58:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:43243 (size: 138.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:58.717360","level":"info","event":"25/07/31 02:58:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:42886","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.004521","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_6 in memory on 172.18.0.8:43615 (size: 691.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.069340","level":"info","event":"25/07/31 02:58:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:42888","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.303392","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.303608","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 2) in 727 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.342262","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_0 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.368764","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.369577","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 67 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.411470","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_1 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.434793","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 6) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.435109","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 67 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.463319","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_2 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.480064","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 7) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.480542","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 6) in 46 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.509054","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_3 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.531507","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 8) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.532377","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 7) in 52 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.574076","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_4 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.592518","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 9) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.593034","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 8) in 62 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.623796","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_5 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.641800","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 10) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.642672","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 9) in 50 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.672923","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_7 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.688127","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 11) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.688548","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 10) in 47 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.718502","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_8 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.735075","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 12) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.735572","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 11) in 48 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.764103","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_9 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.782237","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 13) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.782967","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 12) in 48 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.812545","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_10 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.826889","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 14) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.827286","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 13) in 45 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.853381","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_11 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.867983","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 15) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.868318","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 14) in 41 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.892213","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_12 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.903832","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 16) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.904327","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 15) in 37 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.929458","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_13 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.942151","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 17) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.942259","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 16) in 39 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.968520","level":"info","event":"25/07/31 02:58:59 INFO BlockManagerInfo: Added rdd_14_14 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.982999","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 18) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:58:59.983620","level":"info","event":"25/07/31 02:58:59 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 17) in 42 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.008643","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_15 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.034210","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 19) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.034385","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 18) in 52 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.061522","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_16 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.088979","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 20) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.089503","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 19) in 56 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.123747","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_17 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.136369","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 21) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.136727","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 20) in 48 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.161017","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_18 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.175295","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 22) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.175746","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 21) in 40 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.202285","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_19 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.216228","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 23) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.216634","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 22) in 42 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.239474","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_20 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.249775","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 24) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.250170","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 23) in 35 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.270035","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_21 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.280006","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 25) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.280349","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 24) in 31 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.298559","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_22 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.307533","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 26) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.307878","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 25) in 28 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.311452","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_42 in memory on 172.18.0.8:43243 (size: 562.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.325652","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_23 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.337475","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 27) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.337948","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 26) in 30 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.360476","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_24 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.371638","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 28) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.372012","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 27) in 34 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.390063","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_25 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.399888","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 29) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.400117","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 28) in 28 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.417437","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_26 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.428621","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 30) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.429086","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 29) in 29 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.446314","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_27 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.455598","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 31) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.456113","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 30) in 27 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.473972","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_28 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.484138","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 32) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.484410","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 31) in 29 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.500014","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_29 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.509623","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 33) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.509928","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 32) in 26 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.527128","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_30 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.535496","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 34) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.535760","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 33) in 26 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.551979","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_31 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.561676","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 35) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.562021","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 34) in 26 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.579546","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_32 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.589359","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 36) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.589653","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 35) in 28 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.605673","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_33 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.613779","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 37) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.614029","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 36) in 25 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.629382","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_34 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.640083","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 38) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.640355","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 37) in 27 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.658540","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 39) (172.18.0.8, executor 1, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.659029","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 3) in 2081 ms on 172.18.0.8 (executor 1) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.665536","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_35 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.677150","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 40) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.677630","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 38) in 38 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.696599","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_37 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.697211","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_36 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.707431","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 41) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.707867","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 40) in 31 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.719795","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 42) (172.18.0.8, executor 1, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.720154","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 39) in 61 ms on 172.18.0.8 (executor 1) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.723650","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_38 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.732940","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 43) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.733240","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 41) in 26 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.748962","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_40 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.757551","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_39 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.760459","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 44) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.760871","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 43) in 28 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.776258","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_41 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.778287","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 45) (172.18.0.8, executor 1, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.778696","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 42) in 59 ms on 172.18.0.8 (executor 1) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.784633","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 46) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.784875","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 44) in 25 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.802069","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_44 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.811401","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 47) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.811925","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 46) in 27 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.816722","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_43 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.826318","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_45 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.835750","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 48) (172.18.0.8, executor 1, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.836059","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 45) in 57 ms on 172.18.0.8 (executor 1) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.836561","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 49) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.836983","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 47) in 26 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.851632","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_47 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.858870","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 50) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.859153","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 49) in 22 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.867437","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_46 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.874049","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_48 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.881468","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 51) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.881832","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 50) in 23 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.883090","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 48) in 47 ms on 172.18.0.8 (executor 1) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.896251","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added rdd_14_49 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.904787","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 51) in 23 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.904863","level":"info","event":"25/07/31 02:59:00 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.905200","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: ShuffleMapStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 2.344 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.905257","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.905323","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.905347","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.905366","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.920347","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:43615 in memory (size: 138.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.920714","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 05a2169a22bf:44145 in memory (size: 138.2 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.921710","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:43243 in memory (size: 138.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.925286","level":"info","event":"25/07/31 02:59:00 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.926135","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: Got job 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.926196","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: Final stage: ResultStage 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.926222","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.926243","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.926449","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[20] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.929032","level":"info","event":"25/07/31 02:59:00 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 534.6 KiB, free 126.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.930141","level":"info","event":"25/07/31 02:59:00 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 124.5 KiB, free 126.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.930476","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 05a2169a22bf:44145 (size: 124.5 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.930770","level":"info","event":"25/07/31 02:59:00 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.930993","level":"info","event":"25/07/31 02:59:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.931031","level":"info","event":"25/07/31 02:59:00 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.931734","level":"info","event":"25/07/31 02:59:00 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 52) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.941526","level":"info","event":"25/07/31 02:59:00 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:43243 (size: 124.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:00.974765","level":"info","event":"25/07/31 02:59:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:42888","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.014626","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 52) in 83 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.014696","level":"info","event":"25/07/31 02:59:01 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.015018","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: ResultStage 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.088 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.015078","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.015102","level":"info","event":"25/07/31 02:59:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.015335","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Job 3 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.089941 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.035343","level":"info","event":"25/07/31 02:59:01 INFO CodeGenerator: Code generated in 14.783917 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.036469","level":"info","event":"25/07/31 02:59:01 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.176396","level":"info","event":"25/07/31 02:59:01 INFO CodeGenerator: Code generated in 44.846291 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.176522","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 05a2169a22bf:44145 in memory (size: 124.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.177638","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.8:43243 in memory (size: 124.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.187709","level":"info","event":"25/07/31 02:59:01 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.188398","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Got job 4 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.188450","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.188475","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.189004","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.189180","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[22] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.191559","level":"info","event":"25/07/31 02:59:01 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 684.8 KiB, free 126.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.192781","level":"info","event":"25/07/31 02:59:01 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 154.3 KiB, free 125.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.193079","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 05a2169a22bf:44145 (size: 154.3 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.193368","level":"info","event":"25/07/31 02:59:01 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.193648","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.193702","level":"info","event":"25/07/31 02:59:01 INFO TaskSchedulerImpl: Adding task set 8.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.194736","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 53) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.194965","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 36.0 in stage 8.0 (TID 54) (172.18.0.8, executor 1, partition 36, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.202417","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:43615 (size: 154.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.202856","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:43243 (size: 154.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.290689","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 55) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.291182","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 53) in 97 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.297504","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 56) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.297728","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 55) in 7 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.300000","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 39.0 in stage 8.0 (TID 57) (172.18.0.8, executor 1, partition 39, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.300403","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 36.0 in stage 8.0 (TID 54) in 106 ms on 172.18.0.8 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.304544","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 58) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.304888","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 56) in 8 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.311860","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 42.0 in stage 8.0 (TID 59) (172.18.0.8, executor 1, partition 42, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.312581","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 39.0 in stage 8.0 (TID 57) in 13 ms on 172.18.0.8 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.314686","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 60) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.315020","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 58) in 10 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.320787","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 61) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.321258","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 60) in 7 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.323677","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 43.0 in stage 8.0 (TID 62) (172.18.0.8, executor 1, partition 43, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.323818","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 42.0 in stage 8.0 (TID 59) in 12 ms on 172.18.0.8 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.328761","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 63) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.329254","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 61) in 9 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.332201","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 46.0 in stage 8.0 (TID 64) (172.18.0.8, executor 1, partition 46, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.332462","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 43.0 in stage 8.0 (TID 62) in 9 ms on 172.18.0.8 (executor 1) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.335079","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 65) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.335572","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 63) in 7 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.341148","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 46.0 in stage 8.0 (TID 64) in 9 ms on 172.18.0.8 (executor 1) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.342618","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 66) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.342807","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 65) in 8 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.349963","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 67) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.350347","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 66) in 8 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.355584","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 68) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.355805","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 67) in 6 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.363462","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 69) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.363694","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 68) in 8 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.370179","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 70) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.370451","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 69) in 7 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.376999","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 71) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.377347","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 70) in 8 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.384346","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 72) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.384763","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 71) in 8 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.393282","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 73) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.393706","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 72) in 10 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.402164","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 74) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.402301","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 73) in 10 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.410912","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 75) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.411098","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 74) in 9 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.415981","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 76) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.416190","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 75) in 5 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.421996","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 77) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.422351","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 76) in 7 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.427191","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 20.0 in stage 8.0 (TID 78) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.427517","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 77) in 6 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.432975","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 79) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.433250","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 20.0 in stage 8.0 (TID 78) in 7 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.438115","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 22.0 in stage 8.0 (TID 80) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.438386","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 79) in 6 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.445622","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 23.0 in stage 8.0 (TID 81) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.445833","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 22.0 in stage 8.0 (TID 80) in 8 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.451200","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 24.0 in stage 8.0 (TID 82) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.451508","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 23.0 in stage 8.0 (TID 81) in 6 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.456518","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 25.0 in stage 8.0 (TID 83) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.456775","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 24.0 in stage 8.0 (TID 82) in 6 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.460995","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 26.0 in stage 8.0 (TID 84) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.461309","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 25.0 in stage 8.0 (TID 83) in 5 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.465338","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 27.0 in stage 8.0 (TID 85) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.465620","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 26.0 in stage 8.0 (TID 84) in 5 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.469634","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 28.0 in stage 8.0 (TID 86) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.469939","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 27.0 in stage 8.0 (TID 85) in 4 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.477048","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 29.0 in stage 8.0 (TID 87) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.477429","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 28.0 in stage 8.0 (TID 86) in 8 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.482096","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 30.0 in stage 8.0 (TID 88) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.482407","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 29.0 in stage 8.0 (TID 87) in 6 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.486292","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 31.0 in stage 8.0 (TID 89) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.486552","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 30.0 in stage 8.0 (TID 88) in 5 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.491363","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 32.0 in stage 8.0 (TID 90) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.491534","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 31.0 in stage 8.0 (TID 89) in 5 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.495448","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 33.0 in stage 8.0 (TID 91) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.495715","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 32.0 in stage 8.0 (TID 90) in 4 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.499742","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 34.0 in stage 8.0 (TID 92) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.500007","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 33.0 in stage 8.0 (TID 91) in 4 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.506485","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 35.0 in stage 8.0 (TID 93) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.506776","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 34.0 in stage 8.0 (TID 92) in 7 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.511582","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 37.0 in stage 8.0 (TID 94) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.511742","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 35.0 in stage 8.0 (TID 93) in 5 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.515993","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 38.0 in stage 8.0 (TID 95) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.516154","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 37.0 in stage 8.0 (TID 94) in 5 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.520834","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 40.0 in stage 8.0 (TID 96) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.521030","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 38.0 in stage 8.0 (TID 95) in 5 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.524918","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 41.0 in stage 8.0 (TID 97) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.525175","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 40.0 in stage 8.0 (TID 96) in 5 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.529843","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 44.0 in stage 8.0 (TID 98) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.530021","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 41.0 in stage 8.0 (TID 97) in 5 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.536003","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 45.0 in stage 8.0 (TID 99) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.536166","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 44.0 in stage 8.0 (TID 98) in 7 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.541123","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 47.0 in stage 8.0 (TID 100) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.541316","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 45.0 in stage 8.0 (TID 99) in 6 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.546005","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 48.0 in stage 8.0 (TID 101) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.546182","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 47.0 in stage 8.0 (TID 100) in 6 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.549828","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 49.0 in stage 8.0 (TID 102) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.550090","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 48.0 in stage 8.0 (TID 101) in 4 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.554537","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Finished task 49.0 in stage 8.0 (TID 102) in 5 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.554580","level":"info","event":"25/07/31 02:59:01 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.554933","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.365 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.555037","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.555070","level":"info","event":"25/07/31 02:59:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.555278","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Job 4 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.367507 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.565128","level":"info","event":"25/07/31 02:59:01 INFO CodeGenerator: Code generated in 6.137375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.568954","level":"info","event":"25/07/31 02:59:01 INFO PrepareDeltaScan: DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.583057","level":"info","event":"25/07/31 02:59:01 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.583131","level":"info","event":"25/07/31 02:59:01 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.616405","level":"info","event":"25/07/31 02:59:01 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.668803","level":"info","event":"25/07/31 02:59:01 INFO CodeGenerator: Code generated in 25.104958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.673880","level":"info","event":"25/07/31 02:59:01 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 207.6 KiB, free 125.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.680442","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 05a2169a22bf:44145 in memory (size: 154.3 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.681814","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.8:43615 in memory (size: 154.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.681995","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.8:43243 in memory (size: 154.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.682487","level":"info","event":"25/07/31 02:59:01 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.683201","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 05a2169a22bf:44145 (size: 37.1 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.683728","level":"info","event":"25/07/31 02:59:01 INFO SparkContext: Created broadcast 8 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.687576","level":"info","event":"25/07/31 02:59:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.700527","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Registering RDD 26 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.700627","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Got map stage job 5 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.700674","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.700717","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.700769","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.701032","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[26] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.702682","level":"info","event":"25/07/31 02:59:01 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 44.9 KiB, free 126.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.703248","level":"info","event":"25/07/31 02:59:01 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 126.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.703695","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 05a2169a22bf:44145 (size: 19.9 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.704264","level":"info","event":"25/07/31 02:59:01 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.704300","level":"info","event":"25/07/31 02:59:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[26] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.704815","level":"info","event":"25/07/31 02:59:01 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.705759","level":"info","event":"25/07/31 02:59:01 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 103) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11172 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.711067","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:43615 (size: 19.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:01.806265","level":"info","event":"25/07/31 02:59:01 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:43615 (size: 37.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.188933","level":"info","event":"25/07/31 02:59:02 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 103) in 483 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.189029","level":"info","event":"25/07/31 02:59:02 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.189271","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: ShuffleMapStage 9 (save at NativeMethodAccessorImpl.java:0) finished in 0.488 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.189299","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.189321","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.189340","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.189359","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.194556","level":"info","event":"25/07/31 02:59:02 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.204430","level":"info","event":"25/07/31 02:59:02 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.210650","level":"info","event":"25/07/31 02:59:02 INFO CodeGenerator: Code generated in 4.020958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.246720","level":"info","event":"25/07/31 02:59:02 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.247278","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Got job 6 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.247311","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Final stage: ResultStage 11 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.247335","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.247354","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.247534","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.257086","level":"info","event":"25/07/31 02:59:02 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 362.4 KiB, free 126.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.261214","level":"info","event":"25/07/31 02:59:02 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 132.8 KiB, free 125.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.261307","level":"info","event":"25/07/31 02:59:02 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 05a2169a22bf:44145 in memory (size: 19.9 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.261612","level":"info","event":"25/07/31 02:59:02 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 05a2169a22bf:44145 (size: 132.8 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.261967","level":"info","event":"25/07/31 02:59:02 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.262347","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.262441","level":"info","event":"25/07/31 02:59:02 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.263069","level":"info","event":"25/07/31 02:59:02 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.8:43615 in memory (size: 19.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.263277","level":"info","event":"25/07/31 02:59:02 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 104) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.268287","level":"info","event":"25/07/31 02:59:02 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:43615 (size: 132.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.299516","level":"info","event":"25/07/31 02:59:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:42886","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.762815","level":"info","event":"25/07/31 02:59:02 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 104) in 500 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.763740","level":"info","event":"25/07/31 02:59:02 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.763790","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: ResultStage 11 (save at NativeMethodAccessorImpl.java:0) finished in 0.514 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.763857","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.763883","level":"info","event":"25/07/31 02:59:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.765448","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Job 6 finished: save at NativeMethodAccessorImpl.java:0, took 0.518638 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.766176","level":"info","event":"25/07/31 02:59:02 INFO DeltaFileFormatWriter: Start to commit write Job 0c33d939-a9de-46bc-88d9-51529fd1acab.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.766814","level":"info","event":"25/07/31 02:59:02 INFO DeltaFileFormatWriter: Write Job 0c33d939-a9de-46bc-88d9-51529fd1acab committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.768427","level":"info","event":"25/07/31 02:59:02 INFO DeltaFileFormatWriter: Finished processing stats for write job 0c33d939-a9de-46bc-88d9-51529fd1acab.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.851115","level":"info","event":"25/07/31 02:59:02 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.851240","level":"info","event":"25/07/31 02:59:02 INFO DAGScheduler: Job 7 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000134 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:02.895335","level":"info","event":"25/07/31 02:59:02 INFO OptimisticTransaction: [tableId=b9cb3af6,txnId=670e12a8] Attempting to commit version 0 with 4 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.020814","level":"info","event":"25/07/31 02:59:03 INFO DeltaLog: Creating a new snapshot v0 for commit version 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.020957","level":"info","event":"25/07/31 02:59:03 INFO DeltaLog: Loading version 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.023347","level":"info","event":"25/07/31 02:59:03 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1334)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.036817","level":"info","event":"25/07/31 02:59:03 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.036933","level":"info","event":"25/07/31 02:59:03 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.036971","level":"info","event":"25/07/31 02:59:03 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#726.minReaderVersion) OR isnotnull(metaData#725.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.043563","level":"info","event":"25/07/31 02:59:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 206.2 KiB, free 125.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.047127","level":"info","event":"25/07/31 02:59:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 125.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.047415","level":"info","event":"25/07/31 02:59:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 05a2169a22bf:44145 (size: 36.5 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.047993","level":"info","event":"25/07/31 02:59:03 INFO SparkContext: Created broadcast 11 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.048549","level":"info","event":"25/07/31 02:59:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.059664","level":"info","event":"25/07/31 02:59:03 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.060219","level":"info","event":"25/07/31 02:59:03 INFO DAGScheduler: Got job 8 (toString at String.java:4220) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.060277","level":"info","event":"25/07/31 02:59:03 INFO DAGScheduler: Final stage: ResultStage 12 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.060301","level":"info","event":"25/07/31 02:59:03 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.060323","level":"info","event":"25/07/31 02:59:03 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.060693","level":"info","event":"25/07/31 02:59:03 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[36] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.061443","level":"info","event":"25/07/31 02:59:03 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 40.0 KiB, free 125.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.067004","level":"info","event":"25/07/31 02:59:03 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 125.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.067439","level":"info","event":"25/07/31 02:59:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 05a2169a22bf:44145 (size: 13.7 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.067712","level":"info","event":"25/07/31 02:59:03 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.067930","level":"info","event":"25/07/31 02:59:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[36] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.067985","level":"info","event":"25/07/31 02:59:03 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.068243","level":"info","event":"25/07/31 02:59:03 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 05a2169a22bf:44145 in memory (size: 132.8 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.069026","level":"info","event":"25/07/31 02:59:03 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 105) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11164 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.079841","level":"info","event":"25/07/31 02:59:03 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.8:43615 in memory (size: 132.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.084991","level":"info","event":"25/07/31 02:59:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:43243 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:03.237111","level":"info","event":"25/07/31 02:59:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:43243 (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.209716","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 105) in 1140 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.210852","level":"info","event":"25/07/31 02:59:04 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.210996","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: ResultStage 12 (toString at String.java:4220) finished in 1.149 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.211063","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.211128","level":"info","event":"25/07/31 02:59:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.211210","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Job 8 finished: toString at String.java:4220, took 1.151352 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.219327","level":"info","event":"25/07/31 02:59:04 INFO Snapshot: [tableId=b9cb3af6-5c4e-4be0-9a84-2067d689cea2] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=0, metadata=Metadata(d7996a00-d6f7-4e29-b869-bb695b5b86be,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930737028)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000000.json; isDirectory=false; length=1334; replication=1; blocksize=33554432; modification_time=1753930742996; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=4a7a9513f64fdb056552216dbd849d48 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@33db5ecc,1753930742996), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.221301","level":"info","event":"25/07/31 02:59:04 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=0, metadata=Metadata(d7996a00-d6f7-4e29-b869-bb695b5b86be,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930737028)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000000.json; isDirectory=false; length=1334; replication=1; blocksize=33554432; modification_time=1753930742996; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=4a7a9513f64fdb056552216dbd849d48 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@33db5ecc,1753930742996), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.229133","level":"info","event":"25/07/31 02:59:04 INFO Snapshot: [tableId=d7996a00-d6f7-4e29-b869-bb695b5b86be] DELTA: Compute snapshot for version: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.231053","level":"info","event":"25/07/31 02:59:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 205.9 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.235954","level":"info","event":"25/07/31 02:59:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.236365","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 05a2169a22bf:44145 (size: 36.4 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.237010","level":"info","event":"25/07/31 02:59:04 INFO SparkContext: Created broadcast 13 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.320835","level":"info","event":"25/07/31 02:59:04 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.320943","level":"info","event":"25/07/31 02:59:04 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.320987","level":"info","event":"25/07/31 02:59:04 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.342226","level":"info","event":"25/07/31 02:59:04 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 206.2 KiB, free 125.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.350576","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 05a2169a22bf:44145 in memory (size: 36.5 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.351586","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.8:43243 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.351853","level":"info","event":"25/07/31 02:59:04 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.352136","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 05a2169a22bf:44145 (size: 36.5 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.352714","level":"info","event":"25/07/31 02:59:04 INFO SparkContext: Created broadcast 14 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.353403","level":"info","event":"25/07/31 02:59:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.357569","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Registering RDD 40 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.357776","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Got map stage job 9 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.357848","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Final stage: ShuffleMapStage 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.357906","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.357937","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.358085","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[40] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.359547","level":"info","event":"25/07/31 02:59:04 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 105.6 KiB, free 125.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.360052","level":"info","event":"25/07/31 02:59:04 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 125.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.360202","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 05a2169a22bf:44145 (size: 32.6 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.360504","level":"info","event":"25/07/31 02:59:04 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.360732","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[40] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.360816","level":"info","event":"25/07/31 02:59:04 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.361645","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 106) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11153 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.362329","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 05a2169a22bf:44145 in memory (size: 13.7 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.364220","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.8:43243 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.375462","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:43243 (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.450695","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:43243 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.486738","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 106) in 125 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.486834","level":"info","event":"25/07/31 02:59:04 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.487007","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: ShuffleMapStage 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.128 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.487039","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.487119","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.487175","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.487196","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.518486","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 05a2169a22bf:44145 in memory (size: 32.6 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.519960","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.8:43243 in memory (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.557554","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Registering RDD 50 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.557637","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Got map stage job 10 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.557664","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Final stage: ShuffleMapStage 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.557698","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.557993","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.558103","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[50] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.561184","level":"info","event":"25/07/31 02:59:04 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 603.4 KiB, free 125.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.565310","level":"info","event":"25/07/31 02:59:04 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 125.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.565527","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 05a2169a22bf:44145 (size: 138.2 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.565791","level":"info","event":"25/07/31 02:59:04 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.566066","level":"info","event":"25/07/31 02:59:04 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[50] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.566118","level":"info","event":"25/07/31 02:59:04 INFO TaskSchedulerImpl: Adding task set 15.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.566806","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 17.0 in stage 15.0 (TID 107) (172.18.0.8, executor 0, partition 17, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.566914","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 42.0 in stage 15.0 (TID 108) (172.18.0.8, executor 1, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.574919","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.8:43243 (size: 138.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.584420","level":"info","event":"25/07/31 02:59:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:42888","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.594635","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.8:43615 (size: 138.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.611492","level":"info","event":"25/07/31 02:59:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:42886","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.612959","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_42 in memory on 172.18.0.8:43243 (size: 487.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.634288","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 109) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.634879","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 42.0 in stage 15.0 (TID 108) in 68 ms on 172.18.0.8 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.645253","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_17 in memory on 172.18.0.8:43615 (size: 443.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.661832","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 110) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.662468","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 17.0 in stage 15.0 (TID 107) in 95 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.667117","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_0 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.682222","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 111) (172.18.0.8, executor 1, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.682458","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 109) in 49 ms on 172.18.0.8 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.689059","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_1 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.716468","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 112) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.716595","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 110) in 55 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.717754","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_2 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.731487","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 113) (172.18.0.8, executor 1, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.731873","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 111) in 50 ms on 172.18.0.8 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.744390","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_3 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.755935","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 114) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.756122","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 112) in 40 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.761108","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_4 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.775723","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 115) (172.18.0.8, executor 1, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.775967","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 113) in 45 ms on 172.18.0.8 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.776809","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_5 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.787569","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 116) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.787865","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 114) in 32 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.804658","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_6 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.811758","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_7 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.821110","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 117) (172.18.0.8, executor 1, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.821534","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 118) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.821914","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 115) in 47 ms on 172.18.0.8 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.822181","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 116) in 34 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.843733","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_9 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.847721","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_8 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.862456","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 119) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.862676","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 118) in 41 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.869533","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 11.0 in stage 15.0 (TID 120) (172.18.0.8, executor 1, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.869773","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 117) in 49 ms on 172.18.0.8 (executor 1) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.882874","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_10 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.891235","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_11 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.892396","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 12.0 in stage 15.0 (TID 121) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.892844","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 119) in 31 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.903777","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 13.0 in stage 15.0 (TID 122) (172.18.0.8, executor 1, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.904296","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 11.0 in stage 15.0 (TID 120) in 36 ms on 172.18.0.8 (executor 1) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.909770","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_12 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.920376","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 14.0 in stage 15.0 (TID 123) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.920606","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 12.0 in stage 15.0 (TID 121) in 28 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.938533","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_14 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.938998","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_13 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.947322","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 15.0 in stage 15.0 (TID 124) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.947671","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 14.0 in stage 15.0 (TID 123) in 27 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.948547","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 16.0 in stage 15.0 (TID 125) (172.18.0.8, executor 1, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.948803","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 13.0 in stage 15.0 (TID 122) in 45 ms on 172.18.0.8 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.967326","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_16 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.967420","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_15 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.974538","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 18.0 in stage 15.0 (TID 126) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.975106","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 15.0 in stage 15.0 (TID 124) in 28 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.981832","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Starting task 19.0 in stage 15.0 (TID 127) (172.18.0.8, executor 1, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.982108","level":"info","event":"25/07/31 02:59:04 INFO TaskSetManager: Finished task 16.0 in stage 15.0 (TID 125) in 33 ms on 172.18.0.8 (executor 1) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:04.991575","level":"info","event":"25/07/31 02:59:04 INFO BlockManagerInfo: Added rdd_47_18 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.000924","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 20.0 in stage 15.0 (TID 128) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.001280","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 18.0 in stage 15.0 (TID 126) in 27 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.005168","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_19 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.015887","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 21.0 in stage 15.0 (TID 129) (172.18.0.8, executor 1, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.016001","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_20 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.016195","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 19.0 in stage 15.0 (TID 127) in 35 ms on 172.18.0.8 (executor 1) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.023838","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 22.0 in stage 15.0 (TID 130) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.024129","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 20.0 in stage 15.0 (TID 128) in 23 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.034929","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_21 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.041578","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_22 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.044476","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 23.0 in stage 15.0 (TID 131) (172.18.0.8, executor 1, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.044771","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 21.0 in stage 15.0 (TID 129) in 29 ms on 172.18.0.8 (executor 1) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.049246","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 24.0 in stage 15.0 (TID 132) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.049510","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 22.0 in stage 15.0 (TID 130) in 26 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.064055","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_23 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.071778","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_24 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.073840","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 25.0 in stage 15.0 (TID 133) (172.18.0.8, executor 1, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.074052","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 23.0 in stage 15.0 (TID 131) in 29 ms on 172.18.0.8 (executor 1) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.080430","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 26.0 in stage 15.0 (TID 134) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.080862","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 24.0 in stage 15.0 (TID 132) in 32 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.092798","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_25 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.099179","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_26 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.112007","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 27.0 in stage 15.0 (TID 135) (172.18.0.8, executor 1, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.112125","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 25.0 in stage 15.0 (TID 133) in 38 ms on 172.18.0.8 (executor 1) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.128049","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 28.0 in stage 15.0 (TID 136) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.128171","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 26.0 in stage 15.0 (TID 134) in 47 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.149634","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_27 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.173280","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_28 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.195814","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 29.0 in stage 15.0 (TID 137) (172.18.0.8, executor 1, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.196291","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 27.0 in stage 15.0 (TID 135) in 84 ms on 172.18.0.8 (executor 1) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.197156","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 30.0 in stage 15.0 (TID 138) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.197981","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 28.0 in stage 15.0 (TID 136) in 71 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.221710","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_30 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.228310","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_29 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.236295","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 31.0 in stage 15.0 (TID 139) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.236998","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 30.0 in stage 15.0 (TID 138) in 40 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.239175","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 32.0 in stage 15.0 (TID 140) (172.18.0.8, executor 1, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.239269","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 29.0 in stage 15.0 (TID 137) in 44 ms on 172.18.0.8 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.259331","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_31 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.263227","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_32 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.274466","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 33.0 in stage 15.0 (TID 141) (172.18.0.8, executor 1, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.276000","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 32.0 in stage 15.0 (TID 140) in 36 ms on 172.18.0.8 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.276337","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 34.0 in stage 15.0 (TID 142) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.276548","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 31.0 in stage 15.0 (TID 139) in 41 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.293239","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_33 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.296990","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_34 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.310179","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 35.0 in stage 15.0 (TID 143) (172.18.0.8, executor 1, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.311015","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 33.0 in stage 15.0 (TID 141) in 37 ms on 172.18.0.8 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.313366","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 36.0 in stage 15.0 (TID 144) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.313631","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 34.0 in stage 15.0 (TID 142) in 37 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.332238","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_35 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.336125","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_36 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.347596","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 37.0 in stage 15.0 (TID 145) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.347705","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 36.0 in stage 15.0 (TID 144) in 34 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.349494","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 38.0 in stage 15.0 (TID 146) (172.18.0.8, executor 1, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.349710","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 35.0 in stage 15.0 (TID 143) in 41 ms on 172.18.0.8 (executor 1) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.370075","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_38 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.374960","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_37 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.381187","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 39.0 in stage 15.0 (TID 147) (172.18.0.8, executor 1, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.381285","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 38.0 in stage 15.0 (TID 146) in 31 ms on 172.18.0.8 (executor 1) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.387121","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 40.0 in stage 15.0 (TID 148) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.388118","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 37.0 in stage 15.0 (TID 145) in 41 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.404663","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_39 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.410048","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_40 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.420477","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 41.0 in stage 15.0 (TID 149) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.420882","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 40.0 in stage 15.0 (TID 148) in 34 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.452060","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 43.0 in stage 15.0 (TID 150) (172.18.0.8, executor 1, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.459208","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 39.0 in stage 15.0 (TID 147) in 62 ms on 172.18.0.8 (executor 1) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.479559","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_41 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.502268","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_43 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.504175","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 44.0 in stage 15.0 (TID 151) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.504227","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 41.0 in stage 15.0 (TID 149) in 84 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.543930","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 45.0 in stage 15.0 (TID 152) (172.18.0.8, executor 1, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.545377","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 43.0 in stage 15.0 (TID 150) in 98 ms on 172.18.0.8 (executor 1) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.565457","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_45 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.565573","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_44 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.598675","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 46.0 in stage 15.0 (TID 153) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.600108","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 44.0 in stage 15.0 (TID 151) in 92 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.600146","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 47.0 in stage 15.0 (TID 154) (172.18.0.8, executor 1, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.600175","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 45.0 in stage 15.0 (TID 152) in 60 ms on 172.18.0.8 (executor 1) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.623883","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_47 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.628257","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_46 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.634411","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 48.0 in stage 15.0 (TID 155) (172.18.0.8, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.634933","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 47.0 in stage 15.0 (TID 154) in 40 ms on 172.18.0.8 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.640820","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 49.0 in stage 15.0 (TID 156) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.640975","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 46.0 in stage 15.0 (TID 153) in 49 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.657191","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_49 in memory on 172.18.0.8:43615 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.661494","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added rdd_47_48 in memory on 172.18.0.8:43243 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.664628","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 49.0 in stage 15.0 (TID 156) in 24 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.670696","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 48.0 in stage 15.0 (TID 155) in 37 ms on 172.18.0.8 (executor 1) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.670809","level":"info","event":"25/07/31 02:59:05 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.675506","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: ShuffleMapStage 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.113 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.675596","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.675622","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.675644","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.675663","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.697515","level":"info","event":"25/07/31 02:59:05 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.698356","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: Got job 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.698408","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: Final stage: ResultStage 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.698433","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.698458","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.698575","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[53] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.706224","level":"info","event":"25/07/31 02:59:05 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 534.7 KiB, free 124.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.707858","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 05a2169a22bf:44145 in memory (size: 138.2 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.708925","level":"info","event":"25/07/31 02:59:05 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 124.7 KiB, free 125.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.708986","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 05a2169a22bf:44145 (size: 124.7 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.709244","level":"info","event":"25/07/31 02:59:05 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.709464","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[53] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.709544","level":"info","event":"25/07/31 02:59:05 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.710374","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 157) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.713135","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.8:43243 in memory (size: 138.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.713293","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.8:43615 in memory (size: 138.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.728062","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.8:43615 (size: 124.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.737472","level":"info","event":"25/07/31 02:59:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.8:42886","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.806881","level":"info","event":"25/07/31 02:59:05 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 157) in 95 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.807722","level":"info","event":"25/07/31 02:59:05 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.807773","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: ResultStage 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.107 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.807813","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.807862","level":"info","event":"25/07/31 02:59:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.807921","level":"info","event":"25/07/31 02:59:05 INFO DAGScheduler: Job 11 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.109829 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.811938","level":"info","event":"25/07/31 02:59:05 INFO Snapshot: [tableId=d7996a00-d6f7-4e29-b869-bb695b5b86be] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.824453","level":"info","event":"25/07/31 02:59:05 INFO OptimisticTransaction: [tableId=b9cb3af6,txnId=670e12a8] Committed delta #0 to s3a://activefence-bucket/bbc_tech/gold/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.826690","level":"info","event":"INFO:__main__:Gold layer processing complete","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.827436","level":"info","event":"25/07/31 02:59:05 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.836797","level":"info","event":"25/07/31 02:59:05 INFO SparkUI: Stopped Spark web UI at http://05a2169a22bf:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.838306","level":"info","event":"25/07/31 02:59:05 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.838382","level":"info","event":"25/07/31 02:59:05 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.850965","level":"info","event":"25/07/31 02:59:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.915189","level":"info","event":"25/07/31 02:59:05 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.915698","level":"info","event":"25/07/31 02:59:05 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.917275","level":"info","event":"25/07/31 02:59:05 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.919571","level":"info","event":"25/07/31 02:59:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:05.931844","level":"info","event":"25/07/31 02:59:05 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.227465","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.227818","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.289430","level":"info","event":"25/07/31 02:59:06 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.289644","level":"info","event":"25/07/31 02:59:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-60e2330b-1c20-4dd1-bab1-34f21838dbf4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.291687","level":"info","event":"25/07/31 02:59:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1/pyspark-9599f8b8-572f-4d41-afd5-19f3383244dd","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.293266","level":"info","event":"25/07/31 02:59:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-2ddfb8fc-c501-4f4b-b3d7-d69b4a9be8e1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.298247","level":"info","event":"25/07/31 02:59:06 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.298364","level":"info","event":"25/07/31 02:59:06 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T02:59:06.298484","level":"info","event":"25/07/31 02:59:06 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
