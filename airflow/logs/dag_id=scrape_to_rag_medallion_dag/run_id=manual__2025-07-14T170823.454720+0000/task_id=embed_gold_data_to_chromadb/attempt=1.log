{"timestamp":"2025-07-14T17:08:24.820638","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-14T17:08:24.821436","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-14T17:08:32.733679Z","level":"error","event":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.870753Z","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.976666Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.977275Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.980185Z","level":"error","event":"org.apache.hadoop#hadoop-aws added as a dependency","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.980529Z","level":"error","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.980993Z","level":"error","event":"org.apache.spark#spark-avro_2.12 added as a dependency","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.981333Z","level":"error","event":"io.delta#delta-spark_2.12 added as a dependency","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.981705Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-b4bdf73f-b25d-4268-883a-87397fa05ac7;1.0","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:34.982092Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.185691Z","level":"error","event":"\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.223748Z","level":"error","event":"\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.247219Z","level":"error","event":"\tfound com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.285207Z","level":"error","event":"\tfound org.apache.spark#spark-avro_2.12;3.5.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.309162Z","level":"error","event":"\tfound org.tukaani#xz;1.9 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.328491Z","level":"error","event":"\tfound io.delta#delta-spark_2.12;3.1.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.350064Z","level":"error","event":"\tfound io.delta#delta-storage;3.1.0 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.367430Z","level":"error","event":"\tfound org.antlr#antlr4-runtime;4.9.3 in central","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.402809Z","level":"error","event":":: resolution report :: resolve 402ms :: artifacts dl 19ms","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.404386Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.405218Z","level":"error","event":"\tcom.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.405768Z","level":"error","event":"\tio.delta#delta-spark_2.12;3.1.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.406351Z","level":"error","event":"\tio.delta#delta-storage;3.1.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.406887Z","level":"error","event":"\torg.antlr#antlr4-runtime;4.9.3 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.407353Z","level":"error","event":"\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.407857Z","level":"error","event":"\torg.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.408254Z","level":"error","event":"\torg.tukaani#xz;1.9 from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.408629Z","level":"error","event":"\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.408969Z","level":"error","event":"\t:: evicted modules:","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.409573Z","level":"error","event":"\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.410090Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.410470Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.410883Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.411263Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.411731Z","level":"error","event":"\t|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.412196Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.413578Z","level":"error","event":":: retrieving :: org.apache.spark#spark-submit-parent-b4bdf73f-b25d-4268-883a-87397fa05ac7","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.414202Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.422940Z","level":"error","event":"\t0 artifacts copied, 8 already retrieved (0kB/9ms)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.700877Z","level":"error","event":"25/07/14 17:08:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.960675Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:35.961215Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:38.845419","level":"info","event":"Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.","logger":"chromadb.telemetry.product.posthog"}
{"timestamp":"2025-07-14T17:08:40.435613Z","level":"error","event":"25/07/14 17:08:40 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:08:49.885563Z","level":"info","event":"root","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:49.886408Z","level":"info","event":" |-- article_id: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:49.886932Z","level":"info","event":" |-- title: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:49.887424Z","level":"info","event":" |-- pub_date: date (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:49.887865Z","level":"info","event":" |-- summary: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:49.888177Z","level":"info","event":" |-- load_timestamp: timestamp_ntz (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:49.888550Z","level":"info","event":" |-- year_month: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:49.888908Z","level":"info","event":"","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T17:08:50.917706Z","level":"error","event":"\r[Stage 0:>                                                          (0 + 1) / 1]\r\r                                                                                \r25/07/14 17:08:50 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-14T17:09:01.233413","level":"error","event":"Error processing Delta table: list index out of range","logger":"unusual_prefix_0aab8e1abe4a8f324d874f9a30de87ad63865522_activefence"}
{"timestamp":"2025-07-14T17:09:01.234051","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"IndexError","exc_value":"list index out of range","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":867,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1159,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":216,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":239,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":81,"name":"run"},{"filename":"/opt/airflow/dags/activefence.py","lineno":304,"name":"embed_gold_data"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-07-14T17:09:02.080502Z","level":"error","event":"\r[Stage 1:>                                                          (0 + 1) / 1]\r\r[Stage 3:>                                                         (0 + 2) / 50]\r\r[Stage 3:==>                                                       (2 + 2) / 50]\r\r[Stage 3:======>                                                   (6 + 2) / 50]\r\r[Stage 3:=========>                                                (8 + 2) / 50]\r\r[Stage 3:===========>                                             (10 + 2) / 50]\r\r[Stage 3:=============>                                           (12 + 2) / 50]\r\r[Stage 3:=================>                                       (15 + 2) / 50]\r\r[Stage 3:====================>                                    (18 + 2) / 50]\r\r[Stage 3:=========================>                               (22 + 2) / 50]\r\r[Stage 3:=============================>                           (26 + 2) / 50]\r\r[Stage 3:==================================>                      (30 + 2) / 50]\r\r[Stage 3:=======================================>                 (35 + 2) / 50]\r\r[Stage 3:=============================================>           (40 + 2) / 50]\r\r[Stage 3:===================================================>     (45 + 2) / 50]\r\r                                                                                \r\r[Stage 8:==================================>                      (30 + 3) / 50]\r\r[Stage 8:======================================================>  (48 + 2) / 50]\r\r                                                                                \r\r[Stage 9:>                                                          (0 + 1) / 1]","chan":"stderr","logger":"task"}
