{"timestamp":"2025-07-31T07:37:51.485324","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-31T07:37:51.485637","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-31T07:37:53.757521","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-31T07:37:53.758192","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 1 --executor-memory 1g --driver-memory 512m --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.501519","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.542949","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543021","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543051","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543073","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543092","level":"info","event":"executorMemory          1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543119","level":"info","event":"executorCores           1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543142","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543186","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543206","level":"info","event":"driverMemory            512m","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543223","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543240","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543272","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543290","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543307","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543324","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543341","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543358","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543375","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543392","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543432","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543473","level":"info","event":"primaryResource         file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543495","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543512","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543528","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543563","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543587","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543604","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543620","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543637","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543655","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543673","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543704","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543724","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543740","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543757","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543773","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543790","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543833","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543871","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543892","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543909","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543926","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.543943","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.606843","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.642586","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.642664","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.644612","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.644655","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.644676","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.644711","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.645024","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-be3bbf09-76b0-4790-ab42-f4ced6d5327a;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.645081","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.725402","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.738710","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.745735","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.760437","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.768442","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.775120","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.781392","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.787588","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.802877","level":"info","event":":: resolution report :: resolve 150ms :: artifacts dl 8ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.802956","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.802983","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803006","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803026","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803046","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803063","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803129","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803179","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803199","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803240","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803279","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803328","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803349","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803367","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803386","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803480","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.803539","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.806012","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-be3bbf09-76b0-4790-ab42-f4ced6d5327a","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.806067","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.809443","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/4ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.906571","level":"info","event":"25/07/31 07:37:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.993187","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.993274","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.993306","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.993327","level":"info","event":"file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.993346","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994363","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994429","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994457","level":"info","event":"(spark.app.submitTime,1753947474986)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994477","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994496","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994513","level":"info","event":"(spark.executor.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994529","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994551","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994569","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994586","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994604","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994625","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994642","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994658","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994677","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994711","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994730","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994748","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994791","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994812","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994843","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994862","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994879","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994896","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994913","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994928","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994945","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994962","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:54.994980","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.565769","level":"info","event":"INFO:__main__:Starting Spark job...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.634285","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.634373","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.634486","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.645015","level":"info","event":"25/07/31 07:37:55 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.645083","level":"info","event":"25/07/31 07:37:55 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.645206","level":"info","event":"25/07/31 07:37:55 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.645361","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.655352","level":"info","event":"25/07/31 07:37:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.658913","level":"info","event":"25/07/31 07:37:55 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.659413","level":"info","event":"25/07/31 07:37:55 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.688455","level":"info","event":"25/07/31 07:37:55 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.688546","level":"info","event":"25/07/31 07:37:55 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.688640","level":"info","event":"25/07/31 07:37:55 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.688783","level":"info","event":"25/07/31 07:37:55 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.688973","level":"info","event":"25/07/31 07:37:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.791546","level":"info","event":"25/07/31 07:37:55 INFO Utils: Successfully started service 'sparkDriver' on port 43339.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.810127","level":"info","event":"25/07/31 07:37:55 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.825573","level":"info","event":"25/07/31 07:37:55 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.832681","level":"info","event":"25/07/31 07:37:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.832973","level":"info","event":"25/07/31 07:37:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.834519","level":"info","event":"25/07/31 07:37:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.843874","level":"info","event":"25/07/31 07:37:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-170c234c-c4be-44f9-a611-d76174b2f8d6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.849377","level":"info","event":"25/07/31 07:37:55 INFO MemoryStore: MemoryStore started with capacity 127.2 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.856322","level":"info","event":"25/07/31 07:37:55 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.912137","level":"info","event":"25/07/31 07:37:55 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.937835","level":"info","event":"25/07/31 07:37:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.951907","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://05a2169a22bf:43339/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.952008","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://05a2169a22bf:43339/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.952150","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://05a2169a22bf:43339/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.952217","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://05a2169a22bf:43339/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.952324","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://05a2169a22bf:43339/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.952379","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://05a2169a22bf:43339/jars/org.tukaani_xz-1.9.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.952518","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://05a2169a22bf:43339/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.952583","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://05a2169a22bf:43339/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.953570","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://05a2169a22bf:43339/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.953891","level":"info","event":"25/07/31 07:37:55 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-015660ad-4c26-4be3-a789-41d5acbcbc82/userFiles-f680e7d2-efa4-46a5-a4e6-26f8bb04e07b/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.961157","level":"info","event":"25/07/31 07:37:55 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://05a2169a22bf:43339/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:55.961240","level":"info","event":"25/07/31 07:37:55 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-015660ad-4c26-4be3-a789-41d5acbcbc82/userFiles-f680e7d2-efa4-46a5-a4e6-26f8bb04e07b/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.306919","level":"info","event":"25/07/31 07:37:56 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://05a2169a22bf:43339/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.307220","level":"info","event":"25/07/31 07:37:56 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-015660ad-4c26-4be3-a789-41d5acbcbc82/userFiles-f680e7d2-efa4-46a5-a4e6-26f8bb04e07b/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.312486","level":"info","event":"25/07/31 07:37:56 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://05a2169a22bf:43339/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.312549","level":"info","event":"25/07/31 07:37:56 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-015660ad-4c26-4be3-a789-41d5acbcbc82/userFiles-f680e7d2-efa4-46a5-a4e6-26f8bb04e07b/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.337419","level":"info","event":"25/07/31 07:37:56 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://05a2169a22bf:43339/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.337509","level":"info","event":"25/07/31 07:37:56 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-015660ad-4c26-4be3-a789-41d5acbcbc82/userFiles-f680e7d2-efa4-46a5-a4e6-26f8bb04e07b/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.344253","level":"info","event":"25/07/31 07:37:56 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://05a2169a22bf:43339/files/org.tukaani_xz-1.9.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.344349","level":"info","event":"25/07/31 07:37:56 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-015660ad-4c26-4be3-a789-41d5acbcbc82/userFiles-f680e7d2-efa4-46a5-a4e6-26f8bb04e07b/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.346669","level":"info","event":"25/07/31 07:37:56 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://05a2169a22bf:43339/files/io.delta_delta-storage-3.1.0.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.346780","level":"info","event":"25/07/31 07:37:56 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-015660ad-4c26-4be3-a789-41d5acbcbc82/userFiles-f680e7d2-efa4-46a5-a4e6-26f8bb04e07b/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.348569","level":"info","event":"25/07/31 07:37:56 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://05a2169a22bf:43339/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753947475630","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.348756","level":"info","event":"25/07/31 07:37:56 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-015660ad-4c26-4be3-a789-41d5acbcbc82/userFiles-f680e7d2-efa4-46a5-a4e6-26f8bb04e07b/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.422602","level":"info","event":"25/07/31 07:37:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.453078","level":"info","event":"25/07/31 07:37:56 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.6:7077 after 12 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.504265","level":"info","event":"25/07/31 07:37:56 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250731073756-0011","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.505338","level":"info","event":"25/07/31 07:37:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250731073756-0011/0 on worker-20250731025506-172.18.0.8-40691 (172.18.0.8:40691) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.507978","level":"info","event":"25/07/31 07:37:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250731073756-0011/0 on hostPort 172.18.0.8:40691 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.508120","level":"info","event":"25/07/31 07:37:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250731073756-0011/1 on worker-20250731025506-172.18.0.8-40691 (172.18.0.8:40691) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.508427","level":"info","event":"25/07/31 07:37:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250731073756-0011/1 on hostPort 172.18.0.8:40691 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.512445","level":"info","event":"25/07/31 07:37:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44077.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.512567","level":"info","event":"25/07/31 07:37:56 INFO NettyBlockTransferService: Server created on 05a2169a22bf:44077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.514147","level":"info","event":"25/07/31 07:37:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.526004","level":"info","event":"25/07/31 07:37:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 05a2169a22bf, 44077, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.527976","level":"info","event":"25/07/31 07:37:56 INFO BlockManagerMasterEndpoint: Registering block manager 05a2169a22bf:44077 with 127.2 MiB RAM, BlockManagerId(driver, 05a2169a22bf, 44077, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.529201","level":"info","event":"25/07/31 07:37:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 05a2169a22bf, 44077, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.529852","level":"info","event":"25/07/31 07:37:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 05a2169a22bf, 44077, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.568108","level":"info","event":"25/07/31 07:37:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731073756-0011/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.569394","level":"info","event":"25/07/31 07:37:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731073756-0011/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.673230","level":"info","event":"25/07/31 07:37:56 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.817649","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.817775","level":"info","event":"INFO:__main__:Reading parquet data from s3a://activefence-bucket/bbc_tech/bronze","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.821908","level":"info","event":"25/07/31 07:37:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:56.823003","level":"info","event":"25/07/31 07:37:56 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:57.298488","level":"info","event":"25/07/31 07:37:57 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:57.304615","level":"info","event":"25/07/31 07:37:57 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:57.304720","level":"info","event":"25/07/31 07:37:57 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:57.849349","level":"info","event":"25/07/31 07:37:57 INFO InMemoryFileIndex: It took 43 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:57.987191","level":"info","event":"25/07/31 07:37:57 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:49516) with ID 1,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:57.988025","level":"info","event":"25/07/31 07:37:57 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:49508) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.017165","level":"info","event":"25/07/31 07:37:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:40237 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.8, 40237, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.017863","level":"info","event":"25/07/31 07:37:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:34365 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.8, 34365, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.100176","level":"info","event":"25/07/31 07:37:58 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.114425","level":"info","event":"25/07/31 07:37:58 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.114529","level":"info","event":"25/07/31 07:37:58 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.114601","level":"info","event":"25/07/31 07:37:58 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.115100","level":"info","event":"25/07/31 07:37:58 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.117535","level":"info","event":"25/07/31 07:37:58 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.164823","level":"info","event":"25/07/31 07:37:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 108.3 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.228385","level":"info","event":"25/07/31 07:37:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.235822","level":"info","event":"25/07/31 07:37:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 05a2169a22bf:44077 (size: 39.3 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.239370","level":"info","event":"25/07/31 07:37:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.255522","level":"info","event":"25/07/31 07:37:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:37:58.256391","level":"info","event":"25/07/31 07:37:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:01.207454","level":"info","event":"25/07/31 07:38:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 10672 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:01.393851","level":"info","event":"25/07/31 07:38:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:40237 (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:02.786843","level":"info","event":"25/07/31 07:38:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1591 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:02.788351","level":"info","event":"25/07/31 07:38:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:02.794508","level":"info","event":"25/07/31 07:38:02 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 4.660 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:02.797214","level":"info","event":"25/07/31 07:38:02 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:02.797798","level":"info","event":"25/07/31 07:38:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:02.799977","level":"info","event":"25/07/31 07:38:02 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 4.699571 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:02.999823","level":"info","event":"25/07/31 07:38:02 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 05a2169a22bf:44077 in memory (size: 39.3 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.002749","level":"info","event":"25/07/31 07:38:03 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.8:40237 in memory (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194164","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194246","level":"info","event":"|-- article_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194270","level":"info","event":"|-- title: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194290","level":"info","event":"|-- pub_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194324","level":"info","event":"|-- summary: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194350","level":"info","event":"|-- load_timestamp: timestamp_ntz (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194367","level":"info","event":"|-- year_month: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194384","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194429","level":"info","event":"INFO:__main__:Input dataframe schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.194448","level":"info","event":"None","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.402448","level":"info","event":"25/07/31 07:38:03 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.402990","level":"info","event":"25/07/31 07:38:03 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.403301","level":"info","event":"25/07/31 07:38:03 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.563050","level":"info","event":"25/07/31 07:38:03 INFO CodeGenerator: Code generated in 83.519083 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.579198","level":"info","event":"25/07/31 07:38:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.4 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.585673","level":"info","event":"25/07/31 07:38:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.586112","level":"info","event":"25/07/31 07:38:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 05a2169a22bf:44077 (size: 36.8 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.586748","level":"info","event":"25/07/31 07:38:03 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.594138","level":"info","event":"25/07/31 07:38:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 18952167 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.619813","level":"info","event":"25/07/31 07:38:03 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.622251","level":"info","event":"25/07/31 07:38:03 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.622341","level":"info","event":"25/07/31 07:38:03 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.622437","level":"info","event":"25/07/31 07:38:03 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.622743","level":"info","event":"25/07/31 07:38:03 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.623130","level":"info","event":"25/07/31 07:38:03 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.640333","level":"info","event":"25/07/31 07:38:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.641304","level":"info","event":"25/07/31 07:38:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.641664","level":"info","event":"25/07/31 07:38:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 05a2169a22bf:44077 (size: 7.9 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.642022","level":"info","event":"25/07/31 07:38:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.642956","level":"info","event":"25/07/31 07:38:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.643042","level":"info","event":"25/07/31 07:38:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.646890","level":"info","event":"25/07/31 07:38:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11873 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.647160","level":"info","event":"25/07/31 07:38:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11714 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.673917","level":"info","event":"25/07/31 07:38:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.8:40237 (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.757312","level":"info","event":"25/07/31 07:38:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.8:34365 (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:03.933911","level":"info","event":"25/07/31 07:38:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:40237 (size: 36.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.065143","level":"info","event":"25/07/31 07:38:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:34365 (size: 36.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.110489","level":"info","event":"25/07/31 07:38:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 467 ms on 172.18.0.8 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.647353","level":"info","event":"25/07/31 07:38:04 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1000 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.647476","level":"info","event":"25/07/31 07:38:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.648171","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.022 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.648751","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.648956","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.649103","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.649246","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.670536","level":"info","event":"25/07/31 07:38:04 INFO CodeGenerator: Code generated in 5.801541 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.683018","level":"info","event":"25/07/31 07:38:04 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.684136","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.684203","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.684232","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.684368","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.684740","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.691950","level":"info","event":"25/07/31 07:38:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.692578","level":"info","event":"25/07/31 07:38:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.692876","level":"info","event":"25/07/31 07:38:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 05a2169a22bf:44077 (size: 5.9 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.693222","level":"info","event":"25/07/31 07:38:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.693515","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.693557","level":"info","event":"25/07/31 07:38:04 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.695591","level":"info","event":"25/07/31 07:38:04 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.712687","level":"info","event":"25/07/31 07:38:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:34365 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.741308","level":"info","event":"25/07/31 07:38:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:49508","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.796676","level":"info","event":"25/07/31 07:38:04 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 102 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.796794","level":"info","event":"25/07/31 07:38:04 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.797311","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.107 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.797461","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.797492","level":"info","event":"25/07/31 07:38:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.797778","level":"info","event":"25/07/31 07:38:04 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.114638 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.801776","level":"info","event":"INFO:__main__:Number of rows read from bronze layer: 2755","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.919806","level":"info","event":"25/07/31 07:38:04 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 05a2169a22bf:44077 in memory (size: 7.9 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.922041","level":"info","event":"25/07/31 07:38:04 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.8:40237 in memory (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.922446","level":"info","event":"25/07/31 07:38:04 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.923792","level":"info","event":"25/07/31 07:38:04 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.8:34365 in memory (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.928532","level":"info","event":"25/07/31 07:38:04 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 05a2169a22bf:44077 in memory (size: 5.9 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.930263","level":"info","event":"25/07/31 07:38:04 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:34365 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:04.954620","level":"info","event":"25/07/31 07:38:04 INFO DeltaLog: Loading version 7.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.309761","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 05a2169a22bf:44077 in memory (size: 36.8 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.312068","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:40237 in memory (size: 36.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.312413","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:34365 in memory (size: 36.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.533517","level":"info","event":"25/07/31 07:38:05 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 8, totalFileSize: 18609)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.595567","level":"info","event":"25/07/31 07:38:05 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.597449","level":"info","event":"25/07/31 07:38:05 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.597634","level":"info","event":"25/07/31 07:38:05 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#75.minReaderVersion) OR isnotnull(metaData#74.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.648823","level":"info","event":"25/07/31 07:38:05 INFO CodeGenerator: Code generated in 38.310208 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.650989","level":"info","event":"25/07/31 07:38:05 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 206.0 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.656197","level":"info","event":"25/07/31 07:38:05 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.656620","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 05a2169a22bf:44077 (size: 36.5 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.657197","level":"info","event":"25/07/31 07:38:05 INFO SparkContext: Created broadcast 4 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.666763","level":"info","event":"25/07/31 07:38:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 16786520 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.703477","level":"info","event":"25/07/31 07:38:05 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.704205","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: Got job 3 (toString at String.java:4220) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.704258","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: Final stage: ResultStage 4 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.704291","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.704408","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.704654","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[12] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.705967","level":"info","event":"25/07/31 07:38:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 40.1 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.706739","level":"info","event":"25/07/31 07:38:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.707246","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 05a2169a22bf:44077 (size: 13.7 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.707620","level":"info","event":"25/07/31 07:38:05 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.708044","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[12] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.708146","level":"info","event":"25/07/31 07:38:05 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.709188","level":"info","event":"25/07/31 07:38:05 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11643 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.709395","level":"info","event":"25/07/31 07:38:05 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5) (172.18.0.8, executor 1, partition 1, PROCESS_LOCAL, 11643 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.718791","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:34365 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.719067","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:40237 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.864652","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:34365 (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.867094","level":"info","event":"25/07/31 07:38:05 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:40237 (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.932596","level":"info","event":"25/07/31 07:38:05 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 224 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.935397","level":"info","event":"25/07/31 07:38:05 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 226 ms on 172.18.0.8 (executor 1) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.935471","level":"info","event":"25/07/31 07:38:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.935847","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: ResultStage 4 (toString at String.java:4220) finished in 0.230 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.935973","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.936008","level":"info","event":"25/07/31 07:38:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.936274","level":"info","event":"25/07/31 07:38:05 INFO DAGScheduler: Job 3 finished: toString at String.java:4220, took 0.232732 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.974824","level":"info","event":"25/07/31 07:38:05 INFO CodeGenerator: Code generated in 26.756833 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:05.978773","level":"info","event":"25/07/31 07:38:05 INFO Snapshot: [tableId=42ecd9da-7d08-43eb-9188-45a76010f11a] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=7, metadata=Metadata(934fe67a-3cdb-4bd9-9244-c2df2ca4d973,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930718246)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,7,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1753930720698; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=d47aaa5e0705bd3da0aee32518e8b6b8 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000001.json; isDirectory=false; length=2196; replication=1; blocksize=33554432; modification_time=1753930939939; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=4558ffddef68d813b66e7e8ab8b486e3 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000002.json; isDirectory=false; length=2400; replication=1; blocksize=33554432; modification_time=1753938633963; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=4ab3154a2f34f4d994c9f01ad937ee22 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000003.json; isDirectory=false; length=2402; replication=1; blocksize=33554432; modification_time=1753938843318; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=6d035414d31d26dff9de54dd346a8a9c versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000004.json; isDirectory=false; length=2402; replication=1; blocksize=33554432; modification_time=1753939815104; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=b94927f72c3c27abf593e1fce55731a1 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000005.json; isDirectory=false; length=2404; replication=1; blocksize=33554432; modification_time=1753946527641; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f723ac7d3ce127b990ff925c56e3d7a7 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000006.json; isDirectory=false; length=2405; replication=1; blocksize=33554432; modification_time=1753946661934; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=11b149ee52ec9f92917f70fbc4017113 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000007.json; isDirectory=false; length=2405; replication=1; blocksize=33554432; modification_time=1753947074487; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f0bb873327b18a375fd10a8f6eba7349 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@2aed2538,1753947074487), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.114495","level":"info","event":"25/07/31 07:38:06 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Compute snapshot for version: 7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.124901","level":"info","event":"25/07/31 07:38:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 205.7 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.130086","level":"info","event":"25/07/31 07:38:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.130495","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 05a2169a22bf:44077 (size: 36.4 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.131275","level":"info","event":"25/07/31 07:38:06 INFO SparkContext: Created broadcast 6 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.310750","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 05a2169a22bf:44077 in memory (size: 13.7 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.312662","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:34365 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.313686","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:40237 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.406431","level":"info","event":"25/07/31 07:38:06 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.406534","level":"info","event":"25/07/31 07:38:06 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.406600","level":"info","event":"25/07/31 07:38:06 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.415541","level":"info","event":"25/07/31 07:38:06 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.495662","level":"info","event":"25/07/31 07:38:06 INFO CodeGenerator: Code generated in 57.363583 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.498969","level":"info","event":"25/07/31 07:38:06 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 206.0 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.503345","level":"info","event":"25/07/31 07:38:06 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.503744","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 05a2169a22bf:44077 (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.504479","level":"info","event":"25/07/31 07:38:06 INFO SparkContext: Created broadcast 7 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.505212","level":"info","event":"25/07/31 07:38:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 16786520 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.517288","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 05a2169a22bf:44077 in memory (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.520249","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:34365 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.521689","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:40237 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.528389","level":"info","event":"25/07/31 07:38:06 INFO DAGScheduler: Registering RDD 16 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.528460","level":"info","event":"25/07/31 07:38:06 INFO DAGScheduler: Got map stage job 4 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.528487","level":"info","event":"25/07/31 07:38:06 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.528510","level":"info","event":"25/07/31 07:38:06 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.528639","level":"info","event":"25/07/31 07:38:06 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.528899","level":"info","event":"25/07/31 07:38:06 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[16] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.531126","level":"info","event":"25/07/31 07:38:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 105.6 KiB, free 126.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.531716","level":"info","event":"25/07/31 07:38:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 126.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.532085","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 05a2169a22bf:44077 (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.532328","level":"info","event":"25/07/31 07:38:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.532589","level":"info","event":"25/07/31 07:38:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[16] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.532624","level":"info","event":"25/07/31 07:38:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.533267","level":"info","event":"25/07/31 07:38:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11632 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.533467","level":"info","event":"25/07/31 07:38:06 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11632 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.541513","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:40237 (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.541660","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:34365 (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.748087","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:34365 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:06.748182","level":"info","event":"25/07/31 07:38:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:40237 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.239574","level":"info","event":"25/07/31 07:38:07 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 706 ms on 172.18.0.8 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.239686","level":"info","event":"25/07/31 07:38:07 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 706 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.239761","level":"info","event":"25/07/31 07:38:07 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.240293","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: ShuffleMapStage 5 (save at NativeMethodAccessorImpl.java:0) finished in 0.711 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.240334","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.240374","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.240402","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.240430","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.277861","level":"info","event":"25/07/31 07:38:07 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 05a2169a22bf:44077 in memory (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.280481","level":"info","event":"25/07/31 07:38:07 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.8:34365 in memory (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.280844","level":"info","event":"25/07/31 07:38:07 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.8:40237 in memory (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.422879","level":"info","event":"25/07/31 07:38:07 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.422985","level":"info","event":"25/07/31 07:38:07 INFO CodeGenerator: Code generated in 131.158584 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.454904","level":"info","event":"25/07/31 07:38:07 INFO CodeGenerator: Code generated in 22.347958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.571455","level":"info","event":"25/07/31 07:38:07 INFO CodeGenerator: Code generated in 22.378708 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.574864","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: Registering RDD 26 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.574939","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: Got map stage job 5 (save at NativeMethodAccessorImpl.java:0) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.574967","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.574988","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.576096","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.576381","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[26] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.596653","level":"info","event":"25/07/31 07:38:07 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 603.4 KiB, free 126.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.597669","level":"info","event":"25/07/31 07:38:07 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 138.3 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.597992","level":"info","event":"25/07/31 07:38:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 05a2169a22bf:44077 (size: 138.3 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.598299","level":"info","event":"25/07/31 07:38:07 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.598574","level":"info","event":"25/07/31 07:38:07 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[26] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.598630","level":"info","event":"25/07/31 07:38:07 INFO TaskSchedulerImpl: Adding task set 7.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.599428","level":"info","event":"25/07/31 07:38:07 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8) (172.18.0.8, executor 0, partition 1, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.599563","level":"info","event":"25/07/31 07:38:07 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 9) (172.18.0.8, executor 1, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.606980","level":"info","event":"25/07/31 07:38:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:34365 (size: 138.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.610653","level":"info","event":"25/07/31 07:38:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:40237 (size: 138.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.701581","level":"info","event":"25/07/31 07:38:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:49508","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.703757","level":"info","event":"25/07/31 07:38:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:49516","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.952292","level":"info","event":"25/07/31 07:38:07 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.18.0.8:40237 (size: 806.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:07.961340","level":"info","event":"25/07/31 07:38:07 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.18.0.8:34365 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.227132","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 10) (172.18.0.8, executor 0, partition 6, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.228562","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 629 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.235763","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 11) (172.18.0.8, executor 1, partition 8, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.236243","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 9) in 636 ms on 172.18.0.8 (executor 1) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.268503","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.18.0.8:34365 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.275393","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.18.0.8:40237 (size: 305.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.292075","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 12) (172.18.0.8, executor 0, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.292516","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 10) in 66 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.299735","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 13) (172.18.0.8, executor 1, partition 17, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.300248","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 11) in 64 ms on 172.18.0.8 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.323457","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_10 in memory on 172.18.0.8:34365 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.335055","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_17 in memory on 172.18.0.8:40237 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.340059","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 14) (172.18.0.8, executor 0, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.340820","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 12) in 49 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.357432","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 15) (172.18.0.8, executor 1, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.357758","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 13) in 58 ms on 172.18.0.8 (executor 1) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.379746","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_27 in memory on 172.18.0.8:34365 (size: 692.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.394368","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_30 in memory on 172.18.0.8:40237 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.404752","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 16) (172.18.0.8, executor 0, partition 34, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.406908","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 14) in 65 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.417991","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 17) (172.18.0.8, executor 1, partition 37, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.420195","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 15) in 62 ms on 172.18.0.8 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.433808","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_34 in memory on 172.18.0.8:34365 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.450886","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 18) (172.18.0.8, executor 0, partition 39, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.451483","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 16) in 47 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.455037","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_37 in memory on 172.18.0.8:40237 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.480842","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 19) (172.18.0.8, executor 1, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.480935","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 17) in 63 ms on 172.18.0.8 (executor 1) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.484085","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_39 in memory on 172.18.0.8:34365 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.501279","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 20) (172.18.0.8, executor 0, partition 44, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.501764","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 18) in 51 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.533345","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_44 in memory on 172.18.0.8:34365 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.550743","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 21) (172.18.0.8, executor 0, partition 45, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.551255","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 20) in 51 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.579904","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_45 in memory on 172.18.0.8:34365 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.597937","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 22) (172.18.0.8, executor 0, partition 47, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.598235","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 21) in 48 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.622673","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_47 in memory on 172.18.0.8:34365 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.634175","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 23) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.634622","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 22) in 37 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.638923","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_42 in memory on 172.18.0.8:40237 (size: 562.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.655902","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.655985","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 24) (172.18.0.8, executor 1, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.656343","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 19) in 177 ms on 172.18.0.8 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.668040","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 25) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.668543","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 23) in 35 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.688228","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.691768","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.703784","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 26) (172.18.0.8, executor 1, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.704035","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 24) in 48 ms on 172.18.0.8 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.705559","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 27) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.705968","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 25) in 38 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.728420","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.736390","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.742661","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 28) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.743031","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 27) in 37 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.752012","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 29) (172.18.0.8, executor 1, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.752331","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 26) in 49 ms on 172.18.0.8 (executor 1) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.766788","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.778153","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 30) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.778505","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 28) in 36 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.784920","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_11 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.797386","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_12 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.801988","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 31) (172.18.0.8, executor 1, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.802218","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 29) in 51 ms on 172.18.0.8 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.807026","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 32) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.807388","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 30) in 30 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.826519","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_14 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.832886","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_13 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.836045","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 33) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.836608","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 32) in 30 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.848233","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 34) (172.18.0.8, executor 1, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.848453","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 31) in 47 ms on 172.18.0.8 (executor 1) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.856485","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_15 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.869814","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 35) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.870116","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 33) in 34 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.889558","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_18 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.889760","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_16 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.902083","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 36) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.903095","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 35) in 33 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.909308","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 37) (172.18.0.8, executor 1, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.909768","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 34) in 62 ms on 172.18.0.8 (executor 1) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.921648","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_19 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.932114","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 38) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.932538","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 36) in 31 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.944752","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_20 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.949489","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_21 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.958615","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 39) (172.18.0.8, executor 1, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.958787","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 37) in 50 ms on 172.18.0.8 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.959092","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 40) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.959573","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 38) in 28 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.977507","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_23 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.987719","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 41) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.987979","level":"info","event":"25/07/31 07:38:08 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 40) in 29 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:08.991382","level":"info","event":"25/07/31 07:38:08 INFO BlockManagerInfo: Added rdd_23_22 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.008382","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 42) (172.18.0.8, executor 1, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.009544","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 39) in 51 ms on 172.18.0.8 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.036092","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_24 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.046166","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_25 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.048322","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 43) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.048731","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 41) in 61 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.056899","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 44) (172.18.0.8, executor 1, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.057599","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 42) in 50 ms on 172.18.0.8 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.075372","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_26 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.078005","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_28 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.088343","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 45) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.088635","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 43) in 40 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.089022","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 46) (172.18.0.8, executor 1, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.089200","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 44) in 33 ms on 172.18.0.8 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.110655","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_31 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.114749","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_29 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.122334","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 47) (172.18.0.8, executor 1, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.122666","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 46) in 34 ms on 172.18.0.8 (executor 1) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.134617","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 48) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.134979","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 45) in 47 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.142545","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_32 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.154817","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 49) (172.18.0.8, executor 1, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.155095","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 47) in 33 ms on 172.18.0.8 (executor 1) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.164096","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_33 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.175409","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_35 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.178240","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 50) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.178645","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 48) in 44 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.185510","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 51) (172.18.0.8, executor 1, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.185720","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 49) in 31 ms on 172.18.0.8 (executor 1) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.208221","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_38 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.208304","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_36 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.219938","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 52) (172.18.0.8, executor 1, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.220291","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 51) in 35 ms on 172.18.0.8 (executor 1) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.223330","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 53) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.223615","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 50) in 46 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.241373","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_40 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.254836","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 54) (172.18.0.8, executor 1, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.255239","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 52) in 35 ms on 172.18.0.8 (executor 1) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.261471","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_41 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.271855","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 55) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.272138","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 53) in 48 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.279416","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_43 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.289151","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 56) (172.18.0.8, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.289454","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_46 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.289532","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 54) in 35 ms on 172.18.0.8 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.297069","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 57) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.297644","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 55) in 26 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.309950","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_48 in memory on 172.18.0.8:40237 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.311238","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added rdd_23_49 in memory on 172.18.0.8:34365 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.318576","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 57) in 22 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.319955","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 56) in 31 ms on 172.18.0.8 (executor 1) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.320016","level":"info","event":"25/07/31 07:38:09 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.320318","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0) finished in 1.741 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.320388","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.320436","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.320472","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.320495","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.338456","level":"info","event":"25/07/31 07:38:09 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.339128","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Got job 6 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.339170","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Final stage: ResultStage 10 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.339194","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.339215","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.339456","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[29] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.341763","level":"info","event":"25/07/31 07:38:09 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 534.7 KiB, free 125.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.343372","level":"info","event":"25/07/31 07:38:09 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 124.6 KiB, free 125.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.343664","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 05a2169a22bf:44077 (size: 124.6 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.343993","level":"info","event":"25/07/31 07:38:09 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.344164","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[29] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.344193","level":"info","event":"25/07/31 07:38:09 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.344844","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 58) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.349727","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:40237 (size: 124.6 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.355657","level":"info","event":"25/07/31 07:38:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:49516","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.384266","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 58) in 40 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.384348","level":"info","event":"25/07/31 07:38:09 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.384576","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: ResultStage 10 (save at NativeMethodAccessorImpl.java:0) finished in 0.045 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.384678","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.384729","level":"info","event":"25/07/31 07:38:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.385003","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Job 6 finished: save at NativeMethodAccessorImpl.java:0, took 0.046409 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.409916","level":"info","event":"25/07/31 07:38:09 INFO CodeGenerator: Code generated in 16.703875 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.411117","level":"info","event":"25/07/31 07:38:09 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.454777","level":"info","event":"25/07/31 07:38:09 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.456287","level":"info","event":"25/07/31 07:38:09 INFO FileSourceStrategy: Pushed Filters: IsNotNull(article_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.456353","level":"info","event":"25/07/31 07:38:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(article_id#0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.479993","level":"info","event":"25/07/31 07:38:09 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.497060","level":"info","event":"25/07/31 07:38:09 INFO CodeGenerator: Code generated in 6.2585 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.499130","level":"info","event":"25/07/31 07:38:09 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 208.0 KiB, free 125.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.502308","level":"info","event":"25/07/31 07:38:09 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 125.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.502614","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 05a2169a22bf:44077 (size: 37.0 KiB, free: 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.502962","level":"info","event":"25/07/31 07:38:09 INFO SparkContext: Created broadcast 11 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.503589","level":"info","event":"25/07/31 07:38:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 18952167 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.522348","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 05a2169a22bf:44077 in memory (size: 124.6 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.523031","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.8:40237 in memory (size: 124.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.526790","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 05a2169a22bf:44077 in memory (size: 138.3 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.527686","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.8:40237 in memory (size: 138.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.527983","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.8:34365 in memory (size: 138.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.538904","level":"info","event":"25/07/31 07:38:09 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.539350","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Got job 7 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.539404","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Final stage: ResultStage 11 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.539430","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.539508","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.539752","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[32] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.551836","level":"info","event":"25/07/31 07:38:09 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 358.2 KiB, free 126.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.554306","level":"info","event":"25/07/31 07:38:09 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 127.8 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.554573","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 05a2169a22bf:44077 (size: 127.8 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.554938","level":"info","event":"25/07/31 07:38:09 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.555193","level":"info","event":"25/07/31 07:38:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[32] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.555231","level":"info","event":"25/07/31 07:38:09 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.555959","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 59) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11884 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.556074","level":"info","event":"25/07/31 07:38:09 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 60) (172.18.0.8, executor 1, partition 1, PROCESS_LOCAL, 11725 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.563235","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:40237 (size: 127.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.563307","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:34365 (size: 127.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.605081","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:40237 (size: 37.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:09.851203","level":"info","event":"25/07/31 07:38:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:34365 (size: 37.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.172751","level":"info","event":"25/07/31 07:38:10 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 60) in 617 ms on 172.18.0.8 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.253817","level":"info","event":"25/07/31 07:38:10 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 59) in 698 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.253914","level":"info","event":"25/07/31 07:38:10 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.254957","level":"info","event":"25/07/31 07:38:10 INFO DAGScheduler: ResultStage 11 (save at NativeMethodAccessorImpl.java:0) finished in 0.714 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.255090","level":"info","event":"25/07/31 07:38:10 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.255144","level":"info","event":"25/07/31 07:38:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.255327","level":"info","event":"25/07/31 07:38:10 INFO DAGScheduler: Job 7 finished: save at NativeMethodAccessorImpl.java:0, took 0.716344 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.256668","level":"info","event":"25/07/31 07:38:10 INFO DeltaFileFormatWriter: Start to commit write Job 08761624-6ddb-4f56-96d0-1e4f265098c3.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.257665","level":"info","event":"25/07/31 07:38:10 INFO DeltaFileFormatWriter: Write Job 08761624-6ddb-4f56-96d0-1e4f265098c3 committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:10.259473","level":"info","event":"25/07/31 07:38:10 INFO DeltaFileFormatWriter: Finished processing stats for write job 08761624-6ddb-4f56-96d0-1e4f265098c3.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:11.843526","level":"info","event":"25/07/31 07:38:11 INFO CodeGenerator: Code generated in 1434.9665 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.221985","level":"info","event":"25/07/31 07:38:12 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.223898","level":"info","event":"25/07/31 07:38:12 INFO DAGScheduler: Got job 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.223962","level":"info","event":"25/07/31 07:38:12 INFO DAGScheduler: Final stage: ResultStage 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.223987","level":"info","event":"25/07/31 07:38:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.225296","level":"info","event":"25/07/31 07:38:12 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.227365","level":"info","event":"25/07/31 07:38:12 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[34] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.290014","level":"info","event":"25/07/31 07:38:12 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 684.9 KiB, free 125.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.299341","level":"info","event":"25/07/31 07:38:12 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 154.4 KiB, free 125.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.300339","level":"info","event":"25/07/31 07:38:12 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 05a2169a22bf:44077 (size: 154.4 KiB, free: 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.308403","level":"info","event":"25/07/31 07:38:12 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.332049","level":"info","event":"25/07/31 07:38:12 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 13 (MapPartitionsRDD[34] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.352320","level":"info","event":"25/07/31 07:38:12 INFO TaskSchedulerImpl: Adding task set 13.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.518466","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 61) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.526383","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 62) (172.18.0.8, executor 1, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.732678","level":"info","event":"25/07/31 07:38:12 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:40237 (size: 154.4 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.733864","level":"info","event":"25/07/31 07:38:12 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:34365 (size: 154.4 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.898712","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 63) (172.18.0.8, executor 1, partition 3, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.900337","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 62) in 383 ms on 172.18.0.8 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.900413","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 64) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.900441","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 61) in 405 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.913375","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 65) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.915104","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 66) (172.18.0.8, executor 1, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.915159","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 64) in 18 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:12.915186","level":"info","event":"25/07/31 07:38:12 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 63) in 19 ms on 172.18.0.8 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:13.025078","level":"info","event":"25/07/31 07:38:13 INFO TaskSetManager: Starting task 8.0 in stage 13.0 (TID 67) (172.18.0.8, executor 1, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:13.040894","level":"info","event":"25/07/31 07:38:13 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 68) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:13.051467","level":"info","event":"25/07/31 07:38:13 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 66) in 126 ms on 172.18.0.8 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:13.075469","level":"info","event":"25/07/31 07:38:13 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 65) in 143 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:13.288410","level":"info","event":"25/07/31 07:38:13 INFO TaskSetManager: Starting task 7.0 in stage 13.0 (TID 69) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:13.312509","level":"info","event":"25/07/31 07:38:13 INFO TaskSetManager: Finished task 6.0 in stage 13.0 (TID 68) in 278 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:13.456957","level":"info","event":"25/07/31 07:38:13 INFO TaskSetManager: Starting task 11.0 in stage 13.0 (TID 70) (172.18.0.8, executor 1, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:13.547729","level":"info","event":"25/07/31 07:38:13 INFO TaskSetManager: Finished task 8.0 in stage 13.0 (TID 67) in 507 ms on 172.18.0.8 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:25.906328","level":"info","event":"25/07/31 07:38:25 INFO TaskSetManager: Starting task 9.0 in stage 13.0 (TID 71) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:27.134313","level":"info","event":"25/07/31 07:38:26 INFO TaskSetManager: Finished task 7.0 in stage 13.0 (TID 69) in 13406 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T07:38:36.669289","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 1 --executor-memory 1g --driver-memory 512m --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py. Error code is: -9.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":867,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1159,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":570,"name":"submit"}],"is_group":false,"exceptions":[]}]}
