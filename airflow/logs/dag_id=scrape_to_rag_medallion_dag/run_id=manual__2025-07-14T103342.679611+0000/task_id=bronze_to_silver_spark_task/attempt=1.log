{"timestamp":"2025-07-14T10:34:21.657088","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-14T10:34:21.657712","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-14T10:34:30.672960","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-14T10:34:30.675344","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:30.741736","level":"info","event":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.324951","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471194","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471628","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471729","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471782","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471829","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471872","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471914","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471955","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.471997","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472047","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472087","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472123","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472159","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472195","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472232","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472268","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472305","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.472354","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.473009","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.473289","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.473528","level":"info","event":"primaryResource         file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.473754","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.473873","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.473971","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.474062","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.474370","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.474538","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.474750","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.474857","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.474981","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475189","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475293","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475373","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475451","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475529","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475604","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475680","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475763","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475842","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475918","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.475992","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.476067","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.476142","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.655163","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.746272","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.746535","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.753325","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.753616","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.753687","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.753735","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.758474","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-23b3bbc3-c1be-4700-8677-50b5e32615b0;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.758768","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:32.979124","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.015453","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.038487","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.073936","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.095820","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.119450","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.142457","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.160511","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.197560","level":"info","event":":: resolution report :: resolve 419ms :: artifacts dl 20ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198048","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198193","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198279","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198347","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198414","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198494","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198633","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198733","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198782","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198827","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198894","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.198980","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.199033","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.199075","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.199117","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.199166","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.199204","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.207083","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-23b3bbc3-c1be-4700-8677-50b5e32615b0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.207438","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.217484","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/10ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.472712","level":"info","event":"25/07/14 10:34:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.684670","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.684854","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.684930","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.684977","level":"info","event":"file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.685022","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690096","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690314","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690391","level":"info","event":"(spark.app.submitTime,1752489273655)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690443","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690490","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690532","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690575","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690625","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690667","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690762","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690825","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690873","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690916","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.690994","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691054","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691147","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691206","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691254","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691353","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691404","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691449","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691530","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691581","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691660","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691714","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.691807","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.692057","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.692186","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:33.692253","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.479841","level":"info","event":"25/07/14 10:34:35 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.480849","level":"info","event":"25/07/14 10:34:35 INFO SparkContext: OS info Linux, 5.15.153.1-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.481429","level":"info","event":"25/07/14 10:34:35 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.508522","level":"info","event":"25/07/14 10:34:35 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.508751","level":"info","event":"25/07/14 10:34:35 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.509113","level":"info","event":"25/07/14 10:34:35 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.509397","level":"info","event":"25/07/14 10:34:35 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.528419","level":"info","event":"25/07/14 10:34:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.538326","level":"info","event":"25/07/14 10:34:35 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.540015","level":"info","event":"25/07/14 10:34:35 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.593339","level":"info","event":"25/07/14 10:34:35 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.593640","level":"info","event":"25/07/14 10:34:35 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.594064","level":"info","event":"25/07/14 10:34:35 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.594325","level":"info","event":"25/07/14 10:34:35 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.594578","level":"info","event":"25/07/14 10:34:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.876924","level":"info","event":"25/07/14 10:34:35 INFO Utils: Successfully started service 'sparkDriver' on port 33153.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.905604","level":"info","event":"25/07/14 10:34:35 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.938566","level":"info","event":"25/07/14 10:34:35 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.954362","level":"info","event":"25/07/14 10:34:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.954863","level":"info","event":"25/07/14 10:34:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.958400","level":"info","event":"25/07/14 10:34:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.979245","level":"info","event":"25/07/14 10:34:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-36284355-bbe1-4844-9587-42a37c91317c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:35.994285","level":"info","event":"25/07/14 10:34:35 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.009939","level":"info","event":"25/07/14 10:34:36 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.135712","level":"info","event":"25/07/14 10:34:36 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.208599","level":"info","event":"25/07/14 10:34:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.251430","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://390343db465a:33153/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.251877","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://390343db465a:33153/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.252190","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://390343db465a:33153/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.252297","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://390343db465a:33153/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.252788","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://390343db465a:33153/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.252976","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://390343db465a:33153/jars/org.tukaani_xz-1.9.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.253227","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://390343db465a:33153/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.253449","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://390343db465a:33153/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.259078","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://390343db465a:33153/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.260197","level":"info","event":"25/07/14 10:34:36 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/userFiles-1a0a2b7e-5ce8-44c2-b929-328449a029a8/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.275310","level":"info","event":"25/07/14 10:34:36 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://390343db465a:33153/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:36.275484","level":"info","event":"25/07/14 10:34:36 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/userFiles-1a0a2b7e-5ce8-44c2-b929-328449a029a8/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.289170","level":"info","event":"25/07/14 10:34:38 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://390343db465a:33153/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.289852","level":"info","event":"25/07/14 10:34:38 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/userFiles-1a0a2b7e-5ce8-44c2-b929-328449a029a8/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.297063","level":"info","event":"25/07/14 10:34:38 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://390343db465a:33153/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.297767","level":"info","event":"25/07/14 10:34:38 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/userFiles-1a0a2b7e-5ce8-44c2-b929-328449a029a8/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.333300","level":"info","event":"25/07/14 10:34:38 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://390343db465a:33153/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.333586","level":"info","event":"25/07/14 10:34:38 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/userFiles-1a0a2b7e-5ce8-44c2-b929-328449a029a8/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.342754","level":"info","event":"25/07/14 10:34:38 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://390343db465a:33153/files/org.tukaani_xz-1.9.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.342956","level":"info","event":"25/07/14 10:34:38 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/userFiles-1a0a2b7e-5ce8-44c2-b929-328449a029a8/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.349653","level":"info","event":"25/07/14 10:34:38 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://390343db465a:33153/files/io.delta_delta-storage-3.1.0.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.349830","level":"info","event":"25/07/14 10:34:38 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/userFiles-1a0a2b7e-5ce8-44c2-b929-328449a029a8/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.355509","level":"info","event":"25/07/14 10:34:38 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://390343db465a:33153/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1752489275470","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.355812","level":"info","event":"25/07/14 10:34:38 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/userFiles-1a0a2b7e-5ce8-44c2-b929-328449a029a8/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.448129","level":"info","event":"25/07/14 10:34:38 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.505124","level":"info","event":"25/07/14 10:34:38 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.6:7077 after 29 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.609669","level":"info","event":"25/07/14 10:34:38 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250714103438-0002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.620888","level":"info","event":"25/07/14 10:34:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250714103438-0002/0 on worker-20250714100205-172.21.0.8-45663 (172.21.0.8:45663) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.621257","level":"info","event":"25/07/14 10:34:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43951.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.621930","level":"info","event":"25/07/14 10:34:38 INFO NettyBlockTransferService: Server created on 390343db465a:43951","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.623017","level":"info","event":"25/07/14 10:34:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250714103438-0002/0 on hostPort 172.21.0.8:45663 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.624645","level":"info","event":"25/07/14 10:34:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.630900","level":"info","event":"25/07/14 10:34:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 390343db465a, 43951, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.636059","level":"info","event":"25/07/14 10:34:38 INFO BlockManagerMasterEndpoint: Registering block manager 390343db465a:43951 with 434.4 MiB RAM, BlockManagerId(driver, 390343db465a, 43951, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.639747","level":"info","event":"25/07/14 10:34:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 390343db465a, 43951, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.640861","level":"info","event":"25/07/14 10:34:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 390343db465a, 43951, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.817864","level":"info","event":"25/07/14 10:34:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250714103438-0002/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:38.888187","level":"info","event":"25/07/14 10:34:38 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:39.221879","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:39.229254","level":"info","event":"25/07/14 10:34:39 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:39.233307","level":"info","event":"25/07/14 10:34:39 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:40.720366","level":"info","event":"25/07/14 10:34:40 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:40.732683","level":"info","event":"25/07/14 10:34:40 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:40.732931","level":"info","event":"25/07/14 10:34:40 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.203609","level":"info","event":"25/07/14 10:34:42 INFO InMemoryFileIndex: It took 127 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.849784","level":"info","event":"25/07/14 10:34:42 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.878398","level":"info","event":"25/07/14 10:34:42 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.878642","level":"info","event":"25/07/14 10:34:42 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.878910","level":"info","event":"25/07/14 10:34:42 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.881199","level":"info","event":"25/07/14 10:34:42 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.886518","level":"info","event":"25/07/14 10:34:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.959890","level":"info","event":"25/07/14 10:34:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 108.2 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:42.983838","level":"info","event":"25/07/14 10:34:42 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.8:46872) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:43.082745","level":"info","event":"25/07/14 10:34:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:43.086741","level":"info","event":"25/07/14 10:34:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 390343db465a:43951 (size: 39.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:43.092841","level":"info","event":"25/07/14 10:34:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:43.127406","level":"info","event":"25/07/14 10:34:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:43.128751","level":"info","event":"25/07/14 10:34:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:43.186803","level":"info","event":"25/07/14 10:34:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.21.0.8:41043 with 1048.8 MiB RAM, BlockManagerId(0, 172.21.0.8, 41043, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:48.574691","level":"info","event":"25/07/14 10:34:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 10672 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:48.964500","level":"info","event":"25/07/14 10:34:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.21.0.8:41043 (size: 39.2 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:51.580613","level":"info","event":"25/07/14 10:34:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3030 ms on 172.21.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:51.582764","level":"info","event":"25/07/14 10:34:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:51.591514","level":"info","event":"25/07/14 10:34:51 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 8.685 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:51.594248","level":"info","event":"25/07/14 10:34:51 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:51.594398","level":"info","event":"25/07/14 10:34:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:51.596110","level":"info","event":"25/07/14 10:34:51 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 8.745980 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:51.667990","level":"info","event":"25/07/14 10:34:51 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 390343db465a:43951 in memory (size: 39.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:51.679779","level":"info","event":"25/07/14 10:34:51 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.21.0.8:41043 in memory (size: 39.2 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:53.189407","level":"info","event":"25/07/14 10:34:53 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:53.215231","level":"info","event":"25/07/14 10:34:53 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:54.301718","level":"info","event":"25/07/14 10:34:54 INFO InitialSnapshot: [tableId=d80bebd5-957c-495c-ba34-ab64aa51ffa9] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(3fea67d9-c925-4526-b074-5d858ac65db8,null,null,Format(parquet,Map()),null,List(),Map(),Some(1752489294295)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@1bea88cf,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:54.409922","level":"info","event":"25/07/14 10:34:54 INFO DeltaLog: No delta log found for the Delta table at s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:54.410725","level":"info","event":"25/07/14 10:34:54 INFO InitialSnapshot: [tableId=3fea67d9-c925-4526-b074-5d858ac65db8] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(a87aa851-bc99-4a45-a09b-6da1f88efafb,null,null,Format(parquet,Map()),null,List(),Map(),Some(1752489294410)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@1bea88cf,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:54.523717","level":"info","event":"25/07/14 10:34:54 INFO OptimisticTransaction: [tableId=a87aa851,txnId=8dca2a33] Updated metadata from - to Metadata(6ea4255e-0d5f-498f-91fb-741c54487f11,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1752489294494))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.023241","level":"info","event":"25/07/14 10:34:55 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.031477","level":"info","event":"25/07/14 10:34:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(article_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.031993","level":"info","event":"25/07/14 10:34:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(article_id#0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.106656","level":"info","event":"25/07/14 10:34:55 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.418567","level":"info","event":"25/07/14 10:34:55 INFO CodeGenerator: Code generated in 212.109346 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.440370","level":"info","event":"25/07/14 10:34:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 208.0 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.454739","level":"info","event":"25/07/14 10:34:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.455502","level":"info","event":"25/07/14 10:34:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 390343db465a:43951 (size: 37.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.457779","level":"info","event":"25/07/14 10:34:55 INFO SparkContext: Created broadcast 1 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.469314","level":"info","event":"25/07/14 10:34:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.602141","level":"info","event":"25/07/14 10:34:55 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.603921","level":"info","event":"25/07/14 10:34:55 INFO DAGScheduler: Got job 1 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.604101","level":"info","event":"25/07/14 10:34:55 INFO DAGScheduler: Final stage: ResultStage 1 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.604176","level":"info","event":"25/07/14 10:34:55 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.604226","level":"info","event":"25/07/14 10:34:55 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.604528","level":"info","event":"25/07/14 10:34:55 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[4] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.654932","level":"info","event":"25/07/14 10:34:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 358.1 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.657859","level":"info","event":"25/07/14 10:34:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 127.7 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.658964","level":"info","event":"25/07/14 10:34:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 390343db465a:43951 (size: 127.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.659963","level":"info","event":"25/07/14 10:34:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.660500","level":"info","event":"25/07/14 10:34:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.660630","level":"info","event":"25/07/14 10:34:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.664244","level":"info","event":"25/07/14 10:34:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 11248 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:55.718280","level":"info","event":"25/07/14 10:34:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.21.0.8:41043 (size: 127.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:57.822216","level":"info","event":"25/07/14 10:34:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.21.0.8:41043 (size: 37.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.729558","level":"info","event":"25/07/14 10:34:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4067 ms on 172.21.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.729794","level":"info","event":"25/07/14 10:34:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.732014","level":"info","event":"25/07/14 10:34:59 INFO DAGScheduler: ResultStage 1 (save at NativeMethodAccessorImpl.java:0) finished in 4.123 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.732294","level":"info","event":"25/07/14 10:34:59 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.732418","level":"info","event":"25/07/14 10:34:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.734708","level":"info","event":"25/07/14 10:34:59 INFO DAGScheduler: Job 1 finished: save at NativeMethodAccessorImpl.java:0, took 4.132097 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.738179","level":"info","event":"25/07/14 10:34:59 INFO DeltaFileFormatWriter: Start to commit write Job 66021552-ac22-4a20-be23-1d2655c6e763.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.740065","level":"info","event":"25/07/14 10:34:59 INFO DeltaFileFormatWriter: Write Job 66021552-ac22-4a20-be23-1d2655c6e763 committed. Elapsed time: 1 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:34:59.744214","level":"info","event":"25/07/14 10:34:59 INFO DeltaFileFormatWriter: Finished processing stats for write job 66021552-ac22-4a20-be23-1d2655c6e763.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:00.419312","level":"info","event":"25/07/14 10:35:00 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 390343db465a:43951 in memory (size: 127.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:00.425156","level":"info","event":"25/07/14 10:35:00 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.21.0.8:41043 in memory (size: 127.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:00.995705","level":"info","event":"25/07/14 10:35:00 INFO CodeGenerator: Code generated in 295.627754 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.041338","level":"info","event":"25/07/14 10:35:01 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.042046","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Job 2 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000312 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.122419","level":"info","event":"25/07/14 10:35:01 INFO OptimisticTransaction: [tableId=a87aa851,txnId=8dca2a33] Attempting to commit version 0 with 4 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.388715","level":"info","event":"25/07/14 10:35:01 INFO DeltaLog: Creating a new snapshot v0 for commit version 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.388951","level":"info","event":"25/07/14 10:35:01 INFO DeltaLog: Loading version 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.404336","level":"info","event":"25/07/14 10:35:01 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1998)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.504228","level":"info","event":"25/07/14 10:35:01 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.505032","level":"info","event":"25/07/14 10:35:01 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.505765","level":"info","event":"25/07/14 10:35:01 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#325.minReaderVersion) OR isnotnull(metaData#324.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.550657","level":"info","event":"25/07/14 10:35:01 INFO CodeGenerator: Code generated in 25.708818 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.558776","level":"info","event":"25/07/14 10:35:01 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 206.2 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.573151","level":"info","event":"25/07/14 10:35:01 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.573932","level":"info","event":"25/07/14 10:35:01 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 390343db465a:43951 (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.575223","level":"info","event":"25/07/14 10:35:01 INFO SparkContext: Created broadcast 3 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.591138","level":"info","event":"25/07/14 10:35:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.641006","level":"info","event":"25/07/14 10:35:01 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.642191","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Got job 3 (toString at String.java:4220) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.642345","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Final stage: ResultStage 2 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.642405","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.642451","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.642880","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.645841","level":"info","event":"25/07/14 10:35:01 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.647311","level":"info","event":"25/07/14 10:35:01 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.648523","level":"info","event":"25/07/14 10:35:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 390343db465a:43951 (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.649467","level":"info","event":"25/07/14 10:35:01 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.650224","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.650351","level":"info","event":"25/07/14 10:35:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.652342","level":"info","event":"25/07/14 10:35:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 11166 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.672400","level":"info","event":"25/07/14 10:35:01 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.21.0.8:41043 (size: 13.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.826916","level":"info","event":"25/07/14 10:35:01 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.21.0.8:41043 (size: 36.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.917716","level":"info","event":"25/07/14 10:35:01 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 265 ms on 172.21.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.917995","level":"info","event":"25/07/14 10:35:01 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.919515","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: ResultStage 2 (toString at String.java:4220) finished in 0.275 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.919891","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.919969","level":"info","event":"25/07/14 10:35:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.920542","level":"info","event":"25/07/14 10:35:01 INFO DAGScheduler: Job 3 finished: toString at String.java:4220, took 0.279315 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.967059","level":"info","event":"25/07/14 10:35:01 INFO CodeGenerator: Code generated in 28.777578 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.972630","level":"info","event":"25/07/14 10:35:01 INFO Snapshot: [tableId=a87aa851-bc99-4a45-a09b-6da1f88efafb] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(6ea4255e-0d5f-498f-91fb-741c54487f11,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1752489294494)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1998; replication=1; blocksize=33554432; modification_time=1752489301327; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f2faa5016593f71d7405a9b6bff54479 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@1bea88cf,1752489301327), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.974664","level":"info","event":"25/07/14 10:35:01 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(6ea4255e-0d5f-498f-91fb-741c54487f11,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1752489294494)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1998; replication=1; blocksize=33554432; modification_time=1752489301327; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f2faa5016593f71d7405a9b6bff54479 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@1bea88cf,1752489301327), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.982137","level":"info","event":"25/07/14 10:35:01 INFO Snapshot: [tableId=6ea4255e-0d5f-498f-91fb-741c54487f11] DELTA: Compute snapshot for version: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:01.994185","level":"info","event":"25/07/14 10:35:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 205.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.001977","level":"info","event":"25/07/14 10:35:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.003111","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 390343db465a:43951 (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.004712","level":"info","event":"25/07/14 10:35:02 INFO SparkContext: Created broadcast 5 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.084404","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 390343db465a:43951 in memory (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.091725","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.21.0.8:41043 in memory (size: 13.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.104215","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 390343db465a:43951 in memory (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.106102","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.21.0.8:41043 in memory (size: 36.4 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.306548","level":"info","event":"25/07/14 10:35:02 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.306732","level":"info","event":"25/07/14 10:35:02 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.306798","level":"info","event":"25/07/14 10:35:02 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.358609","level":"info","event":"25/07/14 10:35:02 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.508657","level":"info","event":"25/07/14 10:35:02 INFO CodeGenerator: Code generated in 60.935645 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.512831","level":"info","event":"25/07/14 10:35:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 206.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.520803","level":"info","event":"25/07/14 10:35:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.521633","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 390343db465a:43951 (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.523199","level":"info","event":"25/07/14 10:35:02 INFO SparkContext: Created broadcast 6 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.524283","level":"info","event":"25/07/14 10:35:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.560349","level":"info","event":"25/07/14 10:35:02 INFO DAGScheduler: Registering RDD 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.567596","level":"info","event":"25/07/14 10:35:02 INFO DAGScheduler: Got map stage job 4 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.567885","level":"info","event":"25/07/14 10:35:02 INFO DAGScheduler: Final stage: ShuffleMapStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.568458","level":"info","event":"25/07/14 10:35:02 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.568951","level":"info","event":"25/07/14 10:35:02 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.570125","level":"info","event":"25/07/14 10:35:02 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.580674","level":"info","event":"25/07/14 10:35:02 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 105.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.583078","level":"info","event":"25/07/14 10:35:02 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.583986","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 390343db465a:43951 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.584599","level":"info","event":"25/07/14 10:35:02 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.586637","level":"info","event":"25/07/14 10:35:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.586819","level":"info","event":"25/07/14 10:35:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.589726","level":"info","event":"25/07/14 10:35:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 11155 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.608809","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.21.0.8:41043 (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:02.947778","level":"info","event":"25/07/14 10:35:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.21.0.8:41043 (size: 36.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.046729","level":"info","event":"25/07/14 10:35:03 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 458 ms on 172.21.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.047003","level":"info","event":"25/07/14 10:35:03 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.049138","level":"info","event":"25/07/14 10:35:03 INFO DAGScheduler: ShuffleMapStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.477 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.049481","level":"info","event":"25/07/14 10:35:03 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.049765","level":"info","event":"25/07/14 10:35:03 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.050078","level":"info","event":"25/07/14 10:35:03 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.050286","level":"info","event":"25/07/14 10:35:03 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.087369","level":"info","event":"25/07/14 10:35:03 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 390343db465a:43951 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.092084","level":"info","event":"25/07/14 10:35:03 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.21.0.8:41043 in memory (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.490496","level":"info","event":"25/07/14 10:35:03 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.490782","level":"info","event":"25/07/14 10:35:03 INFO CodeGenerator: Code generated in 300.150356 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:03.614608","level":"info","event":"25/07/14 10:35:03 INFO CodeGenerator: Code generated in 92.553171 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.051643","level":"info","event":"25/07/14 10:35:04 INFO CodeGenerator: Code generated in 97.367989 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.063634","level":"info","event":"25/07/14 10:35:04 INFO DAGScheduler: Registering RDD 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.063903","level":"info","event":"25/07/14 10:35:04 INFO DAGScheduler: Got map stage job 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.063971","level":"info","event":"25/07/14 10:35:04 INFO DAGScheduler: Final stage: ShuffleMapStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.064040","level":"info","event":"25/07/14 10:35:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.068789","level":"info","event":"25/07/14 10:35:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.069740","level":"info","event":"25/07/14 10:35:04 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[26] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.139971","level":"info","event":"25/07/14 10:35:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 603.3 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.149879","level":"info","event":"25/07/14 10:35:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.150915","level":"info","event":"25/07/14 10:35:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 390343db465a:43951 (size: 138.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.151650","level":"info","event":"25/07/14 10:35:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.153653","level":"info","event":"25/07/14 10:35:04 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[26] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.153884","level":"info","event":"25/07/14 10:35:04 INFO TaskSchedulerImpl: Adding task set 5.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.162856","level":"info","event":"25/07/14 10:35:04 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 4) (172.21.0.8, executor 0, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.163319","level":"info","event":"25/07/14 10:35:04 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 5) (172.21.0.8, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.188930","level":"info","event":"25/07/14 10:35:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.21.0.8:41043 (size: 138.2 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:04.380796","level":"info","event":"25/07/14 10:35:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.21.0.8:46872","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.068796","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_42 in memory on 172.21.0.8:41043 (size: 562.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.069748","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_23 in memory on 172.21.0.8:41043 (size: 689.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.374124","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.375171","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 4) in 1215 ms on 172.21.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.376755","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.377727","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 5) in 1215 ms on 172.21.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.482031","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.489611","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.558951","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 8) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.559818","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 187 ms on 172.21.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.567275","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 9) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.568551","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 192 ms on 172.21.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.658761","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.659635","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.715352","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 10) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.716661","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 9) in 150 ms on 172.21.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.719541","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 11) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.720316","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 8) in 161 ms on 172.21.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.796638","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.828859","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.863174","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 12) (172.21.0.8, executor 0, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.863920","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 10) in 149 ms on 172.21.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.884160","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 13) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.885083","level":"info","event":"25/07/14 10:35:05 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 11) in 166 ms on 172.21.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.989020","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:05.993859","level":"info","event":"25/07/14 10:35:05 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.040366","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 14) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.041485","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 12) in 178 ms on 172.21.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.043988","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 15) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.044958","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 13) in 161 ms on 172.21.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.176766","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.177610","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.224832","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 16) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.225522","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 15) in 183 ms on 172.21.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.244588","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 17) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.245307","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 14) in 206 ms on 172.21.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.307615","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_10 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.326940","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_11 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.349272","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 18) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.350476","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 16) in 125 ms on 172.21.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.369547","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 19) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.371484","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 17) in 127 ms on 172.21.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.442384","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_12 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.455945","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_13 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.486433","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 20) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.487873","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 18) in 139 ms on 172.21.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.501590","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 21) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.502939","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 19) in 134 ms on 172.21.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.564317","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_14 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.594174","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_15 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.611265","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 22) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.612073","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 20) in 126 ms on 172.21.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.640342","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 23) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.641603","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 21) in 140 ms on 172.21.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.706158","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_16 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.730674","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_17 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.757531","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 24) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.758273","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 22) in 147 ms on 172.21.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.775593","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 25) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.776387","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 23) in 136 ms on 172.21.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.823541","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_18 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.855559","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_19 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.859496","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 26) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.860177","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 24) in 104 ms on 172.21.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.890569","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 27) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.891421","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 25) in 116 ms on 172.21.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.929292","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_20 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.962962","level":"info","event":"25/07/14 10:35:06 INFO BlockManagerInfo: Added rdd_23_21 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.964897","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 28) (172.21.0.8, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.965757","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 26) in 107 ms on 172.21.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.997056","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 29) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:06.997725","level":"info","event":"25/07/14 10:35:06 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 27) in 108 ms on 172.21.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.030462","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_22 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.066102","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 30) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.068220","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 28) in 102 ms on 172.21.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.068596","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_24 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.112789","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 31) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.113819","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 29) in 117 ms on 172.21.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.151197","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_25 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.210626","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 32) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.211241","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 30) in 146 ms on 172.21.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.216169","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_26 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.252806","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 33) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.253581","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 31) in 141 ms on 172.21.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.282398","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_27 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.333564","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 34) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.334351","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 32) in 124 ms on 172.21.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.351025","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_28 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.386923","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 35) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.387842","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 33) in 136 ms on 172.21.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.413838","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_29 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.455765","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 36) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.457820","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 34) in 125 ms on 172.21.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.472045","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_30 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.504140","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 37) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.505005","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 35) in 118 ms on 172.21.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.522616","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_31 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.552286","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 38) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.552811","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 36) in 98 ms on 172.21.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.572118","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_32 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.607027","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 39) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.607511","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 37) in 105 ms on 172.21.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.614480","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_33 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.650988","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 40) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.651970","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 38) in 100 ms on 172.21.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.671989","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_34 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.705224","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 41) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.706378","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 39) in 99 ms on 172.21.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.715861","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_35 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.757109","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 42) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.758071","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 40) in 108 ms on 172.21.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.779588","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_36 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.812612","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 43) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.814480","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 41) in 110 ms on 172.21.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.823797","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_37 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.855119","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 44) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.855863","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 42) in 100 ms on 172.21.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.871968","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_38 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.908673","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 45) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.909526","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 43) in 98 ms on 172.21.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.917178","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_39 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.946529","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 46) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.947178","level":"info","event":"25/07/14 10:35:07 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 44) in 92 ms on 172.21.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:07.975019","level":"info","event":"25/07/14 10:35:07 INFO BlockManagerInfo: Added rdd_23_40 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.010095","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 47) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.010860","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 45) in 103 ms on 172.21.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.015168","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added rdd_23_41 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.045823","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 48) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.046120","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 46) in 100 ms on 172.21.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.065846","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added rdd_23_43 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.099593","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 49) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.100389","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 47) in 90 ms on 172.21.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.108706","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added rdd_23_44 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.137559","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 50) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.138384","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 48) in 92 ms on 172.21.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.168617","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added rdd_23_45 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.210540","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 51) (172.21.0.8, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.211568","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 49) in 112 ms on 172.21.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.214782","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added rdd_23_46 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.251509","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 52) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.252722","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 50) in 115 ms on 172.21.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.278968","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added rdd_23_47 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.306468","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 53) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.307579","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 51) in 97 ms on 172.21.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.322276","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added rdd_23_48 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.354189","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 52) in 103 ms on 172.21.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.377315","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added rdd_23_49 in memory on 172.21.0.8:41043 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.407691","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 53) in 101 ms on 172.21.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.408291","level":"info","event":"25/07/14 10:35:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.409654","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: ShuffleMapStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 4.327 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.409896","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.410052","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.410158","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.410241","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.453203","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 390343db465a:43951 in memory (size: 138.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.457761","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.21.0.8:41043 in memory (size: 138.2 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.469463","level":"info","event":"25/07/14 10:35:08 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.472890","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: Got job 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.473322","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.473439","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.473551","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.473997","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[29] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.482626","level":"info","event":"25/07/14 10:35:08 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 534.7 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.486484","level":"info","event":"25/07/14 10:35:08 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 124.7 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.487774","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 390343db465a:43951 (size: 124.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.488409","level":"info","event":"25/07/14 10:35:08 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.488849","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.489001","level":"info","event":"25/07/14 10:35:08 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.490466","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 54) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.505502","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.21.0.8:41043 (size: 124.7 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.522246","level":"info","event":"25/07/14 10:35:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.21.0.8:46872","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.596879","level":"info","event":"25/07/14 10:35:08 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 54) in 107 ms on 172.21.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.597610","level":"info","event":"25/07/14 10:35:08 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.598389","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.122 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.598777","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.598915","level":"info","event":"25/07/14 10:35:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.599583","level":"info","event":"25/07/14 10:35:08 INFO DAGScheduler: Job 6 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.129912 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.659432","level":"info","event":"25/07/14 10:35:08 INFO CodeGenerator: Code generated in 43.482964 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.662573","level":"info","event":"25/07/14 10:35:08 INFO Snapshot: [tableId=6ea4255e-0d5f-498f-91fb-741c54487f11] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.692542","level":"info","event":"25/07/14 10:35:08 INFO OptimisticTransaction: [tableId=a87aa851,txnId=8dca2a33] Committed delta #0 to s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.699087","level":"info","event":"INFO:__main__:Data cleaned and loaded to silver layer!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.699570","level":"info","event":"25/07/14 10:35:08 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.720232","level":"info","event":"25/07/14 10:35:08 INFO SparkUI: Stopped Spark web UI at http://390343db465a:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.724680","level":"info","event":"25/07/14 10:35:08 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.725088","level":"info","event":"25/07/14 10:35:08 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.755938","level":"info","event":"25/07/14 10:35:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.781036","level":"info","event":"25/07/14 10:35:08 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.781444","level":"info","event":"25/07/14 10:35:08 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.785782","level":"info","event":"25/07/14 10:35:08 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.790337","level":"info","event":"25/07/14 10:35:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.808612","level":"info","event":"25/07/14 10:35:08 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.962039","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:08.962327","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:09.097726","level":"info","event":"25/07/14 10:35:09 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:09.098409","level":"info","event":"25/07/14 10:35:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-91d5fcd4-5245-415d-876d-04f821dc1190","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:09.102939","level":"info","event":"25/07/14 10:35:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32/pyspark-07eb251b-83ce-415e-95db-75c7c387e25a","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:09.106935","level":"info","event":"25/07/14 10:35:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-88940017-3059-416f-9a85-3c8b2dff2e32","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:09.115600","level":"info","event":"25/07/14 10:35:09 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:09.115776","level":"info","event":"25/07/14 10:35:09 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T10:35:09.115838","level":"info","event":"25/07/14 10:35:09 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
