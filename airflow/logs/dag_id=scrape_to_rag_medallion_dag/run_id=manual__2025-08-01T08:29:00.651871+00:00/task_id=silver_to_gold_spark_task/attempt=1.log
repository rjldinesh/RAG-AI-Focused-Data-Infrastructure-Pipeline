{"timestamp":"2025-08-01T08:41:43.501966","level":"warning","event":"\n        OpenLineage support for Airflow version 3.0.2 is REMOVED.\n        For Airflow 2.7 and later, use the native Airflow Openlineage provider package.\n        Documentation can be found at https://airflow.apache.org/docs/apache-airflow-providers-openlineage\n        ","logger":"root"}
{"timestamp":"2025-08-01T08:41:43.674826","level":"warning","event":"No module named 'airflow.providers.dbt'","logger":"openlineage.airflow.utils"}
{"timestamp":"2025-08-01T08:41:43.678826","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-01T08:41:43.679099","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-01T08:41:44.361629","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-01T08:41:44.362319","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name silver_to_gold_job --verbose --deploy-mode client /opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.111501","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.153830","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.153913","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.153943","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.153968","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.153988","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154006","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154043","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154061","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154078","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154095","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154112","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154129","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154145","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154162","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154179","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154198","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154215","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154232","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154248","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154266","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154283","level":"info","event":"primaryResource         file:/opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154299","level":"info","event":"name                    silver_to_gold_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154316","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154332","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154349","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154367","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154383","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154400","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154418","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154436","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154453","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154469","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154485","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154501","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154518","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154534","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154550","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154566","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154584","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154600","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154617","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154635","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.154652","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.216329","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.255357","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.255453","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.257219","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.257274","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.257296","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.257315","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.257642","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-64818e17-6ac9-4f81-afd0-f3cd2978d550;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.257698","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.347779","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.365580","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.373433","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.388645","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.396537","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.403677","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.413898","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.422906","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435305","level":"info","event":":: resolution report :: resolve 171ms :: artifacts dl 7ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435383","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435408","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435430","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435450","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435469","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435486","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435503","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435522","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435539","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435557","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435575","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435592","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435610","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435627","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435643","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435661","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.435678","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.438404","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-64818e17-6ac9-4f81-afd0-f3cd2978d550","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.438459","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.442048","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/3ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.555992","level":"info","event":"25/08/01 08:41:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.649629","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.649715","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.649909","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.649975","level":"info","event":"file:/opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.650002","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651130","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651170","level":"info","event":"(spark.app.name,silver_to_gold_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651193","level":"info","event":"(spark.app.submitTime,1754037705640)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651211","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651228","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651245","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651262","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651279","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651295","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651312","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651328","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651344","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651359","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651375","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651391","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651407","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651424","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651439","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651460","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651476","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651492","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651509","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651525","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651541","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651557","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651574","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651590","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651608","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:45.651625","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.391830","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.391938","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.392126","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.402418","level":"info","event":"25/08/01 08:41:46 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.402505","level":"info","event":"25/08/01 08:41:46 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.402538","level":"info","event":"25/08/01 08:41:46 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.402820","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.413989","level":"info","event":"25/08/01 08:41:46 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.418064","level":"info","event":"25/08/01 08:41:46 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.418614","level":"info","event":"25/08/01 08:41:46 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.451229","level":"info","event":"25/08/01 08:41:46 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.451317","level":"info","event":"25/08/01 08:41:46 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.451475","level":"info","event":"25/08/01 08:41:46 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.451595","level":"info","event":"25/08/01 08:41:46 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.451712","level":"info","event":"25/08/01 08:41:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.571247","level":"info","event":"25/08/01 08:41:46 INFO Utils: Successfully started service 'sparkDriver' on port 34707.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.592940","level":"info","event":"25/08/01 08:41:46 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.609111","level":"info","event":"25/08/01 08:41:46 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.617057","level":"info","event":"25/08/01 08:41:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.617191","level":"info","event":"25/08/01 08:41:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.619203","level":"info","event":"25/08/01 08:41:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.630610","level":"info","event":"25/08/01 08:41:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d16d5c02-6070-4522-a5b9-7d592efa32c2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.636975","level":"info","event":"25/08/01 08:41:46 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.644942","level":"info","event":"25/08/01 08:41:46 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.707495","level":"info","event":"25/08/01 08:41:46 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.736419","level":"info","event":"25/08/01 08:41:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.752540","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://0baa42e17007:34707/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.752636","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://0baa42e17007:34707/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.752761","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://0baa42e17007:34707/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.752901","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://0baa42e17007:34707/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.753116","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://0baa42e17007:34707/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.753190","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://0baa42e17007:34707/jars/org.tukaani_xz-1.9.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.753274","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://0baa42e17007:34707/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.753428","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://0baa42e17007:34707/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.754481","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://0baa42e17007:34707/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.754853","level":"info","event":"25/08/01 08:41:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/userFiles-45418f8f-04c7-4d51-bd43-3892aac435ca/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.761806","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://0baa42e17007:34707/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.761908","level":"info","event":"25/08/01 08:41:46 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/userFiles-45418f8f-04c7-4d51-bd43-3892aac435ca/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.944600","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://0baa42e17007:34707/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.944753","level":"info","event":"25/08/01 08:41:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/userFiles-45418f8f-04c7-4d51-bd43-3892aac435ca/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.947567","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://0baa42e17007:34707/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.947654","level":"info","event":"25/08/01 08:41:46 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/userFiles-45418f8f-04c7-4d51-bd43-3892aac435ca/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.954255","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://0baa42e17007:34707/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.954337","level":"info","event":"25/08/01 08:41:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/userFiles-45418f8f-04c7-4d51-bd43-3892aac435ca/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.957321","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://0baa42e17007:34707/files/org.tukaani_xz-1.9.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.957387","level":"info","event":"25/08/01 08:41:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/userFiles-45418f8f-04c7-4d51-bd43-3892aac435ca/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.959782","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://0baa42e17007:34707/files/io.delta_delta-storage-3.1.0.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.959862","level":"info","event":"25/08/01 08:41:46 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/userFiles-45418f8f-04c7-4d51-bd43-3892aac435ca/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.961801","level":"info","event":"25/08/01 08:41:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://0baa42e17007:34707/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754037706387","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:46.961944","level":"info","event":"25/08/01 08:41:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/userFiles-45418f8f-04c7-4d51-bd43-3892aac435ca/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.002715","level":"info","event":"25/08/01 08:41:47 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.023342","level":"info","event":"25/08/01 08:41:47 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.5:7077 after 11 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.065278","level":"info","event":"25/08/01 08:41:47 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250801084147-0001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.065986","level":"info","event":"25/08/01 08:41:47 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801084147-0001/0 on worker-20250801084128-172.18.0.8-42021 (172.18.0.8:42021) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.066883","level":"info","event":"25/08/01 08:41:47 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801084147-0001/0 on hostPort 172.18.0.8:42021 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.070100","level":"info","event":"25/08/01 08:41:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42905.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.070206","level":"info","event":"25/08/01 08:41:47 INFO NettyBlockTransferService: Server created on 0baa42e17007:42905","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.071228","level":"info","event":"25/08/01 08:41:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.074433","level":"info","event":"25/08/01 08:41:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 0baa42e17007, 42905, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.076223","level":"info","event":"25/08/01 08:41:47 INFO BlockManagerMasterEndpoint: Registering block manager 0baa42e17007:42905 with 434.4 MiB RAM, BlockManagerId(driver, 0baa42e17007, 42905, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.078086","level":"info","event":"25/08/01 08:41:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 0baa42e17007, 42905, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.078607","level":"info","event":"25/08/01 08:41:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 0baa42e17007, 42905, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.086878","level":"info","event":"25/08/01 08:41:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801084147-0001/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.183340","level":"info","event":"25/08/01 08:41:47 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.347766","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.351373","level":"info","event":"25/08/01 08:41:47 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:47.352437","level":"info","event":"25/08/01 08:41:47 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:48.034495","level":"info","event":"25/08/01 08:41:48 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:48.040281","level":"info","event":"25/08/01 08:41:48 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:48.040376","level":"info","event":"25/08/01 08:41:48 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:48.496842","level":"info","event":"25/08/01 08:41:48 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:48.505318","level":"info","event":"25/08/01 08:41:48 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:58580) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:48.535884","level":"info","event":"25/08/01 08:41:48 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42851 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.8, 42851, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:48.864531","level":"info","event":"25/08/01 08:41:48 INFO DeltaLog: Loading version 10 starting from checkpoint version 10.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.094386","level":"info","event":"25/08/01 08:41:50 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20596)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.094590","level":"info","event":"25/08/01 08:41:50 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20596)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.608077","level":"info","event":"25/08/01 08:41:50 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.608212","level":"info","event":"25/08/01 08:41:50 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.613587","level":"info","event":"25/08/01 08:41:50 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(protocol.minReaderVersion),IsNotNull(metaData.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.613658","level":"info","event":"25/08/01 08:41:50 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(checkpointMetadata.version),IsNotNull(sidecar.path))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.614478","level":"info","event":"25/08/01 08:41:50 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#16.minReaderVersion) OR isnotnull(metaData#11.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.614551","level":"info","event":"25/08/01 08:41:50 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(checkpointMetadata#19.version) OR isnotnull(sidecar#20.path))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.852486","level":"info","event":"25/08/01 08:41:50 INFO CodeGenerator: Code generated in 130.289792 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.868624","level":"info","event":"25/08/01 08:41:50 INFO CodeGenerator: Code generated in 146.486083 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.907204","level":"info","event":"25/08/01 08:41:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.0 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.907295","level":"info","event":"25/08/01 08:41:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 210.4 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.991826","level":"info","event":"25/08/01 08:41:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.991961","level":"info","event":"25/08/01 08:41:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.993543","level":"info","event":"25/08/01 08:41:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 0baa42e17007:42905 (size: 37.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.995353","level":"info","event":"25/08/01 08:41:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 0baa42e17007:42905 (size: 37.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.996374","level":"info","event":"25/08/01 08:41:50 INFO SparkContext: Created broadcast 0 from $anonfun$submit$1 at FutureTask.java:264","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:50.997024","level":"info","event":"25/08/01 08:41:50 INFO SparkContext: Created broadcast 1 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.009150","level":"info","event":"25/08/01 08:41:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.009252","level":"info","event":"25/08/01 08:41:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.091675","level":"info","event":"25/08/01 08:41:51 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.092980","level":"info","event":"25/08/01 08:41:51 INFO SparkContext: Starting job: $anonfun$submit$1 at FutureTask.java:264","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.097689","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Got job 1 ($anonfun$submit$1 at FutureTask.java:264) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.097832","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Final stage: ResultStage 0 ($anonfun$submit$1 at FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.097941","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.098298","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.100471","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at $anonfun$submit$1 at FutureTask.java:264), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.108209","level":"info","event":"25/08/01 08:41:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 25.8 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.109095","level":"info","event":"25/08/01 08:41:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.109463","level":"info","event":"25/08/01 08:41:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 0baa42e17007:42905 (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.109744","level":"info","event":"25/08/01 08:41:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.117960","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at $anonfun$submit$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.118398","level":"info","event":"25/08/01 08:41:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.122959","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Got job 0 (toString at String.java:4220) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.123005","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Final stage: ResultStage 1 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.123031","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.123115","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.123350","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.124597","level":"info","event":"25/08/01 08:41:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 54.9 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.125261","level":"info","event":"25/08/01 08:41:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.125544","level":"info","event":"25/08/01 08:41:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 0baa42e17007:42905 (size: 15.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.125833","level":"info","event":"25/08/01 08:41:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.126543","level":"info","event":"25/08/01 08:41:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.126582","level":"info","event":"25/08/01 08:41:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.128124","level":"info","event":"25/08/01 08:41:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11180 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.132978","level":"info","event":"25/08/01 08:41:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11180 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.262541","level":"info","event":"25/08/01 08:41:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.8:42851 (size: 8.8 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.262818","level":"info","event":"25/08/01 08:41:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:42851 (size: 15.8 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.671278","level":"info","event":"25/08/01 08:41:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:42851 (size: 37.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:51.679310","level":"info","event":"25/08/01 08:41:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:42851 (size: 37.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.375383","level":"info","event":"25/08/01 08:41:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1250 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.376257","level":"info","event":"25/08/01 08:41:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.379748","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: ResultStage 0 ($anonfun$submit$1 at FutureTask.java:264) finished in 1.273 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.380725","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.380955","level":"info","event":"25/08/01 08:41:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.381921","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Job 1 finished: $anonfun$submit$1 at FutureTask.java:264, took 1.288748 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.444613","level":"info","event":"25/08/01 08:41:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1312 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.444785","level":"info","event":"25/08/01 08:41:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.445236","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: ResultStage 1 (toString at String.java:4220) finished in 1.321 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.445298","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.445352","level":"info","event":"25/08/01 08:41:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.445639","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Job 0 finished: toString at String.java:4220, took 1.353801 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.478487","level":"info","event":"25/08/01 08:41:52 INFO CodeGenerator: Code generated in 21.215125 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.483976","level":"info","event":"25/08/01 08:41:52 INFO Snapshot: [tableId=937ea54c-7e1e-4251-9754-47ea8578c4b4] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=10, metadata=Metadata(9ce1f2ed-51b3-4e89-b775-e5382d4313a3,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754033156179)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,10,WrappedArray(),UninitializedV1OrV2ParquetCheckpointProvider(10,S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000010.checkpoint.parquet; isDirectory=false; length=20596; replication=1; blocksize=33554432; modification_time=1754037702456; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=933170ac49042c72bc2f9694f935c9e2 versionId=null,s3a://activefence-bucket/bbc_tech/silver/_delta_log,Some(LastCheckpointInfo(10,24,None,Some(20596),Some(2),Some(StructType(StructField(txn,StructType(StructField(appId,StringType,true),StructField(version,LongType,true),StructField(lastUpdated,LongType,true)),true),StructField(add,StructType(StructField(path,StringType,true),StructField(partitionValues,MapType(StringType,StringType,true),true),StructField(size,LongType,true),StructField(modificationTime,LongType,true),StructField(dataChange,BooleanType,true),StructField(tags,MapType(StringType,StringType,true),true),StructField(deletionVector,StructType(StructField(storageType,StringType,true),StructField(pathOrInlineDv,StringType,true),StructField(offset,IntegerType,true),StructField(sizeInBytes,IntegerType,true),StructField(cardinality,LongType,true),StructField(maxRowIndex,LongType,true)),true),StructField(baseRowId,LongType,true),StructField(defaultRowCommitVersion,LongType,true),StructField(clusteringProvider,StringType,true),StructField(stats,StringType,true)),true),StructField(remove,StructType(StructField(path,StringType,true),StructField(deletionTimestamp,LongType,true),StructField(dataChange,BooleanType,true),StructField(extendedFileMetadata,BooleanType,true),StructField(partitionValues,MapType(StringType,StringType,true),true),StructField(size,LongType,true),StructField(deletionVector,StructType(StructField(storageType,StringType,true),StructField(pathOrInlineDv,StringType,true),StructField(offset,IntegerType,true),StructField(sizeInBytes,IntegerType,true),StructField(cardinality,LongType,true),StructField(maxRowIndex,LongType,true)),true),StructField(baseRowId,LongType,true),StructField(defaultRowCommitVersion,LongType,true)),true),StructField(metaData,StructType(StructField(id,StringType,true),StructField(name,StringType,true),StructField(description,StringType,true),StructField(format,StructType(StructField(provider,StringType,true),StructField(options,MapType(StringType,StringType,true),true)),true),StructField(schemaString,StringType,true),StructField(partitionColumns,ArrayType(StringType,true),true),StructField(configuration,MapType(StringType,StringType,true),true),StructField(createdTime,LongType,true)),true),StructField(protocol,StructType(StructField(minReaderVersion,IntegerType,true),StructField(minWriterVersion,IntegerType,true),StructField(readerFeatures,ArrayType(StringType,true),true),StructField(writerFeatures,ArrayType(StringType,true),true)),true),StructField(domainMetadata,StructType(StructField(domain,StringType,true),StructField(configuration,StringType,true),StructField(removed,BooleanType,true)),true))),None,Some(b0d0e3870748d57ed039dc9729542328)))),1754037700690), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.571873","level":"info","event":"25/08/01 08:41:52 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.588845","level":"info","event":"25/08/01 08:41:52 INFO DeltaLog: Loading version 9.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.591138","level":"info","event":"25/08/01 08:41:52 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 10, totalFileSize: 10645)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.610394","level":"info","event":"25/08/01 08:41:52 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.610619","level":"info","event":"25/08/01 08:41:52 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.610672","level":"info","event":"25/08/01 08:41:52 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#107.minReaderVersion) OR isnotnull(metaData#106.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.631426","level":"info","event":"25/08/01 08:41:52 INFO CodeGenerator: Code generated in 13.369208 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.633276","level":"info","event":"25/08/01 08:41:52 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 206.0 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.639366","level":"info","event":"25/08/01 08:41:52 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.639783","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 0baa42e17007:42905 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.640379","level":"info","event":"25/08/01 08:41:52 INFO SparkContext: Created broadcast 4 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.647292","level":"info","event":"25/08/01 08:41:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 20976842 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.671359","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 0baa42e17007:42905 in memory (size: 37.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.675745","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:42851 in memory (size: 37.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.679063","level":"info","event":"25/08/01 08:41:52 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.679654","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Got job 2 (toString at String.java:4220) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.679736","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Final stage: ResultStage 2 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.679763","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.679786","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.680069","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 0baa42e17007:42905 in memory (size: 15.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.680116","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.681415","level":"info","event":"25/08/01 08:41:52 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 40.1 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.681461","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:42851 in memory (size: 15.8 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.682147","level":"info","event":"25/08/01 08:41:52 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.682481","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 0baa42e17007:42905 (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.682810","level":"info","event":"25/08/01 08:41:52 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.683109","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.683147","level":"info","event":"25/08/01 08:41:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.683891","level":"info","event":"25/08/01 08:41:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11792 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.684127","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 0baa42e17007:42905 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.684296","level":"info","event":"25/08/01 08:41:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11792 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.685380","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.8:42851 in memory (size: 8.8 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.688397","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 0baa42e17007:42905 in memory (size: 37.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.689455","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.8:42851 in memory (size: 37.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.696346","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:42851 (size: 13.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.807779","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:42851 (size: 36.5 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.863667","level":"info","event":"25/08/01 08:41:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 180 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.864675","level":"info","event":"25/08/01 08:41:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 181 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.864755","level":"info","event":"25/08/01 08:41:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.865399","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: ResultStage 2 (toString at String.java:4220) finished in 0.185 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.865481","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.865512","level":"info","event":"25/08/01 08:41:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.865734","level":"info","event":"25/08/01 08:41:52 INFO DAGScheduler: Job 2 finished: toString at String.java:4220, took 0.186526 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.872153","level":"info","event":"25/08/01 08:41:52 INFO Snapshot: [tableId=045a32a3-0bcd-42dc-8ffc-6f88e36809cd] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=9, metadata=Metadata(3547bf11-335a-4bfb-a37a-8cc2809296bb,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754033170534)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,9,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000000.json; isDirectory=false; length=1336; replication=1; blocksize=33554432; modification_time=1754033175410; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=5c3a251d3ca25d55b3fc96ccf13cbcdd versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000001.json; isDirectory=false; length=1031; replication=1; blocksize=33554432; modification_time=1754033448511; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=3bea36df86a521e758a330c73dfb9e49 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000002.json; isDirectory=false; length=1033; replication=1; blocksize=33554432; modification_time=1754034003955; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=52e16d286e67b3560233b6a0cef954c7 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000003.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034146528; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=372c58fa4aee9a5fb8410f6c2b95ba5a versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000004.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034353496; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=1ca25629f04bf0aeba6acfc86f0f52b8 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000005.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034796161; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=151dd235ebf4d834587dd9e477ba413b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000006.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035338336; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=09ac49cc1475bd5703812106b8d84bcf versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000007.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035525575; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=6c753dac8bec87512bcecd2c2c0f587c versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000008.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035700395; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=6d86b8614ebf10eb58d0810dd3fbdd1b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000009.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754036577027; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=9d1ec6bd23168c9d68b12067a7d25ef0 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@79a7f01b,1754036577027), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.919160","level":"info","event":"25/08/01 08:41:52 INFO Snapshot: [tableId=3547bf11-335a-4bfb-a37a-8cc2809296bb] DELTA: Compute snapshot for version: 9","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.927194","level":"info","event":"25/08/01 08:41:52 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 205.7 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.930640","level":"info","event":"25/08/01 08:41:52 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.931086","level":"info","event":"25/08/01 08:41:52 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 0baa42e17007:42905 (size: 36.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:52.931529","level":"info","event":"25/08/01 08:41:52 INFO SparkContext: Created broadcast 6 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.010708","level":"info","event":"25/08/01 08:41:53 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 0baa42e17007:42905 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.012306","level":"info","event":"25/08/01 08:41:53 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:42851 in memory (size: 36.5 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.016888","level":"info","event":"25/08/01 08:41:53 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 0baa42e17007:42905 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.018162","level":"info","event":"25/08/01 08:41:53 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:42851 in memory (size: 13.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.171167","level":"info","event":"25/08/01 08:41:53 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.171305","level":"info","event":"25/08/01 08:41:53 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.171341","level":"info","event":"25/08/01 08:41:53 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.193981","level":"info","event":"25/08/01 08:41:53 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.261134","level":"info","event":"25/08/01 08:41:53 INFO CodeGenerator: Code generated in 33.125625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.262418","level":"info","event":"25/08/01 08:41:53 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 206.0 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.265492","level":"info","event":"25/08/01 08:41:53 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.265902","level":"info","event":"25/08/01 08:41:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 0baa42e17007:42905 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.266439","level":"info","event":"25/08/01 08:41:53 INFO SparkContext: Created broadcast 7 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.267116","level":"info","event":"25/08/01 08:41:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 20976842 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.293669","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: Registering RDD 15 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.295069","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: Got map stage job 3 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.295160","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.295258","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.295474","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.295889","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[15] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.300741","level":"info","event":"25/08/01 08:41:53 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 105.6 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.301355","level":"info","event":"25/08/01 08:41:53 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.301668","level":"info","event":"25/08/01 08:41:53 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 0baa42e17007:42905 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.301964","level":"info","event":"25/08/01 08:41:53 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.302757","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[15] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.302810","level":"info","event":"25/08/01 08:41:53 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.303729","level":"info","event":"25/08/01 08:41:53 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11781 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.303920","level":"info","event":"25/08/01 08:41:53 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11781 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.312460","level":"info","event":"25/08/01 08:41:53 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:42851 (size: 32.6 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.519733","level":"info","event":"25/08/01 08:41:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:42851 (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.968469","level":"info","event":"25/08/01 08:41:53 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 665 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.968557","level":"info","event":"25/08/01 08:41:53 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 665 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.968585","level":"info","event":"25/08/01 08:41:53 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.969844","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: ShuffleMapStage 3 (save at NativeMethodAccessorImpl.java:0) finished in 0.673 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.970029","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.970083","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.970237","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:53.970302","level":"info","event":"25/08/01 08:41:53 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.004391","level":"info","event":"25/08/01 08:41:54 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 0baa42e17007:42905 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.005915","level":"info","event":"25/08/01 08:41:54 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.8:42851 in memory (size: 32.6 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.117357","level":"info","event":"25/08/01 08:41:54 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.117465","level":"info","event":"25/08/01 08:41:54 INFO CodeGenerator: Code generated in 88.725167 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.151510","level":"info","event":"25/08/01 08:41:54 INFO CodeGenerator: Code generated in 23.868291 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.282993","level":"info","event":"25/08/01 08:41:54 INFO CodeGenerator: Code generated in 17.953542 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.288591","level":"info","event":"25/08/01 08:41:54 INFO DAGScheduler: Registering RDD 25 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.288666","level":"info","event":"25/08/01 08:41:54 INFO DAGScheduler: Got map stage job 4 (save at NativeMethodAccessorImpl.java:0) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.288706","level":"info","event":"25/08/01 08:41:54 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.288729","level":"info","event":"25/08/01 08:41:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.289698","level":"info","event":"25/08/01 08:41:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.289904","level":"info","event":"25/08/01 08:41:54 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[25] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.307350","level":"info","event":"25/08/01 08:41:54 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 603.4 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.308603","level":"info","event":"25/08/01 08:41:54 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.308944","level":"info","event":"25/08/01 08:41:54 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 0baa42e17007:42905 (size: 138.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.309235","level":"info","event":"25/08/01 08:41:54 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.309532","level":"info","event":"25/08/01 08:41:54 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[25] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.309568","level":"info","event":"25/08/01 08:41:54 INFO TaskSchedulerImpl: Adding task set 5.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.312170","level":"info","event":"25/08/01 08:41:54 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.312303","level":"info","event":"25/08/01 08:41:54 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 7) (172.18.0.8, executor 0, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.322518","level":"info","event":"25/08/01 08:41:54 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:42851 (size: 138.2 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.442812","level":"info","event":"25/08/01 08:41:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:58580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.754530","level":"info","event":"25/08/01 08:41:54 INFO BlockManagerInfo: Added rdd_22_0 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:54.755035","level":"info","event":"25/08/01 08:41:54 INFO BlockManagerInfo: Added rdd_22_2 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.069623","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 8) (172.18.0.8, executor 0, partition 3, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.070547","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 9) (172.18.0.8, executor 0, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.071168","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 7) in 758 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.071269","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 760 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.133518","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_4 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.133630","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_3 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.158556","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 10) (172.18.0.8, executor 0, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.159217","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 8) in 89 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.161049","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 11) (172.18.0.8, executor 0, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.161323","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 9) in 90 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.237665","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_14 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.237956","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_10 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.277970","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 12) (172.18.0.8, executor 0, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.278615","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 13) (172.18.0.8, executor 0, partition 40, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.278726","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 11) in 118 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.279165","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 10) in 120 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.351230","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_22 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.351949","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_40 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.382108","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 14) (172.18.0.8, executor 0, partition 41, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.382499","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 12) in 105 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.383175","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 15) (172.18.0.8, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.383317","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 13) in 105 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.462235","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_41 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.477032","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 16) (172.18.0.8, executor 0, partition 47, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.477540","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 14) in 96 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.521487","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_47 in memory on 172.18.0.8:42851 (size: 449.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.541525","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 17) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.542292","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 16) in 65 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.569618","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_1 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.583344","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 18) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.583718","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 17) in 42 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.590152","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_42 in memory on 172.18.0.8:42851 (size: 485.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.606544","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 19) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.606986","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 15) in 224 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.611834","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_5 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.624070","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 20) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.624461","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 18) in 42 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.632273","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_6 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.645427","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 21) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.645953","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 19) in 39 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.650988","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_7 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.663341","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 22) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.663729","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 20) in 40 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.670593","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_8 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.684151","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 23) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.684447","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 21) in 39 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.688902","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_9 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.706138","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 24) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.706491","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 22) in 44 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.711306","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_11 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.727467","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 25) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.727935","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 23) in 44 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.735257","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_12 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.754010","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 26) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.754558","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 24) in 49 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.758078","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_13 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.775854","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 27) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.776264","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 25) in 49 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.784711","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_15 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.802178","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 28) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.802538","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 26) in 49 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.805831","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_16 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.815824","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 29) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.816201","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 27) in 41 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.819728","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_17 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.833257","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 30) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.833489","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 28) in 32 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.835827","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_18 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.847990","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 31) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.848256","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 29) in 33 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.853541","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_19 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.864420","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 32) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.864859","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 30) in 32 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.866834","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_20 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.876212","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 33) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.876496","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 31) in 29 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.882568","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_21 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.896149","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 34) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.896505","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 32) in 32 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.902373","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_23 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.918494","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 35) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.918737","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 33) in 43 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.922570","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_24 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.931098","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 36) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.931442","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 34) in 36 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.936550","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_25 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.949216","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 37) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.949623","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 35) in 32 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.952297","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_26 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.964041","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 38) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.964322","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 36) in 34 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.968504","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_27 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.978743","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 39) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.979094","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 37) in 30 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.982232","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_28 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.992462","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 40) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.992748","level":"info","event":"25/08/01 08:41:55 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 38) in 29 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:55.996864","level":"info","event":"25/08/01 08:41:55 INFO BlockManagerInfo: Added rdd_22_29 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.006086","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 41) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.006516","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 39) in 28 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.009134","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_30 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.019189","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 42) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.019488","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 40) in 27 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.023610","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_31 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.035710","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 43) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.036967","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 41) in 31 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.039817","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_32 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.053007","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 44) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.053095","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 42) in 34 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.057491","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_33 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.073393","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 45) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.073844","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 43) in 38 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.079090","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_34 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.091887","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 46) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.092523","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 44) in 41 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.095557","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_35 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.107141","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 47) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.107513","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 45) in 35 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.115441","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_36 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.125433","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 48) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.127833","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_37 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.128997","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 46) in 37 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.136356","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 49) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.136435","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 47) in 30 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.141380","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_38 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.150409","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 50) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.150754","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 48) in 25 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.152702","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_39 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.160967","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 51) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.161267","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 49) in 26 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.166742","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_43 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.175952","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 52) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.176376","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 50) in 26 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.177926","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_44 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.185233","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 53) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.185500","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 51) in 25 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.190515","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_45 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.200386","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 54) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.200640","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 52) in 25 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.203262","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_46 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.212731","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 55) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.212994","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 53) in 28 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.216228","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_48 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.229407","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 54) in 30 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.231750","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_22_49 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.242994","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 55) in 30 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.243079","level":"info","event":"25/08/01 08:41:56 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.243819","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: ShuffleMapStage 5 (save at NativeMethodAccessorImpl.java:0) finished in 1.949 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.243899","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.243925","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.243945","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.243963","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.256101","level":"info","event":"25/08/01 08:41:56 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.256954","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Got job 5 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.257018","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Final stage: ResultStage 8 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.257047","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.257072","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.257346","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.259803","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 534.7 KiB, free 432.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.264074","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 124.6 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.264185","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 0baa42e17007:42905 in memory (size: 138.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.264395","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 0baa42e17007:42905 (size: 124.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.264938","level":"info","event":"25/08/01 08:41:56 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.265553","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.265599","level":"info","event":"25/08/01 08:41:56 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.266134","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.8:42851 in memory (size: 138.2 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.266481","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 56) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.272064","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:42851 (size: 124.6 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.278065","level":"info","event":"25/08/01 08:41:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:58580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.300318","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 56) in 35 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.300400","level":"info","event":"25/08/01 08:41:56 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.300767","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: ResultStage 8 (save at NativeMethodAccessorImpl.java:0) finished in 0.043 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.300948","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.301000","level":"info","event":"25/08/01 08:41:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.301181","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Job 5 finished: save at NativeMethodAccessorImpl.java:0, took 0.044985 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.327811","level":"info","event":"25/08/01 08:41:56 INFO CodeGenerator: Code generated in 21.169709 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.328987","level":"info","event":"25/08/01 08:41:56 INFO Snapshot: [tableId=3547bf11-335a-4bfb-a37a-8cc2809296bb] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.370059","level":"info","event":"25/08/01 08:41:56 INFO PrepareDeltaScan: DELTA: Filtering files for query","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.370752","level":"info","event":"25/08/01 08:41:56 INFO Snapshot: [tableId=9ce1f2ed-51b3-4e89-b775-e5382d4313a3] DELTA: Compute snapshot for version: 10","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.372182","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 205.7 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.375457","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.375767","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 0baa42e17007:42905 (size: 36.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.376296","level":"info","event":"25/08/01 08:41:56 INFO SparkContext: Created broadcast 11 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.377527","level":"info","event":"25/08/01 08:41:56 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20596)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.450058","level":"info","event":"25/08/01 08:41:56 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.450163","level":"info","event":"25/08/01 08:41:56 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.450195","level":"info","event":"25/08/01 08:41:56 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.497743","level":"info","event":"25/08/01 08:41:56 INFO CodeGenerator: Code generated in 25.945958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.500694","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 223.2 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.503937","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 39.4 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.504255","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 0baa42e17007:42905 (size: 39.4 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.504817","level":"info","event":"25/08/01 08:41:56 INFO SparkContext: Created broadcast 12 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.505288","level":"info","event":"25/08/01 08:41:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.508120","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Registering RDD 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.508185","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Got map stage job 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.508212","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Final stage: ShuffleMapStage 9 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.508235","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.508256","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.508443","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[32] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.509376","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 166.7 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.512988","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 43.7 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.514214","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 0baa42e17007:42905 (size: 43.7 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.514561","level":"info","event":"25/08/01 08:41:56 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.514976","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[32] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.515034","level":"info","event":"25/08/01 08:41:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.515456","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 57) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11169 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.515501","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 0baa42e17007:42905 in memory (size: 124.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.517212","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.8:42851 in memory (size: 124.6 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.520553","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:42851 (size: 43.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.552821","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:42851 (size: 39.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.587182","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 57) in 71 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.587291","level":"info","event":"25/08/01 08:41:56 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.587545","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: ShuffleMapStage 9 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.079 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.587575","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.587599","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.587617","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.587635","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.654282","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Registering RDD 42 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.654363","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Got map stage job 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.654390","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Final stage: ShuffleMapStage 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.654414","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.654881","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.655103","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.658621","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 601.7 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.659775","level":"info","event":"25/08/01 08:41:56 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 137.3 KiB, free 432.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.659997","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 0baa42e17007:42905 (size: 137.3 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.660312","level":"info","event":"25/08/01 08:41:56 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.660715","level":"info","event":"25/08/01 08:41:56 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.660768","level":"info","event":"25/08/01 08:41:56 INFO TaskSchedulerImpl: Adding task set 11.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.661505","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 58) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.661651","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 10.0 in stage 11.0 (TID 59) (172.18.0.8, executor 0, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.667359","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:42851 (size: 137.3 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.676336","level":"info","event":"25/08/01 08:41:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:58580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.695644","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_10 in memory on 172.18.0.8:42851 (size: 379.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.695862","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_0 in memory on 172.18.0.8:42851 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.711764","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 11.0 in stage 11.0 (TID 60) (172.18.0.8, executor 0, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.712145","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 12.0 in stage 11.0 (TID 61) (172.18.0.8, executor 0, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.712422","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 10.0 in stage 11.0 (TID 59) in 51 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.713321","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 58) in 51 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.735924","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_11 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.736758","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_12 in memory on 172.18.0.8:42851 (size: 807.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.746171","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 13.0 in stage 11.0 (TID 62) (172.18.0.8, executor 0, partition 13, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.746902","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 18.0 in stage 11.0 (TID 63) (172.18.0.8, executor 0, partition 18, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.746988","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 11.0 in stage 11.0 (TID 60) in 35 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.747896","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 12.0 in stage 11.0 (TID 61) in 36 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.775818","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_18 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.775981","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_13 in memory on 172.18.0.8:42851 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.785506","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 21.0 in stage 11.0 (TID 64) (172.18.0.8, executor 0, partition 21, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.785960","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 18.0 in stage 11.0 (TID 63) in 39 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.786256","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 25.0 in stage 11.0 (TID 65) (172.18.0.8, executor 0, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.786562","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 13.0 in stage 11.0 (TID 62) in 41 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.812064","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_25 in memory on 172.18.0.8:42851 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.812310","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_21 in memory on 172.18.0.8:42851 (size: 379.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.824780","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 27.0 in stage 11.0 (TID 66) (172.18.0.8, executor 0, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.825140","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 25.0 in stage 11.0 (TID 65) in 38 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.825702","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 30.0 in stage 11.0 (TID 67) (172.18.0.8, executor 0, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.825754","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 21.0 in stage 11.0 (TID 64) in 41 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.855417","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_30 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.855738","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_27 in memory on 172.18.0.8:42851 (size: 372.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.867985","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 32.0 in stage 11.0 (TID 68) (172.18.0.8, executor 0, partition 32, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.868311","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 27.0 in stage 11.0 (TID 66) in 44 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.869031","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 34.0 in stage 11.0 (TID 69) (172.18.0.8, executor 0, partition 34, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.869395","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 30.0 in stage 11.0 (TID 67) in 44 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.890137","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_32 in memory on 172.18.0.8:42851 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.890424","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_34 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.914906","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 37.0 in stage 11.0 (TID 70) (172.18.0.8, executor 0, partition 37, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.915534","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 39.0 in stage 11.0 (TID 71) (172.18.0.8, executor 0, partition 39, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.915872","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 32.0 in stage 11.0 (TID 68) in 48 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.916134","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 34.0 in stage 11.0 (TID 69) in 48 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.958774","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_39 in memory on 172.18.0.8:42851 (size: 695.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.959002","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_37 in memory on 172.18.0.8:42851 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.971954","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 42.0 in stage 11.0 (TID 72) (172.18.0.8, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.972244","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 37.0 in stage 11.0 (TID 70) in 58 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.972758","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Starting task 44.0 in stage 11.0 (TID 73) (172.18.0.8, executor 0, partition 44, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.973117","level":"info","event":"25/08/01 08:41:56 INFO TaskSetManager: Finished task 39.0 in stage 11.0 (TID 71) in 57 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.995301","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_44 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:56.996163","level":"info","event":"25/08/01 08:41:56 INFO BlockManagerInfo: Added rdd_39_42 in memory on 172.18.0.8:42851 (size: 562.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.003550","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 46.0 in stage 11.0 (TID 74) (172.18.0.8, executor 0, partition 46, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.003999","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 44.0 in stage 11.0 (TID 73) in 31 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.005466","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 49.0 in stage 11.0 (TID 75) (172.18.0.8, executor 0, partition 49, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.005795","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 42.0 in stage 11.0 (TID 72) in 34 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.026060","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_49 in memory on 172.18.0.8:42851 (size: 377.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.026955","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_46 in memory on 172.18.0.8:42851 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.038788","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 76) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.039161","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 77) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.039388","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 49.0 in stage 11.0 (TID 75) in 34 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.039466","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 46.0 in stage 11.0 (TID 74) in 36 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.063297","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_2 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.063383","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_1 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.077799","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 78) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.078312","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 4.0 in stage 11.0 (TID 79) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.078374","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 77) in 40 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.078401","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 76) in 40 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.103974","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_3 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.104114","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_4 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.116384","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 5.0 in stage 11.0 (TID 80) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.116705","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 78) in 39 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.117091","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 6.0 in stage 11.0 (TID 81) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.117353","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 4.0 in stage 11.0 (TID 79) in 39 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.141229","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_5 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.141537","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_6 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.153411","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 7.0 in stage 11.0 (TID 82) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.154275","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 8.0 in stage 11.0 (TID 83) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.154599","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 5.0 in stage 11.0 (TID 80) in 38 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.154828","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 6.0 in stage 11.0 (TID 81) in 38 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.177997","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_8 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.178288","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_7 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.190658","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 9.0 in stage 11.0 (TID 84) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.191071","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 7.0 in stage 11.0 (TID 82) in 37 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.191205","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 8.0 in stage 11.0 (TID 83) in 38 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.191850","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 14.0 in stage 11.0 (TID 85) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.210108","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_9 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.210190","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_14 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.234529","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 15.0 in stage 11.0 (TID 86) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.235091","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 16.0 in stage 11.0 (TID 87) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.235358","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 9.0 in stage 11.0 (TID 84) in 45 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.235947","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 14.0 in stage 11.0 (TID 85) in 44 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.260815","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_15 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.262078","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_16 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.270138","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 17.0 in stage 11.0 (TID 88) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.270441","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 15.0 in stage 11.0 (TID 86) in 37 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.270641","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 19.0 in stage 11.0 (TID 89) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.270967","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 16.0 in stage 11.0 (TID 87) in 36 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.290278","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_19 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.290352","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_17 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.304110","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 20.0 in stage 11.0 (TID 90) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.304660","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 22.0 in stage 11.0 (TID 91) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.305059","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 17.0 in stage 11.0 (TID 88) in 35 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.305122","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 19.0 in stage 11.0 (TID 89) in 35 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.333363","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_22 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.333449","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_20 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.343966","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 23.0 in stage 11.0 (TID 92) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.344622","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 24.0 in stage 11.0 (TID 93) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.344704","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 22.0 in stage 11.0 (TID 91) in 40 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.344736","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 20.0 in stage 11.0 (TID 90) in 41 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.366974","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_24 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.367065","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_23 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.387006","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 26.0 in stage 11.0 (TID 94) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.387411","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 28.0 in stage 11.0 (TID 95) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.387625","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 23.0 in stage 11.0 (TID 92) in 44 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.387851","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 24.0 in stage 11.0 (TID 93) in 43 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.413541","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_28 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.413634","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_26 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.425754","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 29.0 in stage 11.0 (TID 96) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.425987","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 26.0 in stage 11.0 (TID 94) in 39 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.426644","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 31.0 in stage 11.0 (TID 97) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.426767","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 28.0 in stage 11.0 (TID 95) in 39 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.445904","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_29 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.447738","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_31 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.454250","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 33.0 in stage 11.0 (TID 98) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.454614","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 29.0 in stage 11.0 (TID 96) in 29 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.455881","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 35.0 in stage 11.0 (TID 99) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.456089","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 31.0 in stage 11.0 (TID 97) in 29 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.473870","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_35 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.475228","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_33 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.483044","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 36.0 in stage 11.0 (TID 100) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.484103","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 38.0 in stage 11.0 (TID 101) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.484173","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 33.0 in stage 11.0 (TID 98) in 30 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.484201","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 35.0 in stage 11.0 (TID 99) in 28 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.500230","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_38 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.500317","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_36 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.510995","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 40.0 in stage 11.0 (TID 102) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.511169","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 38.0 in stage 11.0 (TID 101) in 28 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.511616","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 41.0 in stage 11.0 (TID 103) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.511802","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 36.0 in stage 11.0 (TID 100) in 29 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.533159","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_40 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.533242","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_41 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.541504","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 43.0 in stage 11.0 (TID 104) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.541782","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 41.0 in stage 11.0 (TID 103) in 30 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.541927","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 45.0 in stage 11.0 (TID 105) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.542154","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 40.0 in stage 11.0 (TID 102) in 32 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.567649","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_43 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.568270","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_45 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.583062","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 47.0 in stage 11.0 (TID 106) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.583324","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 48.0 in stage 11.0 (TID 107) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.583520","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 43.0 in stage 11.0 (TID 104) in 42 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.583799","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 45.0 in stage 11.0 (TID 105) in 42 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.606404","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_48 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.606496","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added rdd_39_47 in memory on 172.18.0.8:42851 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.618091","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 47.0 in stage 11.0 (TID 106) in 35 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.618171","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 48.0 in stage 11.0 (TID 107) in 35 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.618196","level":"info","event":"25/08/01 08:41:57 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.618546","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: ShuffleMapStage 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.962 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.618601","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.618635","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.618660","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.618694","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.634019","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 0baa42e17007:42905 in memory (size: 137.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.634112","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.8:42851 in memory (size: 137.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.638495","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 0baa42e17007:42905 in memory (size: 43.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.638567","level":"info","event":"25/08/01 08:41:57 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.639303","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.8:42851 in memory (size: 43.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.640754","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Got job 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.641132","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Final stage: ResultStage 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.641288","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.641756","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.642006","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[45] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.644157","level":"info","event":"25/08/01 08:41:57 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 532.9 KiB, free 432.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.645320","level":"info","event":"25/08/01 08:41:57 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 124.1 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.645619","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 0baa42e17007:42905 (size: 124.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.646019","level":"info","event":"25/08/01 08:41:57 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.646298","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[45] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.646342","level":"info","event":"25/08/01 08:41:57 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.647239","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 108) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.654625","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:42851 (size: 124.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.659345","level":"info","event":"25/08/01 08:41:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:58580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.672971","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 108) in 26 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.673041","level":"info","event":"25/08/01 08:41:57 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.673259","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: ResultStage 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.032 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.673420","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.673476","level":"info","event":"25/08/01 08:41:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.673720","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Job 8 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.035091 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.680787","level":"info","event":"25/08/01 08:41:57 INFO Snapshot: [tableId=9ce1f2ed-51b3-4e89-b775-e5382d4313a3] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.797739","level":"info","event":"25/08/01 08:41:57 INFO CodeGenerator: Code generated in 33.124875 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.806471","level":"info","event":"25/08/01 08:41:57 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.807050","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Got job 9 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.807102","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Final stage: ResultStage 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.807129","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.807583","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.807713","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[47] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.809712","level":"info","event":"25/08/01 08:41:57 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 683.1 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.810978","level":"info","event":"25/08/01 08:41:57 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 153.3 KiB, free 432.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.811171","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 0baa42e17007:42905 (size: 153.3 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.811340","level":"info","event":"25/08/01 08:41:57 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.811592","level":"info","event":"25/08/01 08:41:57 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 16 (MapPartitionsRDD[47] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.811631","level":"info","event":"25/08/01 08:41:57 INFO TaskSchedulerImpl: Adding task set 16.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.812598","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 109) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.812715","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 110) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.817995","level":"info","event":"25/08/01 08:41:57 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.8:42851 (size: 153.3 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.905083","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 111) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.905478","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 109) in 93 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.905743","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 112) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.905925","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 110) in 93 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.911830","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 4.0 in stage 16.0 (TID 113) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.912305","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 5.0 in stage 16.0 (TID 114) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.912968","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 111) in 8 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.913215","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 112) in 8 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.918810","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 6.0 in stage 16.0 (TID 115) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.919003","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 5.0 in stage 16.0 (TID 114) in 6 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.919366","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 7.0 in stage 16.0 (TID 116) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.919541","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 4.0 in stage 16.0 (TID 113) in 8 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.926999","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 8.0 in stage 16.0 (TID 117) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.927304","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 6.0 in stage 16.0 (TID 115) in 9 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.927707","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 9.0 in stage 16.0 (TID 118) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.928114","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 7.0 in stage 16.0 (TID 116) in 8 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.933425","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 10.0 in stage 16.0 (TID 119) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.933804","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 11.0 in stage 16.0 (TID 120) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.934212","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 9.0 in stage 16.0 (TID 118) in 7 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.934275","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 8.0 in stage 16.0 (TID 117) in 8 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.942322","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 12.0 in stage 16.0 (TID 121) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.942403","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 11.0 in stage 16.0 (TID 120) in 9 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.942887","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 13.0 in stage 16.0 (TID 122) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.943270","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 10.0 in stage 16.0 (TID 119) in 10 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.949372","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 14.0 in stage 16.0 (TID 123) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.949622","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 12.0 in stage 16.0 (TID 121) in 7 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.950215","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 15.0 in stage 16.0 (TID 124) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.950510","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 13.0 in stage 16.0 (TID 122) in 8 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.957496","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 16.0 in stage 16.0 (TID 125) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.957656","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 14.0 in stage 16.0 (TID 123) in 8 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.958158","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 17.0 in stage 16.0 (TID 126) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.958397","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 15.0 in stage 16.0 (TID 124) in 9 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.967212","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 18.0 in stage 16.0 (TID 127) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.967591","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 19.0 in stage 16.0 (TID 128) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.967862","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 17.0 in stage 16.0 (TID 126) in 10 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.968333","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 16.0 in stage 16.0 (TID 125) in 10 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.975178","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 20.0 in stage 16.0 (TID 129) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.975708","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 21.0 in stage 16.0 (TID 130) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.975997","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 19.0 in stage 16.0 (TID 128) in 8 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.976087","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 18.0 in stage 16.0 (TID 127) in 10 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.984349","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 22.0 in stage 16.0 (TID 131) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.984586","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 21.0 in stage 16.0 (TID 130) in 9 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.984931","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 23.0 in stage 16.0 (TID 132) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.985257","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 20.0 in stage 16.0 (TID 129) in 11 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.994983","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 24.0 in stage 16.0 (TID 133) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.995206","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 22.0 in stage 16.0 (TID 131) in 11 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.995609","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Starting task 25.0 in stage 16.0 (TID 134) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:57.995740","level":"info","event":"25/08/01 08:41:57 INFO TaskSetManager: Finished task 23.0 in stage 16.0 (TID 132) in 11 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.003133","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 26.0 in stage 16.0 (TID 135) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.003389","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 25.0 in stage 16.0 (TID 134) in 8 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.003641","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 27.0 in stage 16.0 (TID 136) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.003928","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 24.0 in stage 16.0 (TID 133) in 9 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.013855","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 28.0 in stage 16.0 (TID 137) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.014488","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 26.0 in stage 16.0 (TID 135) in 12 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.014759","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 29.0 in stage 16.0 (TID 138) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.015449","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 27.0 in stage 16.0 (TID 136) in 11 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.025021","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 30.0 in stage 16.0 (TID 139) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.025543","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 31.0 in stage 16.0 (TID 140) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.025614","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 29.0 in stage 16.0 (TID 138) in 11 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.026220","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 28.0 in stage 16.0 (TID 137) in 12 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.035542","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 32.0 in stage 16.0 (TID 141) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.035873","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 33.0 in stage 16.0 (TID 142) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.036046","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 30.0 in stage 16.0 (TID 139) in 11 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.036102","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 31.0 in stage 16.0 (TID 140) in 11 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.044320","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 34.0 in stage 16.0 (TID 143) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.044548","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 32.0 in stage 16.0 (TID 141) in 9 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.045168","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 35.0 in stage 16.0 (TID 144) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.045534","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 33.0 in stage 16.0 (TID 142) in 10 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.054808","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 36.0 in stage 16.0 (TID 145) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.055264","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 37.0 in stage 16.0 (TID 146) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.055468","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 34.0 in stage 16.0 (TID 143) in 12 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.055654","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 35.0 in stage 16.0 (TID 144) in 11 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.064388","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 38.0 in stage 16.0 (TID 147) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.064614","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 36.0 in stage 16.0 (TID 145) in 10 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.064711","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 39.0 in stage 16.0 (TID 148) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.065229","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 37.0 in stage 16.0 (TID 146) in 10 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.076053","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 40.0 in stage 16.0 (TID 149) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.076243","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 39.0 in stage 16.0 (TID 148) in 12 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.076668","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 41.0 in stage 16.0 (TID 150) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.076847","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 38.0 in stage 16.0 (TID 147) in 12 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.086088","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 42.0 in stage 16.0 (TID 151) (172.18.0.8, executor 0, partition 42, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.086762","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 43.0 in stage 16.0 (TID 152) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.087237","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 40.0 in stage 16.0 (TID 149) in 12 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.091131","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 41.0 in stage 16.0 (TID 150) in 14 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.095253","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 44.0 in stage 16.0 (TID 153) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.095623","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 45.0 in stage 16.0 (TID 154) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.096273","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 42.0 in stage 16.0 (TID 151) in 10 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.096353","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 43.0 in stage 16.0 (TID 152) in 10 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.104006","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 46.0 in stage 16.0 (TID 155) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.104092","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 44.0 in stage 16.0 (TID 153) in 9 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.104570","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 47.0 in stage 16.0 (TID 156) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.104703","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 45.0 in stage 16.0 (TID 154) in 9 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.111650","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 48.0 in stage 16.0 (TID 157) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.111881","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 46.0 in stage 16.0 (TID 155) in 8 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.112337","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 49.0 in stage 16.0 (TID 158) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.112549","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 47.0 in stage 16.0 (TID 156) in 8 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.119379","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 49.0 in stage 16.0 (TID 158) in 7 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.119470","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 48.0 in stage 16.0 (TID 157) in 8 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.119502","level":"info","event":"25/08/01 08:41:58 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.119725","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: ResultStage 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.311 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.119828","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.119853","level":"info","event":"25/08/01 08:41:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.120085","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Job 9 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.313526 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.130354","level":"info","event":"25/08/01 08:41:58 INFO CodeGenerator: Code generated in 6.898417 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.131793","level":"info","event":"25/08/01 08:41:58 INFO PrepareDeltaScan: DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.140039","level":"info","event":"25/08/01 08:41:58 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.140112","level":"info","event":"25/08/01 08:41:58 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.165190","level":"info","event":"25/08/01 08:41:58 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.234833","level":"info","event":"25/08/01 08:41:58 INFO CodeGenerator: Code generated in 35.439375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.236551","level":"info","event":"25/08/01 08:41:58 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 207.6 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.248793","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 0baa42e17007:42905 in memory (size: 153.3 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.250648","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.8:42851 in memory (size: 153.3 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.250759","level":"info","event":"25/08/01 08:41:58 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.251034","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 0baa42e17007:42905 (size: 37.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.251646","level":"info","event":"25/08/01 08:41:58 INFO SparkContext: Created broadcast 17 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.253560","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 0baa42e17007:42905 in memory (size: 124.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.254602","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.8:42851 in memory (size: 124.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.254673","level":"info","event":"25/08/01 08:41:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4224528 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.262409","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Registering RDD 51 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.262492","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Got map stage job 10 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.262520","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.262553","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.262585","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.262623","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[51] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.263587","level":"info","event":"25/08/01 08:41:58 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 44.9 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.264197","level":"info","event":"25/08/01 08:41:58 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.264392","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 0baa42e17007:42905 (size: 19.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.264660","level":"info","event":"25/08/01 08:41:58 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.264844","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[51] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.264898","level":"info","event":"25/08/01 08:41:58 INFO TaskSchedulerImpl: Adding task set 17.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.265371","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 159) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11172 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.265512","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 160) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11172 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.270641","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.8:42851 (size: 19.9 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.350636","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.8:42851 (size: 37.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.487390","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 159) in 216 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.490046","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 160) in 216 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.490168","level":"info","event":"25/08/01 08:41:58 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.490281","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: ShuffleMapStage 17 (save at NativeMethodAccessorImpl.java:0) finished in 0.220 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.490345","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.490398","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.490455","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.490496","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.503139","level":"info","event":"25/08/01 08:41:58 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.517614","level":"info","event":"25/08/01 08:41:58 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.525953","level":"info","event":"25/08/01 08:41:58 INFO CodeGenerator: Code generated in 5.567833 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.574365","level":"info","event":"25/08/01 08:41:58 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.575168","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Got job 11 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.575236","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Final stage: ResultStage 19 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.575283","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.575330","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.575354","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[53] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.585257","level":"info","event":"25/08/01 08:41:58 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 362.4 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.586580","level":"info","event":"25/08/01 08:41:58 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 132.6 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.586819","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 0baa42e17007:42905 (size: 132.6 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.587191","level":"info","event":"25/08/01 08:41:58 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.587390","level":"info","event":"25/08/01 08:41:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[53] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.587437","level":"info","event":"25/08/01 08:41:58 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.588146","level":"info","event":"25/08/01 08:41:58 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 161) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.668861","level":"info","event":"25/08/01 08:41:58 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.8:42851 (size: 132.6 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:41:58.750161","level":"info","event":"25/08/01 08:41:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.8:58580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.135086","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 161) in 1545 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.136095","level":"info","event":"25/08/01 08:42:00 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.136396","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: ResultStage 19 (save at NativeMethodAccessorImpl.java:0) finished in 1.559 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.137038","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.137092","level":"info","event":"25/08/01 08:42:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.142747","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Job 11 finished: save at NativeMethodAccessorImpl.java:0, took 1.568543 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.144117","level":"info","event":"25/08/01 08:42:00 INFO DeltaFileFormatWriter: Start to commit write Job e650eecf-2fec-420a-a0fc-26c6dd09eb3a.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.145415","level":"info","event":"25/08/01 08:42:00 INFO DeltaFileFormatWriter: Write Job e650eecf-2fec-420a-a0fc-26c6dd09eb3a committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.149256","level":"info","event":"25/08/01 08:42:00 INFO DeltaFileFormatWriter: Finished processing stats for write job e650eecf-2fec-420a-a0fc-26c6dd09eb3a.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.253850","level":"info","event":"25/08/01 08:42:00 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.254446","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Got job 12 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.254494","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Final stage: ResultStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.254517","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.254562","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.254592","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[55] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.261558","level":"info","event":"25/08/01 08:42:00 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 685.0 KiB, free 432.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.262741","level":"info","event":"25/08/01 08:42:00 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 0baa42e17007:42905 in memory (size: 19.9 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.263946","level":"info","event":"25/08/01 08:42:00 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.264414","level":"info","event":"25/08/01 08:42:00 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 0baa42e17007:42905 (size: 154.5 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.264553","level":"info","event":"25/08/01 08:42:00 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.265038","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 21 (MapPartitionsRDD[55] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.265115","level":"info","event":"25/08/01 08:42:00 INFO TaskSchedulerImpl: Adding task set 21.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.265886","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 162) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.265986","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 163) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.291082","level":"info","event":"25/08/01 08:42:00 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.8:42851 in memory (size: 19.9 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.321472","level":"info","event":"25/08/01 08:42:00 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.8:42851 (size: 154.5 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.355521","level":"info","event":"25/08/01 08:42:00 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 0baa42e17007:42905 in memory (size: 132.6 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.368437","level":"info","event":"25/08/01 08:42:00 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.8:42851 in memory (size: 132.6 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.396345","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 164) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.398446","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 165) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.398497","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 163) in 130 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.398523","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 162) in 131 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.476375","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 4.0 in stage 21.0 (TID 166) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.478051","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 164) in 81 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.491374","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 5.0 in stage 21.0 (TID 167) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.492344","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 165) in 96 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.506791","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 6.0 in stage 21.0 (TID 168) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.507457","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 4.0 in stage 21.0 (TID 166) in 40 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.507640","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 7.0 in stage 21.0 (TID 169) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.508158","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 5.0 in stage 21.0 (TID 167) in 19 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.543574","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 8.0 in stage 21.0 (TID 170) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.544501","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 9.0 in stage 21.0 (TID 171) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.544549","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 7.0 in stage 21.0 (TID 169) in 34 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.544573","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 6.0 in stage 21.0 (TID 168) in 35 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.565616","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 10.0 in stage 21.0 (TID 172) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.566252","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 11.0 in stage 21.0 (TID 173) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.566311","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 8.0 in stage 21.0 (TID 170) in 26 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.566338","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 9.0 in stage 21.0 (TID 171) in 25 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.578390","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 12.0 in stage 21.0 (TID 174) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.578627","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 11.0 in stage 21.0 (TID 173) in 13 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.579018","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 13.0 in stage 21.0 (TID 175) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.579357","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 10.0 in stage 21.0 (TID 172) in 15 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.587390","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 14.0 in stage 21.0 (TID 176) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.587576","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 15.0 in stage 21.0 (TID 177) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.587764","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 13.0 in stage 21.0 (TID 175) in 9 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.587952","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 12.0 in stage 21.0 (TID 174) in 9 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.599288","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 16.0 in stage 21.0 (TID 178) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.599485","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 14.0 in stage 21.0 (TID 176) in 12 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.599843","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 17.0 in stage 21.0 (TID 179) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.600057","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 15.0 in stage 21.0 (TID 177) in 12 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.607673","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 18.0 in stage 21.0 (TID 180) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.607918","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 17.0 in stage 21.0 (TID 179) in 8 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.608347","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 19.0 in stage 21.0 (TID 181) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.608465","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 16.0 in stage 21.0 (TID 178) in 10 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.615855","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 20.0 in stage 21.0 (TID 182) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.616188","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 21.0 in stage 21.0 (TID 183) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.616344","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 18.0 in stage 21.0 (TID 180) in 9 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.616759","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 19.0 in stage 21.0 (TID 181) in 8 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.623535","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 22.0 in stage 21.0 (TID 184) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.623725","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 20.0 in stage 21.0 (TID 182) in 8 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.624029","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 23.0 in stage 21.0 (TID 185) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.624262","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 21.0 in stage 21.0 (TID 183) in 8 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.630284","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 24.0 in stage 21.0 (TID 186) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.630551","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 22.0 in stage 21.0 (TID 184) in 7 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.630850","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 25.0 in stage 21.0 (TID 187) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.631153","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 23.0 in stage 21.0 (TID 185) in 8 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.637895","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 26.0 in stage 21.0 (TID 188) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.638246","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 27.0 in stage 21.0 (TID 189) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.638422","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 25.0 in stage 21.0 (TID 187) in 8 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.638740","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 24.0 in stage 21.0 (TID 186) in 8 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.647072","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 28.0 in stage 21.0 (TID 190) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.647215","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 27.0 in stage 21.0 (TID 189) in 8 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.647769","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 29.0 in stage 21.0 (TID 191) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.648120","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 26.0 in stage 21.0 (TID 188) in 10 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.656001","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 30.0 in stage 21.0 (TID 192) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.656791","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 31.0 in stage 21.0 (TID 193) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.657201","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 28.0 in stage 21.0 (TID 190) in 11 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.657287","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 29.0 in stage 21.0 (TID 191) in 10 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.676865","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 32.0 in stage 21.0 (TID 194) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.677797","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 30.0 in stage 21.0 (TID 192) in 21 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.677870","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 33.0 in stage 21.0 (TID 195) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.677894","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 31.0 in stage 21.0 (TID 193) in 20 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.684749","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 34.0 in stage 21.0 (TID 196) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.684932","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 33.0 in stage 21.0 (TID 195) in 8 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.685245","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 35.0 in stage 21.0 (TID 197) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.685640","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 32.0 in stage 21.0 (TID 194) in 10 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.690554","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 36.0 in stage 21.0 (TID 198) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.690787","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 35.0 in stage 21.0 (TID 197) in 5 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.691125","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 37.0 in stage 21.0 (TID 199) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.691280","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 34.0 in stage 21.0 (TID 196) in 7 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.699726","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 38.0 in stage 21.0 (TID 200) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.700053","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 39.0 in stage 21.0 (TID 201) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.700240","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 37.0 in stage 21.0 (TID 199) in 10 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.700305","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 36.0 in stage 21.0 (TID 198) in 10 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.706846","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 40.0 in stage 21.0 (TID 202) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.706950","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 39.0 in stage 21.0 (TID 201) in 7 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.707336","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 41.0 in stage 21.0 (TID 203) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.707403","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 38.0 in stage 21.0 (TID 200) in 8 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.715574","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 42.0 in stage 21.0 (TID 204) (172.18.0.8, executor 0, partition 42, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.715722","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 43.0 in stage 21.0 (TID 205) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.715930","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 41.0 in stage 21.0 (TID 203) in 8 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.715993","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 40.0 in stage 21.0 (TID 202) in 9 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.723151","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 44.0 in stage 21.0 (TID 206) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.723706","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 42.0 in stage 21.0 (TID 204) in 9 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.724236","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 45.0 in stage 21.0 (TID 207) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.724365","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 43.0 in stage 21.0 (TID 205) in 9 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.732395","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 46.0 in stage 21.0 (TID 208) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.732895","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 47.0 in stage 21.0 (TID 209) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.733084","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 45.0 in stage 21.0 (TID 207) in 8 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.733127","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 44.0 in stage 21.0 (TID 206) in 10 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.741533","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 48.0 in stage 21.0 (TID 210) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.741637","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 47.0 in stage 21.0 (TID 209) in 8 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.741665","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Starting task 49.0 in stage 21.0 (TID 211) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.741998","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 46.0 in stage 21.0 (TID 208) in 9 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.748723","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 48.0 in stage 21.0 (TID 210) in 8 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.749192","level":"info","event":"25/08/01 08:42:00 INFO TaskSetManager: Finished task 49.0 in stage 21.0 (TID 211) in 7 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.749264","level":"info","event":"25/08/01 08:42:00 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.749994","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: ResultStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.494 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.750057","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.750083","level":"info","event":"25/08/01 08:42:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.750767","level":"info","event":"25/08/01 08:42:00 INFO DAGScheduler: Job 12 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.497105 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:00.777614","level":"info","event":"25/08/01 08:42:00 INFO OptimisticTransaction: [tableId=3547bf11,txnId=8ba58de4] Attempting to commit version 10 with 3 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.338388","level":"info","event":"25/08/01 08:42:03 INFO DeltaLog: Creating a new snapshot v10 for commit version 10","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.339207","level":"info","event":"25/08/01 08:42:03 INFO DeltaLog: Loading version 10.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.426696","level":"info","event":"25/08/01 08:42:03 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 11, totalFileSize: 11680)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.479910","level":"info","event":"25/08/01 08:42:03 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.481287","level":"info","event":"25/08/01 08:42:03 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.481347","level":"info","event":"25/08/01 08:42:03 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#1053.minReaderVersion) OR isnotnull(metaData#1052.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.513270","level":"info","event":"25/08/01 08:42:03 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 206.2 KiB, free 432.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.559377","level":"info","event":"25/08/01 08:42:03 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.573156","level":"info","event":"25/08/01 08:42:03 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 0baa42e17007:42905 (size: 36.5 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.577466","level":"info","event":"25/08/01 08:42:03 INFO SparkContext: Created broadcast 21 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.591407","level":"info","event":"25/08/01 08:42:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23074512 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.655351","level":"info","event":"25/08/01 08:42:03 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.656104","level":"info","event":"25/08/01 08:42:03 INFO DAGScheduler: Got job 13 (toString at String.java:4220) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.656152","level":"info","event":"25/08/01 08:42:03 INFO DAGScheduler: Final stage: ResultStage 22 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.656179","level":"info","event":"25/08/01 08:42:03 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.656205","level":"info","event":"25/08/01 08:42:03 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.656228","level":"info","event":"25/08/01 08:42:03 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[59] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.656352","level":"info","event":"25/08/01 08:42:03 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 40.0 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.658490","level":"info","event":"25/08/01 08:42:03 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.658947","level":"info","event":"25/08/01 08:42:03 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 0baa42e17007:42905 (size: 13.7 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.660756","level":"info","event":"25/08/01 08:42:03 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.663537","level":"info","event":"25/08/01 08:42:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 22 (MapPartitionsRDD[59] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.663848","level":"info","event":"25/08/01 08:42:03 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.672246","level":"info","event":"25/08/01 08:42:03 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 212) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11949 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.673713","level":"info","event":"25/08/01 08:42:03 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 213) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11792 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.760902","level":"info","event":"25/08/01 08:42:03 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.8:42851 (size: 13.7 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:03.857528","level":"info","event":"25/08/01 08:42:03 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.8:42851 (size: 36.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.705971","level":"info","event":"25/08/01 08:42:04 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 213) in 1036 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.707093","level":"info","event":"25/08/01 08:42:04 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 212) in 1038 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.707134","level":"info","event":"25/08/01 08:42:04 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.707159","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: ResultStage 22 (toString at String.java:4220) finished in 1.050 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.707180","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.707200","level":"info","event":"25/08/01 08:42:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.707217","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Job 13 finished: toString at String.java:4220, took 1.051248 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.709459","level":"info","event":"25/08/01 08:42:04 INFO Snapshot: [tableId=3547bf11-335a-4bfb-a37a-8cc2809296bb] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=10, metadata=Metadata(3547bf11-335a-4bfb-a37a-8cc2809296bb,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754033170534)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,10,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000000.json; isDirectory=false; length=1336; replication=1; blocksize=33554432; modification_time=1754033175410; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=5c3a251d3ca25d55b3fc96ccf13cbcdd versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000001.json; isDirectory=false; length=1031; replication=1; blocksize=33554432; modification_time=1754033448511; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=3bea36df86a521e758a330c73dfb9e49 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000002.json; isDirectory=false; length=1033; replication=1; blocksize=33554432; modification_time=1754034003955; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=52e16d286e67b3560233b6a0cef954c7 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000003.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034146528; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=372c58fa4aee9a5fb8410f6c2b95ba5a versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000004.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034353496; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=1ca25629f04bf0aeba6acfc86f0f52b8 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000005.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034796161; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=151dd235ebf4d834587dd9e477ba413b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000006.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035338336; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=09ac49cc1475bd5703812106b8d84bcf versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000007.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035525575; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=6c753dac8bec87512bcecd2c2c0f587c versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000008.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035700395; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=6d86b8614ebf10eb58d0810dd3fbdd1b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000009.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754036577027; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=9d1ec6bd23168c9d68b12067a7d25ef0 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000010.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754037722723; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=cb497482bca5678b9c0a2cf9f048afbc versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@79a7f01b,1754037722723), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.711240","level":"info","event":"25/08/01 08:42:04 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=10, metadata=Metadata(3547bf11-335a-4bfb-a37a-8cc2809296bb,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754033170534)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,10,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000000.json; isDirectory=false; length=1336; replication=1; blocksize=33554432; modification_time=1754033175410; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=5c3a251d3ca25d55b3fc96ccf13cbcdd versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000001.json; isDirectory=false; length=1031; replication=1; blocksize=33554432; modification_time=1754033448511; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=3bea36df86a521e758a330c73dfb9e49 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000002.json; isDirectory=false; length=1033; replication=1; blocksize=33554432; modification_time=1754034003955; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=52e16d286e67b3560233b6a0cef954c7 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000003.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034146528; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=372c58fa4aee9a5fb8410f6c2b95ba5a versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000004.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034353496; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=1ca25629f04bf0aeba6acfc86f0f52b8 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000005.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754034796161; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=151dd235ebf4d834587dd9e477ba413b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000006.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035338336; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=09ac49cc1475bd5703812106b8d84bcf versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000007.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035525575; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=6c753dac8bec87512bcecd2c2c0f587c versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000008.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754035700395; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=6d86b8614ebf10eb58d0810dd3fbdd1b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000009.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754036577027; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=9d1ec6bd23168c9d68b12067a7d25ef0 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000010.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1754037722723; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=cb497482bca5678b9c0a2cf9f048afbc versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@79a7f01b,1754037722723), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.711812","level":"info","event":"25/08/01 08:42:04 INFO MapPartitionsRDD: Removing RDD 22 from persistence list","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.715704","level":"info","event":"25/08/01 08:42:04 INFO BlockManager: Removing RDD 22","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.724351","level":"info","event":"25/08/01 08:42:04 INFO Snapshot: [tableId=3547bf11-335a-4bfb-a37a-8cc2809296bb] DELTA: Compute snapshot for version: 10","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.725236","level":"info","event":"25/08/01 08:42:04 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 205.9 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.728905","level":"info","event":"25/08/01 08:42:04 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.729214","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 0baa42e17007:42905 (size: 36.4 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.729669","level":"info","event":"25/08/01 08:42:04 INFO SparkContext: Created broadcast 23 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.783054","level":"info","event":"25/08/01 08:42:04 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.783336","level":"info","event":"25/08/01 08:42:04 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.783390","level":"info","event":"25/08/01 08:42:04 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.802480","level":"info","event":"25/08/01 08:42:04 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 206.2 KiB, free 431.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.817427","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 0baa42e17007:42905 in memory (size: 36.5 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.818774","level":"info","event":"25/08/01 08:42:04 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.818828","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 0baa42e17007:42905 (size: 36.5 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.821140","level":"info","event":"25/08/01 08:42:04 INFO SparkContext: Created broadcast 24 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.823173","level":"info","event":"25/08/01 08:42:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 23074512 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.826605","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.18.0.8:42851 in memory (size: 36.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.865516","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Registering RDD 63 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.866934","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Got map stage job 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.866980","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Final stage: ShuffleMapStage 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.867003","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.867023","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.867043","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[63] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.869443","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 0baa42e17007:42905 in memory (size: 13.7 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.893884","level":"info","event":"25/08/01 08:42:04 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 105.7 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.896008","level":"info","event":"25/08/01 08:42:04 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.897132","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 0baa42e17007:42905 (size: 32.6 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.897384","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.8:42851 in memory (size: 13.7 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.900105","level":"info","event":"25/08/01 08:42:04 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.901802","level":"info","event":"25/08/01 08:42:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[63] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.901954","level":"info","event":"25/08/01 08:42:04 INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.913474","level":"info","event":"25/08/01 08:42:04 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 214) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11938 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.915804","level":"info","event":"25/08/01 08:42:04 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 215) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11781 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.934898","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 0baa42e17007:42905 in memory (size: 154.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.951287","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.8:42851 in memory (size: 154.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:04.980468","level":"info","event":"25/08/01 08:42:04 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.8:42851 (size: 32.6 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:05.094825","level":"info","event":"25/08/01 08:42:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.8:42851 (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:06.347559","level":"info","event":"25/08/01 08:42:06 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 215) in 1432 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:06.810105","level":"info","event":"25/08/01 08:42:06 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 214) in 1901 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:06.817538","level":"info","event":"25/08/01 08:42:06 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:06.830722","level":"info","event":"25/08/01 08:42:06 INFO DAGScheduler: ShuffleMapStage 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.962 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:06.832084","level":"info","event":"25/08/01 08:42:06 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:06.832212","level":"info","event":"25/08/01 08:42:06 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:06.832265","level":"info","event":"25/08/01 08:42:06 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:06.832294","level":"info","event":"25/08/01 08:42:06 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.292098","level":"info","event":"25/08/01 08:42:07 INFO DAGScheduler: Registering RDD 73 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.292949","level":"info","event":"25/08/01 08:42:07 INFO DAGScheduler: Got map stage job 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.293005","level":"info","event":"25/08/01 08:42:07 INFO DAGScheduler: Final stage: ShuffleMapStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.293032","level":"info","event":"25/08/01 08:42:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.293988","level":"info","event":"25/08/01 08:42:07 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.294434","level":"info","event":"25/08/01 08:42:07 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[73] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.326057","level":"info","event":"25/08/01 08:42:07 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 603.6 KiB, free 432.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.336519","level":"info","event":"25/08/01 08:42:07 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 138.4 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.337537","level":"info","event":"25/08/01 08:42:07 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 0baa42e17007:42905 (size: 138.4 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.339370","level":"info","event":"25/08/01 08:42:07 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.350082","level":"info","event":"25/08/01 08:42:07 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[73] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.352269","level":"info","event":"25/08/01 08:42:07 INFO TaskSchedulerImpl: Adding task set 25.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.360739","level":"info","event":"25/08/01 08:42:07 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 216) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.363538","level":"info","event":"25/08/01 08:42:07 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 217) (172.18.0.8, executor 0, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.458651","level":"info","event":"25/08/01 08:42:07 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.8:42851 (size: 138.4 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.536797","level":"info","event":"25/08/01 08:42:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:58580","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.605458","level":"info","event":"25/08/01 08:42:07 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 0baa42e17007:42905 in memory (size: 32.6 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.628320","level":"info","event":"25/08/01 08:42:07 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.8:42851 in memory (size: 32.6 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.805657","level":"info","event":"25/08/01 08:42:07 INFO BlockManagerInfo: Added rdd_70_2 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:07.815816","level":"info","event":"25/08/01 08:42:07 INFO BlockManagerInfo: Added rdd_70_0 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:08.057531","level":"info","event":"25/08/01 08:42:08 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 218) (172.18.0.8, executor 0, partition 3, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:08.073204","level":"info","event":"25/08/01 08:42:08 INFO TaskSetManager: Starting task 4.0 in stage 25.0 (TID 219) (172.18.0.8, executor 0, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:08.085121","level":"info","event":"25/08/01 08:42:08 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 216) in 721 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:08.091502","level":"info","event":"25/08/01 08:42:08 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 217) in 728 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:08.589843","level":"info","event":"25/08/01 08:42:08 INFO BlockManagerInfo: Added rdd_70_4 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:08.629178","level":"info","event":"25/08/01 08:42:08 INFO BlockManagerInfo: Added rdd_70_3 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:10.438139","level":"info","event":"25/08/01 08:42:10 INFO TaskSetManager: Starting task 7.0 in stage 25.0 (TID 220) (172.18.0.8, executor 0, partition 7, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:10.451009","level":"info","event":"25/08/01 08:42:10 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 218) in 2393 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:10.464002","level":"info","event":"25/08/01 08:42:10 INFO TaskSetManager: Starting task 10.0 in stage 25.0 (TID 221) (172.18.0.8, executor 0, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:10.470298","level":"info","event":"25/08/01 08:42:10 INFO TaskSetManager: Finished task 4.0 in stage 25.0 (TID 219) in 2395 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:11.401831","level":"info","event":"25/08/01 08:42:11 INFO BlockManagerInfo: Added rdd_70_7 in memory on 172.18.0.8:42851 (size: 449.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:11.427376","level":"info","event":"25/08/01 08:42:11 INFO BlockManagerInfo: Added rdd_70_10 in memory on 172.18.0.8:42851 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:15.970661","level":"info","event":"25/08/01 08:42:15 INFO TaskSetManager: Starting task 14.0 in stage 25.0 (TID 222) (172.18.0.8, executor 0, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:16.174995","level":"info","event":"25/08/01 08:42:15 INFO TaskSetManager: Finished task 10.0 in stage 25.0 (TID 221) in 5517 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:16.679675","level":"info","event":"25/08/01 08:42:16 INFO TaskSetManager: Starting task 22.0 in stage 25.0 (TID 223) (172.18.0.8, executor 0, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:16.889568","level":"info","event":"25/08/01 08:42:16 INFO TaskSetManager: Finished task 7.0 in stage 25.0 (TID 220) in 6342 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.329334","level":"info","event":"25/08/01 08:42:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801084147-0001/0 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.331945","level":"info","event":"25/08/01 08:42:20 INFO StandaloneSchedulerBackend: Executor app-20250801084147-0001/0 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.336896","level":"info","event":"25/08/01 08:42:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801084147-0001/1 on worker-20250801084128-172.18.0.8-42021 (172.18.0.8:42021) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.337039","level":"info","event":"25/08/01 08:42:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801084147-0001/1 on hostPort 172.18.0.8:42021 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.352582","level":"info","event":"25/08/01 08:42:20 ERROR TaskSchedulerImpl: Lost executor 0 on 172.18.0.8: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.377500","level":"info","event":"25/08/01 08:42:20 WARN TaskSetManager: Lost task 22.0 in stage 25.0 (TID 223) (172.18.0.8 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.377618","level":"info","event":"25/08/01 08:42:20 WARN TaskSetManager: Lost task 14.0 in stage 25.0 (TID 222) (172.18.0.8 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.378784","level":"info","event":"25/08/01 08:42:20 INFO DAGScheduler: Resubmitted ShuffleMapTask(25, 3), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.378844","level":"info","event":"25/08/01 08:42:20 INFO DAGScheduler: Resubmitted ShuffleMapTask(25, 7), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.379976","level":"info","event":"25/08/01 08:42:20 INFO DAGScheduler: Resubmitted ShuffleMapTask(25, 2), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.380032","level":"info","event":"25/08/01 08:42:20 INFO DAGScheduler: Resubmitted ShuffleMapTask(25, 0), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.380425","level":"info","event":"25/08/01 08:42:20 INFO DAGScheduler: Resubmitted ShuffleMapTask(25, 4), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.380633","level":"info","event":"25/08/01 08:42:20 INFO DAGScheduler: Resubmitted ShuffleMapTask(25, 10), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.388662","level":"info","event":"25/08/01 08:42:20 INFO DAGScheduler: Executor lost: 0 (epoch 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.388953","level":"info","event":"25/08/01 08:42:20 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.389601","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_4 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392778","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_26 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392824","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_47 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392848","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392868","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_29 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392888","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392905","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_15 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392923","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_39 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392939","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392956","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.392989","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_7 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393025","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_22 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393058","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_33 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393076","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393105","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_48 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393125","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393141","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_19 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393172","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_1 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393198","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_31 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393214","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_34 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393231","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_28 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393246","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_35 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393263","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_8 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393440","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_32 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393532","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393575","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_45 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393612","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_46 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393640","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_23 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393679","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_27 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393717","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_37 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393759","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393784","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_9 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393802","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_25 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393835","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_41 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393868","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393900","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_42 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393946","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_21 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.393984","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_20 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394014","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_6 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394099","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394141","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_44 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394160","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_17 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394178","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_36 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394195","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_43 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394212","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_3 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394231","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_30 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394262","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394329","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_3 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394350","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_16 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394367","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_24 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394383","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_7 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394400","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_38 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394416","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394433","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_4 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394449","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_40 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.394465","level":"info","event":"25/08/01 08:42:20 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_39_49 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.396341","level":"info","event":"25/08/01 08:42:20 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.18.0.8, 42851, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.396457","level":"info","event":"25/08/01 08:42:20 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.397029","level":"info","event":"25/08/01 08:42:20 INFO DAGScheduler: Shuffle files lost for executor: 0 (epoch 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:20.405248","level":"info","event":"25/08/01 08:42:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801084147-0001/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:22.030588","level":"info","event":"25/08/01 08:42:22 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:36566) with ID 1,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:22.060843","level":"info","event":"25/08/01 08:42:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42573 with 1048.8 MiB RAM, BlockManagerId(1, 172.18.0.8, 42573, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:23.552885","level":"info","event":"25/08/01 08:42:23 INFO TaskSetManager: Starting task 14.1 in stage 25.0 (TID 224) (172.18.0.8, executor 1, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:23.553108","level":"info","event":"25/08/01 08:42:23 INFO TaskSetManager: Starting task 22.1 in stage 25.0 (TID 225) (172.18.0.8, executor 1, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:23.836472","level":"info","event":"25/08/01 08:42:23 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.8:42573 (size: 138.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.216182","level":"info","event":"25/08/01 08:42:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:36566","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.246321","level":"info","event":"25/08/01 08:42:24 INFO TaskSetManager: Starting task 10.1 in stage 25.0 (TID 226) (172.18.0.8, executor 1, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.246923","level":"info","event":"25/08/01 08:42:24 INFO TaskSetManager: Starting task 4.1 in stage 25.0 (TID 227) (172.18.0.8, executor 1, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.249210","level":"info","event":"25/08/01 08:42:24 WARN TaskSetManager: Lost task 14.1 in stage 25.0 (TID 224) (172.18.0.8 executor 1): FetchFailed(null, shuffleId=5, mapIndex=-1, mapId=-1, reduceId=14, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250128","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 14","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250222","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250320","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250479","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250545","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250585","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250624","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250650","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250686","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250706","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250723","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250754","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250771","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250787","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250804","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250820","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250843","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250879","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250901","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250918","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250934","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250954","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.250986","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251006","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251022","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251037","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251054","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251084","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251104","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251120","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251135","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251151","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251166","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251181","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251196","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251213","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251227","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251244","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251259","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251275","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251308","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251325","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251341","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251357","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251373","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251390","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251406","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251422","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251438","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251454","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251469","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251484","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251500","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251516","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251533","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251563","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251583","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251599","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251616","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251632","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251648","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251664","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251680","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251696","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251712","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251729","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251748","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251775","level":"info","event":"25/08/01 08:42:24 INFO TaskSetManager: task 14.1 in stage 25.0 (TID 224) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251813","level":"info","event":"25/08/01 08:42:24 INFO DAGScheduler: Marking ShuffleMapStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as failed due to a fetch failure from ShuffleMapStage 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251860","level":"info","event":"25/08/01 08:42:24 INFO DAGScheduler: ShuffleMapStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) failed in 16.953 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 14","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251882","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251897","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251913","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251928","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251944","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251959","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251975","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.251989","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252006","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252021","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252041","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252075","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252092","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252107","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252123","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252138","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252154","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252168","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252184","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252200","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252215","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252230","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252246","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252261","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252292","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252309","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252327","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252365","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252387","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252403","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252419","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252435","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252450","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252466","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252483","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252499","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252515","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252531","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252547","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252563","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252579","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252595","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252611","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252626","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252642","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252657","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252673","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252687","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252703","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252717","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252733","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252748","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252781","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252801","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252817","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252832","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252848","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252864","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252880","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252895","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252911","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252926","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252942","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252958","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252974","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.252990","level":"info","event":"25/08/01 08:42:24 INFO DAGScheduler: Resubmitting ShuffleMapStage 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) and ShuffleMapStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) due to fetch failure","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253008","level":"info","event":"25/08/01 08:42:24 WARN TaskSetManager: Lost task 22.1 in stage 25.0 (TID 225) (172.18.0.8 executor 1): FetchFailed(null, shuffleId=5, mapIndex=-1, mapId=-1, reduceId=22, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253024","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 22","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253039","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253054","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253070","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253085","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253101","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253117","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253132","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253148","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253164","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253180","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253196","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253211","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253226","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253242","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253258","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253273","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253308","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253342","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253360","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253377","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253391","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253407","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253422","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253437","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253452","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253468","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253490","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253506","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253521","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253537","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253553","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253568","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253584","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253598","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253614","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253629","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253645","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253659","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253675","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253690","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253706","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253720","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253765","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253801","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.253846","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266294","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266382","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266417","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266438","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266457","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266474","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266492","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266509","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266526","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266558","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266580","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266597","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266629","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266649","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266685","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266711","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266740","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266760","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266776","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266809","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266844","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266891","level":"info","event":"25/08/01 08:42:24 INFO TaskSetManager: task 22.1 in stage 25.0 (TID 225) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266933","level":"info","event":"25/08/01 08:42:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:36566","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.266966","level":"info","event":"25/08/01 08:42:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:36566","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267467","level":"info","event":"25/08/01 08:42:24 WARN TaskSetManager: Lost task 10.1 in stage 25.0 (TID 226) (172.18.0.8 executor 1): FetchFailed(null, shuffleId=5, mapIndex=-1, mapId=-1, reduceId=10, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267525","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 10","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267569","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267591","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267610","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267628","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267648","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267683","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267706","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267737","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267772","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267803","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267824","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267855","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267873","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267889","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267905","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267920","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267936","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267966","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.267983","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268000","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268018","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268036","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268052","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268068","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268084","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268100","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268116","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268132","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268148","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268173","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268209","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268249","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268299","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268335","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268366","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268384","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268400","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268417","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268432","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268447","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268476","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268494","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268509","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268525","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268557","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268574","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268590","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268617","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268637","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268653","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268678","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268705","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268722","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268737","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268753","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268781","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268810","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268832","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268849","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268865","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268890","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268911","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268930","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.268997","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.269019","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.269045","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.269073","level":"info","event":"25/08/01 08:42:24 INFO TaskSetManager: task 10.1 in stage 25.0 (TID 226) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271419","level":"info","event":"25/08/01 08:42:24 WARN TaskSetManager: Lost task 4.1 in stage 25.0 (TID 227) (172.18.0.8 executor 1): FetchFailed(null, shuffleId=5, mapIndex=-1, mapId=-1, reduceId=4, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271494","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271539","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271589","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271617","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271662","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271711","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271750","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271782","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271838","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271859","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271878","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271920","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271957","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.271998","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272036","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272073","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272093","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272122","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272170","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272218","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272259","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272307","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272360","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272405","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272460","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272500","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272536","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272580","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272621","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272657","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272680","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272703","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272735","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272775","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272811","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272850","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272883","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272902","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272941","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.272978","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273015","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273038","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273055","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273080","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273103","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273138","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273159","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273189","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273218","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273258","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273301","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273341","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273380","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273420","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273461","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273487","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273526","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273560","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273586","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273618","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273665","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273689","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273705","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273722","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273738","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273755","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273779","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273823","level":"info","event":"25/08/01 08:42:24 INFO TaskSetManager: task 4.1 in stage 25.0 (TID 227) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.273879","level":"info","event":"25/08/01 08:42:24 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.454011","level":"info","event":"25/08/01 08:42:24 INFO DAGScheduler: Resubmitting failed stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.454757","level":"info","event":"25/08/01 08:42:24 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[63] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.457269","level":"info","event":"25/08/01 08:42:24 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 105.7 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.459181","level":"info","event":"25/08/01 08:42:24 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.459502","level":"info","event":"25/08/01 08:42:24 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 0baa42e17007:42905 (size: 32.6 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.459953","level":"info","event":"25/08/01 08:42:24 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.460248","level":"info","event":"25/08/01 08:42:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[63] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.460337","level":"info","event":"25/08/01 08:42:24 INFO TaskSchedulerImpl: Adding task set 24.1 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.461053","level":"info","event":"25/08/01 08:42:24 INFO TaskSetManager: Starting task 0.0 in stage 24.1 (TID 228) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11938 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.461213","level":"info","event":"25/08/01 08:42:24 INFO TaskSetManager: Starting task 1.0 in stage 24.1 (TID 229) (172.18.0.8, executor 1, partition 1, PROCESS_LOCAL, 11781 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.471525","level":"info","event":"25/08/01 08:42:24 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.8:42573 (size: 32.6 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:24.935069","level":"info","event":"25/08/01 08:42:24 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.8:42573 (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.053341","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 1.0 in stage 24.1 (TID 229) in 1591 ms on 172.18.0.8 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.053581","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 0.0 in stage 24.1 (TID 228) in 1593 ms on 172.18.0.8 (executor 1) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.053636","level":"info","event":"25/08/01 08:42:26 INFO TaskSchedulerImpl: Removed TaskSet 24.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.054436","level":"info","event":"25/08/01 08:42:26 INFO DAGScheduler: ShuffleMapStage 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.599 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.054525","level":"info","event":"25/08/01 08:42:26 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.054579","level":"info","event":"25/08/01 08:42:26 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.054615","level":"info","event":"25/08/01 08:42:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 25)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.054662","level":"info","event":"25/08/01 08:42:26 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.055235","level":"info","event":"25/08/01 08:42:26 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[73] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.056326","level":"info","event":"25/08/01 08:42:26 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 25.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.062754","level":"info","event":"25/08/01 08:42:26 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 603.6 KiB, free 431.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.065639","level":"info","event":"25/08/01 08:42:26 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 138.4 KiB, free 431.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.065874","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 0baa42e17007:42905 (size: 138.4 KiB, free: 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.066257","level":"info","event":"25/08/01 08:42:26 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.066689","level":"info","event":"25/08/01 08:42:26 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[73] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.066765","level":"info","event":"25/08/01 08:42:26 INFO TaskSchedulerImpl: Adding task set 25.1 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.067622","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 0.0 in stage 25.1 (TID 230) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.067823","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 2.0 in stage 25.1 (TID 231) (172.18.0.8, executor 1, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.080587","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.8:42573 (size: 138.4 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.093705","level":"info","event":"25/08/01 08:42:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:36566","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.405711","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added rdd_70_0 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.405806","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added rdd_70_2 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.748361","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 3.0 in stage 25.1 (TID 232) (172.18.0.8, executor 1, partition 3, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.749235","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 4.0 in stage 25.1 (TID 233) (172.18.0.8, executor 1, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.749347","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 0.0 in stage 25.1 (TID 230) in 682 ms on 172.18.0.8 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.749678","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 2.0 in stage 25.1 (TID 231) in 682 ms on 172.18.0.8 (executor 1) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.810264","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added rdd_70_4 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.810396","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added rdd_70_3 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.836093","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 7.0 in stage 25.1 (TID 234) (172.18.0.8, executor 1, partition 7, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.836589","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 10.0 in stage 25.1 (TID 235) (172.18.0.8, executor 1, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.836769","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 3.0 in stage 25.1 (TID 232) in 89 ms on 172.18.0.8 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.836988","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 4.0 in stage 25.1 (TID 233) in 88 ms on 172.18.0.8 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.895935","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added rdd_70_7 in memory on 172.18.0.8:42573 (size: 449.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.896702","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added rdd_70_10 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.914271","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 14.0 in stage 25.1 (TID 236) (172.18.0.8, executor 1, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.914496","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 7.0 in stage 25.1 (TID 234) in 79 ms on 172.18.0.8 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.914785","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 22.0 in stage 25.1 (TID 237) (172.18.0.8, executor 1, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.915087","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 10.0 in stage 25.1 (TID 235) in 78 ms on 172.18.0.8 (executor 1) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.965160","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added rdd_70_22 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.965244","level":"info","event":"25/08/01 08:42:26 INFO BlockManagerInfo: Added rdd_70_14 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.987511","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 40.0 in stage 25.1 (TID 238) (172.18.0.8, executor 1, partition 40, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.987990","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Starting task 41.0 in stage 25.1 (TID 239) (172.18.0.8, executor 1, partition 41, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.988445","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 22.0 in stage 25.1 (TID 237) in 73 ms on 172.18.0.8 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:26.988978","level":"info","event":"25/08/01 08:42:26 INFO TaskSetManager: Finished task 14.0 in stage 25.1 (TID 236) in 75 ms on 172.18.0.8 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.043731","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_40 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.043843","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_41 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.067015","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 42.0 in stage 25.1 (TID 240) (172.18.0.8, executor 1, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.067675","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 47.0 in stage 25.1 (TID 241) (172.18.0.8, executor 1, partition 47, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.067751","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 41.0 in stage 25.1 (TID 239) in 80 ms on 172.18.0.8 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.067916","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 40.0 in stage 25.1 (TID 238) in 80 ms on 172.18.0.8 (executor 1) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.109136","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_47 in memory on 172.18.0.8:42573 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.127887","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 1.0 in stage 25.1 (TID 242) (172.18.0.8, executor 1, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.128165","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 47.0 in stage 25.1 (TID 241) in 60 ms on 172.18.0.8 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.154672","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_1 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.171337","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 5.0 in stage 25.1 (TID 243) (172.18.0.8, executor 1, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.171738","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 1.0 in stage 25.1 (TID 242) in 44 ms on 172.18.0.8 (executor 1) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.198236","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_5 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.212421","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 6.0 in stage 25.1 (TID 244) (172.18.0.8, executor 1, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.212713","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 5.0 in stage 25.1 (TID 243) in 42 ms on 172.18.0.8 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.236398","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_6 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.247630","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 8.0 in stage 25.1 (TID 245) (172.18.0.8, executor 1, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.248507","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 6.0 in stage 25.1 (TID 244) in 36 ms on 172.18.0.8 (executor 1) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.275970","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_8 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.286243","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 9.0 in stage 25.1 (TID 246) (172.18.0.8, executor 1, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.286628","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 8.0 in stage 25.1 (TID 245) in 39 ms on 172.18.0.8 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.287654","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_42 in memory on 172.18.0.8:42573 (size: 485.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.299897","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 11.0 in stage 25.1 (TID 247) (172.18.0.8, executor 1, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.300349","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 42.0 in stage 25.1 (TID 240) in 234 ms on 172.18.0.8 (executor 1) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.304179","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_9 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.313263","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 12.0 in stage 25.1 (TID 248) (172.18.0.8, executor 1, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.313565","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 9.0 in stage 25.1 (TID 246) in 28 ms on 172.18.0.8 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.318564","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_11 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.328796","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 13.0 in stage 25.1 (TID 249) (172.18.0.8, executor 1, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.329206","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 11.0 in stage 25.1 (TID 247) in 29 ms on 172.18.0.8 (executor 1) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.331234","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_12 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.340649","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 15.0 in stage 25.1 (TID 250) (172.18.0.8, executor 1, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.340949","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 12.0 in stage 25.1 (TID 248) in 28 ms on 172.18.0.8 (executor 1) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.346370","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_13 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.356672","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 16.0 in stage 25.1 (TID 251) (172.18.0.8, executor 1, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.357016","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 13.0 in stage 25.1 (TID 249) in 28 ms on 172.18.0.8 (executor 1) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.358157","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_15 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.367347","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 17.0 in stage 25.1 (TID 252) (172.18.0.8, executor 1, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.367526","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 15.0 in stage 25.1 (TID 250) in 27 ms on 172.18.0.8 (executor 1) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.372879","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_16 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.385250","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 18.0 in stage 25.1 (TID 253) (172.18.0.8, executor 1, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.385430","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 16.0 in stage 25.1 (TID 251) in 27 ms on 172.18.0.8 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.385465","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_17 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.393565","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 19.0 in stage 25.1 (TID 254) (172.18.0.8, executor 1, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.393824","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 17.0 in stage 25.1 (TID 252) in 26 ms on 172.18.0.8 (executor 1) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.401634","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_18 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.410588","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 20.0 in stage 25.1 (TID 255) (172.18.0.8, executor 1, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.410669","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 18.0 in stage 25.1 (TID 253) in 28 ms on 172.18.0.8 (executor 1) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.412228","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_19 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.420016","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 21.0 in stage 25.1 (TID 256) (172.18.0.8, executor 1, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.420263","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 19.0 in stage 25.1 (TID 254) in 27 ms on 172.18.0.8 (executor 1) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.425233","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_20 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.434429","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 23.0 in stage 25.1 (TID 257) (172.18.0.8, executor 1, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.434695","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 20.0 in stage 25.1 (TID 255) in 24 ms on 172.18.0.8 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.436439","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_21 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.446487","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 24.0 in stage 25.1 (TID 258) (172.18.0.8, executor 1, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.446734","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 21.0 in stage 25.1 (TID 256) in 26 ms on 172.18.0.8 (executor 1) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.454137","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_23 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.463989","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 25.0 in stage 25.1 (TID 259) (172.18.0.8, executor 1, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.464101","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 23.0 in stage 25.1 (TID 257) in 31 ms on 172.18.0.8 (executor 1) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.470435","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_24 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.487650","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 26.0 in stage 25.1 (TID 260) (172.18.0.8, executor 1, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.488968","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 24.0 in stage 25.1 (TID 258) in 43 ms on 172.18.0.8 (executor 1) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.493983","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_25 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.516768","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 27.0 in stage 25.1 (TID 261) (172.18.0.8, executor 1, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.517040","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 25.0 in stage 25.1 (TID 259) in 53 ms on 172.18.0.8 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.520496","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_26 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.532854","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 28.0 in stage 25.1 (TID 262) (172.18.0.8, executor 1, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.533474","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 26.0 in stage 25.1 (TID 260) in 47 ms on 172.18.0.8 (executor 1) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.536036","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_27 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.544963","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 29.0 in stage 25.1 (TID 263) (172.18.0.8, executor 1, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.546030","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 27.0 in stage 25.1 (TID 261) in 29 ms on 172.18.0.8 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.552351","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_28 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.562454","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 30.0 in stage 25.1 (TID 264) (172.18.0.8, executor 1, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.562827","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 28.0 in stage 25.1 (TID 262) in 30 ms on 172.18.0.8 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.563759","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_29 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.573032","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 31.0 in stage 25.1 (TID 265) (172.18.0.8, executor 1, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.573494","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 29.0 in stage 25.1 (TID 263) in 29 ms on 172.18.0.8 (executor 1) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.585771","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_30 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.594243","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_31 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.594702","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 32.0 in stage 25.1 (TID 266) (172.18.0.8, executor 1, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.595388","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 30.0 in stage 25.1 (TID 264) in 34 ms on 172.18.0.8 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.605041","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 33.0 in stage 25.1 (TID 267) (172.18.0.8, executor 1, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.605605","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 31.0 in stage 25.1 (TID 265) in 33 ms on 172.18.0.8 (executor 1) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.614991","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_32 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.626892","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 34.0 in stage 25.1 (TID 268) (172.18.0.8, executor 1, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.627343","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 32.0 in stage 25.1 (TID 266) in 32 ms on 172.18.0.8 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.631535","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_33 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.643322","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 35.0 in stage 25.1 (TID 269) (172.18.0.8, executor 1, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.643654","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 33.0 in stage 25.1 (TID 267) in 39 ms on 172.18.0.8 (executor 1) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.649157","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_34 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.668576","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 36.0 in stage 25.1 (TID 270) (172.18.0.8, executor 1, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.668908","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 34.0 in stage 25.1 (TID 268) in 39 ms on 172.18.0.8 (executor 1) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.669237","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_35 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.680030","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 37.0 in stage 25.1 (TID 271) (172.18.0.8, executor 1, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.680373","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 35.0 in stage 25.1 (TID 269) in 38 ms on 172.18.0.8 (executor 1) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.685559","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_36 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.707354","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_37 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.724697","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 38.0 in stage 25.1 (TID 272) (172.18.0.8, executor 1, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.725848","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 36.0 in stage 25.1 (TID 270) in 60 ms on 172.18.0.8 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.726744","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 39.0 in stage 25.1 (TID 273) (172.18.0.8, executor 1, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.726989","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 37.0 in stage 25.1 (TID 271) in 48 ms on 172.18.0.8 (executor 1) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.804301","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_38 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.805707","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_39 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.874540","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 43.0 in stage 25.1 (TID 274) (172.18.0.8, executor 1, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.878220","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 38.0 in stage 25.1 (TID 272) in 155 ms on 172.18.0.8 (executor 1) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.884816","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 44.0 in stage 25.1 (TID 275) (172.18.0.8, executor 1, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.885115","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 39.0 in stage 25.1 (TID 273) in 158 ms on 172.18.0.8 (executor 1) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.900136","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_43 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.900796","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_44 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.912387","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 45.0 in stage 25.1 (TID 276) (172.18.0.8, executor 1, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.912585","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 43.0 in stage 25.1 (TID 274) in 48 ms on 172.18.0.8 (executor 1) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.913316","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 46.0 in stage 25.1 (TID 277) (172.18.0.8, executor 1, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.913413","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 44.0 in stage 25.1 (TID 275) in 29 ms on 172.18.0.8 (executor 1) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.929744","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_46 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.929840","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_45 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.938653","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 48.0 in stage 25.1 (TID 278) (172.18.0.8, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.938743","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 46.0 in stage 25.1 (TID 277) in 26 ms on 172.18.0.8 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.938957","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Starting task 49.0 in stage 25.1 (TID 279) (172.18.0.8, executor 1, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.939600","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 45.0 in stage 25.1 (TID 276) in 27 ms on 172.18.0.8 (executor 1) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.955339","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_49 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.955418","level":"info","event":"25/08/01 08:42:27 INFO BlockManagerInfo: Added rdd_70_48 in memory on 172.18.0.8:42573 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.965149","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 49.0 in stage 25.1 (TID 279) in 26 ms on 172.18.0.8 (executor 1) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.965232","level":"info","event":"25/08/01 08:42:27 INFO TaskSetManager: Finished task 48.0 in stage 25.1 (TID 278) in 27 ms on 172.18.0.8 (executor 1) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.965262","level":"info","event":"25/08/01 08:42:27 INFO TaskSchedulerImpl: Removed TaskSet 25.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.965837","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: ShuffleMapStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.907 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.965916","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.965954","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.965999","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.966026","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.985338","level":"info","event":"25/08/01 08:42:27 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.986067","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: Got job 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.986125","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: Final stage: ResultStage 28 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.986155","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.986175","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.986413","level":"info","event":"25/08/01 08:42:27 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[76] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:27.988847","level":"info","event":"25/08/01 08:42:27 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 534.9 KiB, free 430.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.000038","level":"info","event":"25/08/01 08:42:27 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 124.8 KiB, free 430.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.000372","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 0baa42e17007:42905 in memory (size: 32.6 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.000659","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 0baa42e17007:42905 (size: 124.8 KiB, free: 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.000921","level":"info","event":"25/08/01 08:42:28 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.001160","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[76] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.001215","level":"info","event":"25/08/01 08:42:28 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.001954","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 280) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.014070","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.8:42573 (size: 124.8 KiB, free: 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.015041","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.8:42573 in memory (size: 32.6 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.018810","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 0baa42e17007:42905 in memory (size: 138.4 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.019839","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.18.0.8:42573 in memory (size: 138.4 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.022820","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 0baa42e17007:42905 in memory (size: 138.4 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.023547","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.8:42573 in memory (size: 138.4 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.052923","level":"info","event":"25/08/01 08:42:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.18.0.8:36566","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.083997","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 280) in 82 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.084097","level":"info","event":"25/08/01 08:42:28 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.084483","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: ResultStage 28 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.098 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.084552","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.084580","level":"info","event":"25/08/01 08:42:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.084749","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Job 16 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.099388 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.092935","level":"info","event":"25/08/01 08:42:28 INFO Snapshot: [tableId=3547bf11-335a-4bfb-a37a-8cc2809296bb] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.109096","level":"info","event":"25/08/01 08:42:28 INFO OptimisticTransaction: [tableId=3547bf11,txnId=8ba58de4] Committed delta #10 to s3a://activefence-bucket/bbc_tech/gold/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.272436","level":"info","event":"25/08/01 08:42:28 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.341305","level":"info","event":"25/08/01 08:42:28 INFO CodeGenerator: Code generated in 31.387708 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.343594","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Registering RDD 78 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.343689","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Got map stage job 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.343719","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Final stage: ShuffleMapStage 30 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.343745","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.344101","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.344294","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[78] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.347011","level":"info","event":"25/08/01 08:42:28 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 575.4 KiB, free 431.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.348667","level":"info","event":"25/08/01 08:42:28 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 130.3 KiB, free 431.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.349117","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 0baa42e17007:42905 (size: 130.3 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.349399","level":"info","event":"25/08/01 08:42:28 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.349722","level":"info","event":"25/08/01 08:42:28 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[78] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.349780","level":"info","event":"25/08/01 08:42:28 INFO TaskSchedulerImpl: Adding task set 30.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.350387","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 281) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.350558","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 282) (172.18.0.8, executor 1, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.388176","level":"info","event":"25/08/01 08:42:28 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.18.0.8:42573 (size: 130.3 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.427022","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 283) (172.18.0.8, executor 1, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.428188","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 282) in 75 ms on 172.18.0.8 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.428245","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 284) (172.18.0.8, executor 1, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.428274","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 281) in 77 ms on 172.18.0.8 (executor 1) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.445371","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 4.0 in stage 30.0 (TID 285) (172.18.0.8, executor 1, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.446477","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 284) in 18 ms on 172.18.0.8 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.446523","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 5.0 in stage 30.0 (TID 286) (172.18.0.8, executor 1, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.446549","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 283) in 19 ms on 172.18.0.8 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.463545","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 6.0 in stage 30.0 (TID 287) (172.18.0.8, executor 1, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.464538","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 4.0 in stage 30.0 (TID 285) in 20 ms on 172.18.0.8 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.464583","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 7.0 in stage 30.0 (TID 288) (172.18.0.8, executor 1, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.464606","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 5.0 in stage 30.0 (TID 286) in 19 ms on 172.18.0.8 (executor 1) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.475718","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 8.0 in stage 30.0 (TID 289) (172.18.0.8, executor 1, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.475832","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 6.0 in stage 30.0 (TID 287) in 14 ms on 172.18.0.8 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.476243","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 9.0 in stage 30.0 (TID 290) (172.18.0.8, executor 1, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.476523","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 7.0 in stage 30.0 (TID 288) in 13 ms on 172.18.0.8 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.484977","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 10.0 in stage 30.0 (TID 291) (172.18.0.8, executor 1, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.485309","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 11.0 in stage 30.0 (TID 292) (172.18.0.8, executor 1, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.485499","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 8.0 in stage 30.0 (TID 289) in 10 ms on 172.18.0.8 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.485562","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 9.0 in stage 30.0 (TID 290) in 10 ms on 172.18.0.8 (executor 1) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.492326","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 12.0 in stage 30.0 (TID 293) (172.18.0.8, executor 1, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.492486","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 11.0 in stage 30.0 (TID 292) in 8 ms on 172.18.0.8 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.492859","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 13.0 in stage 30.0 (TID 294) (172.18.0.8, executor 1, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.492919","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 10.0 in stage 30.0 (TID 291) in 9 ms on 172.18.0.8 (executor 1) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.498890","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 14.0 in stage 30.0 (TID 295) (172.18.0.8, executor 1, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.499028","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 12.0 in stage 30.0 (TID 293) in 7 ms on 172.18.0.8 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.500024","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 15.0 in stage 30.0 (TID 296) (172.18.0.8, executor 1, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.500292","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 13.0 in stage 30.0 (TID 294) in 8 ms on 172.18.0.8 (executor 1) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.506193","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 16.0 in stage 30.0 (TID 297) (172.18.0.8, executor 1, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.506477","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 15.0 in stage 30.0 (TID 296) in 7 ms on 172.18.0.8 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.506577","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 17.0 in stage 30.0 (TID 298) (172.18.0.8, executor 1, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.507017","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 14.0 in stage 30.0 (TID 295) in 8 ms on 172.18.0.8 (executor 1) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.525683","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 18.0 in stage 30.0 (TID 299) (172.18.0.8, executor 1, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.526815","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 16.0 in stage 30.0 (TID 297) in 19 ms on 172.18.0.8 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.526860","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 19.0 in stage 30.0 (TID 300) (172.18.0.8, executor 1, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.526884","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 17.0 in stage 30.0 (TID 298) in 19 ms on 172.18.0.8 (executor 1) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.537517","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 20.0 in stage 30.0 (TID 301) (172.18.0.8, executor 1, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.537784","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 21.0 in stage 30.0 (TID 302) (172.18.0.8, executor 1, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.537909","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 18.0 in stage 30.0 (TID 299) in 14 ms on 172.18.0.8 (executor 1) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.538050","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 19.0 in stage 30.0 (TID 300) in 12 ms on 172.18.0.8 (executor 1) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.549895","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 22.0 in stage 30.0 (TID 303) (172.18.0.8, executor 1, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.551497","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 20.0 in stage 30.0 (TID 301) in 11 ms on 172.18.0.8 (executor 1) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.551551","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 23.0 in stage 30.0 (TID 304) (172.18.0.8, executor 1, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.551575","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 21.0 in stage 30.0 (TID 302) in 13 ms on 172.18.0.8 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.572831","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 24.0 in stage 30.0 (TID 305) (172.18.0.8, executor 1, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.573977","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 23.0 in stage 30.0 (TID 304) in 21 ms on 172.18.0.8 (executor 1) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.574021","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 25.0 in stage 30.0 (TID 306) (172.18.0.8, executor 1, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.574046","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 22.0 in stage 30.0 (TID 303) in 26 ms on 172.18.0.8 (executor 1) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.582032","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 26.0 in stage 30.0 (TID 307) (172.18.0.8, executor 1, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.582127","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 25.0 in stage 30.0 (TID 306) in 11 ms on 172.18.0.8 (executor 1) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.582354","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 27.0 in stage 30.0 (TID 308) (172.18.0.8, executor 1, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.582620","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 24.0 in stage 30.0 (TID 305) in 12 ms on 172.18.0.8 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.589411","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 28.0 in stage 30.0 (TID 309) (172.18.0.8, executor 1, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.590166","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 29.0 in stage 30.0 (TID 310) (172.18.0.8, executor 1, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.590224","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 26.0 in stage 30.0 (TID 307) in 9 ms on 172.18.0.8 (executor 1) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.590514","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 27.0 in stage 30.0 (TID 308) in 8 ms on 172.18.0.8 (executor 1) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.650848","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 30.0 in stage 30.0 (TID 311) (172.18.0.8, executor 1, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.654478","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 28.0 in stage 30.0 (TID 309) in 61 ms on 172.18.0.8 (executor 1) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.654546","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 31.0 in stage 30.0 (TID 312) (172.18.0.8, executor 1, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.654572","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 29.0 in stage 30.0 (TID 310) in 64 ms on 172.18.0.8 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.739323","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 32.0 in stage 30.0 (TID 313) (172.18.0.8, executor 1, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.742891","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 31.0 in stage 30.0 (TID 312) in 84 ms on 172.18.0.8 (executor 1) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.744252","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 33.0 in stage 30.0 (TID 314) (172.18.0.8, executor 1, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.744736","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 30.0 in stage 30.0 (TID 311) in 98 ms on 172.18.0.8 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.800653","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 34.0 in stage 30.0 (TID 315) (172.18.0.8, executor 1, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.806251","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 32.0 in stage 30.0 (TID 313) in 64 ms on 172.18.0.8 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.806588","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 35.0 in stage 30.0 (TID 316) (172.18.0.8, executor 1, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.806624","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 33.0 in stage 30.0 (TID 314) in 61 ms on 172.18.0.8 (executor 1) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.859365","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 36.0 in stage 30.0 (TID 317) (172.18.0.8, executor 1, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.860599","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 35.0 in stage 30.0 (TID 316) in 59 ms on 172.18.0.8 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.860650","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 37.0 in stage 30.0 (TID 318) (172.18.0.8, executor 1, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.860678","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 34.0 in stage 30.0 (TID 315) in 62 ms on 172.18.0.8 (executor 1) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.896192","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 38.0 in stage 30.0 (TID 319) (172.18.0.8, executor 1, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.897839","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 37.0 in stage 30.0 (TID 318) in 31 ms on 172.18.0.8 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.897902","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 39.0 in stage 30.0 (TID 320) (172.18.0.8, executor 1, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.897927","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 36.0 in stage 30.0 (TID 317) in 34 ms on 172.18.0.8 (executor 1) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.971576","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 40.0 in stage 30.0 (TID 321) (172.18.0.8, executor 1, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.973485","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 38.0 in stage 30.0 (TID 319) in 82 ms on 172.18.0.8 (executor 1) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.973537","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Starting task 41.0 in stage 30.0 (TID 322) (172.18.0.8, executor 1, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:28.973567","level":"info","event":"25/08/01 08:42:28 INFO TaskSetManager: Finished task 39.0 in stage 30.0 (TID 320) in 82 ms on 172.18.0.8 (executor 1) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.056660","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Starting task 42.0 in stage 30.0 (TID 323) (172.18.0.8, executor 1, partition 42, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.058378","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 40.0 in stage 30.0 (TID 321) in 88 ms on 172.18.0.8 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.058444","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Starting task 43.0 in stage 30.0 (TID 324) (172.18.0.8, executor 1, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.058475","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 41.0 in stage 30.0 (TID 322) in 86 ms on 172.18.0.8 (executor 1) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.155084","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Starting task 44.0 in stage 30.0 (TID 325) (172.18.0.8, executor 1, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.164184","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 43.0 in stage 30.0 (TID 324) in 98 ms on 172.18.0.8 (executor 1) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.192333","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Starting task 45.0 in stage 30.0 (TID 326) (172.18.0.8, executor 1, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.194355","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 42.0 in stage 30.0 (TID 323) in 134 ms on 172.18.0.8 (executor 1) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.263381","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Starting task 46.0 in stage 30.0 (TID 327) (172.18.0.8, executor 1, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.277897","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 45.0 in stage 30.0 (TID 326) in 64 ms on 172.18.0.8 (executor 1) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.279602","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Starting task 47.0 in stage 30.0 (TID 328) (172.18.0.8, executor 1, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.279658","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 44.0 in stage 30.0 (TID 325) in 108 ms on 172.18.0.8 (executor 1) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.443599","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Starting task 48.0 in stage 30.0 (TID 329) (172.18.0.8, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.448802","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Starting task 49.0 in stage 30.0 (TID 330) (172.18.0.8, executor 1, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.448907","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 46.0 in stage 30.0 (TID 327) in 196 ms on 172.18.0.8 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.448936","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 47.0 in stage 30.0 (TID 328) in 195 ms on 172.18.0.8 (executor 1) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.526822","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 48.0 in stage 30.0 (TID 329) in 88 ms on 172.18.0.8 (executor 1) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.528026","level":"info","event":"25/08/01 08:42:29 INFO TaskSetManager: Finished task 49.0 in stage 30.0 (TID 330) in 80 ms on 172.18.0.8 (executor 1) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.528090","level":"info","event":"25/08/01 08:42:29 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.528120","level":"info","event":"25/08/01 08:42:29 INFO DAGScheduler: ShuffleMapStage 30 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.182 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.528143","level":"info","event":"25/08/01 08:42:29 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.528162","level":"info","event":"25/08/01 08:42:29 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.528179","level":"info","event":"25/08/01 08:42:29 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.528196","level":"info","event":"25/08/01 08:42:29 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.643949","level":"info","event":"25/08/01 08:42:29 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 0baa42e17007:42905 in memory (size: 124.8 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.707070","level":"info","event":"25/08/01 08:42:29 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.18.0.8:42573 in memory (size: 124.8 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.774455","level":"info","event":"25/08/01 08:42:29 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 0baa42e17007:42905 in memory (size: 130.3 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:29.859354","level":"info","event":"25/08/01 08:42:29 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.18.0.8:42573 in memory (size: 130.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:30.275838","level":"info","event":"25/08/01 08:42:30 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.deserializetoobject_doConsume_0$ is 12323 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:30.279389","level":"info","event":"25/08/01 08:42:30 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.serializefromobject_doConsume_0$ is 15190 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:30.290828","level":"info","event":"25/08/01 08:42:30 INFO CodeGenerator: Code generated in 618.52975 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.142964","level":"info","event":"25/08/01 08:42:31 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.200062","level":"info","event":"25/08/01 08:42:31 INFO DAGScheduler: Got job 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.201519","level":"info","event":"25/08/01 08:42:31 INFO DAGScheduler: Final stage: ResultStage 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.201590","level":"info","event":"25/08/01 08:42:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.201617","level":"info","event":"25/08/01 08:42:31 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.239026","level":"info","event":"25/08/01 08:42:31 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[81] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.284784","level":"info","event":"25/08/01 08:42:31 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 484.4 KiB, free 432.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.297984","level":"info","event":"25/08/01 08:42:31 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 117.0 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.302398","level":"info","event":"25/08/01 08:42:31 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 0baa42e17007:42905 (size: 117.0 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.314116","level":"info","event":"25/08/01 08:42:31 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.336961","level":"info","event":"25/08/01 08:42:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[81] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.351340","level":"info","event":"25/08/01 08:42:31 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.390102","level":"info","event":"25/08/01 08:42:31 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 331) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:31.609933","level":"info","event":"25/08/01 08:42:31 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.8:42573 (size: 117.0 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:42:41.214607","level":"info","event":"25/08/01 08:42:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.8:36566","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.796040","level":"info","event":"25/08/01 08:43:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801084147-0001/1 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.796330","level":"info","event":"25/08/01 08:43:24 INFO StandaloneSchedulerBackend: Executor app-20250801084147-0001/1 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803229","level":"info","event":"25/08/01 08:43:24 ERROR TaskSchedulerImpl: Lost executor 1 on 172.18.0.8: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803339","level":"info","event":"25/08/01 08:43:24 WARN TaskSetManager: Lost task 0.0 in stage 33.0 (TID 331) (172.18.0.8 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803431","level":"info","event":"25/08/01 08:43:24 INFO DAGScheduler: Executor lost: 1 (epoch 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803498","level":"info","event":"25/08/01 08:43:24 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803547","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_43 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803599","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_8 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803641","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_21 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803700","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_4 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803747","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_31 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803800","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_46 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803840","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803863","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803889","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_16 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803922","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_26 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803944","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_19 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803962","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_25 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.803996","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_47 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.804044","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_42 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.809638","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_39 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.809732","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.809766","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_49 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.809785","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_9 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.809802","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_29 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.815623","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_17 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.815765","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.815807","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_38 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.815843","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_22 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.815875","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.815908","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_6 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.815946","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_7 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.815979","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_20 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816018","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_3 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816052","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_23 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816129","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816171","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_41 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816224","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816265","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_32 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816323","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_34 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816377","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_1 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816431","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_44 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816484","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_40 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816540","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816606","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_35 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816671","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_27 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816721","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_28 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816773","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_30 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816812","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_48 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816879","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816930","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_24 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.816987","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_45 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817040","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_15 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817114","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_33 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817170","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_37 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817232","level":"info","event":"25/08/01 08:43:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_36 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817287","level":"info","event":"25/08/01 08:43:24 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 172.18.0.8, 42573, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817368","level":"info","event":"25/08/01 08:43:24 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817420","level":"info","event":"25/08/01 08:43:24 INFO DAGScheduler: Shuffle files lost for executor: 1 (epoch 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817462","level":"info","event":"25/08/01 08:43:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801084147-0001/2 on worker-20250801084128-172.18.0.8-42021 (172.18.0.8:42021) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.817507","level":"info","event":"25/08/01 08:43:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801084147-0001/2 on hostPort 172.18.0.8:42021 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:24.877401","level":"info","event":"25/08/01 08:43:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801084147-0001/2 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:26.505129","level":"info","event":"25/08/01 08:43:26 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:37376) with ID 2,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:26.530905","level":"info","event":"25/08/01 08:43:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:35851 with 1048.8 MiB RAM, BlockManagerId(2, 172.18.0.8, 35851, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.278036","level":"info","event":"25/08/01 08:43:28 INFO TaskSetManager: Starting task 0.1 in stage 33.0 (TID 332) (172.18.0.8, executor 2, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.362598","level":"info","event":"25/08/01 08:43:28 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.8:35851 (size: 117.0 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.539193","level":"info","event":"25/08/01 08:43:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.8:37376","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555263","level":"info","event":"25/08/01 08:43:28 WARN TaskSetManager: Lost task 0.1 in stage 33.0 (TID 332) (172.18.0.8 executor 2): FetchFailed(null, shuffleId=7, mapIndex=-1, mapId=-1, reduceId=0, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555372","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 7 partition 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555431","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555490","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555544","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555583","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555606","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555652","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555684","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555707","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555733","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555750","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555767","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555784","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555800","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555817","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555833","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555849","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555865","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555880","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555896","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555911","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555927","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555943","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555959","level":"info","event":"at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555974","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.555990","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556005","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556021","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556040","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556056","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556085","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556102","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556118","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556135","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556152","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556181","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556216","level":"info","event":"25/08/01 08:43:28 INFO TaskSetManager: task 0.1 in stage 33.0 (TID 332) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556259","level":"info","event":"25/08/01 08:43:28 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556297","level":"info","event":"25/08/01 08:43:28 INFO DAGScheduler: Marking ResultStage 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as failed due to a fetch failure from ShuffleMapStage 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556319","level":"info","event":"25/08/01 08:43:28 INFO DAGScheduler: ResultStage 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) failed in 57.341 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 7 partition 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556336","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556351","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556368","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556383","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556433","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556452","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556469","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556498","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556521","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556536","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556555","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556584","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556600","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556616","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556632","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556649","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556684","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556714","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556737","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556754","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556786","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556831","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556867","level":"info","event":"at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556885","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556902","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556928","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556949","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556965","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556981","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.556997","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.557013","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.557030","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.557046","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.557061","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.557093","level":"info","event":"25/08/01 08:43:28 INFO DAGScheduler: Resubmitting ShuffleMapStage 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) and ResultStage 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) due to fetch failure","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.756561","level":"info","event":"25/08/01 08:43:28 INFO DAGScheduler: Resubmitting failed stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.757903","level":"info","event":"25/08/01 08:43:28 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[63] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.761173","level":"info","event":"25/08/01 08:43:28 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 105.7 KiB, free 432.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.763394","level":"info","event":"25/08/01 08:43:28 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 432.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.763471","level":"info","event":"25/08/01 08:43:28 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 0baa42e17007:42905 (size: 32.6 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.763852","level":"info","event":"25/08/01 08:43:28 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.764128","level":"info","event":"25/08/01 08:43:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[63] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.764181","level":"info","event":"25/08/01 08:43:28 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.764738","level":"info","event":"25/08/01 08:43:28 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 333) (172.18.0.8, executor 2, partition 0, PROCESS_LOCAL, 11938 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.764834","level":"info","event":"25/08/01 08:43:28 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 334) (172.18.0.8, executor 2, partition 1, PROCESS_LOCAL, 11781 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:28.778183","level":"info","event":"25/08/01 08:43:28 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.8:35851 (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:29.330476","level":"info","event":"25/08/01 08:43:29 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.8:35851 (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.249956","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 333) in 1485 ms on 172.18.0.8 (executor 2) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.250226","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 334) in 1485 ms on 172.18.0.8 (executor 2) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.250294","level":"info","event":"25/08/01 08:43:30 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.250341","level":"info","event":"25/08/01 08:43:30 INFO DAGScheduler: ShuffleMapStage 31 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.492 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.250364","level":"info","event":"25/08/01 08:43:30 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.250412","level":"info","event":"25/08/01 08:43:30 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.250442","level":"info","event":"25/08/01 08:43:30 INFO DAGScheduler: waiting: Set(ResultStage 33, ShuffleMapStage 32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.250479","level":"info","event":"25/08/01 08:43:30 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.250955","level":"info","event":"25/08/01 08:43:30 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[78] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.255173","level":"info","event":"25/08/01 08:43:30 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 575.4 KiB, free 431.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.257457","level":"info","event":"25/08/01 08:43:30 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 130.3 KiB, free 431.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.258006","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 0baa42e17007:42905 (size: 130.3 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.258377","level":"info","event":"25/08/01 08:43:30 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.258722","level":"info","event":"25/08/01 08:43:30 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[78] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.258781","level":"info","event":"25/08/01 08:43:30 INFO TaskSchedulerImpl: Adding task set 32.1 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.259536","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 0.0 in stage 32.1 (TID 335) (172.18.0.8, executor 2, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.259584","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 2.0 in stage 32.1 (TID 336) (172.18.0.8, executor 2, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.271027","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.8:35851 (size: 130.3 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.347798","level":"info","event":"25/08/01 08:43:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:37376","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.354090","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 0baa42e17007:42905 in memory (size: 32.6 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.360995","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.8:35851 in memory (size: 32.6 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.363529","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 0baa42e17007:42905 in memory (size: 117.0 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.364363","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.8:35851 in memory (size: 117.0 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.652813","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_0 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.652930","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_2 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.679891","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 3.0 in stage 32.1 (TID 337) (172.18.0.8, executor 2, partition 3, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.680030","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 2.0 in stage 32.1 (TID 336) in 420 ms on 172.18.0.8 (executor 2) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.680447","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 4.0 in stage 32.1 (TID 338) (172.18.0.8, executor 2, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.680504","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 0.0 in stage 32.1 (TID 335) in 421 ms on 172.18.0.8 (executor 2) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.746137","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_3 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.746237","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_4 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.749511","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 7.0 in stage 32.1 (TID 339) (172.18.0.8, executor 2, partition 7, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.749761","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 4.0 in stage 32.1 (TID 338) in 69 ms on 172.18.0.8 (executor 2) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.750002","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 10.0 in stage 32.1 (TID 340) (172.18.0.8, executor 2, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.750361","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 3.0 in stage 32.1 (TID 337) in 71 ms on 172.18.0.8 (executor 2) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.812938","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_7 in memory on 172.18.0.8:35851 (size: 449.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.813121","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_10 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.820408","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 14.0 in stage 32.1 (TID 341) (172.18.0.8, executor 2, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.820634","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 7.0 in stage 32.1 (TID 339) in 71 ms on 172.18.0.8 (executor 2) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.820870","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 22.0 in stage 32.1 (TID 342) (172.18.0.8, executor 2, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.821039","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 10.0 in stage 32.1 (TID 340) in 71 ms on 172.18.0.8 (executor 2) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.883630","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_14 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.883721","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_22 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.887012","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 40.0 in stage 32.1 (TID 343) (172.18.0.8, executor 2, partition 40, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.887233","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 22.0 in stage 32.1 (TID 342) in 67 ms on 172.18.0.8 (executor 2) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.887574","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 41.0 in stage 32.1 (TID 344) (172.18.0.8, executor 2, partition 41, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.887622","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 14.0 in stage 32.1 (TID 341) in 67 ms on 172.18.0.8 (executor 2) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.943257","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_40 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.943340","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_41 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.946989","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 42.0 in stage 32.1 (TID 345) (172.18.0.8, executor 2, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.947188","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 41.0 in stage 32.1 (TID 344) in 60 ms on 172.18.0.8 (executor 2) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.947459","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Starting task 47.0 in stage 32.1 (TID 346) (172.18.0.8, executor 2, partition 47, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.947528","level":"info","event":"25/08/01 08:43:30 INFO TaskSetManager: Finished task 40.0 in stage 32.1 (TID 343) in 61 ms on 172.18.0.8 (executor 2) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:30.999280","level":"info","event":"25/08/01 08:43:30 INFO BlockManagerInfo: Added rdd_70_47 in memory on 172.18.0.8:35851 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.002131","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 1.0 in stage 32.1 (TID 347) (172.18.0.8, executor 2, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.002217","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 47.0 in stage 32.1 (TID 346) in 55 ms on 172.18.0.8 (executor 2) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.029254","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_1 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.034379","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 5.0 in stage 32.1 (TID 348) (172.18.0.8, executor 2, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.034641","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 1.0 in stage 32.1 (TID 347) in 33 ms on 172.18.0.8 (executor 2) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.058855","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_5 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.061288","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 6.0 in stage 32.1 (TID 349) (172.18.0.8, executor 2, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.061632","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 5.0 in stage 32.1 (TID 348) in 27 ms on 172.18.0.8 (executor 2) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.080490","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_6 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.082787","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 8.0 in stage 32.1 (TID 350) (172.18.0.8, executor 2, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.083060","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 6.0 in stage 32.1 (TID 349) in 21 ms on 172.18.0.8 (executor 2) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.101958","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_8 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.104261","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 9.0 in stage 32.1 (TID 351) (172.18.0.8, executor 2, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.104476","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 8.0 in stage 32.1 (TID 350) in 22 ms on 172.18.0.8 (executor 2) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.114989","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_42 in memory on 172.18.0.8:35851 (size: 485.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.117825","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 11.0 in stage 32.1 (TID 352) (172.18.0.8, executor 2, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.117993","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 42.0 in stage 32.1 (TID 345) in 171 ms on 172.18.0.8 (executor 2) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.123869","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_9 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.126590","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 12.0 in stage 32.1 (TID 353) (172.18.0.8, executor 2, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.126768","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 9.0 in stage 32.1 (TID 351) in 22 ms on 172.18.0.8 (executor 2) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.150499","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_11 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.153158","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 13.0 in stage 32.1 (TID 354) (172.18.0.8, executor 2, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.153426","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 11.0 in stage 32.1 (TID 352) in 36 ms on 172.18.0.8 (executor 2) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.161182","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_12 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.164139","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 15.0 in stage 32.1 (TID 355) (172.18.0.8, executor 2, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.164213","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 12.0 in stage 32.1 (TID 353) in 38 ms on 172.18.0.8 (executor 2) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.180651","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_13 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.183532","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 16.0 in stage 32.1 (TID 356) (172.18.0.8, executor 2, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.183618","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 13.0 in stage 32.1 (TID 354) in 31 ms on 172.18.0.8 (executor 2) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.191417","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_15 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.194315","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 17.0 in stage 32.1 (TID 357) (172.18.0.8, executor 2, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.194608","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 15.0 in stage 32.1 (TID 355) in 31 ms on 172.18.0.8 (executor 2) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.211233","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_16 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.215729","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 18.0 in stage 32.1 (TID 358) (172.18.0.8, executor 2, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.215842","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 16.0 in stage 32.1 (TID 356) in 32 ms on 172.18.0.8 (executor 2) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.220796","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_17 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.223546","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 19.0 in stage 32.1 (TID 359) (172.18.0.8, executor 2, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.223832","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 17.0 in stage 32.1 (TID 357) in 29 ms on 172.18.0.8 (executor 2) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.258471","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_18 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.260212","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerInfo: Added rdd_70_19 in memory on 172.18.0.8:35851 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.260546","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 20.0 in stage 32.1 (TID 360) (172.18.0.8, executor 2, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.261039","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 18.0 in stage 32.1 (TID 358) in 45 ms on 172.18.0.8 (executor 2) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.262456","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Starting task 21.0 in stage 32.1 (TID 361) (172.18.0.8, executor 2, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.262709","level":"info","event":"25/08/01 08:43:31 INFO TaskSetManager: Finished task 19.0 in stage 32.1 (TID 359) in 39 ms on 172.18.0.8 (executor 2) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.381765","level":"info","event":"25/08/01 08:43:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801084147-0001/2 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.382745","level":"info","event":"25/08/01 08:43:31 INFO StandaloneSchedulerBackend: Executor app-20250801084147-0001/2 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.382808","level":"info","event":"25/08/01 08:43:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801084147-0001/3 on worker-20250801084128-172.18.0.8-42021 (172.18.0.8:42021) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.382838","level":"info","event":"25/08/01 08:43:31 ERROR TaskSchedulerImpl: Lost executor 2 on 172.18.0.8: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.382860","level":"info","event":"25/08/01 08:43:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801084147-0001/3 on hostPort 172.18.0.8:42021 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.382892","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 47), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.382913","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 15), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.382935","level":"info","event":"25/08/01 08:43:31 WARN TaskSetManager: Lost task 21.0 in stage 32.1 (TID 361) (172.18.0.8 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.382972","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 6), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383003","level":"info","event":"25/08/01 08:43:31 WARN TaskSetManager: Lost task 20.0 in stage 32.1 (TID 360) (172.18.0.8 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383021","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 18), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383039","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 10), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383090","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 40), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383123","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 11), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383163","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 3), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383189","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 13), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383213","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 42), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383245","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 2), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383264","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 5), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383298","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 17), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383327","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 7), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383351","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 22), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383388","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 9), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383414","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 14), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383443","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 8), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383474","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 19), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383494","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 41), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383510","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 12), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383530","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 0), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383548","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 16), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383565","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 1), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383583","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Resubmitted ShuffleMapTask(32, 4), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383602","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Executor lost: 2 (epoch 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383625","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383643","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_8 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383673","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_7 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383695","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_3 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383717","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383751","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_4 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383787","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383811","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383827","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_41 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383843","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_16 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383859","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383875","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_19 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383890","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_47 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383905","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_1 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383924","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_42 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383950","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_40 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383982","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.383998","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384030","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_9 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384079","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_17 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384110","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384147","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384184","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_15 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384225","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_22 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384260","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384297","level":"info","event":"25/08/01 08:43:31 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_70_6 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384318","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, 172.18.0.8, 35851, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384338","level":"info","event":"25/08/01 08:43:31 INFO BlockManagerMaster: Removed 2 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.384367","level":"info","event":"25/08/01 08:43:31 INFO DAGScheduler: Shuffle files lost for executor: 2 (epoch 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:31.409943","level":"info","event":"25/08/01 08:43:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801084147-0001/3 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:32.511771","level":"info","event":"25/08/01 08:43:32 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:47000) with ID 3,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:32.541671","level":"info","event":"25/08/01 08:43:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:37619 with 1048.8 MiB RAM, BlockManagerId(3, 172.18.0.8, 37619, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:33.613442","level":"info","event":"25/08/01 08:43:33 INFO TaskSetManager: Starting task 4.1 in stage 32.1 (TID 362) (172.18.0.8, executor 3, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:33.613639","level":"info","event":"25/08/01 08:43:33 INFO TaskSetManager: Starting task 0.1 in stage 32.1 (TID 363) (172.18.0.8, executor 3, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:33.710178","level":"info","event":"25/08/01 08:43:33 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.8:37619 (size: 130.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.216954","level":"info","event":"25/08/01 08:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:47000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238421","level":"info","event":"25/08/01 08:43:34 INFO TaskSetManager: Starting task 41.1 in stage 32.1 (TID 364) (172.18.0.8, executor 3, partition 41, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238547","level":"info","event":"25/08/01 08:43:34 WARN TaskSetManager: Lost task 4.1 in stage 32.1 (TID 362) (172.18.0.8 executor 3): FetchFailed(null, shuffleId=5, mapIndex=-1, mapId=-1, reduceId=4, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238592","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238638","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238692","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238747","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238790","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238848","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238891","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238918","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238935","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238952","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.238994","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239027","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239060","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239119","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239154","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239173","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239191","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239207","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239222","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239239","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239254","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239282","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239301","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239317","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239334","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239363","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239381","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239397","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239413","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239428","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239444","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239458","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239474","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239489","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239505","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239520","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239536","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239552","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239569","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239585","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239602","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239618","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239634","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239650","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239666","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239683","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239699","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239715","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239731","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239746","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239762","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239777","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239811","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239831","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239847","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239864","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239888","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239922","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239943","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239958","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239974","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.239989","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240006","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240032","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240062","level":"info","event":"25/08/01 08:43:34 INFO TaskSetManager: task 4.1 in stage 32.1 (TID 362) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240093","level":"info","event":"25/08/01 08:43:34 INFO DAGScheduler: Marking ShuffleMapStage 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as failed due to a fetch failure from ShuffleMapStage 31 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240111","level":"info","event":"25/08/01 08:43:34 WARN TaskSetManager: Lost task 0.1 in stage 32.1 (TID 363) (172.18.0.8 executor 3): FetchFailed(null, shuffleId=5, mapIndex=-1, mapId=-1, reduceId=0, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240128","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240143","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240160","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240176","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240192","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240207","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240223","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240238","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240254","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240270","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240297","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240316","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240330","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240346","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240373","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240392","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240423","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240439","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240455","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240471","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240486","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240503","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240517","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240533","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240548","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240563","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240578","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240594","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240609","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240624","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240639","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240655","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240670","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240686","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240702","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240717","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240745","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240769","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240786","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240801","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240827","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240868","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240888","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240909","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240932","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240948","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240963","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.240979","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241006","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241032","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241048","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241064","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241092","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241109","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241124","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241140","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241156","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241171","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241187","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241201","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241217","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241232","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241248","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241264","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241280","level":"info","event":"25/08/01 08:43:34 INFO DAGScheduler: ShuffleMapStage 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) failed in 3.986 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241297","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241312","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241328","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241342","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241358","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241373","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241388","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241403","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241427","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241449","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241465","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241481","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241497","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241513","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241529","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241545","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241560","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241576","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241592","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241607","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241623","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241638","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241653","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241669","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241683","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241699","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241716","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241732","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241748","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241765","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241793","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241808","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241824","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241846","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.241862","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250299","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250349","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250379","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250411","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250431","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250449","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250466","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250482","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250509","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250529","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250546","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250563","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250580","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250596","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250621","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250645","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250661","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250678","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250695","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250711","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250728","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250743","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250759","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250775","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250791","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250824","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250844","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250862","level":"info","event":"25/08/01 08:43:34 INFO TaskSetManager: task 0.1 in stage 32.1 (TID 363) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250880","level":"info","event":"25/08/01 08:43:34 INFO DAGScheduler: Resubmitting ShuffleMapStage 31 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) and ShuffleMapStage 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) due to fetch failure","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.250919","level":"info","event":"25/08/01 08:43:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:47000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251434","level":"info","event":"25/08/01 08:43:34 WARN TaskSetManager: Lost task 41.1 in stage 32.1 (TID 364) (172.18.0.8 executor 3): FetchFailed(null, shuffleId=5, mapIndex=-1, mapId=-1, reduceId=41, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251506","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 5 partition 41","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251550","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251582","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251627","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251660","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251681","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251699","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251716","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251734","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251751","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251767","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251784","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251800","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251816","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251831","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251847","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251862","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251877","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251891","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251905","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251919","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251933","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251947","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251962","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251976","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.251990","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252005","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252019","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252033","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252047","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252062","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252090","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252106","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252121","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252136","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252152","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252168","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252183","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252198","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252214","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252230","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252244","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252259","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252274","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252290","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252305","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252319","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252333","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252347","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252360","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252374","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252389","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252403","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252416","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252430","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252452","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252471","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252485","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252500","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252514","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252528","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252542","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252557","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252572","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252590","level":"info","event":"25/08/01 08:43:34 INFO TaskSetManager: task 41.1 in stage 32.1 (TID 364) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.252606","level":"info","event":"25/08/01 08:43:34 INFO TaskSchedulerImpl: Removed TaskSet 32.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.439319","level":"info","event":"25/08/01 08:43:34 INFO DAGScheduler: Resubmitting failed stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.439827","level":"info","event":"25/08/01 08:43:34 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[63] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.442127","level":"info","event":"25/08/01 08:43:34 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 105.7 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.447381","level":"info","event":"25/08/01 08:43:34 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.447803","level":"info","event":"25/08/01 08:43:34 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 0baa42e17007:42905 (size: 32.6 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.448302","level":"info","event":"25/08/01 08:43:34 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.448530","level":"info","event":"25/08/01 08:43:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[63] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.448586","level":"info","event":"25/08/01 08:43:34 INFO TaskSchedulerImpl: Adding task set 31.1 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.449308","level":"info","event":"25/08/01 08:43:34 INFO TaskSetManager: Starting task 0.0 in stage 31.1 (TID 365) (172.18.0.8, executor 3, partition 0, PROCESS_LOCAL, 11938 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.449437","level":"info","event":"25/08/01 08:43:34 INFO TaskSetManager: Starting task 1.0 in stage 31.1 (TID 366) (172.18.0.8, executor 3, partition 1, PROCESS_LOCAL, 11781 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.458308","level":"info","event":"25/08/01 08:43:34 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.8:37619 (size: 32.6 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:34.897765","level":"info","event":"25/08/01 08:43:34 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.8:37619 (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.860313","level":"info","event":"25/08/01 08:43:35 INFO TaskSetManager: Finished task 1.0 in stage 31.1 (TID 366) in 1411 ms on 172.18.0.8 (executor 3) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.860431","level":"info","event":"25/08/01 08:43:35 INFO TaskSetManager: Finished task 0.0 in stage 31.1 (TID 365) in 1411 ms on 172.18.0.8 (executor 3) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.860484","level":"info","event":"25/08/01 08:43:35 INFO TaskSchedulerImpl: Removed TaskSet 31.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.860835","level":"info","event":"25/08/01 08:43:35 INFO DAGScheduler: ShuffleMapStage 31 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.420 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.861060","level":"info","event":"25/08/01 08:43:35 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.861198","level":"info","event":"25/08/01 08:43:35 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.861241","level":"info","event":"25/08/01 08:43:35 INFO DAGScheduler: waiting: Set(ResultStage 33, ShuffleMapStage 32)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.861264","level":"info","event":"25/08/01 08:43:35 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.861641","level":"info","event":"25/08/01 08:43:35 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[78] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.861759","level":"info","event":"25/08/01 08:43:35 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 32.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.866009","level":"info","event":"25/08/01 08:43:35 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 575.4 KiB, free 431.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.867266","level":"info","event":"25/08/01 08:43:35 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 130.3 KiB, free 431.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.867477","level":"info","event":"25/08/01 08:43:35 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 0baa42e17007:42905 (size: 130.3 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.867744","level":"info","event":"25/08/01 08:43:35 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.867987","level":"info","event":"25/08/01 08:43:35 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[78] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.868024","level":"info","event":"25/08/01 08:43:35 INFO TaskSchedulerImpl: Adding task set 32.2 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.868709","level":"info","event":"25/08/01 08:43:35 INFO TaskSetManager: Starting task 0.0 in stage 32.2 (TID 367) (172.18.0.8, executor 3, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.868805","level":"info","event":"25/08/01 08:43:35 INFO TaskSetManager: Starting task 2.0 in stage 32.2 (TID 368) (172.18.0.8, executor 3, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.879818","level":"info","event":"25/08/01 08:43:35 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.8:37619 (size: 130.3 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:35.897758","level":"info","event":"25/08/01 08:43:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.8:47000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.222133","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_2 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.222308","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_0 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.256758","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 3.0 in stage 32.2 (TID 369) (172.18.0.8, executor 3, partition 3, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.257117","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 4.0 in stage 32.2 (TID 370) (172.18.0.8, executor 3, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.257465","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 0.0 in stage 32.2 (TID 367) in 389 ms on 172.18.0.8 (executor 3) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.257642","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 2.0 in stage 32.2 (TID 368) in 389 ms on 172.18.0.8 (executor 3) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.311222","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_3 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.311332","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_4 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.314662","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 7.0 in stage 32.2 (TID 371) (172.18.0.8, executor 3, partition 7, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.314825","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 4.0 in stage 32.2 (TID 370) in 58 ms on 172.18.0.8 (executor 3) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.315113","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 10.0 in stage 32.2 (TID 372) (172.18.0.8, executor 3, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.315207","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 3.0 in stage 32.2 (TID 369) in 59 ms on 172.18.0.8 (executor 3) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.366208","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_7 in memory on 172.18.0.8:37619 (size: 449.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.366303","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_10 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.371486","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 14.0 in stage 32.2 (TID 373) (172.18.0.8, executor 3, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.372259","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 7.0 in stage 32.2 (TID 371) in 58 ms on 172.18.0.8 (executor 3) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.372613","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 22.0 in stage 32.2 (TID 374) (172.18.0.8, executor 3, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.372893","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 10.0 in stage 32.2 (TID 372) in 58 ms on 172.18.0.8 (executor 3) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.431982","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_22 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.432083","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_14 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.435195","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 40.0 in stage 32.2 (TID 375) (172.18.0.8, executor 3, partition 40, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.435508","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 41.0 in stage 32.2 (TID 376) (172.18.0.8, executor 3, partition 41, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.435712","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 14.0 in stage 32.2 (TID 373) in 64 ms on 172.18.0.8 (executor 3) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.436653","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 22.0 in stage 32.2 (TID 374) in 64 ms on 172.18.0.8 (executor 3) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.488230","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_41 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.488318","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_40 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.492801","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 42.0 in stage 32.2 (TID 377) (172.18.0.8, executor 3, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.492920","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 41.0 in stage 32.2 (TID 376) in 57 ms on 172.18.0.8 (executor 3) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.493221","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 47.0 in stage 32.2 (TID 378) (172.18.0.8, executor 3, partition 47, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.493350","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 40.0 in stage 32.2 (TID 375) in 59 ms on 172.18.0.8 (executor 3) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.540480","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_47 in memory on 172.18.0.8:37619 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.543370","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 1.0 in stage 32.2 (TID 379) (172.18.0.8, executor 3, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.543601","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 47.0 in stage 32.2 (TID 378) in 51 ms on 172.18.0.8 (executor 3) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.567539","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_1 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.571883","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 5.0 in stage 32.2 (TID 380) (172.18.0.8, executor 3, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.572228","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 1.0 in stage 32.2 (TID 379) in 28 ms on 172.18.0.8 (executor 3) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.596143","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_5 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.599015","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 6.0 in stage 32.2 (TID 381) (172.18.0.8, executor 3, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.599246","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 5.0 in stage 32.2 (TID 380) in 28 ms on 172.18.0.8 (executor 3) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.623741","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_6 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.626469","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 8.0 in stage 32.2 (TID 382) (172.18.0.8, executor 3, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.626615","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 6.0 in stage 32.2 (TID 381) in 28 ms on 172.18.0.8 (executor 3) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.668954","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_8 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.689115","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 9.0 in stage 32.2 (TID 383) (172.18.0.8, executor 3, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.693622","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 8.0 in stage 32.2 (TID 382) in 58 ms on 172.18.0.8 (executor 3) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.739581","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_9 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.761108","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_42 in memory on 172.18.0.8:37619 (size: 485.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.769062","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 11.0 in stage 32.2 (TID 384) (172.18.0.8, executor 3, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.771008","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 9.0 in stage 32.2 (TID 383) in 77 ms on 172.18.0.8 (executor 3) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.776590","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 12.0 in stage 32.2 (TID 385) (172.18.0.8, executor 3, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.777047","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 42.0 in stage 32.2 (TID 377) in 284 ms on 172.18.0.8 (executor 3) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.813295","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_11 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.814301","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_12 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.832451","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 13.0 in stage 32.2 (TID 386) (172.18.0.8, executor 3, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.833654","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 12.0 in stage 32.2 (TID 385) in 57 ms on 172.18.0.8 (executor 3) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.833713","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 15.0 in stage 32.2 (TID 387) (172.18.0.8, executor 3, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.834708","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 11.0 in stage 32.2 (TID 384) in 79 ms on 172.18.0.8 (executor 3) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.874684","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_13 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.875784","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_15 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.894159","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 16.0 in stage 32.2 (TID 388) (172.18.0.8, executor 3, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.903170","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 15.0 in stage 32.2 (TID 387) in 56 ms on 172.18.0.8 (executor 3) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.907729","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 17.0 in stage 32.2 (TID 389) (172.18.0.8, executor 3, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.907968","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 13.0 in stage 32.2 (TID 386) in 58 ms on 172.18.0.8 (executor 3) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.940059","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_16 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.951929","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 18.0 in stage 32.2 (TID 390) (172.18.0.8, executor 3, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.952390","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 16.0 in stage 32.2 (TID 388) in 64 ms on 172.18.0.8 (executor 3) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.975328","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_17 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.989577","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Starting task 19.0 in stage 32.2 (TID 391) (172.18.0.8, executor 3, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.990214","level":"info","event":"25/08/01 08:43:36 INFO TaskSetManager: Finished task 17.0 in stage 32.2 (TID 389) in 99 ms on 172.18.0.8 (executor 3) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:36.996392","level":"info","event":"25/08/01 08:43:36 INFO BlockManagerInfo: Added rdd_70_18 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.007666","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 20.0 in stage 32.2 (TID 392) (172.18.0.8, executor 3, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.008751","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 18.0 in stage 32.2 (TID 390) in 57 ms on 172.18.0.8 (executor 3) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.023896","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_19 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.028001","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 21.0 in stage 32.2 (TID 393) (172.18.0.8, executor 3, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.028272","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 19.0 in stage 32.2 (TID 391) in 41 ms on 172.18.0.8 (executor 3) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.031332","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_20 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.052986","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 23.0 in stage 32.2 (TID 394) (172.18.0.8, executor 3, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.054933","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 20.0 in stage 32.2 (TID 392) in 52 ms on 172.18.0.8 (executor 3) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.070506","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_21 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.079600","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 24.0 in stage 32.2 (TID 395) (172.18.0.8, executor 3, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.081198","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_23 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.081245","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 21.0 in stage 32.2 (TID 393) in 52 ms on 172.18.0.8 (executor 3) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.094354","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 25.0 in stage 32.2 (TID 396) (172.18.0.8, executor 3, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.097010","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 23.0 in stage 32.2 (TID 394) in 44 ms on 172.18.0.8 (executor 3) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.110413","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_24 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.113794","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 26.0 in stage 32.2 (TID 397) (172.18.0.8, executor 3, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.113972","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_25 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.114516","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 24.0 in stage 32.2 (TID 395) in 37 ms on 172.18.0.8 (executor 3) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.117154","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 27.0 in stage 32.2 (TID 398) (172.18.0.8, executor 3, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.117250","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 25.0 in stage 32.2 (TID 396) in 25 ms on 172.18.0.8 (executor 3) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.133232","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_26 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.134329","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_27 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.135849","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 28.0 in stage 32.2 (TID 399) (172.18.0.8, executor 3, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.136091","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 29.0 in stage 32.2 (TID 400) (172.18.0.8, executor 3, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.136251","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 26.0 in stage 32.2 (TID 397) in 23 ms on 172.18.0.8 (executor 3) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.136386","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 27.0 in stage 32.2 (TID 398) in 20 ms on 172.18.0.8 (executor 3) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.162215","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_28 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.163715","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_29 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.165621","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 30.0 in stage 32.2 (TID 401) (172.18.0.8, executor 3, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.165844","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 28.0 in stage 32.2 (TID 399) in 30 ms on 172.18.0.8 (executor 3) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.166101","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 31.0 in stage 32.2 (TID 402) (172.18.0.8, executor 3, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.166159","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 29.0 in stage 32.2 (TID 400) in 31 ms on 172.18.0.8 (executor 3) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.193619","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_30 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.193796","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_31 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.197373","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 32.0 in stage 32.2 (TID 403) (172.18.0.8, executor 3, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.197573","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 31.0 in stage 32.2 (TID 402) in 32 ms on 172.18.0.8 (executor 3) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.197806","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 33.0 in stage 32.2 (TID 404) (172.18.0.8, executor 3, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.198822","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 30.0 in stage 32.2 (TID 401) in 33 ms on 172.18.0.8 (executor 3) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.236232","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_32 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.238190","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_33 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.247439","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 34.0 in stage 32.2 (TID 405) (172.18.0.8, executor 3, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.247703","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 33.0 in stage 32.2 (TID 404) in 50 ms on 172.18.0.8 (executor 3) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.247734","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 35.0 in stage 32.2 (TID 406) (172.18.0.8, executor 3, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.247758","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 32.0 in stage 32.2 (TID 403) in 50 ms on 172.18.0.8 (executor 3) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.292882","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_35 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.293789","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_34 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.313036","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 36.0 in stage 32.2 (TID 407) (172.18.0.8, executor 3, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.315803","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 34.0 in stage 32.2 (TID 405) in 61 ms on 172.18.0.8 (executor 3) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.315873","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 37.0 in stage 32.2 (TID 408) (172.18.0.8, executor 3, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.315905","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 35.0 in stage 32.2 (TID 406) in 61 ms on 172.18.0.8 (executor 3) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.350195","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_37 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.351278","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_36 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.354514","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 38.0 in stage 32.2 (TID 409) (172.18.0.8, executor 3, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.354668","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 36.0 in stage 32.2 (TID 407) in 47 ms on 172.18.0.8 (executor 3) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.354995","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 39.0 in stage 32.2 (TID 410) (172.18.0.8, executor 3, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.355098","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 37.0 in stage 32.2 (TID 408) in 47 ms on 172.18.0.8 (executor 3) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.407641","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_38 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.408596","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_39 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.416289","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 43.0 in stage 32.2 (TID 411) (172.18.0.8, executor 3, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.416650","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 38.0 in stage 32.2 (TID 409) in 62 ms on 172.18.0.8 (executor 3) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.416980","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 44.0 in stage 32.2 (TID 412) (172.18.0.8, executor 3, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.417455","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 39.0 in stage 32.2 (TID 410) in 63 ms on 172.18.0.8 (executor 3) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.445243","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_43 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.446328","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_44 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.449126","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 45.0 in stage 32.2 (TID 413) (172.18.0.8, executor 3, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.449445","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 43.0 in stage 32.2 (TID 411) in 34 ms on 172.18.0.8 (executor 3) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.449675","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 46.0 in stage 32.2 (TID 414) (172.18.0.8, executor 3, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.449867","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 44.0 in stage 32.2 (TID 412) in 33 ms on 172.18.0.8 (executor 3) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.519816","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_46 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.520810","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_45 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.522196","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 48.0 in stage 32.2 (TID 415) (172.18.0.8, executor 3, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.522437","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 46.0 in stage 32.2 (TID 414) in 73 ms on 172.18.0.8 (executor 3) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.522788","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 49.0 in stage 32.2 (TID 416) (172.18.0.8, executor 3, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.523105","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 45.0 in stage 32.2 (TID 413) in 75 ms on 172.18.0.8 (executor 3) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.574672","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_48 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.575304","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added rdd_70_49 in memory on 172.18.0.8:37619 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.577347","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 48.0 in stage 32.2 (TID 415) in 56 ms on 172.18.0.8 (executor 3) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578020","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Finished task 49.0 in stage 32.2 (TID 416) in 55 ms on 172.18.0.8 (executor 3) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578253","level":"info","event":"25/08/01 08:43:37 INFO TaskSchedulerImpl: Removed TaskSet 32.2, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578419","level":"info","event":"25/08/01 08:43:37 INFO DAGScheduler: ShuffleMapStage 32 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.715 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578492","level":"info","event":"25/08/01 08:43:37 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578549","level":"info","event":"25/08/01 08:43:37 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578585","level":"info","event":"25/08/01 08:43:37 INFO DAGScheduler: waiting: Set(ResultStage 33)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578610","level":"info","event":"25/08/01 08:43:37 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578950","level":"info","event":"25/08/01 08:43:37 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[81] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.578996","level":"info","event":"25/08/01 08:43:37 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 33.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.584515","level":"info","event":"25/08/01 08:43:37 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 484.4 KiB, free 430.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.588767","level":"info","event":"25/08/01 08:43:37 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 117.0 KiB, free 430.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.589194","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 0baa42e17007:42905 (size: 117.0 KiB, free: 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.590349","level":"info","event":"25/08/01 08:43:37 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.590559","level":"info","event":"25/08/01 08:43:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[81] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.590608","level":"info","event":"25/08/01 08:43:37 INFO TaskSchedulerImpl: Adding task set 33.1 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.591483","level":"info","event":"25/08/01 08:43:37 INFO TaskSetManager: Starting task 0.0 in stage 33.1 (TID 417) (172.18.0.8, executor 3, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.613882","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.8:37619 (size: 117.0 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.683773","level":"info","event":"25/08/01 08:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.8:47000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.704432","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 0baa42e17007:42905 in memory (size: 130.3 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.732342","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.18.0.8:37619 in memory (size: 130.3 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.790782","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.8:37619 in memory (size: 130.3 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.793034","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 0baa42e17007:42905 in memory (size: 130.3 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.805500","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 0baa42e17007:42905 in memory (size: 32.6 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:37.807615","level":"info","event":"25/08/01 08:43:37 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.8:37619 in memory (size: 32.6 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:42.816736","level":"info","event":"25/08/01 08:43:42 INFO TaskSetManager: Finished task 0.0 in stage 33.1 (TID 417) in 5221 ms on 172.18.0.8 (executor 3) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:42.817727","level":"info","event":"25/08/01 08:43:42 INFO TaskSchedulerImpl: Removed TaskSet 33.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:42.817798","level":"info","event":"25/08/01 08:43:42 INFO DAGScheduler: ResultStage 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 5.235 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:42.817913","level":"info","event":"25/08/01 08:43:42 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:42.818006","level":"info","event":"25/08/01 08:43:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:42.818129","level":"info","event":"25/08/01 08:43:42 INFO DAGScheduler: Job 18 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 71.707854 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:43.931844","level":"info","event":"25/08/01 08:43:43 INFO DeltaLog: Starting the deletion of log files older than 2 Jul 2025 00:00:00 GMT","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:44.903488","level":"info","event":"25/08/01 08:43:44 INFO DeltaLog: Deleted 0 log files older than 2 Jul 2025 00:00:00 GMT","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:44.917693","level":"info","event":"INFO:__main__:Gold layer processing complete","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:44.927766","level":"info","event":"25/08/01 08:43:44 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.267043","level":"info","event":"25/08/01 08:43:46 INFO SparkUI: Stopped Spark web UI at http://0baa42e17007:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.304081","level":"info","event":"25/08/01 08:43:46 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.304580","level":"info","event":"25/08/01 08:43:46 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.339299","level":"info","event":"25/08/01 08:43:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.546744","level":"info","event":"25/08/01 08:43:46 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.548109","level":"info","event":"25/08/01 08:43:46 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.549500","level":"info","event":"25/08/01 08:43:46 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.554854","level":"info","event":"25/08/01 08:43:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.589426","level":"info","event":"25/08/01 08:43:46 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.793784","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:46.794300","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:47.348978","level":"info","event":"25/08/01 08:43:47 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:47.349315","level":"info","event":"25/08/01 08:43:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:47.351857","level":"info","event":"25/08/01 08:43:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-91604a51-12a5-4289-83d2-13fd99b30e8d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:47.353972","level":"info","event":"25/08/01 08:43:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-a7fd9674-9664-4623-8826-9b6ad6eacaa1/pyspark-07a3c356-af62-4640-81d3-8b1f329dcc01","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:47.358769","level":"info","event":"25/08/01 08:43:47 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:47.358878","level":"info","event":"25/08/01 08:43:47 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T08:43:47.358930","level":"info","event":"25/08/01 08:43:47 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
