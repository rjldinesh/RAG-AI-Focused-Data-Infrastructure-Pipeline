{"timestamp":"2025-07-30T17:04:02.597694","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-30T17:04:02.597975","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-30T17:04:06.432265","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-30T17:04:06.432931","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 1 --executor-memory 1g --driver-memory 512m --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.161242","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203118","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203197","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203227","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203266","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203287","level":"info","event":"executorMemory          1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203307","level":"info","event":"executorCores           1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203326","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203345","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203362","level":"info","event":"driverMemory            512m","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203380","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203398","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203415","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203433","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203450","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203467","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203485","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203503","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203520","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203537","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203554","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203572","level":"info","event":"primaryResource         file:/opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203589","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203607","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203625","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203642","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203679","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203698","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203714","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203733","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203751","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203769","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203786","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203804","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203821","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203838","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203876","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203899","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203916","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203933","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203950","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203966","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.203984","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.204000","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.269228","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.307296","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.307373","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.309089","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.309130","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.309170","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.309296","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.309603","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-2f914990-d314-4cfa-96c9-2e39cbe90fbe;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.309635","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.393802","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.408194","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.415069","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.427303","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.434801","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.443506","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.450328","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.458360","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.472879","level":"info","event":":: resolution report :: resolve 155ms :: artifacts dl 8ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.472935","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.472959","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.472980","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.472998","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473018","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473035","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473054","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473072","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473090","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473109","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473228","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473271","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473291","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473307","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473327","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473434","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.473455","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.476137","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-2f914990-d314-4cfa-96c9-2e39cbe90fbe","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.476199","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.479440","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/3ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.583006","level":"info","event":"25/07/30 17:04:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.677406","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.677497","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.677541","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.677562","level":"info","event":"file:/opt/spark-jobs/silver_to_gold.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.677583","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.678987","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679034","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679058","level":"info","event":"(spark.app.submitTime,1753895047670)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679077","level":"info","event":"(spark.driver.memory,512m)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679094","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679112","level":"info","event":"(spark.executor.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679130","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679150","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679167","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679184","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679201","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679218","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679235","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679252","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679269","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679286","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679303","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679321","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679339","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679356","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679373","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679390","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679407","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679424","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679441","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679457","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679483","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679508","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:07.679535","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.397307","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.397391","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.397503","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.406097","level":"info","event":"25/07/30 17:04:08 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.406528","level":"info","event":"25/07/30 17:04:08 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.406766","level":"info","event":"25/07/30 17:04:08 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.407299","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.416431","level":"info","event":"25/07/30 17:04:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.419672","level":"info","event":"25/07/30 17:04:08 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.420192","level":"info","event":"25/07/30 17:04:08 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.445600","level":"info","event":"25/07/30 17:04:08 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.445689","level":"info","event":"25/07/30 17:04:08 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.445824","level":"info","event":"25/07/30 17:04:08 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.445940","level":"info","event":"25/07/30 17:04:08 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.446097","level":"info","event":"25/07/30 17:04:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.543222","level":"info","event":"25/07/30 17:04:08 INFO Utils: Successfully started service 'sparkDriver' on port 36805.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.564653","level":"info","event":"25/07/30 17:04:08 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.580151","level":"info","event":"25/07/30 17:04:08 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.588466","level":"info","event":"25/07/30 17:04:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.588636","level":"info","event":"25/07/30 17:04:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.590514","level":"info","event":"25/07/30 17:04:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.601403","level":"info","event":"25/07/30 17:04:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b916d29b-26ce-4234-b806-6e85367277e8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.606651","level":"info","event":"25/07/30 17:04:08 INFO MemoryStore: MemoryStore started with capacity 127.2 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.613793","level":"info","event":"25/07/30 17:04:08 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.672381","level":"info","event":"25/07/30 17:04:08 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.700072","level":"info","event":"25/07/30 17:04:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.715073","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://efd5d439613e:36805/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.715165","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://efd5d439613e:36805/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.715281","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://efd5d439613e:36805/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.715415","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://efd5d439613e:36805/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.715467","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://efd5d439613e:36805/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.715535","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://efd5d439613e:36805/jars/org.tukaani_xz-1.9.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.715615","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://efd5d439613e:36805/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.715744","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://efd5d439613e:36805/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.716775","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://efd5d439613e:36805/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.717083","level":"info","event":"25/07/30 17:04:08 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/userFiles-b09910e1-2615-4f93-a42d-4cc38299ad56/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.724187","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://efd5d439613e:36805/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.724244","level":"info","event":"25/07/30 17:04:08 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/userFiles-b09910e1-2615-4f93-a42d-4cc38299ad56/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.903740","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://efd5d439613e:36805/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.903831","level":"info","event":"25/07/30 17:04:08 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/userFiles-b09910e1-2615-4f93-a42d-4cc38299ad56/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.906152","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://efd5d439613e:36805/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.906239","level":"info","event":"25/07/30 17:04:08 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/userFiles-b09910e1-2615-4f93-a42d-4cc38299ad56/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.912877","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://efd5d439613e:36805/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.912941","level":"info","event":"25/07/30 17:04:08 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/userFiles-b09910e1-2615-4f93-a42d-4cc38299ad56/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.915153","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://efd5d439613e:36805/files/org.tukaani_xz-1.9.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.915211","level":"info","event":"25/07/30 17:04:08 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/userFiles-b09910e1-2615-4f93-a42d-4cc38299ad56/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.917190","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://efd5d439613e:36805/files/io.delta_delta-storage-3.1.0.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.917253","level":"info","event":"25/07/30 17:04:08 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/userFiles-b09910e1-2615-4f93-a42d-4cc38299ad56/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.921127","level":"info","event":"25/07/30 17:04:08 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://efd5d439613e:36805/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753895048394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.921180","level":"info","event":"25/07/30 17:04:08 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/userFiles-b09910e1-2615-4f93-a42d-4cc38299ad56/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:08.958012","level":"info","event":"25/07/30 17:04:08 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.026398","level":"info","event":"25/07/30 17:04:09 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.5:7077 after 38 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.130315","level":"info","event":"25/07/30 17:04:09 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250730170409-0015","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.134178","level":"info","event":"25/07/30 17:04:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250730170409-0015/0 on worker-20250730152320-172.18.0.9-39293 (172.18.0.9:39293) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.135947","level":"info","event":"25/07/30 17:04:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20250730170409-0015/0 on hostPort 172.18.0.9:39293 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.136370","level":"info","event":"25/07/30 17:04:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250730170409-0015/1 on worker-20250730152320-172.18.0.9-39293 (172.18.0.9:39293) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.136410","level":"info","event":"25/07/30 17:04:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20250730170409-0015/1 on hostPort 172.18.0.9:39293 with 1 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.151971","level":"info","event":"25/07/30 17:04:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44283.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.153358","level":"info","event":"25/07/30 17:04:09 INFO NettyBlockTransferService: Server created on efd5d439613e:44283","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.156480","level":"info","event":"25/07/30 17:04:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.167031","level":"info","event":"25/07/30 17:04:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, efd5d439613e, 44283, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.173803","level":"info","event":"25/07/30 17:04:09 INFO BlockManagerMasterEndpoint: Registering block manager efd5d439613e:44283 with 127.2 MiB RAM, BlockManagerId(driver, efd5d439613e, 44283, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.173973","level":"info","event":"25/07/30 17:04:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, efd5d439613e, 44283, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.174025","level":"info","event":"25/07/30 17:04:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, efd5d439613e, 44283, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.212411","level":"info","event":"25/07/30 17:04:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250730170409-0015/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.213047","level":"info","event":"25/07/30 17:04:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250730170409-0015/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.485891","level":"info","event":"25/07/30 17:04:09 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.680907","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.684927","level":"info","event":"25/07/30 17:04:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:09.686131","level":"info","event":"25/07/30 17:04:09 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:10.534009","level":"info","event":"25/07/30 17:04:10 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:10.547418","level":"info","event":"25/07/30 17:04:10 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:10.547665","level":"info","event":"25/07/30 17:04:10 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:11.215911","level":"info","event":"25/07/30 17:04:11 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:11.256230","level":"info","event":"25/07/30 17:04:11 INFO DeltaLog: Loading version 7.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:11.301661","level":"info","event":"25/07/30 17:04:11 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.9:45284) with ID 1,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:11.305704","level":"info","event":"25/07/30 17:04:11 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.9:45280) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:11.340890","level":"info","event":"25/07/30 17:04:11 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.9:45247 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.9, 45247, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:11.341429","level":"info","event":"25/07/30 17:04:11 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.9:39097 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.9, 39097, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:12.685231","level":"info","event":"25/07/30 17:04:12 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 8, totalFileSize: 18609)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.473347","level":"info","event":"25/07/30 17:04:13 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.481903","level":"info","event":"25/07/30 17:04:13 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.482782","level":"info","event":"25/07/30 17:04:13 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#11.minReaderVersion) OR isnotnull(metaData#10.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.769852","level":"info","event":"25/07/30 17:04:13 INFO CodeGenerator: Code generated in 117.79625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.804201","level":"info","event":"25/07/30 17:04:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 206.0 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.831406","level":"info","event":"25/07/30 17:04:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.832603","level":"info","event":"25/07/30 17:04:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on efd5d439613e:44283 (size: 36.5 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.838150","level":"info","event":"25/07/30 17:04:13 INFO SparkContext: Created broadcast 0 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.846102","level":"info","event":"25/07/30 17:04:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 16786520 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.915288","level":"info","event":"25/07/30 17:04:13 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.920632","level":"info","event":"25/07/30 17:04:13 INFO DAGScheduler: Got job 0 (toString at String.java:4220) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.920741","level":"info","event":"25/07/30 17:04:13 INFO DAGScheduler: Final stage: ResultStage 0 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.920775","level":"info","event":"25/07/30 17:04:13 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.921141","level":"info","event":"25/07/30 17:04:13 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.923439","level":"info","event":"25/07/30 17:04:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.931705","level":"info","event":"25/07/30 17:04:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.0 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.932876","level":"info","event":"25/07/30 17:04:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.933091","level":"info","event":"25/07/30 17:04:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on efd5d439613e:44283 (size: 13.7 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.933399","level":"info","event":"25/07/30 17:04:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.940814","level":"info","event":"25/07/30 17:04:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.941368","level":"info","event":"25/07/30 17:04:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.951012","level":"info","event":"25/07/30 17:04:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.9, executor 1, partition 0, PROCESS_LOCAL, 11643 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:13.952582","level":"info","event":"25/07/30 17:04:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 11643 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:14.241968","level":"info","event":"25/07/30 17:04:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.9:39097 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:14.242732","level":"info","event":"25/07/30 17:04:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.9:45247 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:14.820511","level":"info","event":"25/07/30 17:04:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.9:39097 (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:14.820714","level":"info","event":"25/07/30 17:04:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.9:45247 (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.447851","level":"info","event":"25/07/30 17:04:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1500 ms on 172.18.0.9 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.448583","level":"info","event":"25/07/30 17:04:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1496 ms on 172.18.0.9 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.448891","level":"info","event":"25/07/30 17:04:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.451917","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: ResultStage 0 (toString at String.java:4220) finished in 1.522 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.452744","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.452941","level":"info","event":"25/07/30 17:04:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.453841","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Job 0 finished: toString at String.java:4220, took 1.538333 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.486776","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on efd5d439613e:44283 in memory (size: 13.7 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.492227","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.9:39097 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.494769","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.9:45247 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.503549","level":"info","event":"25/07/30 17:04:15 INFO CodeGenerator: Code generated in 32.355625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.507442","level":"info","event":"25/07/30 17:04:15 INFO Snapshot: [tableId=42f02839-b2b7-46c3-8cf6-1a803813e4ea] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=7, metadata=Metadata(82ad5421-24ce-4d38-8164-c7ba05900532,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753890673286)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,7,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1753890675666; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=76c5b6f4ac2576041d1f8e31c702afd9 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000001.json; isDirectory=false; length=2196; replication=1; blocksize=33554432; modification_time=1753890872096; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=aeff6a466e27a43501b3bcc493de720b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000002.json; isDirectory=false; length=2400; replication=1; blocksize=33554432; modification_time=1753891352837; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=2970568b40e0a6f9974276ce5c6bec90 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000003.json; isDirectory=false; length=2402; replication=1; blocksize=33554432; modification_time=1753891476355; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c1320e0923a967372527a52be4fbe24e versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000004.json; isDirectory=false; length=2402; replication=1; blocksize=33554432; modification_time=1753891567204; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=3ab193e19040497ba942a8c3ad51349a versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000005.json; isDirectory=false; length=2404; replication=1; blocksize=33554432; modification_time=1753893419033; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=5fc1336ca28cc4a037cda409a668ef60 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000006.json; isDirectory=false; length=2405; replication=1; blocksize=33554432; modification_time=1753893515851; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=d272bc401751fbb9f77252bdfee720e8 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000007.json; isDirectory=false; length=2405; replication=1; blocksize=33554432; modification_time=1753895040684; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=245c56431dcbc3bdedb3ee5cb9af6f09 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@7048f78c,1753895040684), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.643312","level":"info","event":"25/07/30 17:04:15 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.660416","level":"info","event":"25/07/30 17:04:15 INFO DeltaLog: Loading version 4.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.663685","level":"info","event":"25/07/30 17:04:15 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 5, totalFileSize: 5472)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.691333","level":"info","event":"25/07/30 17:04:15 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.691512","level":"info","event":"25/07/30 17:04:15 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.691687","level":"info","event":"25/07/30 17:04:15 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#72.minReaderVersion) OR isnotnull(metaData#71.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.700769","level":"info","event":"25/07/30 17:04:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 206.0 KiB, free 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.706803","level":"info","event":"25/07/30 17:04:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.707377","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on efd5d439613e:44283 (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.708068","level":"info","event":"25/07/30 17:04:15 INFO SparkContext: Created broadcast 2 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.708693","level":"info","event":"25/07/30 17:04:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10488496 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.729011","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on efd5d439613e:44283 in memory (size: 36.5 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.729749","level":"info","event":"25/07/30 17:04:15 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.733135","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Got job 1 (toString at String.java:4220) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.733245","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Final stage: ResultStage 1 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.733302","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.733346","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.733400","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.9:39097 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.733443","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.733493","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.9:45247 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.733547","level":"info","event":"25/07/30 17:04:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 40.0 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.736958","level":"info","event":"25/07/30 17:04:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.737267","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on efd5d439613e:44283 (size: 13.7 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.740368","level":"info","event":"25/07/30 17:04:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.740921","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.741075","level":"info","event":"25/07/30 17:04:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.746243","level":"info","event":"25/07/30 17:04:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 11478 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.746854","level":"info","event":"25/07/30 17:04:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3) (172.18.0.9, executor 1, partition 1, PROCESS_LOCAL, 11321 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.762556","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.9:39097 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.762929","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.9:45247 (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.778587","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.9:45247 (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.778749","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.9:39097 (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.815447","level":"info","event":"25/07/30 17:04:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 69 ms on 172.18.0.9 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.823829","level":"info","event":"25/07/30 17:04:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 78 ms on 172.18.0.9 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.823931","level":"info","event":"25/07/30 17:04:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.824505","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: ResultStage 1 (toString at String.java:4220) finished in 0.093 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.824759","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.824836","level":"info","event":"25/07/30 17:04:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.824886","level":"info","event":"25/07/30 17:04:15 INFO DAGScheduler: Job 1 finished: toString at String.java:4220, took 0.095062 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.835789","level":"info","event":"25/07/30 17:04:15 INFO Snapshot: [tableId=e191c270-0cfe-4df9-bb4d-d5a8bbc8158e] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=4, metadata=Metadata(5e0965ee-836d-4153-95e5-24b2f62e3e7b,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753890888679)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,4,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000000.json; isDirectory=false; length=1336; replication=1; blocksize=33554432; modification_time=1753890894354; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=396660e452df253d28809dd2168f10ee versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000001.json; isDirectory=false; length=1031; replication=1; blocksize=33554432; modification_time=1753891405629; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=9bb9e7db76ba50333757bf408d995e7a versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000002.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753891588051; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f4b4023744c578233c087d624d151164 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000003.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753893439999; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=4c774b9b2c7c96fb1bc206ca12d2a8f2 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000004.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753893537255; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=967f1877c6bd879e96f9277a58e11f25 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@7048f78c,1753893537255), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.885845","level":"info","event":"25/07/30 17:04:15 INFO Snapshot: [tableId=5e0965ee-836d-4153-95e5-24b2f62e3e7b] DELTA: Compute snapshot for version: 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.895426","level":"info","event":"25/07/30 17:04:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 205.7 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.899425","level":"info","event":"25/07/30 17:04:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.899984","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on efd5d439613e:44283 (size: 36.4 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.900619","level":"info","event":"25/07/30 17:04:15 INFO SparkContext: Created broadcast 4 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.993509","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on efd5d439613e:44283 in memory (size: 36.5 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.995455","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.9:39097 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.995817","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.9:45247 in memory (size: 36.5 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:15.999562","level":"info","event":"25/07/30 17:04:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on efd5d439613e:44283 in memory (size: 13.7 KiB, free: 127.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.008584","level":"info","event":"25/07/30 17:04:16 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.9:39097 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.013301","level":"info","event":"25/07/30 17:04:16 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.9:45247 in memory (size: 13.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.158122","level":"info","event":"25/07/30 17:04:16 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.158216","level":"info","event":"25/07/30 17:04:16 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.158247","level":"info","event":"25/07/30 17:04:16 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.179751","level":"info","event":"25/07/30 17:04:16 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.267450","level":"info","event":"25/07/30 17:04:16 INFO CodeGenerator: Code generated in 47.886625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.268920","level":"info","event":"25/07/30 17:04:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 206.0 KiB, free 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.272024","level":"info","event":"25/07/30 17:04:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 126.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.272368","level":"info","event":"25/07/30 17:04:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on efd5d439613e:44283 (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.272874","level":"info","event":"25/07/30 17:04:16 INFO SparkContext: Created broadcast 5 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.273431","level":"info","event":"25/07/30 17:04:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10488496 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.304165","level":"info","event":"25/07/30 17:04:16 INFO DAGScheduler: Registering RDD 11 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.307348","level":"info","event":"25/07/30 17:04:16 INFO DAGScheduler: Got map stage job 2 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.307412","level":"info","event":"25/07/30 17:04:16 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.307508","level":"info","event":"25/07/30 17:04:16 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.307770","level":"info","event":"25/07/30 17:04:16 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.308168","level":"info","event":"25/07/30 17:04:16 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.313703","level":"info","event":"25/07/30 17:04:16 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 105.6 KiB, free 126.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.314446","level":"info","event":"25/07/30 17:04:16 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 126.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.314774","level":"info","event":"25/07/30 17:04:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on efd5d439613e:44283 (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.315069","level":"info","event":"25/07/30 17:04:16 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.315652","level":"info","event":"25/07/30 17:04:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.315693","level":"info","event":"25/07/30 17:04:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.316778","level":"info","event":"25/07/30 17:04:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 11467 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.317009","level":"info","event":"25/07/30 17:04:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5) (172.18.0.9, executor 1, partition 1, PROCESS_LOCAL, 11310 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.327679","level":"info","event":"25/07/30 17:04:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.9:39097 (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.327779","level":"info","event":"25/07/30 17:04:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.9:45247 (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.595912","level":"info","event":"25/07/30 17:04:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.9:45247 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:16.597165","level":"info","event":"25/07/30 17:04:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.9:39097 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.089014","level":"info","event":"25/07/30 17:04:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 772 ms on 172.18.0.9 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.094257","level":"info","event":"25/07/30 17:04:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 778 ms on 172.18.0.9 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.094337","level":"info","event":"25/07/30 17:04:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.094933","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: ShuffleMapStage 2 (save at NativeMethodAccessorImpl.java:0) finished in 0.786 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.095108","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.095399","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.095574","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.095663","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.135470","level":"info","event":"25/07/30 17:04:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on efd5d439613e:44283 in memory (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.136934","level":"info","event":"25/07/30 17:04:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.9:45247 in memory (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.137186","level":"info","event":"25/07/30 17:04:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.9:39097 in memory (size: 32.6 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.283343","level":"info","event":"25/07/30 17:04:17 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.284397","level":"info","event":"25/07/30 17:04:17 INFO CodeGenerator: Code generated in 128.972209 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.329569","level":"info","event":"25/07/30 17:04:17 INFO CodeGenerator: Code generated in 30.34475 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.485262","level":"info","event":"25/07/30 17:04:17 INFO CodeGenerator: Code generated in 27.682083 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.489139","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: Registering RDD 21 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.489270","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: Got map stage job 3 (save at NativeMethodAccessorImpl.java:0) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.489301","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.489321","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.490404","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.490731","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[21] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.506401","level":"info","event":"25/07/30 17:04:17 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 603.4 KiB, free 126.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.507506","level":"info","event":"25/07/30 17:04:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 138.3 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.507847","level":"info","event":"25/07/30 17:04:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on efd5d439613e:44283 (size: 138.3 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.508197","level":"info","event":"25/07/30 17:04:17 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.508571","level":"info","event":"25/07/30 17:04:17 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[21] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.508632","level":"info","event":"25/07/30 17:04:17 INFO TaskSchedulerImpl: Adding task set 4.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.510835","level":"info","event":"25/07/30 17:04:17 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 6) (172.18.0.9, executor 1, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.510979","level":"info","event":"25/07/30 17:04:17 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 7) (172.18.0.9, executor 0, partition 9, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.522508","level":"info","event":"25/07/30 17:04:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.9:39097 (size: 138.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.522588","level":"info","event":"25/07/30 17:04:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.9:45247 (size: 138.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.624526","level":"info","event":"25/07/30 17:04:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.9:45284","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.624703","level":"info","event":"25/07/30 17:04:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.9:45280","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.974525","level":"info","event":"25/07/30 17:04:17 INFO BlockManagerInfo: Added rdd_18_4 in memory on 172.18.0.9:45247 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:17.987924","level":"info","event":"25/07/30 17:04:17 INFO BlockManagerInfo: Added rdd_18_9 in memory on 172.18.0.9:39097 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.281291","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 19.0 in stage 4.0 (TID 8) (172.18.0.9, executor 1, partition 19, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.282750","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 31.0 in stage 4.0 (TID 9) (172.18.0.9, executor 0, partition 31, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.283762","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 7) in 773 ms on 172.18.0.9 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.287662","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 6) in 775 ms on 172.18.0.9 (executor 1) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.331864","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_31 in memory on 172.18.0.9:39097 (size: 448.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.341001","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_19 in memory on 172.18.0.9:45247 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.359114","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 35.0 in stage 4.0 (TID 10) (172.18.0.9, executor 0, partition 35, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.359743","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 31.0 in stage 4.0 (TID 9) in 77 ms on 172.18.0.9 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.368995","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 42.0 in stage 4.0 (TID 11) (172.18.0.9, executor 1, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.369292","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 19.0 in stage 4.0 (TID 8) in 89 ms on 172.18.0.9 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.395002","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_35 in memory on 172.18.0.9:39097 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.415311","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 12) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.418346","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 35.0 in stage 4.0 (TID 10) in 59 ms on 172.18.0.9 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.447254","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_0 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.474870","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 13) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.476285","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 12) in 61 ms on 172.18.0.9 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.519155","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_1 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.541061","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 14) (172.18.0.9, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.541443","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 13) in 67 ms on 172.18.0.9 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.572406","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_42 in memory on 172.18.0.9:45247 (size: 487.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.572706","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_2 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.590389","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 15) (172.18.0.9, executor 1, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.590726","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 42.0 in stage 4.0 (TID 11) in 222 ms on 172.18.0.9 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.591573","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 16) (172.18.0.9, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.592418","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 14) in 52 ms on 172.18.0.9 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.623031","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_5 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.627143","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_3 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.636443","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 17) (172.18.0.9, executor 0, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.636861","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 16) in 45 ms on 172.18.0.9 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.645993","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 18) (172.18.0.9, executor 1, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.646370","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 15) in 57 ms on 172.18.0.9 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.660446","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_6 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.675198","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 19) (172.18.0.9, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.675587","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 17) in 39 ms on 172.18.0.9 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.681217","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_7 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.699627","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 10.0 in stage 4.0 (TID 20) (172.18.0.9, executor 1, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.700084","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 18) in 54 ms on 172.18.0.9 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.702072","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_8 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.722383","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 11.0 in stage 4.0 (TID 21) (172.18.0.9, executor 0, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.723122","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 19) in 48 ms on 172.18.0.9 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.736462","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_10 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.745219","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_11 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.753608","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 12.0 in stage 4.0 (TID 22) (172.18.0.9, executor 1, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.754050","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 10.0 in stage 4.0 (TID 20) in 54 ms on 172.18.0.9 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.758401","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 13.0 in stage 4.0 (TID 23) (172.18.0.9, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.758919","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 11.0 in stage 4.0 (TID 21) in 37 ms on 172.18.0.9 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.782396","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_13 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.784351","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_12 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.794523","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 14.0 in stage 4.0 (TID 24) (172.18.0.9, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.794956","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 13.0 in stage 4.0 (TID 23) in 36 ms on 172.18.0.9 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.800220","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 15.0 in stage 4.0 (TID 25) (172.18.0.9, executor 1, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.800488","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 12.0 in stage 4.0 (TID 22) in 47 ms on 172.18.0.9 (executor 1) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.816096","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_14 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.826963","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_15 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.830350","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 16.0 in stage 4.0 (TID 26) (172.18.0.9, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.830595","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 14.0 in stage 4.0 (TID 24) in 36 ms on 172.18.0.9 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.841425","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 17.0 in stage 4.0 (TID 27) (172.18.0.9, executor 1, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.841644","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 15.0 in stage 4.0 (TID 25) in 42 ms on 172.18.0.9 (executor 1) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.852723","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_16 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.864251","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 18.0 in stage 4.0 (TID 28) (172.18.0.9, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.864581","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 16.0 in stage 4.0 (TID 26) in 34 ms on 172.18.0.9 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.870387","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_17 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.884110","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 20.0 in stage 4.0 (TID 29) (172.18.0.9, executor 1, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.884500","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 17.0 in stage 4.0 (TID 27) in 43 ms on 172.18.0.9 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.887537","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_18 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.898747","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 21.0 in stage 4.0 (TID 30) (172.18.0.9, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.899141","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 18.0 in stage 4.0 (TID 28) in 35 ms on 172.18.0.9 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.909877","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_20 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.921331","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_21 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.923870","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 22.0 in stage 4.0 (TID 31) (172.18.0.9, executor 1, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.924387","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 20.0 in stage 4.0 (TID 29) in 41 ms on 172.18.0.9 (executor 1) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.934030","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 23.0 in stage 4.0 (TID 32) (172.18.0.9, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.934223","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 21.0 in stage 4.0 (TID 30) in 36 ms on 172.18.0.9 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.941900","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_22 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.951603","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 24.0 in stage 4.0 (TID 33) (172.18.0.9, executor 1, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.952177","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 22.0 in stage 4.0 (TID 31) in 29 ms on 172.18.0.9 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.956656","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_23 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.967016","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 25.0 in stage 4.0 (TID 34) (172.18.0.9, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.967488","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 23.0 in stage 4.0 (TID 32) in 34 ms on 172.18.0.9 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.969724","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_24 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.979290","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 26.0 in stage 4.0 (TID 35) (172.18.0.9, executor 1, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.979593","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 24.0 in stage 4.0 (TID 33) in 28 ms on 172.18.0.9 (executor 1) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.987643","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_25 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.997967","level":"info","event":"25/07/30 17:04:18 INFO BlockManagerInfo: Added rdd_18_26 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.998731","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Starting task 27.0 in stage 4.0 (TID 36) (172.18.0.9, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:18.999271","level":"info","event":"25/07/30 17:04:18 INFO TaskSetManager: Finished task 25.0 in stage 4.0 (TID 34) in 32 ms on 172.18.0.9 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.007808","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 28.0 in stage 4.0 (TID 37) (172.18.0.9, executor 1, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.008092","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 26.0 in stage 4.0 (TID 35) in 29 ms on 172.18.0.9 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.020403","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_27 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.024185","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_28 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.031987","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 29.0 in stage 4.0 (TID 38) (172.18.0.9, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.032593","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 27.0 in stage 4.0 (TID 36) in 34 ms on 172.18.0.9 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.034038","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 30.0 in stage 4.0 (TID 39) (172.18.0.9, executor 1, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.034359","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 28.0 in stage 4.0 (TID 37) in 27 ms on 172.18.0.9 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.049843","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_29 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.051051","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_30 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.059417","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 32.0 in stage 4.0 (TID 40) (172.18.0.9, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.059705","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 29.0 in stage 4.0 (TID 38) in 28 ms on 172.18.0.9 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.060140","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 33.0 in stage 4.0 (TID 41) (172.18.0.9, executor 1, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.060487","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 30.0 in stage 4.0 (TID 39) in 27 ms on 172.18.0.9 (executor 1) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.078458","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_32 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.079114","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_33 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.087938","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 34.0 in stage 4.0 (TID 42) (172.18.0.9, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.088231","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 32.0 in stage 4.0 (TID 40) in 29 ms on 172.18.0.9 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.088850","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 36.0 in stage 4.0 (TID 43) (172.18.0.9, executor 1, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.088936","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 33.0 in stage 4.0 (TID 41) in 29 ms on 172.18.0.9 (executor 1) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.104361","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_34 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.105386","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_36 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.114658","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 37.0 in stage 4.0 (TID 44) (172.18.0.9, executor 1, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.114902","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 36.0 in stage 4.0 (TID 43) in 26 ms on 172.18.0.9 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.115523","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 38.0 in stage 4.0 (TID 45) (172.18.0.9, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.116120","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 34.0 in stage 4.0 (TID 42) in 28 ms on 172.18.0.9 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.130762","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_37 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.130869","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_38 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.139798","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 39.0 in stage 4.0 (TID 46) (172.18.0.9, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.140447","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 40.0 in stage 4.0 (TID 47) (172.18.0.9, executor 1, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.140587","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 38.0 in stage 4.0 (TID 45) in 25 ms on 172.18.0.9 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.140842","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 37.0 in stage 4.0 (TID 44) in 26 ms on 172.18.0.9 (executor 1) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.157949","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_40 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.158046","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_39 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.166208","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 41.0 in stage 4.0 (TID 48) (172.18.0.9, executor 1, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.166487","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 40.0 in stage 4.0 (TID 47) in 26 ms on 172.18.0.9 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.166949","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 43.0 in stage 4.0 (TID 49) (172.18.0.9, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.167191","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 39.0 in stage 4.0 (TID 46) in 28 ms on 172.18.0.9 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.182437","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_43 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.182543","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_41 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.194579","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 44.0 in stage 4.0 (TID 50) (172.18.0.9, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.195131","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 43.0 in stage 4.0 (TID 49) in 28 ms on 172.18.0.9 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.195530","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 45.0 in stage 4.0 (TID 51) (172.18.0.9, executor 1, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.195948","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 41.0 in stage 4.0 (TID 48) in 30 ms on 172.18.0.9 (executor 1) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.212319","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_44 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.212498","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_45 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.219945","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 46.0 in stage 4.0 (TID 52) (172.18.0.9, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.220208","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 44.0 in stage 4.0 (TID 50) in 26 ms on 172.18.0.9 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.220728","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 47.0 in stage 4.0 (TID 53) (172.18.0.9, executor 1, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.220939","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 45.0 in stage 4.0 (TID 51) in 25 ms on 172.18.0.9 (executor 1) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.236179","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_47 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.239125","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_46 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.245278","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 48.0 in stage 4.0 (TID 54) (172.18.0.9, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.245588","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 47.0 in stage 4.0 (TID 53) in 25 ms on 172.18.0.9 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.248429","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 49.0 in stage 4.0 (TID 55) (172.18.0.9, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.248714","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 46.0 in stage 4.0 (TID 52) in 29 ms on 172.18.0.9 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.260471","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_48 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.264501","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_18_49 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.268123","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 48.0 in stage 4.0 (TID 54) in 23 ms on 172.18.0.9 (executor 1) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.275767","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 49.0 in stage 4.0 (TID 55) in 27 ms on 172.18.0.9 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.275848","level":"info","event":"25/07/30 17:04:19 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.276235","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: ShuffleMapStage 4 (save at NativeMethodAccessorImpl.java:0) finished in 1.781 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.276402","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.276553","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.276600","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.276623","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.288687","level":"info","event":"25/07/30 17:04:19 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.289275","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Got job 4 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.289313","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Final stage: ResultStage 7 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.289334","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.289407","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.289596","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[24] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.291814","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 534.7 KiB, free 125.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.292826","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 124.6 KiB, free 125.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.293130","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on efd5d439613e:44283 (size: 124.6 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.293345","level":"info","event":"25/07/30 17:04:19 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.293512","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[24] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.293544","level":"info","event":"25/07/30 17:04:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.294320","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 56) (172.18.0.9, executor 1, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.299164","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.9:45247 (size: 124.6 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.304363","level":"info","event":"25/07/30 17:04:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.9:45284","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.329013","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 56) in 34 ms on 172.18.0.9 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.329094","level":"info","event":"25/07/30 17:04:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.329360","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: ResultStage 7 (save at NativeMethodAccessorImpl.java:0) finished in 0.040 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.329411","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.329436","level":"info","event":"25/07/30 17:04:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.329653","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Job 4 finished: save at NativeMethodAccessorImpl.java:0, took 0.040905 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.353412","level":"info","event":"25/07/30 17:04:19 INFO CodeGenerator: Code generated in 17.718667 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.354416","level":"info","event":"25/07/30 17:04:19 INFO Snapshot: [tableId=5e0965ee-836d-4153-95e5-24b2f62e3e7b] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.378271","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Removed broadcast_8_piece0 on efd5d439613e:44283 in memory (size: 124.6 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.379583","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.9:45247 in memory (size: 124.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.382634","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Removed broadcast_7_piece0 on efd5d439613e:44283 in memory (size: 138.3 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.384088","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.9:39097 in memory (size: 138.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.384363","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.9:45247 in memory (size: 138.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.396583","level":"info","event":"25/07/30 17:04:19 INFO PrepareDeltaScan: DELTA: Filtering files for query","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.397386","level":"info","event":"25/07/30 17:04:19 INFO Snapshot: [tableId=82ad5421-24ce-4d38-8164-c7ba05900532] DELTA: Compute snapshot for version: 7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.398824","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 205.7 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.402116","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 126.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.402439","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on efd5d439613e:44283 (size: 36.4 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.402887","level":"info","event":"25/07/30 17:04:19 INFO SparkContext: Created broadcast 9 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.478091","level":"info","event":"25/07/30 17:04:19 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.478184","level":"info","event":"25/07/30 17:04:19 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.478273","level":"info","event":"25/07/30 17:04:19 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.499616","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 206.0 KiB, free 126.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.502595","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 126.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.502872","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on efd5d439613e:44283 (size: 36.5 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.503407","level":"info","event":"25/07/30 17:04:19 INFO SparkContext: Created broadcast 10 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.503915","level":"info","event":"25/07/30 17:04:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 16786520 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.506962","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Registering RDD 28 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.507030","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Got map stage job 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.507060","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Final stage: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.507081","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.507102","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.507320","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[28] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.508463","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 105.6 KiB, free 126.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.509030","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 126.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.509301","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on efd5d439613e:44283 (size: 32.6 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.509556","level":"info","event":"25/07/30 17:04:19 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.509706","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[28] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.509740","level":"info","event":"25/07/30 17:04:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.510353","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 57) (172.18.0.9, executor 1, partition 0, PROCESS_LOCAL, 11632 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.510480","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 58) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 11632 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.516519","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.9:45247 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.516614","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.9:39097 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.528614","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.9:45247 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.528874","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.9:39097 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.569635","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 58) in 59 ms on 172.18.0.9 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.569748","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 57) in 59 ms on 172.18.0.9 (executor 1) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.569776","level":"info","event":"25/07/30 17:04:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.570202","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.062 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.570467","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.570591","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.570635","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.570696","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.598217","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Removed broadcast_11_piece0 on efd5d439613e:44283 in memory (size: 32.6 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.599536","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.9:39097 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.599766","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.9:45247 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.639069","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Registering RDD 38 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.639150","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Got map stage job 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.639176","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Final stage: ShuffleMapStage 10 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.639199","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.639664","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.640061","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[38] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.645129","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 603.4 KiB, free 125.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.646162","level":"info","event":"25/07/30 17:04:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 138.1 KiB, free 125.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.646500","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on efd5d439613e:44283 (size: 138.1 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.646720","level":"info","event":"25/07/30 17:04:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.647089","level":"info","event":"25/07/30 17:04:19 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[38] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.647131","level":"info","event":"25/07/30 17:04:19 INFO TaskSchedulerImpl: Adding task set 10.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.647931","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 11.0 in stage 10.0 (TID 59) (172.18.0.9, executor 1, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.648031","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 12.0 in stage 10.0 (TID 60) (172.18.0.9, executor 0, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.653610","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.9:45247 (size: 138.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.653706","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.9:39097 (size: 138.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.659151","level":"info","event":"25/07/30 17:04:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.9:45280","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.659237","level":"info","event":"25/07/30 17:04:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.9:45284","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.671247","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_11 in memory on 172.18.0.9:45247 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.675431","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_12 in memory on 172.18.0.9:39097 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.680896","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 16.0 in stage 10.0 (TID 61) (172.18.0.9, executor 1, partition 16, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.681169","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 11.0 in stage 10.0 (TID 59) in 33 ms on 172.18.0.9 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.693874","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 17.0 in stage 10.0 (TID 62) (172.18.0.9, executor 0, partition 17, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.694208","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 12.0 in stage 10.0 (TID 60) in 46 ms on 172.18.0.9 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.699077","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_16 in memory on 172.18.0.9:45247 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.706722","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 19.0 in stage 10.0 (TID 63) (172.18.0.9, executor 1, partition 19, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.707191","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 16.0 in stage 10.0 (TID 61) in 26 ms on 172.18.0.9 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.709433","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_17 in memory on 172.18.0.9:39097 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.717604","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 22.0 in stage 10.0 (TID 64) (172.18.0.9, executor 0, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.718008","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 17.0 in stage 10.0 (TID 62) in 24 ms on 172.18.0.9 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.721792","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_19 in memory on 172.18.0.9:45247 (size: 377.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.729264","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 24.0 in stage 10.0 (TID 65) (172.18.0.9, executor 1, partition 24, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.729518","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 19.0 in stage 10.0 (TID 63) in 23 ms on 172.18.0.9 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.732279","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_22 in memory on 172.18.0.9:39097 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.740411","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 26.0 in stage 10.0 (TID 66) (172.18.0.9, executor 0, partition 26, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.740629","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 22.0 in stage 10.0 (TID 64) in 23 ms on 172.18.0.9 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.744610","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_24 in memory on 172.18.0.9:45247 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.751993","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 27.0 in stage 10.0 (TID 67) (172.18.0.9, executor 1, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.752189","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 24.0 in stage 10.0 (TID 65) in 24 ms on 172.18.0.9 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.754767","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_26 in memory on 172.18.0.9:39097 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.762404","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 28.0 in stage 10.0 (TID 68) (172.18.0.9, executor 0, partition 28, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.762731","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 26.0 in stage 10.0 (TID 66) in 22 ms on 172.18.0.9 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.767789","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_27 in memory on 172.18.0.9:45247 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.775965","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 31.0 in stage 10.0 (TID 69) (172.18.0.9, executor 1, partition 31, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.776121","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 27.0 in stage 10.0 (TID 67) in 25 ms on 172.18.0.9 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.781197","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_28 in memory on 172.18.0.9:39097 (size: 693.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.789826","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 36.0 in stage 10.0 (TID 70) (172.18.0.9, executor 0, partition 36, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.790383","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 28.0 in stage 10.0 (TID 68) in 28 ms on 172.18.0.9 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.791067","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_31 in memory on 172.18.0.9:45247 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.799252","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 41.0 in stage 10.0 (TID 71) (172.18.0.9, executor 1, partition 41, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.799507","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 31.0 in stage 10.0 (TID 69) in 24 ms on 172.18.0.9 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.810535","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_36 in memory on 172.18.0.9:39097 (size: 702.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.818529","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_41 in memory on 172.18.0.9:45247 (size: 307.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.823459","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 42.0 in stage 10.0 (TID 72) (172.18.0.9, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.823692","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 36.0 in stage 10.0 (TID 70) in 34 ms on 172.18.0.9 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.827096","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 46.0 in stage 10.0 (TID 73) (172.18.0.9, executor 1, partition 46, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.827409","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 41.0 in stage 10.0 (TID 71) in 29 ms on 172.18.0.9 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.840787","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_46 in memory on 172.18.0.9:45247 (size: 306.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.847515","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 74) (172.18.0.9, executor 1, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.847812","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 46.0 in stage 10.0 (TID 73) in 21 ms on 172.18.0.9 (executor 1) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.860869","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_0 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.867305","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 75) (172.18.0.9, executor 1, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.867582","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 74) in 20 ms on 172.18.0.9 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.884640","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_1 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.892226","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 76) (172.18.0.9, executor 1, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.892715","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 75) in 26 ms on 172.18.0.9 (executor 1) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.906560","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_2 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.914155","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 77) (172.18.0.9, executor 1, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.914363","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 76) in 23 ms on 172.18.0.9 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.927448","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_42 in memory on 172.18.0.9:39097 (size: 562.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.928536","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_3 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.936190","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 78) (172.18.0.9, executor 1, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.936399","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 77) in 23 ms on 172.18.0.9 (executor 1) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.937009","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 79) (172.18.0.9, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.937153","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 42.0 in stage 10.0 (TID 72) in 115 ms on 172.18.0.9 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.949943","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_4 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.950326","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_5 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.956593","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 80) (172.18.0.9, executor 1, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.956805","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 78) in 21 ms on 172.18.0.9 (executor 1) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.957444","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 81) (172.18.0.9, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.957694","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 79) in 21 ms on 172.18.0.9 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.970855","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_6 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.976097","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_7 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.981156","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 82) (172.18.0.9, executor 1, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.981888","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 80) in 25 ms on 172.18.0.9 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.991941","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 83) (172.18.0.9, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.992151","level":"info","event":"25/07/30 17:04:19 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 81) in 34 ms on 172.18.0.9 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:19.996643","level":"info","event":"25/07/30 17:04:19 INFO BlockManagerInfo: Added rdd_35_8 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.004373","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 10.0 in stage 10.0 (TID 84) (172.18.0.9, executor 1, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.004658","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 82) in 24 ms on 172.18.0.9 (executor 1) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.013790","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_9 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.018170","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_10 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.022871","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 13.0 in stage 10.0 (TID 85) (172.18.0.9, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.023134","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 83) in 31 ms on 172.18.0.9 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.026139","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 14.0 in stage 10.0 (TID 86) (172.18.0.9, executor 1, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.026347","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 10.0 in stage 10.0 (TID 84) in 22 ms on 172.18.0.9 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.038861","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_13 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.038939","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_14 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.045627","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 15.0 in stage 10.0 (TID 87) (172.18.0.9, executor 1, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.045848","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 14.0 in stage 10.0 (TID 86) in 20 ms on 172.18.0.9 (executor 1) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.046297","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 18.0 in stage 10.0 (TID 88) (172.18.0.9, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.046658","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 13.0 in stage 10.0 (TID 85) in 24 ms on 172.18.0.9 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.059973","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_18 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.060713","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_15 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.067184","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 20.0 in stage 10.0 (TID 89) (172.18.0.9, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.067485","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 18.0 in stage 10.0 (TID 88) in 21 ms on 172.18.0.9 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.067846","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 21.0 in stage 10.0 (TID 90) (172.18.0.9, executor 1, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.068131","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 15.0 in stage 10.0 (TID 87) in 22 ms on 172.18.0.9 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.081149","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_20 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.081230","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_21 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.088125","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 23.0 in stage 10.0 (TID 91) (172.18.0.9, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.088227","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 20.0 in stage 10.0 (TID 89) in 22 ms on 172.18.0.9 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.088570","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 25.0 in stage 10.0 (TID 92) (172.18.0.9, executor 1, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.088734","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 21.0 in stage 10.0 (TID 90) in 21 ms on 172.18.0.9 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.101097","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_25 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.104984","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_23 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.108122","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 29.0 in stage 10.0 (TID 93) (172.18.0.9, executor 1, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.108463","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 25.0 in stage 10.0 (TID 92) in 20 ms on 172.18.0.9 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.113590","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 30.0 in stage 10.0 (TID 94) (172.18.0.9, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.113665","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 23.0 in stage 10.0 (TID 91) in 26 ms on 172.18.0.9 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.121747","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_29 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.127517","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 32.0 in stage 10.0 (TID 95) (172.18.0.9, executor 1, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.127783","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 29.0 in stage 10.0 (TID 93) in 20 ms on 172.18.0.9 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.128374","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_30 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.134960","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 33.0 in stage 10.0 (TID 96) (172.18.0.9, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.135139","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 30.0 in stage 10.0 (TID 94) in 22 ms on 172.18.0.9 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.140385","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_32 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.146710","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 34.0 in stage 10.0 (TID 97) (172.18.0.9, executor 1, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.146994","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 32.0 in stage 10.0 (TID 95) in 19 ms on 172.18.0.9 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.147227","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_33 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.154046","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 35.0 in stage 10.0 (TID 98) (172.18.0.9, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.154153","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 33.0 in stage 10.0 (TID 96) in 20 ms on 172.18.0.9 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.158701","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_34 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.164348","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 37.0 in stage 10.0 (TID 99) (172.18.0.9, executor 1, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.164649","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 34.0 in stage 10.0 (TID 97) in 18 ms on 172.18.0.9 (executor 1) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.166198","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_35 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.172456","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 38.0 in stage 10.0 (TID 100) (172.18.0.9, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.172630","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 35.0 in stage 10.0 (TID 98) in 19 ms on 172.18.0.9 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.176622","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_37 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.183691","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_38 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.183766","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 39.0 in stage 10.0 (TID 101) (172.18.0.9, executor 1, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.183917","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 37.0 in stage 10.0 (TID 99) in 19 ms on 172.18.0.9 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.190548","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 40.0 in stage 10.0 (TID 102) (172.18.0.9, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.190849","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 38.0 in stage 10.0 (TID 100) in 18 ms on 172.18.0.9 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.196521","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_39 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.202814","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 43.0 in stage 10.0 (TID 103) (172.18.0.9, executor 1, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.203195","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 39.0 in stage 10.0 (TID 101) in 19 ms on 172.18.0.9 (executor 1) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.203568","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_40 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.209784","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 44.0 in stage 10.0 (TID 104) (172.18.0.9, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.210019","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 40.0 in stage 10.0 (TID 102) in 19 ms on 172.18.0.9 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.214944","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_43 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.221785","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 45.0 in stage 10.0 (TID 105) (172.18.0.9, executor 1, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.222083","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 43.0 in stage 10.0 (TID 103) in 19 ms on 172.18.0.9 (executor 1) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.223542","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_44 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.233779","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 47.0 in stage 10.0 (TID 106) (172.18.0.9, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.234065","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 44.0 in stage 10.0 (TID 104) in 24 ms on 172.18.0.9 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.234924","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_45 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.242041","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 48.0 in stage 10.0 (TID 107) (172.18.0.9, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.242225","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 45.0 in stage 10.0 (TID 105) in 21 ms on 172.18.0.9 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.251903","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_47 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.256095","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_48 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.258447","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 49.0 in stage 10.0 (TID 108) (172.18.0.9, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.258612","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 47.0 in stage 10.0 (TID 106) in 25 ms on 172.18.0.9 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.262864","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 48.0 in stage 10.0 (TID 107) in 21 ms on 172.18.0.9 (executor 1) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.270316","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added rdd_35_49 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.276324","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 49.0 in stage 10.0 (TID 108) in 18 ms on 172.18.0.9 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.276400","level":"info","event":"25/07/30 17:04:20 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.276717","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: ShuffleMapStage 10 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.635 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.276782","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.276807","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.276827","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.276845","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.285293","level":"info","event":"25/07/30 17:04:20 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.286052","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Got job 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.286091","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Final stage: ResultStage 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.286115","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.286135","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.286256","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[41] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.290794","level":"info","event":"25/07/30 17:04:20 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 534.7 KiB, free 125.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.291255","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Removed broadcast_12_piece0 on efd5d439613e:44283 in memory (size: 138.1 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.291886","level":"info","event":"25/07/30 17:04:20 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 124.7 KiB, free 125.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.292128","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.9:39097 in memory (size: 138.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.292286","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.9:45247 in memory (size: 138.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.292323","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on efd5d439613e:44283 (size: 124.7 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.292706","level":"info","event":"25/07/30 17:04:20 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.292908","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[41] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.293076","level":"info","event":"25/07/30 17:04:20 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.293837","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 109) (172.18.0.9, executor 1, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.297936","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.9:45247 (size: 124.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.301724","level":"info","event":"25/07/30 17:04:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.9:45284","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.316023","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 109) in 22 ms on 172.18.0.9 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.316104","level":"info","event":"25/07/30 17:04:20 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.316318","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: ResultStage 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.030 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.316422","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.316458","level":"info","event":"25/07/30 17:04:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.316649","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Job 7 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.031309 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.320747","level":"info","event":"25/07/30 17:04:20 INFO Snapshot: [tableId=82ad5421-24ce-4d38-8164-c7ba05900532] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.407480","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Removed broadcast_13_piece0 on efd5d439613e:44283 in memory (size: 124.7 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.408411","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.9:45247 in memory (size: 124.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.425042","level":"info","event":"25/07/30 17:04:20 INFO CodeGenerator: Code generated in 34.134625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.432662","level":"info","event":"25/07/30 17:04:20 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.434138","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Got job 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.434206","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Final stage: ResultStage 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.434236","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.434779","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.434937","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[43] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.436898","level":"info","event":"25/07/30 17:04:20 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 684.9 KiB, free 125.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.438461","level":"info","event":"25/07/30 17:04:20 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 154.4 KiB, free 125.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.438650","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on efd5d439613e:44283 (size: 154.4 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.438903","level":"info","event":"25/07/30 17:04:20 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.439206","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 15 (MapPartitionsRDD[43] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.439248","level":"info","event":"25/07/30 17:04:20 INFO TaskSchedulerImpl: Adding task set 15.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.440487","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 110) (172.18.0.9, executor 1, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.440543","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 111) (172.18.0.9, executor 0, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.445454","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.9:45247 (size: 154.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.445545","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.9:39097 (size: 154.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.517224","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 112) (172.18.0.9, executor 1, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.517531","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 110) in 77 ms on 172.18.0.9 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.520128","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 113) (172.18.0.9, executor 0, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.520433","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 111) in 80 ms on 172.18.0.9 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.523425","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 114) (172.18.0.9, executor 1, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.523776","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 112) in 7 ms on 172.18.0.9 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.526262","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 115) (172.18.0.9, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.526639","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 113) in 7 ms on 172.18.0.9 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.529572","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 116) (172.18.0.9, executor 1, partition 3, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.529851","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 114) in 6 ms on 172.18.0.9 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.531873","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 12.0 in stage 15.0 (TID 117) (172.18.0.9, executor 0, partition 12, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.532254","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 115) in 7 ms on 172.18.0.9 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.535037","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 118) (172.18.0.9, executor 1, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.535371","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 116) in 6 ms on 172.18.0.9 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.538181","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 13.0 in stage 15.0 (TID 119) (172.18.0.9, executor 0, partition 13, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.538558","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 12.0 in stage 15.0 (TID 117) in 7 ms on 172.18.0.9 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.540838","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 120) (172.18.0.9, executor 1, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.541163","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 118) in 6 ms on 172.18.0.9 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.544535","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 17.0 in stage 15.0 (TID 121) (172.18.0.9, executor 0, partition 17, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.545259","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 13.0 in stage 15.0 (TID 119) in 8 ms on 172.18.0.9 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.546307","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 122) (172.18.0.9, executor 1, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.546608","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 120) in 6 ms on 172.18.0.9 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.551132","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 18.0 in stage 15.0 (TID 123) (172.18.0.9, executor 0, partition 18, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.551734","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 17.0 in stage 15.0 (TID 121) in 7 ms on 172.18.0.9 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.552179","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 124) (172.18.0.9, executor 1, partition 10, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.552494","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 122) in 6 ms on 172.18.0.9 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.556794","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 20.0 in stage 15.0 (TID 125) (172.18.0.9, executor 0, partition 20, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.557152","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 18.0 in stage 15.0 (TID 123) in 6 ms on 172.18.0.9 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.557806","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 11.0 in stage 15.0 (TID 126) (172.18.0.9, executor 1, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.558122","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 124) in 6 ms on 172.18.0.9 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.563230","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 14.0 in stage 15.0 (TID 127) (172.18.0.9, executor 1, partition 14, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.563547","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 11.0 in stage 15.0 (TID 126) in 6 ms on 172.18.0.9 (executor 1) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.564129","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 22.0 in stage 15.0 (TID 128) (172.18.0.9, executor 0, partition 22, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.564464","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 20.0 in stage 15.0 (TID 125) in 8 ms on 172.18.0.9 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.568687","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 15.0 in stage 15.0 (TID 129) (172.18.0.9, executor 1, partition 15, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.568907","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 14.0 in stage 15.0 (TID 127) in 6 ms on 172.18.0.9 (executor 1) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.569621","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 23.0 in stage 15.0 (TID 130) (172.18.0.9, executor 0, partition 23, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.569874","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 22.0 in stage 15.0 (TID 128) in 6 ms on 172.18.0.9 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.574218","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 16.0 in stage 15.0 (TID 131) (172.18.0.9, executor 1, partition 16, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.574460","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 15.0 in stage 15.0 (TID 129) in 6 ms on 172.18.0.9 (executor 1) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.574804","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 26.0 in stage 15.0 (TID 132) (172.18.0.9, executor 0, partition 26, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.575072","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 23.0 in stage 15.0 (TID 130) in 5 ms on 172.18.0.9 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.579805","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 19.0 in stage 15.0 (TID 133) (172.18.0.9, executor 1, partition 19, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.580120","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 28.0 in stage 15.0 (TID 134) (172.18.0.9, executor 0, partition 28, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.580302","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 16.0 in stage 15.0 (TID 131) in 7 ms on 172.18.0.9 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.580513","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 26.0 in stage 15.0 (TID 132) in 6 ms on 172.18.0.9 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.585467","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 21.0 in stage 15.0 (TID 135) (172.18.0.9, executor 1, partition 21, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.585768","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 19.0 in stage 15.0 (TID 133) in 6 ms on 172.18.0.9 (executor 1) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.590714","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 30.0 in stage 15.0 (TID 136) (172.18.0.9, executor 0, partition 30, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.591294","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 24.0 in stage 15.0 (TID 137) (172.18.0.9, executor 1, partition 24, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.591524","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 28.0 in stage 15.0 (TID 134) in 12 ms on 172.18.0.9 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.591810","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 21.0 in stage 15.0 (TID 135) in 6 ms on 172.18.0.9 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.598104","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 25.0 in stage 15.0 (TID 138) (172.18.0.9, executor 1, partition 25, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.598404","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 24.0 in stage 15.0 (TID 137) in 8 ms on 172.18.0.9 (executor 1) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.601592","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 33.0 in stage 15.0 (TID 139) (172.18.0.9, executor 0, partition 33, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.601807","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 30.0 in stage 15.0 (TID 136) in 11 ms on 172.18.0.9 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.605287","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 27.0 in stage 15.0 (TID 140) (172.18.0.9, executor 1, partition 27, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.605443","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 25.0 in stage 15.0 (TID 138) in 8 ms on 172.18.0.9 (executor 1) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.608737","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 35.0 in stage 15.0 (TID 141) (172.18.0.9, executor 0, partition 35, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.608817","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 33.0 in stage 15.0 (TID 139) in 7 ms on 172.18.0.9 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.613716","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 29.0 in stage 15.0 (TID 142) (172.18.0.9, executor 1, partition 29, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.614139","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 27.0 in stage 15.0 (TID 140) in 9 ms on 172.18.0.9 (executor 1) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.615230","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 36.0 in stage 15.0 (TID 143) (172.18.0.9, executor 0, partition 36, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.615450","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 35.0 in stage 15.0 (TID 141) in 7 ms on 172.18.0.9 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.619717","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 31.0 in stage 15.0 (TID 144) (172.18.0.9, executor 1, partition 31, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.620109","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 29.0 in stage 15.0 (TID 142) in 6 ms on 172.18.0.9 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.620534","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 38.0 in stage 15.0 (TID 145) (172.18.0.9, executor 0, partition 38, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.620799","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 36.0 in stage 15.0 (TID 143) in 5 ms on 172.18.0.9 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.625181","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 32.0 in stage 15.0 (TID 146) (172.18.0.9, executor 1, partition 32, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.625312","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 31.0 in stage 15.0 (TID 144) in 6 ms on 172.18.0.9 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.625720","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 40.0 in stage 15.0 (TID 147) (172.18.0.9, executor 0, partition 40, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.625915","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 38.0 in stage 15.0 (TID 145) in 5 ms on 172.18.0.9 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.630138","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 34.0 in stage 15.0 (TID 148) (172.18.0.9, executor 1, partition 34, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.630325","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 32.0 in stage 15.0 (TID 146) in 6 ms on 172.18.0.9 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.630791","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 42.0 in stage 15.0 (TID 149) (172.18.0.9, executor 0, partition 42, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.630835","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 40.0 in stage 15.0 (TID 147) in 5 ms on 172.18.0.9 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.636003","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 37.0 in stage 15.0 (TID 150) (172.18.0.9, executor 1, partition 37, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.636289","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 44.0 in stage 15.0 (TID 151) (172.18.0.9, executor 0, partition 44, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.636494","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 34.0 in stage 15.0 (TID 148) in 7 ms on 172.18.0.9 (executor 1) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.636730","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 42.0 in stage 15.0 (TID 149) in 6 ms on 172.18.0.9 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.641366","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 39.0 in stage 15.0 (TID 152) (172.18.0.9, executor 1, partition 39, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.641950","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 47.0 in stage 15.0 (TID 153) (172.18.0.9, executor 0, partition 47, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.642237","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 37.0 in stage 15.0 (TID 150) in 7 ms on 172.18.0.9 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.642423","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 44.0 in stage 15.0 (TID 151) in 6 ms on 172.18.0.9 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.647132","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 41.0 in stage 15.0 (TID 154) (172.18.0.9, executor 1, partition 41, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.647389","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 39.0 in stage 15.0 (TID 152) in 6 ms on 172.18.0.9 (executor 1) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.647767","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 49.0 in stage 15.0 (TID 155) (172.18.0.9, executor 0, partition 49, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.648013","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 47.0 in stage 15.0 (TID 153) in 6 ms on 172.18.0.9 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.652898","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 43.0 in stage 15.0 (TID 156) (172.18.0.9, executor 1, partition 43, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.653107","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 41.0 in stage 15.0 (TID 154) in 7 ms on 172.18.0.9 (executor 1) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.653658","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 49.0 in stage 15.0 (TID 155) in 6 ms on 172.18.0.9 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.658154","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 45.0 in stage 15.0 (TID 157) (172.18.0.9, executor 1, partition 45, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.658409","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 43.0 in stage 15.0 (TID 156) in 6 ms on 172.18.0.9 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.663175","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 46.0 in stage 15.0 (TID 158) (172.18.0.9, executor 1, partition 46, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.663412","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 45.0 in stage 15.0 (TID 157) in 6 ms on 172.18.0.9 (executor 1) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.668755","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 48.0 in stage 15.0 (TID 159) (172.18.0.9, executor 1, partition 48, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.669232","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 46.0 in stage 15.0 (TID 158) in 7 ms on 172.18.0.9 (executor 1) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.675199","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Finished task 48.0 in stage 15.0 (TID 159) in 6 ms on 172.18.0.9 (executor 1) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.675298","level":"info","event":"25/07/30 17:04:20 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.675493","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: ResultStage 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.240 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.675811","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.675870","level":"info","event":"25/07/30 17:04:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.675922","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Job 8 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.243137 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.684849","level":"info","event":"25/07/30 17:04:20 INFO CodeGenerator: Code generated in 5.811042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.685562","level":"info","event":"25/07/30 17:04:20 INFO PrepareDeltaScan: DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.691090","level":"info","event":"25/07/30 17:04:20 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.691162","level":"info","event":"25/07/30 17:04:20 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.722612","level":"info","event":"25/07/30 17:04:20 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.773932","level":"info","event":"25/07/30 17:04:20 INFO CodeGenerator: Code generated in 24.370458 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.776885","level":"info","event":"25/07/30 17:04:20 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 207.6 KiB, free 125.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.783788","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Removed broadcast_14_piece0 on efd5d439613e:44283 in memory (size: 154.4 KiB, free: 127.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.784087","level":"info","event":"25/07/30 17:04:20 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.784439","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on efd5d439613e:44283 (size: 37.1 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.784768","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.9:39097 in memory (size: 154.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.785043","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.9:45247 in memory (size: 154.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.785135","level":"info","event":"25/07/30 17:04:20 INFO SparkContext: Created broadcast 15 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.790066","level":"info","event":"25/07/30 17:04:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4214768 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.801922","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Registering RDD 47 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.802007","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Got map stage job 9 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.802035","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.806447","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.806528","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.806775","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[47] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.808122","level":"info","event":"25/07/30 17:04:20 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 44.9 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.808660","level":"info","event":"25/07/30 17:04:20 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 126.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.809007","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on efd5d439613e:44283 (size: 19.9 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.809283","level":"info","event":"25/07/30 17:04:20 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.809478","level":"info","event":"25/07/30 17:04:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[47] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.809519","level":"info","event":"25/07/30 17:04:20 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.810062","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 160) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 11172 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.810140","level":"info","event":"25/07/30 17:04:20 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 161) (172.18.0.9, executor 1, partition 1, PROCESS_LOCAL, 11172 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.815585","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.9:39097 (size: 19.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.815938","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.9:45247 (size: 19.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.914182","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.9:39097 (size: 37.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:20.922478","level":"info","event":"25/07/30 17:04:20 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.9:45247 (size: 37.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.196566","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 161) in 386 ms on 172.18.0.9 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.201188","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 160) in 391 ms on 172.18.0.9 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.201278","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.201539","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: ShuffleMapStage 16 (save at NativeMethodAccessorImpl.java:0) finished in 0.395 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.201579","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.201599","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.201621","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.201639","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.206695","level":"info","event":"25/07/30 17:04:21 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.214985","level":"info","event":"25/07/30 17:04:21 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.221537","level":"info","event":"25/07/30 17:04:21 INFO CodeGenerator: Code generated in 4.801875 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.251009","level":"info","event":"25/07/30 17:04:21 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.251515","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Got job 10 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.251577","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Final stage: ResultStage 18 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.251607","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.251628","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.251735","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[49] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.261115","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 362.4 KiB, free 125.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.264316","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 132.8 KiB, free 125.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.264366","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Removed broadcast_16_piece0 on efd5d439613e:44283 in memory (size: 19.9 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.264444","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on efd5d439613e:44283 (size: 132.8 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.264758","level":"info","event":"25/07/30 17:04:21 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.264897","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[49] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.264940","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.265390","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.9:39097 in memory (size: 19.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.265474","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.9:45247 in memory (size: 19.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.265629","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 162) (172.18.0.9, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.269638","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.9:39097 (size: 132.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.296848","level":"info","event":"25/07/30 17:04:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.9:45280","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.540737","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 162) in 275 ms on 172.18.0.9 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.540826","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.541109","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: ResultStage 18 (save at NativeMethodAccessorImpl.java:0) finished in 0.288 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.541174","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.541202","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.541695","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Job 10 finished: save at NativeMethodAccessorImpl.java:0, took 0.290633 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.542292","level":"info","event":"25/07/30 17:04:21 INFO DeltaFileFormatWriter: Start to commit write Job 403af5d4-475a-473e-8216-281fc12facf9.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.542755","level":"info","event":"25/07/30 17:04:21 INFO DeltaFileFormatWriter: Write Job 403af5d4-475a-473e-8216-281fc12facf9 committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.543811","level":"info","event":"25/07/30 17:04:21 INFO DeltaFileFormatWriter: Finished processing stats for write job 403af5d4-475a-473e-8216-281fc12facf9.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.595831","level":"info","event":"25/07/30 17:04:21 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.596327","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Got job 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.596373","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.596398","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.596741","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.596908","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[51] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.601113","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 684.9 KiB, free 124.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.601773","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Removed broadcast_17_piece0 on efd5d439613e:44283 in memory (size: 132.8 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.602604","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 154.4 KiB, free 125.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.602766","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on efd5d439613e:44283 (size: 154.4 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.602878","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.9:39097 in memory (size: 132.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.603048","level":"info","event":"25/07/30 17:04:21 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.603418","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 20 (MapPartitionsRDD[51] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.603465","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Adding task set 20.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.604172","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 163) (172.18.0.9, executor 1, partition 3, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.604231","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 164) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.609188","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.9:45247 (size: 154.4 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.609271","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.9:39097 (size: 154.4 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.614500","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 165) (172.18.0.9, executor 1, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.614738","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 163) in 11 ms on 172.18.0.9 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.615295","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 166) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.615515","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 164) in 11 ms on 172.18.0.9 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.622023","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 167) (172.18.0.9, executor 0, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.622333","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 166) in 7 ms on 172.18.0.9 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.624187","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 168) (172.18.0.9, executor 1, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.624544","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 165) in 10 ms on 172.18.0.9 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.628287","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 169) (172.18.0.9, executor 0, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.628649","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 167) in 7 ms on 172.18.0.9 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.629347","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 10.0 in stage 20.0 (TID 170) (172.18.0.9, executor 1, partition 10, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.629615","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 168) in 6 ms on 172.18.0.9 (executor 1) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.634228","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 12.0 in stage 20.0 (TID 171) (172.18.0.9, executor 1, partition 12, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.634314","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 10.0 in stage 20.0 (TID 170) in 5 ms on 172.18.0.9 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.634795","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 172) (172.18.0.9, executor 0, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.634833","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 169) in 7 ms on 172.18.0.9 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.639493","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 15.0 in stage 20.0 (TID 173) (172.18.0.9, executor 1, partition 15, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.639907","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 8.0 in stage 20.0 (TID 174) (172.18.0.9, executor 0, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.640015","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 12.0 in stage 20.0 (TID 171) in 6 ms on 172.18.0.9 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.640045","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 172) in 5 ms on 172.18.0.9 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.644344","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 17.0 in stage 20.0 (TID 175) (172.18.0.9, executor 1, partition 17, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.644545","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 15.0 in stage 20.0 (TID 173) in 5 ms on 172.18.0.9 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.645391","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 9.0 in stage 20.0 (TID 176) (172.18.0.9, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.645926","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 8.0 in stage 20.0 (TID 174) in 6 ms on 172.18.0.9 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.649150","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 19.0 in stage 20.0 (TID 177) (172.18.0.9, executor 1, partition 19, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.649273","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 17.0 in stage 20.0 (TID 175) in 5 ms on 172.18.0.9 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.650947","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 11.0 in stage 20.0 (TID 178) (172.18.0.9, executor 0, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.651238","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 9.0 in stage 20.0 (TID 176) in 6 ms on 172.18.0.9 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.653834","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 20.0 in stage 20.0 (TID 179) (172.18.0.9, executor 1, partition 20, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.654105","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 19.0 in stage 20.0 (TID 177) in 5 ms on 172.18.0.9 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.656480","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 13.0 in stage 20.0 (TID 180) (172.18.0.9, executor 0, partition 13, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.656631","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 11.0 in stage 20.0 (TID 178) in 6 ms on 172.18.0.9 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.658732","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 22.0 in stage 20.0 (TID 181) (172.18.0.9, executor 1, partition 22, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.659043","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 20.0 in stage 20.0 (TID 179) in 5 ms on 172.18.0.9 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.662113","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 14.0 in stage 20.0 (TID 182) (172.18.0.9, executor 0, partition 14, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.662353","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 13.0 in stage 20.0 (TID 180) in 6 ms on 172.18.0.9 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.663551","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 24.0 in stage 20.0 (TID 183) (172.18.0.9, executor 1, partition 24, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.663825","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 22.0 in stage 20.0 (TID 181) in 5 ms on 172.18.0.9 (executor 1) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.667926","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 16.0 in stage 20.0 (TID 184) (172.18.0.9, executor 0, partition 16, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.668093","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 14.0 in stage 20.0 (TID 182) in 6 ms on 172.18.0.9 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.668415","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 26.0 in stage 20.0 (TID 185) (172.18.0.9, executor 1, partition 26, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.668750","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 24.0 in stage 20.0 (TID 183) in 5 ms on 172.18.0.9 (executor 1) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.673254","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 28.0 in stage 20.0 (TID 186) (172.18.0.9, executor 1, partition 28, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.673514","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 26.0 in stage 20.0 (TID 185) in 5 ms on 172.18.0.9 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.673760","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 18.0 in stage 20.0 (TID 187) (172.18.0.9, executor 0, partition 18, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.673959","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 16.0 in stage 20.0 (TID 184) in 6 ms on 172.18.0.9 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.678154","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 30.0 in stage 20.0 (TID 188) (172.18.0.9, executor 1, partition 30, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.678357","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 28.0 in stage 20.0 (TID 186) in 6 ms on 172.18.0.9 (executor 1) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.679351","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 21.0 in stage 20.0 (TID 189) (172.18.0.9, executor 0, partition 21, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.679584","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 18.0 in stage 20.0 (TID 187) in 6 ms on 172.18.0.9 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.683058","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 33.0 in stage 20.0 (TID 190) (172.18.0.9, executor 1, partition 33, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.683224","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 30.0 in stage 20.0 (TID 188) in 6 ms on 172.18.0.9 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.684588","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 23.0 in stage 20.0 (TID 191) (172.18.0.9, executor 0, partition 23, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.684826","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 21.0 in stage 20.0 (TID 189) in 5 ms on 172.18.0.9 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.691829","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 36.0 in stage 20.0 (TID 192) (172.18.0.9, executor 1, partition 36, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.692060","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 33.0 in stage 20.0 (TID 190) in 9 ms on 172.18.0.9 (executor 1) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.693241","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 25.0 in stage 20.0 (TID 193) (172.18.0.9, executor 0, partition 25, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.693410","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 23.0 in stage 20.0 (TID 191) in 9 ms on 172.18.0.9 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.696986","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 37.0 in stage 20.0 (TID 194) (172.18.0.9, executor 1, partition 37, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.697061","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 36.0 in stage 20.0 (TID 192) in 6 ms on 172.18.0.9 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.698591","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 27.0 in stage 20.0 (TID 195) (172.18.0.9, executor 0, partition 27, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.698852","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 25.0 in stage 20.0 (TID 193) in 5 ms on 172.18.0.9 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.701409","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 40.0 in stage 20.0 (TID 196) (172.18.0.9, executor 1, partition 40, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.701596","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 37.0 in stage 20.0 (TID 194) in 5 ms on 172.18.0.9 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.703388","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 29.0 in stage 20.0 (TID 197) (172.18.0.9, executor 0, partition 29, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.703534","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 27.0 in stage 20.0 (TID 195) in 5 ms on 172.18.0.9 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.706026","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 41.0 in stage 20.0 (TID 198) (172.18.0.9, executor 1, partition 41, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.706907","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 40.0 in stage 20.0 (TID 196) in 5 ms on 172.18.0.9 (executor 1) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.712150","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 42.0 in stage 20.0 (TID 199) (172.18.0.9, executor 1, partition 42, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.712855","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 31.0 in stage 20.0 (TID 200) (172.18.0.9, executor 0, partition 31, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.712933","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 41.0 in stage 20.0 (TID 198) in 7 ms on 172.18.0.9 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.713319","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 29.0 in stage 20.0 (TID 197) in 10 ms on 172.18.0.9 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.717976","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 45.0 in stage 20.0 (TID 201) (172.18.0.9, executor 1, partition 45, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.718259","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 42.0 in stage 20.0 (TID 199) in 7 ms on 172.18.0.9 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.719740","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 32.0 in stage 20.0 (TID 202) (172.18.0.9, executor 0, partition 32, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.719853","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 31.0 in stage 20.0 (TID 200) in 7 ms on 172.18.0.9 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.724042","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 47.0 in stage 20.0 (TID 203) (172.18.0.9, executor 1, partition 47, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.724402","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 45.0 in stage 20.0 (TID 201) in 7 ms on 172.18.0.9 (executor 1) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.729214","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 34.0 in stage 20.0 (TID 204) (172.18.0.9, executor 0, partition 34, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.729795","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 32.0 in stage 20.0 (TID 202) in 10 ms on 172.18.0.9 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.729944","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 48.0 in stage 20.0 (TID 205) (172.18.0.9, executor 1, partition 48, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.730209","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 47.0 in stage 20.0 (TID 203) in 7 ms on 172.18.0.9 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.735268","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 35.0 in stage 20.0 (TID 206) (172.18.0.9, executor 0, partition 35, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.735347","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 48.0 in stage 20.0 (TID 205) in 6 ms on 172.18.0.9 (executor 1) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.735505","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 34.0 in stage 20.0 (TID 204) in 7 ms on 172.18.0.9 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.740243","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 38.0 in stage 20.0 (TID 207) (172.18.0.9, executor 0, partition 38, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.740472","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 35.0 in stage 20.0 (TID 206) in 6 ms on 172.18.0.9 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.745244","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 39.0 in stage 20.0 (TID 208) (172.18.0.9, executor 0, partition 39, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.745410","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 38.0 in stage 20.0 (TID 207) in 6 ms on 172.18.0.9 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.749742","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 43.0 in stage 20.0 (TID 209) (172.18.0.9, executor 0, partition 43, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.749895","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 39.0 in stage 20.0 (TID 208) in 5 ms on 172.18.0.9 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.754467","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 44.0 in stage 20.0 (TID 210) (172.18.0.9, executor 0, partition 44, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.754791","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 43.0 in stage 20.0 (TID 209) in 5 ms on 172.18.0.9 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.759229","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 46.0 in stage 20.0 (TID 211) (172.18.0.9, executor 0, partition 46, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.759472","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 44.0 in stage 20.0 (TID 210) in 5 ms on 172.18.0.9 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.763402","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 49.0 in stage 20.0 (TID 212) (172.18.0.9, executor 0, partition 49, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.763607","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 46.0 in stage 20.0 (TID 211) in 4 ms on 172.18.0.9 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.767890","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 49.0 in stage 20.0 (TID 212) in 4 ms on 172.18.0.9 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.767928","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.768143","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: ResultStage 20 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.170 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.768192","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.768214","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.768410","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Job 11 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.172547 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.783869","level":"info","event":"25/07/30 17:04:21 INFO OptimisticTransaction: [tableId=5e0965ee,txnId=87663aa4] Attempting to commit version 5 with 3 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.907450","level":"info","event":"25/07/30 17:04:21 INFO DeltaLog: Creating a new snapshot v5 for commit version 5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.907536","level":"info","event":"25/07/30 17:04:21 INFO DeltaLog: Loading version 5.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.909524","level":"info","event":"25/07/30 17:04:21 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 6, totalFileSize: 6507)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.918915","level":"info","event":"25/07/30 17:04:21 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.919002","level":"info","event":"25/07/30 17:04:21 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.919029","level":"info","event":"25/07/30 17:04:21 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#1029.minReaderVersion) OR isnotnull(metaData#1028.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.923576","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 206.2 KiB, free 125.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.928799","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Removed broadcast_18_piece0 on efd5d439613e:44283 in memory (size: 154.4 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.929810","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.9:39097 in memory (size: 154.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.929866","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 125.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.929890","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.9:45247 in memory (size: 154.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.930178","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on efd5d439613e:44283 (size: 36.5 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.930725","level":"info","event":"25/07/30 17:04:21 INFO SparkContext: Created broadcast 19 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.931302","level":"info","event":"25/07/30 17:04:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12586165 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.939196","level":"info","event":"25/07/30 17:04:21 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.939655","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Got job 12 (toString at String.java:4220) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.939718","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Final stage: ResultStage 21 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.939745","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.939767","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.939907","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[55] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.940702","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 40.0 KiB, free 125.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.941090","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 125.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.941325","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on efd5d439613e:44283 (size: 13.7 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.941519","level":"info","event":"25/07/30 17:04:21 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.941623","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (MapPartitionsRDD[55] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.941649","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.942045","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 213) (172.18.0.9, executor 1, partition 0, PROCESS_LOCAL, 11478 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.942143","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 214) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 11478 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.946400","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.9:45247 (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.946462","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.9:39097 (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.951747","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.9:39097 (size: 36.5 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.951908","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.9:45247 (size: 36.5 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.972096","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 214) in 29 ms on 172.18.0.9 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.973185","level":"info","event":"25/07/30 17:04:21 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 213) in 32 ms on 172.18.0.9 (executor 1) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.973262","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.973342","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: ResultStage 21 (toString at String.java:4220) finished in 0.033 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.973374","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.973396","level":"info","event":"25/07/30 17:04:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.973544","level":"info","event":"25/07/30 17:04:21 INFO DAGScheduler: Job 12 finished: toString at String.java:4220, took 0.034372 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.975849","level":"info","event":"25/07/30 17:04:21 INFO Snapshot: [tableId=5e0965ee-836d-4153-95e5-24b2f62e3e7b] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=5, metadata=Metadata(5e0965ee-836d-4153-95e5-24b2f62e3e7b,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753890888679)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,5,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000000.json; isDirectory=false; length=1336; replication=1; blocksize=33554432; modification_time=1753890894354; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=396660e452df253d28809dd2168f10ee versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000001.json; isDirectory=false; length=1031; replication=1; blocksize=33554432; modification_time=1753891405629; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=9bb9e7db76ba50333757bf408d995e7a versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000002.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753891588051; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f4b4023744c578233c087d624d151164 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000003.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753893439999; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=4c774b9b2c7c96fb1bc206ca12d2a8f2 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000004.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753893537255; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=967f1877c6bd879e96f9277a58e11f25 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000005.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753895061889; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=79999279b3331414753ac670d0371421 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@7048f78c,1753895061889), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.976374","level":"info","event":"25/07/30 17:04:21 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/gold/_delta_log, version=5, metadata=Metadata(5e0965ee-836d-4153-95e5-24b2f62e3e7b,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"article_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid_title_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753890888679)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/gold/_delta_log,5,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000000.json; isDirectory=false; length=1336; replication=1; blocksize=33554432; modification_time=1753890894354; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=396660e452df253d28809dd2168f10ee versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000001.json; isDirectory=false; length=1031; replication=1; blocksize=33554432; modification_time=1753891405629; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=9bb9e7db76ba50333757bf408d995e7a versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000002.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753891588051; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f4b4023744c578233c087d624d151164 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000003.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753893439999; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=4c774b9b2c7c96fb1bc206ca12d2a8f2 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000004.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753893537255; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=967f1877c6bd879e96f9277a58e11f25 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/gold/_delta_log/00000000000000000005.json; isDirectory=false; length=1035; replication=1; blocksize=33554432; modification_time=1753895061889; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=79999279b3331414753ac670d0371421 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@7048f78c,1753895061889), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.976638","level":"info","event":"25/07/30 17:04:21 INFO MapPartitionsRDD: Removing RDD 18 from persistence list","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.979578","level":"info","event":"25/07/30 17:04:21 INFO BlockManager: Removing RDD 18","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.983281","level":"info","event":"25/07/30 17:04:21 INFO Snapshot: [tableId=5e0965ee-836d-4153-95e5-24b2f62e3e7b] DELTA: Compute snapshot for version: 5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.984399","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 205.9 KiB, free 125.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.987168","level":"info","event":"25/07/30 17:04:21 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 125.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.987538","level":"info","event":"25/07/30 17:04:21 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on efd5d439613e:44283 (size: 36.5 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:21.987846","level":"info","event":"25/07/30 17:04:21 INFO SparkContext: Created broadcast 21 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.032705","level":"info","event":"25/07/30 17:04:22 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.032794","level":"info","event":"25/07/30 17:04:22 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.032819","level":"info","event":"25/07/30 17:04:22 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.043877","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_20_piece0 on efd5d439613e:44283 in memory (size: 13.7 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.045076","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.9:45247 in memory (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.045155","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.9:39097 in memory (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.047774","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_19_piece0 on efd5d439613e:44283 in memory (size: 36.5 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.048521","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.9:39097 in memory (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.048597","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.9:45247 in memory (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.051133","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 206.2 KiB, free 125.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.054423","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 125.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.054552","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on efd5d439613e:44283 (size: 36.5 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.055021","level":"info","event":"25/07/30 17:04:22 INFO SparkContext: Created broadcast 22 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.055385","level":"info","event":"25/07/30 17:04:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12586165 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.057707","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Registering RDD 59 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.057763","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Got map stage job 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.057785","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Final stage: ShuffleMapStage 22 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.057803","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.057823","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.057941","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[59] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.058917","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 105.6 KiB, free 125.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.059284","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 125.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.059565","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on efd5d439613e:44283 (size: 32.6 KiB, free: 126.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.059776","level":"info","event":"25/07/30 17:04:22 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.059882","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[59] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.059916","level":"info","event":"25/07/30 17:04:22 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.060325","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 215) (172.18.0.9, executor 1, partition 0, PROCESS_LOCAL, 11467 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.060400","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 216) (172.18.0.9, executor 0, partition 1, PROCESS_LOCAL, 11467 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.064233","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.9:39097 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.064291","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.9:45247 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.072372","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.9:45247 (size: 36.5 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.073979","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.9:39097 (size: 36.5 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.099109","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 215) in 38 ms on 172.18.0.9 (executor 1) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.099413","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 216) in 39 ms on 172.18.0.9 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.099461","level":"info","event":"25/07/30 17:04:22 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.099758","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: ShuffleMapStage 22 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.041 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.099795","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.099816","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.099835","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.099852","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.118928","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_23_piece0 on efd5d439613e:44283 in memory (size: 32.6 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.119933","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.9:45247 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.119997","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.9:39097 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.161068","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Registering RDD 69 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.161159","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Got map stage job 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.161188","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Final stage: ShuffleMapStage 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.161211","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.161363","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.161451","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[69] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.166742","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 603.4 KiB, free 125.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.167717","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 124.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.167874","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on efd5d439613e:44283 (size: 138.2 KiB, free: 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.168133","level":"info","event":"25/07/30 17:04:22 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.168403","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[69] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.168446","level":"info","event":"25/07/30 17:04:22 INFO TaskSchedulerImpl: Adding task set 24.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.169110","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 4.0 in stage 24.0 (TID 217) (172.18.0.9, executor 0, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.169164","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 9.0 in stage 24.0 (TID 218) (172.18.0.9, executor 1, partition 9, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.174697","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.9:45247 (size: 138.2 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.174946","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.9:39097 (size: 138.2 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.180292","level":"info","event":"25/07/30 17:04:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.9:45280","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.180387","level":"info","event":"25/07/30 17:04:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.9:45284","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.190107","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_9 in memory on 172.18.0.9:45247 (size: 306.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.192094","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_4 in memory on 172.18.0.9:39097 (size: 306.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.197293","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 14.0 in stage 24.0 (TID 219) (172.18.0.9, executor 1, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.197546","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 9.0 in stage 24.0 (TID 218) in 28 ms on 172.18.0.9 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.198393","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 19.0 in stage 24.0 (TID 220) (172.18.0.9, executor 0, partition 19, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.198725","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 4.0 in stage 24.0 (TID 217) in 30 ms on 172.18.0.9 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.210134","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_14 in memory on 172.18.0.9:45247 (size: 449.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.215327","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_19 in memory on 172.18.0.9:39097 (size: 306.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.215967","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 31.0 in stage 24.0 (TID 221) (172.18.0.9, executor 1, partition 31, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.216227","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 14.0 in stage 24.0 (TID 219) in 20 ms on 172.18.0.9 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.222805","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 35.0 in stage 24.0 (TID 222) (172.18.0.9, executor 0, partition 35, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.223040","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 19.0 in stage 24.0 (TID 220) in 24 ms on 172.18.0.9 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.232443","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_31 in memory on 172.18.0.9:45247 (size: 306.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.238852","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 42.0 in stage 24.0 (TID 223) (172.18.0.9, executor 1, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.239008","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 31.0 in stage 24.0 (TID 221) in 23 ms on 172.18.0.9 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.241883","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_35 in memory on 172.18.0.9:39097 (size: 306.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.248877","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 224) (172.18.0.9, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.249128","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 35.0 in stage 24.0 (TID 222) in 26 ms on 172.18.0.9 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.252200","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_42 in memory on 172.18.0.9:45247 (size: 487.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.260651","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_0 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.261122","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 225) (172.18.0.9, executor 1, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.261277","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 42.0 in stage 24.0 (TID 223) in 23 ms on 172.18.0.9 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.266277","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 226) (172.18.0.9, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.266613","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 224) in 18 ms on 172.18.0.9 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.272813","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_1 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.279038","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_2 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.279322","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 227) (172.18.0.9, executor 1, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.279616","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 225) in 19 ms on 172.18.0.9 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.286065","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 5.0 in stage 24.0 (TID 228) (172.18.0.9, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.286283","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 226) in 20 ms on 172.18.0.9 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.292142","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_3 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.297893","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_5 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.298059","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 6.0 in stage 24.0 (TID 229) (172.18.0.9, executor 1, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.298284","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 227) in 19 ms on 172.18.0.9 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.304223","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 7.0 in stage 24.0 (TID 230) (172.18.0.9, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.304596","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 5.0 in stage 24.0 (TID 228) in 19 ms on 172.18.0.9 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.310198","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_6 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.316689","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 8.0 in stage 24.0 (TID 231) (172.18.0.9, executor 1, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.316999","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 6.0 in stage 24.0 (TID 229) in 19 ms on 172.18.0.9 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.317748","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_7 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.327041","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 10.0 in stage 24.0 (TID 232) (172.18.0.9, executor 0, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.327195","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 7.0 in stage 24.0 (TID 230) in 24 ms on 172.18.0.9 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.329800","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_8 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.337860","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 11.0 in stage 24.0 (TID 233) (172.18.0.9, executor 1, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.338085","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 8.0 in stage 24.0 (TID 231) in 21 ms on 172.18.0.9 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.343573","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_10 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.349407","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 12.0 in stage 24.0 (TID 234) (172.18.0.9, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.349514","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 10.0 in stage 24.0 (TID 232) in 23 ms on 172.18.0.9 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.350276","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_11 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.355950","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 13.0 in stage 24.0 (TID 235) (172.18.0.9, executor 1, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.356155","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 11.0 in stage 24.0 (TID 233) in 19 ms on 172.18.0.9 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.360629","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_12 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.365917","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 15.0 in stage 24.0 (TID 236) (172.18.0.9, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.366094","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 12.0 in stage 24.0 (TID 234) in 16 ms on 172.18.0.9 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.367828","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_13 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.373904","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 16.0 in stage 24.0 (TID 237) (172.18.0.9, executor 1, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.374247","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 13.0 in stage 24.0 (TID 235) in 18 ms on 172.18.0.9 (executor 1) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.379111","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_15 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.399526","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 17.0 in stage 24.0 (TID 238) (172.18.0.9, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.412364","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 15.0 in stage 24.0 (TID 236) in 34 ms on 172.18.0.9 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.412470","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_16 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.426954","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 18.0 in stage 24.0 (TID 239) (172.18.0.9, executor 1, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.427407","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 16.0 in stage 24.0 (TID 237) in 54 ms on 172.18.0.9 (executor 1) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.430887","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_17 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.437541","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 20.0 in stage 24.0 (TID 240) (172.18.0.9, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.437723","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 17.0 in stage 24.0 (TID 238) in 41 ms on 172.18.0.9 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.440158","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_18 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.446511","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 21.0 in stage 24.0 (TID 241) (172.18.0.9, executor 1, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.446632","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 18.0 in stage 24.0 (TID 239) in 20 ms on 172.18.0.9 (executor 1) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.449646","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_20 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.458865","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 22.0 in stage 24.0 (TID 242) (172.18.0.9, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.458969","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_21 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.458997","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 20.0 in stage 24.0 (TID 240) in 21 ms on 172.18.0.9 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.465722","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 23.0 in stage 24.0 (TID 243) (172.18.0.9, executor 1, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.465810","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 21.0 in stage 24.0 (TID 241) in 19 ms on 172.18.0.9 (executor 1) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.474681","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_22 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.477644","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_23 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.484909","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 24.0 in stage 24.0 (TID 244) (172.18.0.9, executor 1, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.485133","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 25.0 in stage 24.0 (TID 245) (172.18.0.9, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.485528","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 23.0 in stage 24.0 (TID 243) in 20 ms on 172.18.0.9 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.486249","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 22.0 in stage 24.0 (TID 242) in 27 ms on 172.18.0.9 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.505458","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_24 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.509030","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_25 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.513022","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 26.0 in stage 24.0 (TID 246) (172.18.0.9, executor 1, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.513540","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 24.0 in stage 24.0 (TID 244) in 29 ms on 172.18.0.9 (executor 1) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.522665","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 27.0 in stage 24.0 (TID 247) (172.18.0.9, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.523052","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 25.0 in stage 24.0 (TID 245) in 38 ms on 172.18.0.9 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.526551","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_26 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.532831","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 28.0 in stage 24.0 (TID 248) (172.18.0.9, executor 1, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.533196","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 26.0 in stage 24.0 (TID 246) in 21 ms on 172.18.0.9 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.542547","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_27 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.548058","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_28 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.550510","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 29.0 in stage 24.0 (TID 249) (172.18.0.9, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.550893","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 27.0 in stage 24.0 (TID 247) in 28 ms on 172.18.0.9 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.555198","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 30.0 in stage 24.0 (TID 250) (172.18.0.9, executor 1, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.555481","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 28.0 in stage 24.0 (TID 248) in 23 ms on 172.18.0.9 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.568801","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_30 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.569314","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_29 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.577557","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 32.0 in stage 24.0 (TID 251) (172.18.0.9, executor 1, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.578087","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 30.0 in stage 24.0 (TID 250) in 23 ms on 172.18.0.9 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.578476","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 33.0 in stage 24.0 (TID 252) (172.18.0.9, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.578698","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 29.0 in stage 24.0 (TID 249) in 28 ms on 172.18.0.9 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.592624","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_32 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.599875","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 34.0 in stage 24.0 (TID 253) (172.18.0.9, executor 1, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.600197","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 32.0 in stage 24.0 (TID 251) in 23 ms on 172.18.0.9 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.603737","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_33 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.613839","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_34 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.613918","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 36.0 in stage 24.0 (TID 254) (172.18.0.9, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.614309","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 33.0 in stage 24.0 (TID 252) in 36 ms on 172.18.0.9 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.620310","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 37.0 in stage 24.0 (TID 255) (172.18.0.9, executor 1, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.620394","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 34.0 in stage 24.0 (TID 253) in 21 ms on 172.18.0.9 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.633297","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_37 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.633432","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_36 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.639292","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 38.0 in stage 24.0 (TID 256) (172.18.0.9, executor 1, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.639430","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 37.0 in stage 24.0 (TID 255) in 19 ms on 172.18.0.9 (executor 1) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.639768","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 39.0 in stage 24.0 (TID 257) (172.18.0.9, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.639982","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 36.0 in stage 24.0 (TID 254) in 26 ms on 172.18.0.9 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.651873","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_39 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.652158","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_38 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.658197","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 40.0 in stage 24.0 (TID 258) (172.18.0.9, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.658336","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 39.0 in stage 24.0 (TID 257) in 19 ms on 172.18.0.9 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.658765","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 41.0 in stage 24.0 (TID 259) (172.18.0.9, executor 1, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.658839","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 38.0 in stage 24.0 (TID 256) in 19 ms on 172.18.0.9 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.670617","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_40 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.671100","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_41 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.677686","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 43.0 in stage 24.0 (TID 260) (172.18.0.9, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.677846","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 44.0 in stage 24.0 (TID 261) (172.18.0.9, executor 1, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.679334","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 40.0 in stage 24.0 (TID 258) in 21 ms on 172.18.0.9 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.679422","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 41.0 in stage 24.0 (TID 259) in 21 ms on 172.18.0.9 (executor 1) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.692268","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_43 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.692359","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_44 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.697811","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 45.0 in stage 24.0 (TID 262) (172.18.0.9, executor 1, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.697913","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 44.0 in stage 24.0 (TID 261) in 20 ms on 172.18.0.9 (executor 1) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.698252","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 46.0 in stage 24.0 (TID 263) (172.18.0.9, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.698776","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 43.0 in stage 24.0 (TID 260) in 22 ms on 172.18.0.9 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.710810","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_45 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.711182","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_46 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.717760","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 47.0 in stage 24.0 (TID 264) (172.18.0.9, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.717847","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 46.0 in stage 24.0 (TID 263) in 19 ms on 172.18.0.9 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.723542","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 48.0 in stage 24.0 (TID 265) (172.18.0.9, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.723751","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 45.0 in stage 24.0 (TID 262) in 26 ms on 172.18.0.9 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.731258","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_47 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.736761","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_48 in memory on 172.18.0.9:45247 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.738392","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 49.0 in stage 24.0 (TID 266) (172.18.0.9, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.738838","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 47.0 in stage 24.0 (TID 264) in 21 ms on 172.18.0.9 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.751490","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 48.0 in stage 24.0 (TID 265) in 28 ms on 172.18.0.9 (executor 1) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.754574","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added rdd_66_49 in memory on 172.18.0.9:39097 (size: 46.0 B, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.762055","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 49.0 in stage 24.0 (TID 266) in 23 ms on 172.18.0.9 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.762149","level":"info","event":"25/07/30 17:04:22 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.762428","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: ShuffleMapStage 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.600 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.762511","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.762800","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.762971","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.763056","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.777307","level":"info","event":"25/07/30 17:04:22 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.777925","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Got job 15 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.777984","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Final stage: ResultStage 27 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.778027","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.778070","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.778096","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[72] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.778568","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_24_piece0 on efd5d439613e:44283 in memory (size: 138.2 KiB, free: 127.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.779783","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.9:39097 in memory (size: 138.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.779862","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.9:45247 in memory (size: 138.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.780492","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 534.8 KiB, free 125.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.781745","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 124.7 KiB, free 124.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.781894","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on efd5d439613e:44283 (size: 124.7 KiB, free: 126.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.782259","level":"info","event":"25/07/30 17:04:22 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.782597","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[72] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.782650","level":"info","event":"25/07/30 17:04:22 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.783265","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 267) (172.18.0.9, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.787103","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.9:39097 (size: 124.7 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.790761","level":"info","event":"25/07/30 17:04:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.18.0.9:45280","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.812936","level":"info","event":"25/07/30 17:04:22 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 267) in 29 ms on 172.18.0.9 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.813021","level":"info","event":"25/07/30 17:04:22 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.813175","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: ResultStage 27 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.035 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.813322","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.813378","level":"info","event":"25/07/30 17:04:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.813406","level":"info","event":"25/07/30 17:04:22 INFO DAGScheduler: Job 15 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.036156 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.817133","level":"info","event":"25/07/30 17:04:22 INFO Snapshot: [tableId=5e0965ee-836d-4153-95e5-24b2f62e3e7b] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.831333","level":"info","event":"25/07/30 17:04:22 INFO OptimisticTransaction: [tableId=5e0965ee,txnId=87663aa4] Committed delta #5 to s3a://activefence-bucket/bbc_tech/gold/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.833019","level":"info","event":"INFO:__main__:Gold layer processing complete","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.833294","level":"info","event":"25/07/30 17:04:22 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.840072","level":"info","event":"25/07/30 17:04:22 INFO SparkUI: Stopped Spark web UI at http://efd5d439613e:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.841330","level":"info","event":"25/07/30 17:04:22 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.841450","level":"info","event":"25/07/30 17:04:22 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.851989","level":"info","event":"25/07/30 17:04:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.872285","level":"info","event":"25/07/30 17:04:22 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.872372","level":"info","event":"25/07/30 17:04:22 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.875224","level":"info","event":"25/07/30 17:04:22 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.876714","level":"info","event":"25/07/30 17:04:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:22.889465","level":"info","event":"25/07/30 17:04:22 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.037268","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.037729","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.092861","level":"info","event":"25/07/30 17:04:23 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.093016","level":"info","event":"25/07/30 17:04:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-d4b86421-18cf-4913-a68b-2e2b984acef9","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.094776","level":"info","event":"25/07/30 17:04:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc/pyspark-71e1c26b-f8e5-4613-9f86-d46ae8bc659e","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.096043","level":"info","event":"25/07/30 17:04:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-5bcda71b-e9fa-4dcb-9b9f-604da8172cdc","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.099112","level":"info","event":"25/07/30 17:04:23 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.099176","level":"info","event":"25/07/30 17:04:23 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-30T17:04:23.099205","level":"info","event":"25/07/30 17:04:23 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
