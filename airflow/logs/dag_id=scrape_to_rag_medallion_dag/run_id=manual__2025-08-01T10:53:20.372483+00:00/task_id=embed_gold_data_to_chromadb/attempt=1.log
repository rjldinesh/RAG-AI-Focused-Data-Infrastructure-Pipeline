{"timestamp":"2025-08-01T10:54:35.306608","level":"warning","event":"\n        OpenLineage support for Airflow version 3.0.2 is REMOVED.\n        For Airflow 2.7 and later, use the native Airflow Openlineage provider package.\n        Documentation can be found at https://airflow.apache.org/docs/apache-airflow-providers-openlineage\n        ","logger":"root"}
{"timestamp":"2025-08-01T10:54:35.503387","level":"warning","event":"No module named 'airflow.providers.dbt'","logger":"openlineage.airflow.utils"}
{"timestamp":"2025-08-01T10:54:35.507809","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-01T10:54:35.508076","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-01T10:54:36.478170","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-01T10:54:36.478994","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=4g --conf spark.driver.memory=2g --conf spark.executor.cores=2 --conf spark.executorEnv.AWS_ACCESS_KEY_ID=ZPnglo5gVhmWx1iC0FdY --conf spark.executorEnv.AWS_SECRET_ACCESS_KEY=****** --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 4g --driver-memory 2g --name embed_gold_data_job --verbose --deploy-mode client /opt/spark-jobs/embed_gold_data.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.367819","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420666","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420754","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420787","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420807","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420827","level":"info","event":"executorMemory          4g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420845","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420862","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420880","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420898","level":"info","event":"driverMemory            2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420916","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420940","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420958","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.420981","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421006","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421023","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421039","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421091","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421113","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421130","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421147","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421163","level":"info","event":"primaryResource         file:/opt/spark-jobs/embed_gold_data.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421179","level":"info","event":"name                    embed_gold_data_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421199","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421216","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421233","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421268","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421286","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421302","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421320","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421337","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421354","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421371","level":"info","event":"(spark.driver.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421402","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421422","level":"info","event":"(spark.executor.memory,4g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421439","level":"info","event":"(spark.executorEnv.AWS_ACCESS_KEY_ID,ZPnglo5gVhmWx1iC0FdY)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421456","level":"info","event":"(spark.executorEnv.AWS_SECRET_ACCESS_KEY,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421486","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421511","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421528","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421545","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421562","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421594","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421615","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421632","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.421649","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.491014","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.530872","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.530968","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.533115","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.533185","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.533209","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.533228","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.533504","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-973f0868-6e15-4fdf-8090-a05b0b33fcf4;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.533528","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.627342","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.642845","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.650945","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.668149","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.678351","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.688378","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.697784","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.705140","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.731896","level":"info","event":":: resolution report :: resolve 181ms :: artifacts dl 17ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.731982","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732009","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732033","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732070","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732089","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732108","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732126","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732143","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732160","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732178","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732197","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732217","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732262","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732286","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732303","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732322","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.732339","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.735133","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-973f0868-6e15-4fdf-8090-a05b0b33fcf4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.735206","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.738388","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/3ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.835007","level":"info","event":"25/08/01 10:54:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.919304","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.919382","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.919425","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.919450","level":"info","event":"file:/opt/spark-jobs/embed_gold_data.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.919470","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920546","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920613","level":"info","event":"(spark.app.name,embed_gold_data_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920640","level":"info","event":"(spark.app.submitTime,1754045677912)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920660","level":"info","event":"(spark.driver.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920678","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920697","level":"info","event":"(spark.executor.memory,4g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920714","level":"info","event":"(spark.executorEnv.AWS_ACCESS_KEY_ID,ZPnglo5gVhmWx1iC0FdY)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920732","level":"info","event":"(spark.executorEnv.AWS_SECRET_ACCESS_KEY,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920765","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920790","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920807","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920824","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920841","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920858","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920876","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920893","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920911","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920929","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.920967","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921002","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921054","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921076","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921094","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921111","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921127","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921145","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921163","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921179","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921196","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921214","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:37.921231","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.295518","level":"info","event":"INFO:embed_gold_data:Starting embeddingGoldData job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.354769","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.354860","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.354932","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.364445","level":"info","event":"25/08/01 10:54:40 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.364530","level":"info","event":"25/08/01 10:54:40 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.364594","level":"info","event":"25/08/01 10:54:40 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.364719","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.372891","level":"info","event":"25/08/01 10:54:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.376141","level":"info","event":"25/08/01 10:54:40 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.376650","level":"info","event":"25/08/01 10:54:40 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.401667","level":"info","event":"25/08/01 10:54:40 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.401749","level":"info","event":"25/08/01 10:54:40 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.401948","level":"info","event":"25/08/01 10:54:40 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.402005","level":"info","event":"25/08/01 10:54:40 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.402066","level":"info","event":"25/08/01 10:54:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.499588","level":"info","event":"25/08/01 10:54:40 INFO Utils: Successfully started service 'sparkDriver' on port 40421.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.520191","level":"info","event":"25/08/01 10:54:40 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.534090","level":"info","event":"25/08/01 10:54:40 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.541501","level":"info","event":"25/08/01 10:54:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.541617","level":"info","event":"25/08/01 10:54:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.543306","level":"info","event":"25/08/01 10:54:40 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.552688","level":"info","event":"25/08/01 10:54:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4960be6d-49b5-4d6d-bd59-8e485bf82ad8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.558130","level":"info","event":"25/08/01 10:54:40 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.565203","level":"info","event":"25/08/01 10:54:40 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.618923","level":"info","event":"25/08/01 10:54:40 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.642877","level":"info","event":"25/08/01 10:54:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.646236","level":"info","event":"25/08/01 10:54:40 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.661378","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://0baa42e17007:40421/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.661457","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://0baa42e17007:40421/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.661562","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://0baa42e17007:40421/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.661639","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://0baa42e17007:40421/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.661731","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://0baa42e17007:40421/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.661879","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://0baa42e17007:40421/jars/org.tukaani_xz-1.9.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.661955","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://0baa42e17007:40421/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.661988","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://0baa42e17007:40421/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.662965","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://0baa42e17007:40421/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.663309","level":"info","event":"25/08/01 10:54:40 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-30970fe0-4f9f-4517-8408-05dbb4d66789/userFiles-d71c7df4-a456-4c35-a9a6-ed3e9274fc43/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.669414","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://0baa42e17007:40421/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.669491","level":"info","event":"25/08/01 10:54:40 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-30970fe0-4f9f-4517-8408-05dbb4d66789/userFiles-d71c7df4-a456-4c35-a9a6-ed3e9274fc43/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.860834","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://0baa42e17007:40421/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.860950","level":"info","event":"25/08/01 10:54:40 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-30970fe0-4f9f-4517-8408-05dbb4d66789/userFiles-d71c7df4-a456-4c35-a9a6-ed3e9274fc43/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.863180","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://0baa42e17007:40421/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.863252","level":"info","event":"25/08/01 10:54:40 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-30970fe0-4f9f-4517-8408-05dbb4d66789/userFiles-d71c7df4-a456-4c35-a9a6-ed3e9274fc43/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.869761","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://0baa42e17007:40421/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.869853","level":"info","event":"25/08/01 10:54:40 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-30970fe0-4f9f-4517-8408-05dbb4d66789/userFiles-d71c7df4-a456-4c35-a9a6-ed3e9274fc43/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.871998","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://0baa42e17007:40421/files/org.tukaani_xz-1.9.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.872069","level":"info","event":"25/08/01 10:54:40 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-30970fe0-4f9f-4517-8408-05dbb4d66789/userFiles-d71c7df4-a456-4c35-a9a6-ed3e9274fc43/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.874005","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://0baa42e17007:40421/files/io.delta_delta-storage-3.1.0.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.874145","level":"info","event":"25/08/01 10:54:40 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-30970fe0-4f9f-4517-8408-05dbb4d66789/userFiles-d71c7df4-a456-4c35-a9a6-ed3e9274fc43/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.875836","level":"info","event":"25/08/01 10:54:40 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://0baa42e17007:40421/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754045680351","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.875881","level":"info","event":"25/08/01 10:54:40 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-30970fe0-4f9f-4517-8408-05dbb4d66789/userFiles-d71c7df4-a456-4c35-a9a6-ed3e9274fc43/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.912138","level":"info","event":"25/08/01 10:54:40 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.930670","level":"info","event":"25/08/01 10:54:40 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.5:7077 after 10 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.972038","level":"info","event":"25/08/01 10:54:40 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250801105440-0002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.975527","level":"info","event":"25/08/01 10:54:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41851.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.975580","level":"info","event":"25/08/01 10:54:40 INFO NettyBlockTransferService: Server created on 0baa42e17007:41851","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.976306","level":"info","event":"25/08/01 10:54:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.978779","level":"info","event":"25/08/01 10:54:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 0baa42e17007, 41851, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.979966","level":"info","event":"25/08/01 10:54:40 INFO BlockManagerMasterEndpoint: Registering block manager 0baa42e17007:41851 with 1048.8 MiB RAM, BlockManagerId(driver, 0baa42e17007, 41851, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.980811","level":"info","event":"25/08/01 10:54:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 0baa42e17007, 41851, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:40.981356","level":"info","event":"25/08/01 10:54:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 0baa42e17007, 41851, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:41.062375","level":"info","event":"25/08/01 10:54:41 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:41.162763","level":"info","event":"INFO:embed_gold_data:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:41.162840","level":"info","event":"INFO:embed_gold_data:SparkSession created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:41.165835","level":"info","event":"25/08/01 10:54:41 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:41.166841","level":"info","event":"25/08/01 10:54:41 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:41.789374","level":"info","event":"25/08/01 10:54:41 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:41.794440","level":"info","event":"25/08/01 10:54:41 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:41.794523","level":"info","event":"25/08/01 10:54:41 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:42.227981","level":"info","event":"25/08/01 10:54:42 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:42.497694","level":"info","event":"25/08/01 10:54:42 INFO DeltaLog: Loading version 22 starting from checkpoint version 20.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.161065","level":"info","event":"25/08/01 10:54:43 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 21629)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.161181","level":"info","event":"25/08/01 10:54:43 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 21629)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.377275","level":"info","event":"25/08/01 10:54:43 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 2, totalFileSize: 4828)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.644455","level":"info","event":"25/08/01 10:54:43 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.649986","level":"info","event":"25/08/01 10:54:43 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.653736","level":"info","event":"25/08/01 10:54:43 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(checkpointMetadata.version),IsNotNull(sidecar.path))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.653807","level":"info","event":"25/08/01 10:54:43 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(protocol.minReaderVersion),IsNotNull(metaData.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.654945","level":"info","event":"25/08/01 10:54:43 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#15.minReaderVersion) OR isnotnull(metaData#11.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.655002","level":"info","event":"25/08/01 10:54:43 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(checkpointMetadata#19.version) OR isnotnull(sidecar#20.path))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.664387","level":"info","event":"25/08/01 10:54:43 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.664661","level":"info","event":"25/08/01 10:54:43 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.664780","level":"info","event":"25/08/01 10:54:43 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#47.minReaderVersion) OR isnotnull(metaData#46.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.929900","level":"info","event":"25/08/01 10:54:43 INFO CodeGenerator: Code generated in 143.327584 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.945115","level":"info","event":"25/08/01 10:54:43 INFO CodeGenerator: Code generated in 158.693167 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.979912","level":"info","event":"25/08/01 10:54:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 210.8 KiB, free 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:43.980074","level":"info","event":"25/08/01 10:54:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.3 KiB, free 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.025035","level":"info","event":"25/08/01 10:54:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.025145","level":"info","event":"25/08/01 10:54:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.026484","level":"info","event":"25/08/01 10:54:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 0baa42e17007:41851 (size: 37.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.027888","level":"info","event":"25/08/01 10:54:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 0baa42e17007:41851 (size: 37.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.028595","level":"info","event":"25/08/01 10:54:44 INFO SparkContext: Created broadcast 0 from $anonfun$submit$1 at FutureTask.java:264","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.028645","level":"info","event":"25/08/01 10:54:44 INFO SparkContext: Created broadcast 1 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.042165","level":"info","event":"25/08/01 10:54:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.042253","level":"info","event":"25/08/01 10:54:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.117855","level":"info","event":"25/08/01 10:54:44 INFO CodeGenerator: Code generated in 31.6625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.120935","level":"info","event":"25/08/01 10:54:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 206.7 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.125206","level":"info","event":"25/08/01 10:54:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.125641","level":"info","event":"25/08/01 10:54:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 0baa42e17007:41851 (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.126159","level":"info","event":"25/08/01 10:54:44 INFO SparkContext: Created broadcast 2 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.133725","level":"info","event":"25/08/01 10:54:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4196718 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.135038","level":"info","event":"25/08/01 10:54:44 INFO SparkContext: Starting job: $anonfun$submit$1 at FutureTask.java:264","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.141990","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Got job 0 ($anonfun$submit$1 at FutureTask.java:264) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.142087","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Final stage: ResultStage 0 ($anonfun$submit$1 at FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.142317","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.142773","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.144149","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at $anonfun$submit$1 at FutureTask.java:264), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.152808","level":"info","event":"25/08/01 10:54:44 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 25.8 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.153605","level":"info","event":"25/08/01 10:54:44 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 1048.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.153942","level":"info","event":"25/08/01 10:54:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 0baa42e17007:41851 (size: 8.8 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.154336","level":"info","event":"25/08/01 10:54:44 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.162172","level":"info","event":"25/08/01 10:54:44 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.164003","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at $anonfun$submit$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.164467","level":"info","event":"25/08/01 10:54:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.169970","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Got job 1 (toString at String.java:4220) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.170062","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Final stage: ResultStage 1 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.170089","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.170132","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.170422","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.173791","level":"info","event":"25/08/01 10:54:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 85.9 KiB, free 1048.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.174564","level":"info","event":"25/08/01 10:54:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 1047.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.174860","level":"info","event":"25/08/01 10:54:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 0baa42e17007:41851 (size: 25.0 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.175215","level":"info","event":"25/08/01 10:54:44 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.175506","level":"info","event":"25/08/01 10:54:44 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:44.175555","level":"info","event":"25/08/01 10:54:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:54:59.171525","level":"info","event":"25/08/01 10:54:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:55:14.173735","level":"info","event":"25/08/01 10:55:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:55:29.171231","level":"info","event":"25/08/01 10:55:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:55:44.177852","level":"info","event":"25/08/01 10:55:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:55:59.176945","level":"info","event":"25/08/01 10:55:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:56:14.174186","level":"info","event":"25/08/01 10:56:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:56:29.172558","level":"info","event":"25/08/01 10:56:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:56:44.173328","level":"info","event":"25/08/01 10:56:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:56:59.176899","level":"info","event":"25/08/01 10:56:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:57:14.175369","level":"info","event":"25/08/01 10:57:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:57:29.172216","level":"info","event":"25/08/01 10:57:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:57:44.172244","level":"info","event":"25/08/01 10:57:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:57:59.176908","level":"info","event":"25/08/01 10:57:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:58:14.172747","level":"info","event":"25/08/01 10:58:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:58:29.179946","level":"info","event":"25/08/01 10:58:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:58:44.177053","level":"info","event":"25/08/01 10:58:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:58:59.179321","level":"info","event":"25/08/01 10:58:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:59:14.178125","level":"info","event":"25/08/01 10:59:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:59:29.177195","level":"info","event":"25/08/01 10:59:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:59:44.185026","level":"info","event":"25/08/01 10:59:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T10:59:59.179430","level":"info","event":"25/08/01 10:59:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:00:14.173697","level":"info","event":"25/08/01 11:00:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:00:29.178757","level":"info","event":"25/08/01 11:00:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:00:44.178948","level":"info","event":"25/08/01 11:00:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:00:59.174131","level":"info","event":"25/08/01 11:00:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:01:14.179448","level":"info","event":"25/08/01 11:01:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:01:29.177395","level":"info","event":"25/08/01 11:01:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:01:44.174315","level":"info","event":"25/08/01 11:01:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:01:59.175384","level":"info","event":"25/08/01 11:01:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:02:14.173221","level":"info","event":"25/08/01 11:02:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:02:29.179875","level":"info","event":"25/08/01 11:02:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:02:44.195380","level":"info","event":"25/08/01 11:02:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:02:59.174265","level":"info","event":"25/08/01 11:02:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:03:14.178070","level":"info","event":"25/08/01 11:03:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:03:29.176114","level":"info","event":"25/08/01 11:03:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:03:44.175463","level":"info","event":"25/08/01 11:03:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:03:59.181162","level":"info","event":"25/08/01 11:03:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:04:12.653409","level":"info","event":"25/08/01 11:04:12 WARN StandaloneAppClient$ClientEndpoint: Connection to 7a0b1630728b:7077 failed; waiting for master to reconnect...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:04:12.653974","level":"info","event":"25/08/01 11:04:12 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnection...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:04:14.174118","level":"info","event":"25/08/01 11:04:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:04:29.179846","level":"info","event":"25/08/01 11:04:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:04:44.174221","level":"info","event":"25/08/01 11:04:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:04:59.170801","level":"info","event":"25/08/01 11:04:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:05:14.182891","level":"info","event":"25/08/01 11:05:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:05:29.174233","level":"info","event":"25/08/01 11:05:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:05:44.170890","level":"info","event":"25/08/01 11:05:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:05:59.250267","level":"info","event":"25/08/01 11:05:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:06:14.173855","level":"info","event":"25/08/01 11:06:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:06:29.186876","level":"info","event":"25/08/01 11:06:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:06:44.176678","level":"info","event":"25/08/01 11:06:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:06:59.181908","level":"info","event":"25/08/01 11:06:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:07:14.171646","level":"info","event":"25/08/01 11:07:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:07:29.175734","level":"info","event":"25/08/01 11:07:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:07:44.171179","level":"info","event":"25/08/01 11:07:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:07:59.186781","level":"info","event":"25/08/01 11:07:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:08:14.174661","level":"info","event":"25/08/01 11:08:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:08:29.174846","level":"info","event":"25/08/01 11:08:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:08:44.170649","level":"info","event":"25/08/01 11:08:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:08:59.174571","level":"info","event":"25/08/01 11:08:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:09:14.172217","level":"info","event":"25/08/01 11:09:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:09:29.180400","level":"info","event":"25/08/01 11:09:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:09:44.171695","level":"info","event":"25/08/01 11:09:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:09:59.176211","level":"info","event":"25/08/01 11:09:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:10:14.171717","level":"info","event":"25/08/01 11:10:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:10:29.171658","level":"info","event":"25/08/01 11:10:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:10:44.172176","level":"info","event":"25/08/01 11:10:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:10:59.172204","level":"info","event":"25/08/01 11:10:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:11:14.172389","level":"info","event":"25/08/01 11:11:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:11:29.171258","level":"info","event":"25/08/01 11:11:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:11:44.170464","level":"info","event":"25/08/01 11:11:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:11:59.171810","level":"info","event":"25/08/01 11:11:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:12:14.171197","level":"info","event":"25/08/01 11:12:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:12:29.174166","level":"info","event":"25/08/01 11:12:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:12:44.170012","level":"info","event":"25/08/01 11:12:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:12:59.171961","level":"info","event":"25/08/01 11:12:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:13:14.171834","level":"info","event":"25/08/01 11:13:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:13:29.172793","level":"info","event":"25/08/01 11:13:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:13:44.170482","level":"info","event":"25/08/01 11:13:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:13:59.171098","level":"info","event":"25/08/01 11:13:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:14:14.171239","level":"info","event":"25/08/01 11:14:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:14:29.171710","level":"info","event":"25/08/01 11:14:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T11:14:39.200700Z","level":"error","event":"Server indicated the task shouldn't be running anymore. Terminating process","detail":{"detail":{"reason":"not_running","message":"TI is no longer in the running state and task should terminate","current_state":"failed"}},"logger":"task"}
{"timestamp":"2025-08-01T11:14:39.212685Z","level":"error","event":"Task killed!","logger":"task"}
