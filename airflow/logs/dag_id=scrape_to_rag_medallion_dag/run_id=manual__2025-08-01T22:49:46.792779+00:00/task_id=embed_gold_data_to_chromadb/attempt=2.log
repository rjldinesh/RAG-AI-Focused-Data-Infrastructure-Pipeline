{"timestamp":"2025-08-01T23:18:43.813962","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-01T23:18:43.814400","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-01T23:18:44.476093","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-01T23:18:44.476811","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=4g --conf spark.driver.memory=2g --conf spark.executor.cores=1 --conf spark.executorEnv.AWS_ACCESS_KEY_ID=ZPnglo5gVhmWx1iC0FdY --conf spark.executorEnv.AWS_SECRET_ACCESS_KEY=****** --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 1 --executor-memory 4g --driver-memory 2g --name embed_gold_data_job --verbose --deploy-mode client /opt/spark-jobs/embed_gold_data.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.193000","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234751","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234829","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234855","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234893","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234911","level":"info","event":"executorMemory          4g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234929","level":"info","event":"executorCores           1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234946","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234966","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.234986","level":"info","event":"driverMemory            2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235003","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235020","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235038","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235056","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235073","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235091","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235108","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235125","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235142","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235159","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235176","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235211","level":"info","event":"primaryResource         file:/opt/spark-jobs/embed_gold_data.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235230","level":"info","event":"name                    embed_gold_data_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235249","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235266","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235283","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235321","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235338","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235355","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235373","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235392","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235408","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235425","level":"info","event":"(spark.driver.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235441","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235482","level":"info","event":"(spark.executor.memory,4g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235500","level":"info","event":"(spark.executorEnv.AWS_ACCESS_KEY_ID,ZPnglo5gVhmWx1iC0FdY)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235516","level":"info","event":"(spark.executorEnv.AWS_SECRET_ACCESS_KEY,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235533","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235550","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235567","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235584","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235602","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235618","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235635","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235653","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.235669","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.308297","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.346392","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.346484","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.348559","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.348626","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.348652","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.348683","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.349046","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-348a78dd-552d-4c0a-9274-cfc83140a5e6;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.349075","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.431405","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.443112","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.449463","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.463899","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.471564","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.478748","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.485103","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.490541","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508094","level":"info","event":":: resolution report :: resolve 151ms :: artifacts dl 8ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508153","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508180","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508218","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508238","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508257","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508276","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508295","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508314","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508333","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508351","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508488","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508513","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508531","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508549","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508565","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508584","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.508599","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.511419","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-348a78dd-552d-4c0a-9274-cfc83140a5e6","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.511477","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.514943","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/3ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.617371","level":"info","event":"25/08/01 23:18:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.704045","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.704121","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.704152","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.704172","level":"info","event":"file:/opt/spark-jobs/embed_gold_data.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.704211","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705334","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705396","level":"info","event":"(spark.app.name,embed_gold_data_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705425","level":"info","event":"(spark.app.submitTime,1754090325696)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705445","level":"info","event":"(spark.driver.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705465","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705481","level":"info","event":"(spark.executor.memory,4g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705499","level":"info","event":"(spark.executorEnv.AWS_ACCESS_KEY_ID,ZPnglo5gVhmWx1iC0FdY)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705514","level":"info","event":"(spark.executorEnv.AWS_SECRET_ACCESS_KEY,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705532","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705553","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705570","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705587","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705604","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705620","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705636","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705653","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705671","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705688","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705716","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705737","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705760","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705778","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705795","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705824","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705845","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705862","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705879","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705896","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705912","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705929","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:45.705947","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.221017","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.221137","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.221337","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.230642","level":"info","event":"25/08/01 23:18:48 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.230830","level":"info","event":"25/08/01 23:18:48 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.230992","level":"info","event":"25/08/01 23:18:48 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.231153","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.241247","level":"info","event":"25/08/01 23:18:48 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.244826","level":"info","event":"25/08/01 23:18:48 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.245745","level":"info","event":"25/08/01 23:18:48 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.272345","level":"info","event":"25/08/01 23:18:48 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.272430","level":"info","event":"25/08/01 23:18:48 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.272578","level":"info","event":"25/08/01 23:18:48 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.272658","level":"info","event":"25/08/01 23:18:48 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.272795","level":"info","event":"25/08/01 23:18:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.378825","level":"info","event":"25/08/01 23:18:48 INFO Utils: Successfully started service 'sparkDriver' on port 34015.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.401405","level":"info","event":"25/08/01 23:18:48 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.417052","level":"info","event":"25/08/01 23:18:48 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.425485","level":"info","event":"25/08/01 23:18:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.425626","level":"info","event":"25/08/01 23:18:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.427890","level":"info","event":"25/08/01 23:18:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.439581","level":"info","event":"25/08/01 23:18:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-749503c7-13a4-4a59-b9df-d2f51af39d94","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.445401","level":"info","event":"25/08/01 23:18:48 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.452855","level":"info","event":"25/08/01 23:18:48 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.511959","level":"info","event":"25/08/01 23:18:48 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.541474","level":"info","event":"25/08/01 23:18:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.557480","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://79dc9458c784:34015/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.557566","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://79dc9458c784:34015/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.557658","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://79dc9458c784:34015/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.557704","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://79dc9458c784:34015/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.557794","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://79dc9458c784:34015/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.557863","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://79dc9458c784:34015/jars/org.tukaani_xz-1.9.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.557964","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://79dc9458c784:34015/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.558067","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://79dc9458c784:34015/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.559217","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://79dc9458c784:34015/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.559535","level":"info","event":"25/08/01 23:18:48 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/userFiles-436fc663-869a-43d4-b944-3ebd92828a28/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.570413","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://79dc9458c784:34015/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.570496","level":"info","event":"25/08/01 23:18:48 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/userFiles-436fc663-869a-43d4-b944-3ebd92828a28/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.913122","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://79dc9458c784:34015/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.913317","level":"info","event":"25/08/01 23:18:48 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/userFiles-436fc663-869a-43d4-b944-3ebd92828a28/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.916521","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://79dc9458c784:34015/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.916597","level":"info","event":"25/08/01 23:18:48 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/userFiles-436fc663-869a-43d4-b944-3ebd92828a28/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.956135","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://79dc9458c784:34015/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.956213","level":"info","event":"25/08/01 23:18:48 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/userFiles-436fc663-869a-43d4-b944-3ebd92828a28/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.959404","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://79dc9458c784:34015/files/org.tukaani_xz-1.9.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.959493","level":"info","event":"25/08/01 23:18:48 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/userFiles-436fc663-869a-43d4-b944-3ebd92828a28/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.961532","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://79dc9458c784:34015/files/io.delta_delta-storage-3.1.0.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.961640","level":"info","event":"25/08/01 23:18:48 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/userFiles-436fc663-869a-43d4-b944-3ebd92828a28/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.964521","level":"info","event":"25/08/01 23:18:48 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://79dc9458c784:34015/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754090328217","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:48.964611","level":"info","event":"25/08/01 23:18:48 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/userFiles-436fc663-869a-43d4-b944-3ebd92828a28/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.018685","level":"info","event":"25/08/01 23:18:49 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.145661","level":"info","event":"25/08/01 23:18:49 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.3:7077 after 104 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.222292","level":"info","event":"25/08/01 23:18:49 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250801231849-0012","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.223302","level":"info","event":"25/08/01 23:18:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801231849-0012/0 on worker-20250801224752-172.18.0.8-40823 (172.18.0.8:40823) with 1 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.224817","level":"info","event":"25/08/01 23:18:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801231849-0012/0 on hostPort 172.18.0.8:40823 with 1 core(s), 4.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.229917","level":"info","event":"25/08/01 23:18:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46547.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.230043","level":"info","event":"25/08/01 23:18:49 INFO NettyBlockTransferService: Server created on 79dc9458c784:46547","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.231737","level":"info","event":"25/08/01 23:18:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.236453","level":"info","event":"25/08/01 23:18:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 79dc9458c784, 46547, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.240653","level":"info","event":"25/08/01 23:18:49 INFO BlockManagerMasterEndpoint: Registering block manager 79dc9458c784:46547 with 1048.8 MiB RAM, BlockManagerId(driver, 79dc9458c784, 46547, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.242400","level":"info","event":"25/08/01 23:18:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 79dc9458c784, 46547, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.243299","level":"info","event":"25/08/01 23:18:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 79dc9458c784, 46547, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.270952","level":"info","event":"25/08/01 23:18:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801231849-0012/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.367442","level":"info","event":"25/08/01 23:18:49 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.505051","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.509376","level":"info","event":"25/08/01 23:18:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:49.511052","level":"info","event":"25/08/01 23:18:49 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:50.234733","level":"info","event":"25/08/01 23:18:50 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:50.240644","level":"info","event":"25/08/01 23:18:50 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:50.240750","level":"info","event":"25/08/01 23:18:50 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:50.715365","level":"info","event":"25/08/01 23:18:50 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:50.747399","level":"info","event":"25/08/01 23:18:50 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:58558) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:50.755495","level":"info","event":"25/08/01 23:18:50 INFO DeltaLog: Loading version 2.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:50.780433","level":"info","event":"25/08/01 23:18:50 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:36419 with 2.2 GiB RAM, BlockManagerId(0, 172.18.0.8, 36419, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:51.921746","level":"info","event":"25/08/01 23:18:51 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 3, totalFileSize: 6591)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.624875","level":"info","event":"25/08/01 23:18:52 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.629458","level":"info","event":"25/08/01 23:18:52 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.630185","level":"info","event":"25/08/01 23:18:52 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#11.minReaderVersion) OR isnotnull(metaData#10.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.904697","level":"info","event":"25/08/01 23:18:52 INFO CodeGenerator: Code generated in 135.886792 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.942418","level":"info","event":"25/08/01 23:18:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 206.7 KiB, free 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.975513","level":"info","event":"25/08/01 23:18:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.976986","level":"info","event":"25/08/01 23:18:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 79dc9458c784:46547 (size: 36.5 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.980012","level":"info","event":"25/08/01 23:18:52 INFO SparkContext: Created broadcast 0 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:52.990715","level":"info","event":"25/08/01 23:18:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6294751 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.071638","level":"info","event":"25/08/01 23:18:53 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.077566","level":"info","event":"25/08/01 23:18:53 INFO DAGScheduler: Got job 0 (toString at String.java:4220) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.077648","level":"info","event":"25/08/01 23:18:53 INFO DAGScheduler: Final stage: ResultStage 0 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.077814","level":"info","event":"25/08/01 23:18:53 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.078151","level":"info","event":"25/08/01 23:18:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.079182","level":"info","event":"25/08/01 23:18:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.088437","level":"info","event":"25/08/01 23:18:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.0 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.092026","level":"info","event":"25/08/01 23:18:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.092437","level":"info","event":"25/08/01 23:18:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 79dc9458c784:46547 (size: 13.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.092748","level":"info","event":"25/08/01 23:18:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.104447","level":"info","event":"25/08/01 23:18:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.105226","level":"info","event":"25/08/01 23:18:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.117489","level":"info","event":"25/08/01 23:18:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11325 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.227133","level":"info","event":"25/08/01 23:18:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:36419 (size: 13.7 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:53.673062","level":"info","event":"25/08/01 23:18:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:36419 (size: 36.5 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.254065","level":"info","event":"25/08/01 23:18:54 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11166 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.265759","level":"info","event":"25/08/01 23:18:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1152 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.301828","level":"info","event":"25/08/01 23:18:54 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 48 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.302141","level":"info","event":"25/08/01 23:18:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.302662","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: ResultStage 0 (toString at String.java:4220) finished in 1.217 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.303795","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.304057","level":"info","event":"25/08/01 23:18:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.305000","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Job 0 finished: toString at String.java:4220, took 1.233216 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.347767","level":"info","event":"25/08/01 23:18:54 INFO CodeGenerator: Code generated in 28.281958 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.351551","level":"info","event":"25/08/01 23:18:54 INFO Snapshot: [tableId=9173655c-9374-49df-8440-0e9de9ea3c06] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=2, metadata=Metadata(1b014827-4f87-4f8e-bdcc-3507acd78253,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754088656543)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,2,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1754088658874; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=036b95c45cbf80b1498a17c0bbeae3da versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000001.json; isDirectory=false; length=2196; replication=1; blocksize=33554432; modification_time=1754088957296; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=dd5e6f66387212f5c50af5d91cc79501 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000002.json; isDirectory=false; length=2400; replication=1; blocksize=33554432; modification_time=1754089588578; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=6ab74396909aaec6118a4229c8797dcd versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@375d234e,1754089588578), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.473573","level":"info","event":"25/08/01 23:18:54 INFO PrepareDeltaScan: DELTA: Filtering files for query","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.482167","level":"info","event":"25/08/01 23:18:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 206.1 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.489642","level":"info","event":"25/08/01 23:18:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.495752","level":"info","event":"25/08/01 23:18:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 79dc9458c784:46547 (size: 36.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.496509","level":"info","event":"25/08/01 23:18:54 INFO SparkContext: Created broadcast 2 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.502766","level":"info","event":"25/08/01 23:18:54 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 79dc9458c784:46547 in memory (size: 13.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.504031","level":"info","event":"25/08/01 23:18:54 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:36419 in memory (size: 13.7 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.773183","level":"info","event":"25/08/01 23:18:54 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.773375","level":"info","event":"25/08/01 23:18:54 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.773413","level":"info","event":"25/08/01 23:18:54 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.797601","level":"info","event":"25/08/01 23:18:54 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.882307","level":"info","event":"25/08/01 23:18:54 INFO CodeGenerator: Code generated in 48.545 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.884006","level":"info","event":"25/08/01 23:18:54 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 206.7 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.889574","level":"info","event":"25/08/01 23:18:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 1048.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.889910","level":"info","event":"25/08/01 23:18:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 79dc9458c784:46547 (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.890584","level":"info","event":"25/08/01 23:18:54 INFO SparkContext: Created broadcast 3 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.891276","level":"info","event":"25/08/01 23:18:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6294751 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.903316","level":"info","event":"25/08/01 23:18:54 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 79dc9458c784:46547 in memory (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.904942","level":"info","event":"25/08/01 23:18:54 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.8:36419 in memory (size: 36.5 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.925815","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Registering RDD 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.927760","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Got map stage job 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.928025","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Final stage: ShuffleMapStage 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.928257","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.928469","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.928884","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.937516","level":"info","event":"25/08/01 23:18:54 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 105.6 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.938160","level":"info","event":"25/08/01 23:18:54 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 1048.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.938512","level":"info","event":"25/08/01 23:18:54 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 79dc9458c784:46547 (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.938800","level":"info","event":"25/08/01 23:18:54 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.939427","level":"info","event":"25/08/01 23:18:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.939467","level":"info","event":"25/08/01 23:18:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.940478","level":"info","event":"25/08/01 23:18:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11314 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:54.951207","level":"info","event":"25/08/01 23:18:54 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:36419 (size: 32.6 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.167883","level":"info","event":"25/08/01 23:18:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:36419 (size: 36.5 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.662741","level":"info","event":"25/08/01 23:18:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11155 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.664082","level":"info","event":"25/08/01 23:18:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 724 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.694146","level":"info","event":"25/08/01 23:18:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 31 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.694257","level":"info","event":"25/08/01 23:18:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.694594","level":"info","event":"25/08/01 23:18:55 INFO DAGScheduler: ShuffleMapStage 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.764 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.695004","level":"info","event":"25/08/01 23:18:55 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.695276","level":"info","event":"25/08/01 23:18:55 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.695492","level":"info","event":"25/08/01 23:18:55 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.695825","level":"info","event":"25/08/01 23:18:55 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.738079","level":"info","event":"25/08/01 23:18:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 79dc9458c784:46547 in memory (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.740516","level":"info","event":"25/08/01 23:18:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:36419 in memory (size: 32.6 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.858130","level":"info","event":"25/08/01 23:18:55 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.858285","level":"info","event":"25/08/01 23:18:55 INFO CodeGenerator: Code generated in 105.08 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:55.897716","level":"info","event":"25/08/01 23:18:55 INFO CodeGenerator: Code generated in 28.344792 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.114341","level":"info","event":"25/08/01 23:18:56 INFO CodeGenerator: Code generated in 58.935542 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.180869","level":"info","event":"25/08/01 23:18:56 INFO CodeGenerator: Code generated in 8.493916 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.205606","level":"info","event":"25/08/01 23:18:56 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.206777","level":"info","event":"25/08/01 23:18:56 INFO DAGScheduler: Got job 2 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.206839","level":"info","event":"25/08/01 23:18:56 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.206869","level":"info","event":"25/08/01 23:18:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.208165","level":"info","event":"25/08/01 23:18:56 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.208507","level":"info","event":"25/08/01 23:18:56 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.218379","level":"info","event":"25/08/01 23:18:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 712.6 KiB, free 1047.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.219822","level":"info","event":"25/08/01 23:18:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 162.6 KiB, free 1047.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.220165","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 79dc9458c784:46547 (size: 162.6 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.220510","level":"info","event":"25/08/01 23:18:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.220832","level":"info","event":"25/08/01 23:18:56 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.220892","level":"info","event":"25/08/01 23:18:56 INFO TaskSchedulerImpl: Adding task set 3.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.223256","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 4) (172.18.0.8, executor 0, partition 3, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.232922","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:36419 (size: 162.6 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.340623","level":"info","event":"25/08/01 23:18:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:58558","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.664321","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added rdd_14_3 in memory on 172.18.0.8:36419 (size: 307.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.721861","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added rdd_18_3 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.731667","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 5) (172.18.0.8, executor 0, partition 12, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.732237","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 4) in 510 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.763363","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added rdd_14_12 in memory on 172.18.0.8:36419 (size: 691.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.788324","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added rdd_18_12 in memory on 172.18.0.8:36419 (size: 585.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.791956","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 6) (172.18.0.8, executor 0, partition 16, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.792357","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 5) in 61 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.827132","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added rdd_14_16 in memory on 172.18.0.8:36419 (size: 691.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.833400","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added rdd_18_16 in memory on 172.18.0.8:36419 (size: 591.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.836276","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 7) (172.18.0.8, executor 0, partition 28, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.836698","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 6) in 45 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.871958","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added rdd_14_28 in memory on 172.18.0.8:36419 (size: 306.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.878026","level":"info","event":"25/08/01 23:18:56 INFO BlockManagerInfo: Added rdd_18_28 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.881832","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 8) (172.18.0.8, executor 0, partition 42, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:56.882137","level":"info","event":"25/08/01 23:18:56 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 7) in 46 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.011976","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_42 in memory on 172.18.0.8:36419 (size: 561.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.017422","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_42 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.020438","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 9) (172.18.0.8, executor 0, partition 44, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.020872","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 8) in 139 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.050594","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_44 in memory on 172.18.0.8:36419 (size: 306.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.055833","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_44 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.059283","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.059750","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 9) in 39 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.088271","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_0 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.097506","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_0 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.100391","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.100829","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 42 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.128884","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_1 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.135825","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_1 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.138847","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 12) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.139318","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 39 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.162072","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_2 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.166910","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_2 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.170223","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 13) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.170694","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 12) in 32 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.189899","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_4 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.193810","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_4 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.196545","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 14) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.196893","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 13) in 27 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.215185","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_5 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.219227","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_5 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.222041","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 15) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.222475","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 14) in 26 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.250064","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_6 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.254717","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_6 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.257558","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 16) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.257836","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 15) in 36 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.275539","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_7 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.279425","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_7 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.284250","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 17) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.284608","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 16) in 27 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.303034","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_8 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.306840","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_8 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.309747","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 18) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.310244","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 17) in 27 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.329075","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_9 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.332690","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_9 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.335344","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 19) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.335616","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 18) in 26 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.353905","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_10 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.358158","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_10 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.361362","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 20) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.361648","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 19) in 26 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.378830","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_11 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.381948","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_11 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.384473","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 21) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.384884","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 20) in 24 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.401102","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_13 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.404474","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_13 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.409291","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 22) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.409645","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 21) in 25 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.425163","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_14 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.428675","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_14 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.431425","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 23) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.431701","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 22) in 23 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.448488","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_15 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.452347","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_15 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.455038","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 24) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.455428","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 23) in 24 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.472366","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_17 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.476284","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_17 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.479055","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 25) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.479478","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 24) in 25 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.498699","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_18 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.502476","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_18 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.505085","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 26) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.505419","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 25) in 27 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.521764","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_19 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.525548","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_19 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.528266","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 27) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.528595","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 26) in 24 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.548620","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_20 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.552385","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_20 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.555298","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 28) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.555589","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 27) in 28 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.573322","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_21 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.577219","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_21 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.580068","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 29) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.580325","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 28) in 26 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.597876","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_22 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.601507","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_22 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.604417","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 30) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.604840","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 29) in 25 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.621885","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_23 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.625049","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_23 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.627462","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 31) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.627848","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 30) in 23 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.642832","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_24 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.645815","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_24 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.648158","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 32) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.648538","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 31) in 21 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.662678","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_25 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.668529","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_25 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.671138","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 33) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.671533","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 32) in 24 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.686961","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_26 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.690888","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_26 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.694505","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 34) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.694863","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 33) in 24 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.711413","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_27 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.714518","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_27 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.716999","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 35) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.717333","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 34) in 23 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.732259","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_29 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.735665","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_29 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.738270","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 36) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.738629","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 35) in 22 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.755303","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_30 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.758257","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_30 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.760550","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 37) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.760929","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 36) in 23 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.775406","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_31 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.778837","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_31 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.783320","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 38) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.783717","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 37) in 23 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.798800","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_32 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.801574","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_32 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.804391","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 39) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.804740","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 38) in 22 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.819721","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_33 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.822432","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_33 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.824999","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 40) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.825470","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 39) in 21 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.839802","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_34 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.842828","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_34 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.845077","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 41) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.845406","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 40) in 21 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.859662","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_35 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.862413","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_35 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.864788","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 42) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.865073","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 41) in 20 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.878720","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_36 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.881557","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_36 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.887298","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 43) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.887680","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 42) in 23 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.901434","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_37 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.904256","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_37 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.906344","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 44) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.906574","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 43) in 20 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.920308","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_38 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.923429","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_38 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.925875","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 45) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.926249","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 44) in 20 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.940125","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_39 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.942859","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_39 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.945092","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 46) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.945350","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 45) in 20 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.959286","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_40 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.961967","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_40 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.964065","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 47) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.964397","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 46) in 20 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.977556","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_41 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.980395","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_18_41 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.982428","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 48) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.982652","level":"info","event":"25/08/01 23:18:57 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 47) in 19 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:57.997990","level":"info","event":"25/08/01 23:18:57 INFO BlockManagerInfo: Added rdd_14_43 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.001114","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_18_43 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.003550","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 49) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.003887","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 48) in 21 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.016023","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_14_45 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.018626","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_18_45 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.020543","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 50) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.020792","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 49) in 17 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.033141","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_14_46 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.035675","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_18_46 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.037683","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 51) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.038058","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 50) in 17 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.050563","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_14_47 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.053467","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_18_47 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.055834","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 52) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.056063","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 51) in 18 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.069238","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_14_48 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.072106","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_18_48 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.074261","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 53) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.074592","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 52) in 19 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.088311","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_14_49 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.093162","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added rdd_18_49 in memory on 172.18.0.8:36419 (size: 46.0 B, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.095629","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 53) in 22 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.095693","level":"info","event":"25/08/01 23:18:58 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.095969","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: ResultStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.881 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.096227","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.096270","level":"info","event":"25/08/01 23:18:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.096628","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Job 2 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.890901 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.116407","level":"info","event":"25/08/01 23:18:58 INFO CodeGenerator: Code generated in 11.063625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.122662","level":"info","event":"25/08/01 23:18:58 INFO Snapshot: [tableId=1b014827-4f87-4f8e-bdcc-3507acd78253] DELTA: Compute snapshot for version: 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.232464","level":"info","event":"25/08/01 23:18:58 INFO CodeGenerator: Code generated in 27.938416 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.237060","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Registering RDD 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.237953","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Got map stage job 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.238006","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Final stage: ShuffleMapStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.238032","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.238762","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.239019","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.246784","level":"info","event":"25/08/01 23:18:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 603.5 KiB, free 1046.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.247967","level":"info","event":"25/08/01 23:18:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 138.3 KiB, free 1046.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.248247","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 79dc9458c784:46547 (size: 138.3 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.248489","level":"info","event":"25/08/01 23:18:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.248876","level":"info","event":"25/08/01 23:18:58 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.248909","level":"info","event":"25/08/01 23:18:58 INFO TaskSchedulerImpl: Adding task set 5.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.250138","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 54) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.255368","level":"info","event":"25/08/01 23:18:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:36419 (size: 138.3 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.569575","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 55) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.570066","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 54) in 320 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.582224","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 56) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.582468","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 55) in 13 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.594718","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 57) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.594892","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 56) in 13 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.606407","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 58) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.606680","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 57) in 12 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.619259","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 59) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.619590","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 58) in 13 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.631238","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 60) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.631509","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 59) in 13 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.642946","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 61) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.643157","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 60) in 12 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.656303","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 62) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.656625","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 61) in 14 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.670329","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 63) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.670504","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 62) in 15 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.684782","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 64) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.685079","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 63) in 15 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.701464","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 65) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.701644","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 64) in 17 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.716152","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 66) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.716398","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 65) in 15 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.737111","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 67) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.737380","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 66) in 22 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.749959","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 68) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.750439","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 67) in 14 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.759770","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 69) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.760016","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 68) in 10 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.771235","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 70) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.771545","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 69) in 12 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.782896","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 71) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.783171","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 70) in 12 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.793971","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 72) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.794282","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 71) in 12 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.807795","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 73) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.808093","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 72) in 14 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.819257","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 74) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.819438","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 73) in 12 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.831949","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 75) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.832227","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 74) in 14 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.843624","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 76) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.843896","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 75) in 12 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.854329","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 77) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.854616","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 76) in 11 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.866717","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 78) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.867038","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 77) in 13 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.878708","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 79) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.878964","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 78) in 12 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.890016","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 80) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.890218","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 79) in 12 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.901797","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 81) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.902009","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 80) in 12 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.912512","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 82) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.912695","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 81) in 11 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.922808","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 83) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.923074","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 82) in 10 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.933048","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 84) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.933354","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 83) in 11 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.943621","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 85) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.943860","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 84) in 11 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.953839","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 86) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.953991","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 85) in 10 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.964300","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 87) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.964579","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 86) in 11 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.973496","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 88) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.973779","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 87) in 10 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.983229","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 89) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.983403","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 88) in 10 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.992966","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 90) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:58.993232","level":"info","event":"25/08/01 23:18:58 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 89) in 11 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.003108","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 91) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.003340","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 90) in 11 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.014050","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 92) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.014292","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 91) in 12 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.024092","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 93) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.024338","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 92) in 11 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.036920","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 94) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.037120","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 93) in 13 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.046971","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 95) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.047186","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 94) in 11 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.055966","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 96) (172.18.0.8, executor 0, partition 42, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.056177","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 95) in 10 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.065653","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 97) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.065934","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 96) in 10 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.074813","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 98) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.075034","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 97) in 9 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.083396","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 99) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.083526","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 98) in 9 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.091732","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 100) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.091892","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 99) in 9 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.100347","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 101) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.100566","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 100) in 9 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.109931","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 102) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.110340","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 101) in 11 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.119117","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 103) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.119370","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 102) in 10 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.127481","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 103) in 9 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.127559","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.127801","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: ShuffleMapStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.888 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.127832","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.127852","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.127870","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.127888","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.145700","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.146461","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Got job 4 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.146520","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.146546","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.146570","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.146720","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.149624","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 534.9 KiB, free 1046.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.150748","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 124.8 KiB, free 1046.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.151047","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 79dc9458c784:46547 (size: 124.8 KiB, free: 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.151379","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.151642","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.151826","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.152768","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 104) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.157911","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:36419 (size: 124.8 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.164281","level":"info","event":"25/08/01 23:18:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:58558","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.188397","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 104) in 36 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.188479","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.188835","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.041 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.189068","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.189128","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.189393","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Job 4 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.043584 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.219891","level":"info","event":"25/08/01 23:18:59 INFO CodeGenerator: Code generated in 24.005834 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.221059","level":"info","event":"25/08/01 23:18:59 INFO Snapshot: [tableId=1b014827-4f87-4f8e-bdcc-3507acd78253] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.232302","level":"info","event":"25/08/01 23:18:59 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.232396","level":"info","event":"25/08/01 23:18:59 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.248866","level":"info","event":"25/08/01 23:18:59 INFO CodeGenerator: Code generated in 3.748459 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.256887","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 207.7 KiB, free 1045.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.262864","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 1045.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.263258","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 79dc9458c784:46547 (size: 37.0 KiB, free: 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.263749","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Created broadcast 8 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.270852","level":"info","event":"25/08/01 23:18:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4207058 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.273928","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.273992","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.274022","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.274044","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.274065","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.274230","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.284185","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 17.3 KiB, free 1045.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.284583","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 1045.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.284853","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 79dc9458c784:46547 (size: 8.0 KiB, free: 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.285093","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.285315","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.285368","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.285852","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 105) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11172 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.290371","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:36419 (size: 8.0 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.315517","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:36419 (size: 37.0 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.500717","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 106) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11172 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.500994","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 105) in 215 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.518287","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 106) in 18 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.518379","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.518549","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.244 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.518590","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.518612","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.518632","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.518650","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.535048","level":"info","event":"25/08/01 23:18:59 INFO CodeGenerator: Code generated in 4.01275 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.542639","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.543255","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.543328","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.543356","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.543377","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.543503","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.544288","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 13.9 KiB, free 1045.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.544810","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 1045.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.545222","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 79dc9458c784:46547 (size: 6.2 KiB, free: 1048.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.545489","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.545632","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.545678","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.546377","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 107) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.550931","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:36419 (size: 6.2 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.552906","level":"info","event":"25/08/01 23:18:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:58558","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.560159","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 107) in 13 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.560245","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.560487","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.560670","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.560728","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.560759","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.018128 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.600928","level":"info","event":"25/08/01 23:18:59 INFO PrepareDeltaScan: DELTA: Filtering files for query","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.643982","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 79dc9458c784:46547 in memory (size: 138.3 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.645303","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.8:36419 in memory (size: 138.3 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.646358","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Starting job: collect at /opt/spark-jobs/embed_gold_data.py:54","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.647265","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Got job 7 (collect at /opt/spark-jobs/embed_gold_data.py:54) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.647322","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Final stage: ResultStage 13 (collect at /opt/spark-jobs/embed_gold_data.py:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.647356","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.647689","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.647916","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[35] at collect at /opt/spark-jobs/embed_gold_data.py:54), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.650559","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 712.6 KiB, free 1045.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.652050","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 79dc9458c784:46547 in memory (size: 124.8 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.652150","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 162.6 KiB, free 1045.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.652537","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 79dc9458c784:46547 (size: 162.6 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.652786","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.653065","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 13 (MapPartitionsRDD[35] at collect at /opt/spark-jobs/embed_gold_data.py:54) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.653145","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Adding task set 13.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.653692","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.8:36419 in memory (size: 124.8 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.654129","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 108) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.658088","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 79dc9458c784:46547 in memory (size: 8.0 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.658996","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.8:36419 in memory (size: 8.0 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.661251","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:36419 (size: 162.6 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.664005","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 79dc9458c784:46547 in memory (size: 162.6 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.664726","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:36419 in memory (size: 162.6 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.667143","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 79dc9458c784:46547 in memory (size: 6.2 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.667849","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.8:36419 in memory (size: 6.2 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.668565","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 109) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.668821","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 108) in 15 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.674982","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 110) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.675229","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 109) in 7 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.683898","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 111) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.684419","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 110) in 10 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.689674","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 112) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.689760","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 111) in 6 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.695232","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 113) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.695668","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 112) in 6 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.701454","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 114) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.701600","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 113) in 7 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.706872","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 7.0 in stage 13.0 (TID 115) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.707143","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 6.0 in stage 13.0 (TID 114) in 5 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.713302","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 8.0 in stage 13.0 (TID 116) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.713560","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 7.0 in stage 13.0 (TID 115) in 7 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.719251","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 9.0 in stage 13.0 (TID 117) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.719425","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 8.0 in stage 13.0 (TID 116) in 7 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.725529","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 10.0 in stage 13.0 (TID 118) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.726029","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 9.0 in stage 13.0 (TID 117) in 7 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.732121","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 11.0 in stage 13.0 (TID 119) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.732471","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 10.0 in stage 13.0 (TID 118) in 7 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.737798","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 12.0 in stage 13.0 (TID 120) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.738036","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 11.0 in stage 13.0 (TID 119) in 6 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.746310","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 13.0 in stage 13.0 (TID 121) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.746596","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 12.0 in stage 13.0 (TID 120) in 9 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.752331","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 14.0 in stage 13.0 (TID 122) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.752627","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 13.0 in stage 13.0 (TID 121) in 7 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.757788","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 15.0 in stage 13.0 (TID 123) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.758093","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 14.0 in stage 13.0 (TID 122) in 6 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.762340","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 16.0 in stage 13.0 (TID 124) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.762755","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 15.0 in stage 13.0 (TID 123) in 5 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.768546","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 17.0 in stage 13.0 (TID 125) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.768799","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 16.0 in stage 13.0 (TID 124) in 7 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.773919","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 18.0 in stage 13.0 (TID 126) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.774180","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 17.0 in stage 13.0 (TID 125) in 5 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.779558","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 19.0 in stage 13.0 (TID 127) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.779821","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 18.0 in stage 13.0 (TID 126) in 6 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.785421","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 20.0 in stage 13.0 (TID 128) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.785724","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 19.0 in stage 13.0 (TID 127) in 6 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.790541","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 21.0 in stage 13.0 (TID 129) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.790843","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 20.0 in stage 13.0 (TID 128) in 5 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.795295","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 22.0 in stage 13.0 (TID 130) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.795497","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 21.0 in stage 13.0 (TID 129) in 5 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.800314","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 23.0 in stage 13.0 (TID 131) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.800607","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 22.0 in stage 13.0 (TID 130) in 6 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.808097","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 24.0 in stage 13.0 (TID 132) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.808413","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 23.0 in stage 13.0 (TID 131) in 9 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.813733","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 25.0 in stage 13.0 (TID 133) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.813954","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 24.0 in stage 13.0 (TID 132) in 6 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.819314","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 26.0 in stage 13.0 (TID 134) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.819478","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 25.0 in stage 13.0 (TID 133) in 6 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.825264","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 27.0 in stage 13.0 (TID 135) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.825565","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 26.0 in stage 13.0 (TID 134) in 7 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.830974","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 28.0 in stage 13.0 (TID 136) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.831121","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 27.0 in stage 13.0 (TID 135) in 6 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.836077","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 29.0 in stage 13.0 (TID 137) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.836459","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 28.0 in stage 13.0 (TID 136) in 6 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.840626","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 30.0 in stage 13.0 (TID 138) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.840812","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 29.0 in stage 13.0 (TID 137) in 5 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.845111","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 31.0 in stage 13.0 (TID 139) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.845240","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 30.0 in stage 13.0 (TID 138) in 5 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.850656","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 32.0 in stage 13.0 (TID 140) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.850856","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 31.0 in stage 13.0 (TID 139) in 6 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.855654","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 33.0 in stage 13.0 (TID 141) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.855975","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 32.0 in stage 13.0 (TID 140) in 5 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.863767","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 34.0 in stage 13.0 (TID 142) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.863979","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 33.0 in stage 13.0 (TID 141) in 8 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.868454","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 35.0 in stage 13.0 (TID 143) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.868660","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 34.0 in stage 13.0 (TID 142) in 5 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.872957","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 36.0 in stage 13.0 (TID 144) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.873282","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 35.0 in stage 13.0 (TID 143) in 5 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.877276","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 37.0 in stage 13.0 (TID 145) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.877518","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 36.0 in stage 13.0 (TID 144) in 5 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.881149","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 38.0 in stage 13.0 (TID 146) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.881327","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 37.0 in stage 13.0 (TID 145) in 5 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.885776","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 39.0 in stage 13.0 (TID 147) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.885936","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 38.0 in stage 13.0 (TID 146) in 5 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.890009","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 40.0 in stage 13.0 (TID 148) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.890174","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 39.0 in stage 13.0 (TID 147) in 5 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.893967","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 41.0 in stage 13.0 (TID 149) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.894232","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 40.0 in stage 13.0 (TID 148) in 5 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.898055","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 42.0 in stage 13.0 (TID 150) (172.18.0.8, executor 0, partition 42, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.898301","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 41.0 in stage 13.0 (TID 149) in 5 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.902387","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 43.0 in stage 13.0 (TID 151) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.902655","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 42.0 in stage 13.0 (TID 150) in 5 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.906662","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 44.0 in stage 13.0 (TID 152) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.906925","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 43.0 in stage 13.0 (TID 151) in 4 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.913884","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 45.0 in stage 13.0 (TID 153) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.914069","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 44.0 in stage 13.0 (TID 152) in 7 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.918513","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 46.0 in stage 13.0 (TID 154) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.918735","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 45.0 in stage 13.0 (TID 153) in 5 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.922821","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 47.0 in stage 13.0 (TID 155) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.922996","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 46.0 in stage 13.0 (TID 154) in 4 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.927288","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 48.0 in stage 13.0 (TID 156) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.927562","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 47.0 in stage 13.0 (TID 155) in 5 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.931854","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 49.0 in stage 13.0 (TID 157) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.932040","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 48.0 in stage 13.0 (TID 156) in 4 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.935920","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Finished task 49.0 in stage 13.0 (TID 157) in 4 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.935987","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.936254","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: ResultStage 13 (collect at /opt/spark-jobs/embed_gold_data.py:54) finished in 0.287 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.936451","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.936495","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.936683","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Job 7 finished: collect at /opt/spark-jobs/embed_gold_data.py:54, took 0.290233 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.944176","level":"info","event":"25/08/01 23:18:59 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.944263","level":"info","event":"25/08/01 23:18:59 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.952654","level":"info","event":"25/08/01 23:18:59 INFO CodeGenerator: Code generated in 4.228 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.954741","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 208.2 KiB, free 1047.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.957905","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 1047.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.958210","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 79dc9458c784:46547 (size: 37.2 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.958550","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Created broadcast 12 from collect at /opt/spark-jobs/embed_gold_data.py:54","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.959227","level":"info","event":"25/08/01 23:18:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4207058 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.963526","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Starting job: collect at /opt/spark-jobs/embed_gold_data.py:54","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.963917","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Got job 8 (collect at /opt/spark-jobs/embed_gold_data.py:54) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.963957","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Final stage: ResultStage 14 (collect at /opt/spark-jobs/embed_gold_data.py:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.963978","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.964000","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.964139","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[39] at collect at /opt/spark-jobs/embed_gold_data.py:54), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.964837","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 18.1 KiB, free 1047.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.965206","level":"info","event":"25/08/01 23:18:59 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 1047.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.965499","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 79dc9458c784:46547 (size: 7.7 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.965740","level":"info","event":"25/08/01 23:18:59 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.965913","level":"info","event":"25/08/01 23:18:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[39] at collect at /opt/spark-jobs/embed_gold_data.py:54) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.965964","level":"info","event":"25/08/01 23:18:59 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.966475","level":"info","event":"25/08/01 23:18:59 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 158) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11183 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.970810","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:36419 (size: 7.7 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:18:59.978815","level":"info","event":"25/08/01 23:18:59 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:36419 (size: 37.2 KiB, free: 2.2 GiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.075343","level":"info","event":"25/08/01 23:19:00 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 158) in 109 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.075459","level":"info","event":"25/08/01 23:19:00 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.075607","level":"info","event":"25/08/01 23:19:00 INFO DAGScheduler: ResultStage 14 (collect at /opt/spark-jobs/embed_gold_data.py:54) finished in 0.111 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.075713","level":"info","event":"25/08/01 23:19:00 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.075742","level":"info","event":"25/08/01 23:19:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.076001","level":"info","event":"25/08/01 23:19:00 INFO DAGScheduler: Job 8 finished: collect at /opt/spark-jobs/embed_gold_data.py:54, took 0.112333 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.179816","level":"info","event":"embedding collections 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.194753","level":"info","event":"Embedding failed (%d): %s 400 {\"error\":\"json: cannot unmarshal array into Go struct field EmbeddingRequest.prompt of type string\"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.194841","level":"info","event":"❌ Embedding request failed!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.194899","level":"info","event":"Request payload: {'model': 'nomic-embed-text', 'prompt': ['Some packaging firms say aluminium could be used more widely in packaging, but cost may hold it back', 'Despite the law some remain sceptical about the effectiveness of porn age checks.', 'Despite the law some remain sceptical about the effectiveness of porn age checks.', 'Billions of dollars of US federal funding for green energy projects hangs in the balance.', 'The founder of the social media giant said one of the sites would cover an area nearly the size of Manhattan.', 'As Chile plans to ramp up lithium mining - a mineral crucial to the EV industry - Ione Wells explores if it can be done more sustainably.', 'Whole TV shows shot in one long take are made possible by new lightweight cameras.', \"Some social media users had threatened to delete their accounts after WeTransfer's terms were updated.\", 'The platform will bring in the measures from 14 July to stop under-18s looking at \"certain mature content\".', 'Minister Peter Kyle claims that by opposing online safety laws the Reform UK leader is siding with sex offenders.', 'It marks a milestone for the once fringe industry, as it expands its power in Washington. ', 'Indian start-ups are using local materials and innovative ideas to make useful and affordable products.', 'Thousands of women registered with Tea have had their images illegally accessed, the US firm says.', 'Catch up on your favourite BBC radio show from your favourite DJ right here, whenever you like. Listen without limits with BBC Sounds.', 'The platform will bring in the measures from 14 July to stop under-18s looking at \"certain mature content\".', 'Catch up on your favourite BBC radio show from your favourite DJ right here, whenever you like. Listen without limits with BBC Sounds.', \"As Bitcoin's price goes up once again, here's a guide to some of the crypto market's trickiest terms.\", 'Catch up on your favourite BBC radio show from your favourite DJ right here, whenever you like. Listen without limits with BBC Sounds.', 'Cabinet minister Heidi Alexander says age checks will not mark the \"end of the conversation\".', 'The UAE and Saudi Arabia are partnering with the US to position themselves as AI hubs.', 'UK mobile network operators are already required to ensure only adults can access adult content while using their network.', 'It marks a milestone for the once fringe industry, as it expands its power in Washington. ', 'Some packaging firms say aluminium could be used more widely in packaging, but cost may hold it back', 'Catch up on your favourite BBC radio show from your favourite DJ right here, whenever you like. Listen without limits with BBC Sounds.', 'Screen time has become synonymous with bad news - but the science may not be as straightforward as it seems', 'Big food firms are phasing out artificial colours, so tech firms are rushing to fill the gap.', 'Huda Kattan is accused of \"using her massive platform to spread vile antisemitic conspiracy theories\".', 'Giant tyre firms are testing tyres that can survive conditions on the Moon and Mars.', 'Cooling systems that avoid the use of polluting refrigerants are being launched.', 'Three men and one woman - aged between 17 and 20 - have been arrested in London and the Midlands.', 'The tech giant said only 469 serious warnings were sent out ahead of the 7.8 magnitude quake.', 'Weather influencers can provide useful local information but are also accused of exaggerating conditions.', 'Exploring some of the latest tech innovations in the world of sport, including AI in boxing, the Esports World Cup, e-bikes and Paralympic wheelchair fencers using biomechanics. ', 'In her first interview since the attack, Co-op\\'s chief executive said she was \"incredibly sorry\" to customers.', 'In Lithuania and Australia, hungry fly larvae are used to process food waste into useful protein.', 'Tech Now meets the team behind WasteShark - can it help tackle marine plastic pollution?', \"The US tech firm behind ChatGPT say it will work with the UK government to 'deliver prosperity for all'.\", 'Despite the war, Ukraine has developed of the most advanced systems for digital government services.', 'In her first interview since the attack, Co-op\\'s chief executive said she was \"incredibly sorry\" to customers.', 'Catch up on your favourite BBC radio show from your favourite DJ right here, whenever you like. Listen without limits with BBC Sounds.', 'Catch up on your favourite BBC radio show from your favourite DJ right here, whenever you like. Listen without limits with BBC Sounds.', 'Start-up firms and researchers are working on lenses that can change their focus.', 'Yasmin Morgan-Griffiths has exclusive behind-the-scenes access to La Sagrada Familia in Barcelona to see how technology is playing a key role in completing Gaudis vision for this historic landmark.', 'The Facebook, Instagram and WhatsApp-owner is pumping billions of dollars into artificial intelligence projects.', 'Challenge yourself with this edition of our monthly AI or real quiz and see if you can get top marks!', 'The biggest tech firms are using AI to forecast the weather but is that better than existing models?', 'Tech companies are restricting debates of public interest to comply the Online Safety Act, analysis shows.', 'Start-up firms and researchers are working on lenses that can change their focus.', 'A UK company says it is better at reproducing a range of accents compared with US or Chinese rivals.', 'The amount carriers now charge for luggage is raising the ire of politicians and consumer groups.', 'The tech giant said only 469 serious warnings were sent out ahead of the 7.8 magnitude quake.', 'Cabinet minister Heidi Alexander says age checks will not mark the \"end of the conversation\".', \"The world's race to decarbonise has led to the rise of electric cars - and with it, soaring demand for lithium, which is required for the batteries\", 'Anyone in the UK wanting to access online porn will soon have to undergo more rigorous age checks.', 'Giant tyre firms are testing tyres that can survive conditions on the Moon and Mars.', 'Heat pump makers are ready to raise output, but demand is still sluggish.', 'Big food firms are phasing out artificial colours, so tech firms are rushing to fill the gap.', \"It comes after a hack which exposed thousands of members' images, posts and comments. \", \"The move would reverse a US ban on sales of the high-end chip to the world's second largest economy.\", 'The Australian government says the world-first ban is aimed at protecting youth from online harm.', 'The streaming firm says AI allowed The Eternaut to complete a sequence faster and cheaper.', 'Workers at Reaction Engines felt they were close to completing a revolutionary jet engine.', 'The new tool marks a significant change for the search giant but raises questions for advertisers.', 'Workers at Reaction Engines felt they were close to completing a revolutionary jet engine.', 'The mobile phone service provider says it carried out work overnight after customers reported problems.', \"The US tech firm behind ChatGPT say it will work with the UK government to 'deliver prosperity for all'.\", 'Anyone in the UK wanting to access online porn will soon have to undergo more rigorous age checks.', \"An arctic vault holds digital back-ups of some of humanity's great works of art, history and technology. \", 'The new tool marks a significant change for the search giant but raises questions for advertisers.', 'Whole TV shows shot in one long take are made possible by new lightweight cameras.', 'Catch up on your favourite BBC radio show from your favourite DJ right here, whenever you like. Listen without limits with BBC Sounds.', 'Huda Kattan is accused of \"using her massive platform to spread vile antisemitic conspiracy theories\".', 'Yasmin Morgan-Griffiths has exclusive behind-the-scenes access to La Sagrada Familia in Barcelona to see how technology is playing a key role in completing Gaudis vision for this historic landmark.', 'Matching trucks with cargo has become digitised, adding efficiency, but driving down earnings. ', 'Heat pump makers are ready to raise output, but demand is still sluggish.', 'Light shows involving hundreds and even thousands of drones are becoming big attractions.', 'Light shows involving hundreds and even thousands of drones are becoming big attractions.', 'UK mobile network operators are already required to ensure only adults can access adult content while using their network.', 'Ofcom said on Friday that more than 6,000 porn sites would begin verifying users, but it believes some are ignoring the new rules.', 'The biggest tech firms are using AI to forecast the weather but is that better than existing models?', \"It comes after a hack which exposed thousands of members' images, posts and comments. \", 'Lithuania has a promising space tech sector, but it wants more government support.', 'A UK company says it is better at reproducing a range of accents compared with US or Chinese rivals.', 'As Chile plans to ramp up lithium mining - a mineral crucial to the EV industry - Ione Wells explores if it can be done more sustainably.', 'Minister Peter Kyle claims that by opposing online safety laws the Reform UK leader is siding with sex offenders.', 'Billions of dollars of US federal funding for green energy projects hangs in the balance.', 'The streaming firm says AI allowed The Eternaut to complete a sequence faster and cheaper.', 'Lithuania has a promising space tech sector, but it wants more government support.', 'Thousands of women registered with Tea have had their images illegally accessed, the US firm says.', \"The move would reverse a US ban on sales of the high-end chip to the world's second largest economy.\", 'In Lithuania and Australia, hungry fly larvae are used to process food waste into useful protein.', 'Hackers have accessed personal information of potentially 800,000 customers of Flutter Entertainment.', 'Ofcom said on Friday that more than 6,000 porn sites would begin verifying users, but it believes some are ignoring the new rules.', 'The founder of the social media giant said one of the sites would cover an area nearly the size of Manhattan.', 'The boss of mobile gaming giant Supercell says the industry needs to take bigger risks to compete.', \"Shareholders accused Meta leaders of damaging the company by allowing repeat violations of Facebook users' privacy.\", 'Indian start-ups are using local materials and innovative ideas to make useful and affordable products.', 'Screen time has become synonymous with bad news - but the science may not be as straightforward as it seems', \"An arctic vault holds digital back-ups of some of humanity's great works of art, history and technology. \", 'Matching trucks with cargo has become digitised, adding efficiency, but driving down earnings. ']}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.194950","level":"info","event":"Status code   : 400","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.194971","level":"info","event":"Response body : {\"error\":\"json: cannot unmarshal array into Go struct field EmbeddingRequest.prompt of type string\"}","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.195593","level":"info","event":"ERROR:__main__:Error in embeddingGoldData","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.195654","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.195685","level":"info","event":"File \"/opt/spark-jobs/embed_gold_data.py\", line 91, in main","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.195706","level":"info","event":"resp.raise_for_status()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.195725","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/requests/models.py\", line 1024, in raise_for_status","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.195743","level":"info","event":"raise HTTPError(http_error_msg, response=self)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.195761","level":"info","event":"requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http://ollama:11434/api/embeddings","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.196149","level":"info","event":"25/08/01 23:19:00 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.203340","level":"info","event":"25/08/01 23:19:00 INFO SparkUI: Stopped Spark web UI at http://79dc9458c784:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.204697","level":"info","event":"25/08/01 23:19:00 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.204915","level":"info","event":"25/08/01 23:19:00 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.216414","level":"info","event":"25/08/01 23:19:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.226776","level":"info","event":"25/08/01 23:19:00 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.226866","level":"info","event":"25/08/01 23:19:00 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.229974","level":"info","event":"25/08/01 23:19:00 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.231383","level":"info","event":"25/08/01 23:19:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.239137","level":"info","event":"25/08/01 23:19:00 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.414282","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.414445","level":"info","event":"File \"/opt/spark-jobs/embed_gold_data.py\", line 116, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.414933","level":"info","event":"main()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.415004","level":"info","event":"File \"/opt/spark-jobs/embed_gold_data.py\", line 91, in main","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.415460","level":"info","event":"resp.raise_for_status()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.415557","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/requests/models.py\", line 1024, in raise_for_status","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.415627","level":"info","event":"raise HTTPError(http_error_msg, response=self)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.415680","level":"info","event":"requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http://ollama:11434/api/embeddings","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:00.663121","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:01.148015","level":"info","event":"25/08/01 23:19:01 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:01.148125","level":"info","event":"25/08/01 23:19:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-1d455217-0af0-4ba6-a27d-aadd51cbf0bc","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:01.150388","level":"info","event":"25/08/01 23:19:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746/pyspark-df6b200d-da3b-44e1-9272-2753b174d314","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:01.151754","level":"info","event":"25/08/01 23:19:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-a94a6218-89a5-445e-bd4a-4c0d7eb6f746","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:01.155254","level":"info","event":"25/08/01 23:19:01 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:01.155317","level":"info","event":"25/08/01 23:19:01 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:01.155351","level":"info","event":"25/08/01 23:19:01 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T23:19:01.190189","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=4g --conf spark.driver.memory=2g --conf spark.executor.cores=1 --conf spark.executorEnv.AWS_ACCESS_KEY_ID=ZPnglo5gVhmWx1iC0FdY --conf spark.executorEnv.AWS_SECRET_ACCESS_KEY=****** --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 1 --executor-memory 4g --driver-memory 2g --name embed_gold_data_job --verbose --deploy-mode client /opt/spark-jobs/embed_gold_data.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":867,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1159,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":570,"name":"submit"}],"is_group":false,"exceptions":[]}]}
