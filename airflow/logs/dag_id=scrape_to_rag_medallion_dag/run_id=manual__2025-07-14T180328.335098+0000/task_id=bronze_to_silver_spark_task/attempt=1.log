{"timestamp":"2025-07-14T18:04:10.990275","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-14T18:04:10.991833","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-14T18:04:18.424007","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-14T18:04:18.426118","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:18.495301","level":"info","event":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.283046","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.410547","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.410732","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.410799","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.410851","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.410893","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.410932","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.410971","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411009","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411048","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411085","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411124","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411164","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411203","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411239","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411275","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411311","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411347","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411383","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411418","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411454","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411489","level":"info","event":"primaryResource         file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411524","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411559","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411593","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411628","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411679","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411715","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411749","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411785","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411824","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411862","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411898","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411932","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.411966","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412000","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412056","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412110","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412152","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412191","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412230","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412267","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412307","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.412346","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.572726","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.669112","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.669429","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.672709","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.672937","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.673058","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.673112","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.673945","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-5e0de3ea-99be-4cea-a32c-7fecba6adc89;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.674061","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.877745","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.916793","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.935802","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.969377","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:20.986854","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.008560","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.033085","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.050538","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in spark-list","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.091253","level":"info","event":":: resolution report :: resolve 392ms :: artifacts dl 25ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.092132","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.092302","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.092435","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.092567","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.092725","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from spark-list in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.092823","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.092912","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093047","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093147","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093247","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093325","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093406","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093482","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093557","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093635","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093713","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.093796","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.101249","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-5e0de3ea-99be-4cea-a32c-7fecba6adc89","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.101498","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.111450","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/9ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.391077","level":"info","event":"25/07/14 18:04:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.648631","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.648809","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.648884","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.648930","level":"info","event":"file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.648972","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.652588","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.652816","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.652881","level":"info","event":"(spark.app.submitTime,1752516261622)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.652926","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.652967","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653004","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653042","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653084","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653119","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653153","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653188","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653223","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653256","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653289","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653326","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653360","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653396","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653434","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653483","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653519","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653556","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653591","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653626","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653661","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653695","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653728","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653762","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653797","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:21.653835","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.266123","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.267003","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: OS info Linux, 5.15.153.1-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.267273","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.287628","level":"info","event":"25/07/14 18:04:23 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.287917","level":"info","event":"25/07/14 18:04:23 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.288138","level":"info","event":"25/07/14 18:04:23 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.288441","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.310992","level":"info","event":"25/07/14 18:04:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.319796","level":"info","event":"25/07/14 18:04:23 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.322111","level":"info","event":"25/07/14 18:04:23 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.394094","level":"info","event":"25/07/14 18:04:23 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.394481","level":"info","event":"25/07/14 18:04:23 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.395099","level":"info","event":"25/07/14 18:04:23 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.395532","level":"info","event":"25/07/14 18:04:23 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.395955","level":"info","event":"25/07/14 18:04:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.635420","level":"info","event":"25/07/14 18:04:23 INFO Utils: Successfully started service 'sparkDriver' on port 35941.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.661825","level":"info","event":"25/07/14 18:04:23 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.699130","level":"info","event":"25/07/14 18:04:23 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.715471","level":"info","event":"25/07/14 18:04:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.716601","level":"info","event":"25/07/14 18:04:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.720482","level":"info","event":"25/07/14 18:04:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.742176","level":"info","event":"25/07/14 18:04:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5225bf06-c8fd-405b-8e84-262196f86394","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.758644","level":"info","event":"25/07/14 18:04:23 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.774507","level":"info","event":"25/07/14 18:04:23 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.888582","level":"info","event":"25/07/14 18:04:23 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.954727","level":"info","event":"25/07/14 18:04:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.991903","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://69f798aefb29:35941/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.992473","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://69f798aefb29:35941/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.992682","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://69f798aefb29:35941/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.992784","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://69f798aefb29:35941/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.993244","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://69f798aefb29:35941/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.993346","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://69f798aefb29:35941/jars/org.tukaani_xz-1.9.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.993394","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://69f798aefb29:35941/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.993438","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://69f798aefb29:35941/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.997083","level":"info","event":"25/07/14 18:04:23 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://69f798aefb29:35941/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:23.998007","level":"info","event":"25/07/14 18:04:23 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/userFiles-5ef54dca-1932-4ae9-b986-add87b2033a4/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.006891","level":"info","event":"25/07/14 18:04:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://69f798aefb29:35941/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.007056","level":"info","event":"25/07/14 18:04:24 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/userFiles-5ef54dca-1932-4ae9-b986-add87b2033a4/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.267078","level":"info","event":"25/07/14 18:04:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://69f798aefb29:35941/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.267281","level":"info","event":"25/07/14 18:04:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/userFiles-5ef54dca-1932-4ae9-b986-add87b2033a4/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.271111","level":"info","event":"25/07/14 18:04:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://69f798aefb29:35941/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.271260","level":"info","event":"25/07/14 18:04:24 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/userFiles-5ef54dca-1932-4ae9-b986-add87b2033a4/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.281600","level":"info","event":"25/07/14 18:04:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://69f798aefb29:35941/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.281791","level":"info","event":"25/07/14 18:04:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/userFiles-5ef54dca-1932-4ae9-b986-add87b2033a4/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.285521","level":"info","event":"25/07/14 18:04:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://69f798aefb29:35941/files/org.tukaani_xz-1.9.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.285676","level":"info","event":"25/07/14 18:04:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/userFiles-5ef54dca-1932-4ae9-b986-add87b2033a4/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.289363","level":"info","event":"25/07/14 18:04:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://69f798aefb29:35941/files/io.delta_delta-storage-3.1.0.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.289522","level":"info","event":"25/07/14 18:04:24 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/userFiles-5ef54dca-1932-4ae9-b986-add87b2033a4/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.293608","level":"info","event":"25/07/14 18:04:24 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://69f798aefb29:35941/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1752516263257","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.293836","level":"info","event":"25/07/14 18:04:24 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/userFiles-5ef54dca-1932-4ae9-b986-add87b2033a4/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.367775","level":"info","event":"25/07/14 18:04:24 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.414503","level":"info","event":"25/07/14 18:04:24 INFO TransportClientFactory: Successfully created connection to spark-master/172.25.0.7:7077 after 26 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.522555","level":"info","event":"25/07/14 18:04:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250714180424-0005","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.527757","level":"info","event":"25/07/14 18:04:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250714180424-0005/0 on worker-20250714175517-172.25.0.8-43715 (172.25.0.8:43715) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.530906","level":"info","event":"25/07/14 18:04:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20250714180424-0005/0 on hostPort 172.25.0.8:43715 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.533332","level":"info","event":"25/07/14 18:04:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33609.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.534015","level":"info","event":"25/07/14 18:04:24 INFO NettyBlockTransferService: Server created on 69f798aefb29:33609","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.537271","level":"info","event":"25/07/14 18:04:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.544147","level":"info","event":"25/07/14 18:04:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 69f798aefb29, 33609, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.548895","level":"info","event":"25/07/14 18:04:24 INFO BlockManagerMasterEndpoint: Registering block manager 69f798aefb29:33609 with 434.4 MiB RAM, BlockManagerId(driver, 69f798aefb29, 33609, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.552492","level":"info","event":"25/07/14 18:04:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 69f798aefb29, 33609, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.553809","level":"info","event":"25/07/14 18:04:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 69f798aefb29, 33609, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.621855","level":"info","event":"25/07/14 18:04:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250714180424-0005/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:24.801772","level":"info","event":"25/07/14 18:04:24 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:25.083325","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:25.093401","level":"info","event":"25/07/14 18:04:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:25.097093","level":"info","event":"25/07/14 18:04:25 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:26.188896","level":"info","event":"25/07/14 18:04:26 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:26.205827","level":"info","event":"25/07/14 18:04:26 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:26.205973","level":"info","event":"25/07/14 18:04:26 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:27.512451","level":"info","event":"25/07/14 18:04:27 INFO InMemoryFileIndex: It took 112 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:27.952389","level":"info","event":"25/07/14 18:04:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.25.0.8:54154) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.050850","level":"info","event":"25/07/14 18:04:28 INFO BlockManagerMasterEndpoint: Registering block manager 172.25.0.8:38685 with 1048.8 MiB RAM, BlockManagerId(0, 172.25.0.8, 38685, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.147493","level":"info","event":"25/07/14 18:04:28 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.174407","level":"info","event":"25/07/14 18:04:28 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.174611","level":"info","event":"25/07/14 18:04:28 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.175385","level":"info","event":"25/07/14 18:04:28 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.177900","level":"info","event":"25/07/14 18:04:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.183086","level":"info","event":"25/07/14 18:04:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.256763","level":"info","event":"25/07/14 18:04:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 108.2 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.318626","level":"info","event":"25/07/14 18:04:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.323994","level":"info","event":"25/07/14 18:04:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 69f798aefb29:33609 (size: 39.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.331556","level":"info","event":"25/07/14 18:04:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.359995","level":"info","event":"25/07/14 18:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:28.361427","level":"info","event":"25/07/14 18:04:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:30.476011","level":"info","event":"25/07/14 18:04:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.25.0.8, executor 0, partition 0, PROCESS_LOCAL, 10672 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:30.813953","level":"info","event":"25/07/14 18:04:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.25.0.8:38685 (size: 39.2 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:32.825442","level":"info","event":"25/07/14 18:04:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2383 ms on 172.25.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:32.829495","level":"info","event":"25/07/14 18:04:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:32.835778","level":"info","event":"25/07/14 18:04:32 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 4.630 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:32.838641","level":"info","event":"25/07/14 18:04:32 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:32.839328","level":"info","event":"25/07/14 18:04:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:32.841393","level":"info","event":"25/07/14 18:04:32 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 4.693739 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:33.529146","level":"info","event":"25/07/14 18:04:33 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 69f798aefb29:33609 in memory (size: 39.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:33.539417","level":"info","event":"25/07/14 18:04:33 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.25.0.8:38685 in memory (size: 39.2 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:34.407531","level":"info","event":"25/07/14 18:04:34 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:34.436374","level":"info","event":"25/07/14 18:04:34 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:35.390629","level":"info","event":"25/07/14 18:04:35 INFO InitialSnapshot: [tableId=d8a5a0da-0a3b-4f65-912f-0c8217fb3b0d] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(6b8fb823-5b8d-45b7-8b49-111c419c120d,null,null,Format(parquet,Map()),null,List(),Map(),Some(1752516275383)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@4719750d,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:35.488545","level":"info","event":"25/07/14 18:04:35 INFO DeltaLog: No delta log found for the Delta table at s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:35.490255","level":"info","event":"25/07/14 18:04:35 INFO InitialSnapshot: [tableId=6b8fb823-5b8d-45b7-8b49-111c419c120d] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(c3c015bb-b570-4cbd-a986-654ebcc72db6,null,null,Format(parquet,Map()),null,List(),Map(),Some(1752516275488)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@4719750d,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:35.601529","level":"info","event":"25/07/14 18:04:35 INFO OptimisticTransaction: [tableId=c3c015bb,txnId=852df46b] Updated metadata from - to Metadata(be432ec5-17cc-4204-8c3d-c06349bc8753,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1752516275572))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.045585","level":"info","event":"25/07/14 18:04:36 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.053861","level":"info","event":"25/07/14 18:04:36 INFO FileSourceStrategy: Pushed Filters: IsNotNull(article_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.054667","level":"info","event":"25/07/14 18:04:36 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(article_id#0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.132572","level":"info","event":"25/07/14 18:04:36 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.493736","level":"info","event":"25/07/14 18:04:36 INFO CodeGenerator: Code generated in 231.827337 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.517604","level":"info","event":"25/07/14 18:04:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 208.0 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.537545","level":"info","event":"25/07/14 18:04:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.538934","level":"info","event":"25/07/14 18:04:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 69f798aefb29:33609 (size: 37.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.541410","level":"info","event":"25/07/14 18:04:36 INFO SparkContext: Created broadcast 1 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.569015","level":"info","event":"25/07/14 18:04:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.773110","level":"info","event":"25/07/14 18:04:36 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.776304","level":"info","event":"25/07/14 18:04:36 INFO DAGScheduler: Got job 1 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.776553","level":"info","event":"25/07/14 18:04:36 INFO DAGScheduler: Final stage: ResultStage 1 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.776624","level":"info","event":"25/07/14 18:04:36 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.776958","level":"info","event":"25/07/14 18:04:36 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.778362","level":"info","event":"25/07/14 18:04:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[4] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.828730","level":"info","event":"25/07/14 18:04:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 358.1 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.834146","level":"info","event":"25/07/14 18:04:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 127.7 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.835663","level":"info","event":"25/07/14 18:04:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 69f798aefb29:33609 (size: 127.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.837250","level":"info","event":"25/07/14 18:04:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.839180","level":"info","event":"25/07/14 18:04:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.839476","level":"info","event":"25/07/14 18:04:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.846231","level":"info","event":"25/07/14 18:04:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.25.0.8, executor 0, partition 0, PROCESS_LOCAL, 11248 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:36.928061","level":"info","event":"25/07/14 18:04:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.25.0.8:38685 (size: 127.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:39.312635","level":"info","event":"25/07/14 18:04:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.25.0.8:38685 (size: 37.0 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.589626","level":"info","event":"25/07/14 18:04:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4747 ms on 172.25.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.589906","level":"info","event":"25/07/14 18:04:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.591624","level":"info","event":"25/07/14 18:04:41 INFO DAGScheduler: ResultStage 1 (save at NativeMethodAccessorImpl.java:0) finished in 4.808 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.592041","level":"info","event":"25/07/14 18:04:41 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.592202","level":"info","event":"25/07/14 18:04:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.593832","level":"info","event":"25/07/14 18:04:41 INFO DAGScheduler: Job 1 finished: save at NativeMethodAccessorImpl.java:0, took 4.821093 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.597385","level":"info","event":"25/07/14 18:04:41 INFO DeltaFileFormatWriter: Start to commit write Job 12413524-9918-4495-a02d-7edeff4d2a1d.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.601248","level":"info","event":"25/07/14 18:04:41 INFO DeltaFileFormatWriter: Write Job 12413524-9918-4495-a02d-7edeff4d2a1d committed. Elapsed time: 1 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:41.606134","level":"info","event":"25/07/14 18:04:41 INFO DeltaFileFormatWriter: Finished processing stats for write job 12413524-9918-4495-a02d-7edeff4d2a1d.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:42.131667","level":"info","event":"25/07/14 18:04:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 69f798aefb29:33609 in memory (size: 127.7 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:42.139291","level":"info","event":"25/07/14 18:04:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.25.0.8:38685 in memory (size: 127.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.204133","level":"info","event":"25/07/14 18:04:43 INFO CodeGenerator: Code generated in 312.120812 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.243243","level":"info","event":"25/07/14 18:04:43 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.244730","level":"info","event":"25/07/14 18:04:43 INFO DAGScheduler: Job 2 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000629 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.332218","level":"info","event":"25/07/14 18:04:43 INFO OptimisticTransaction: [tableId=c3c015bb,txnId=852df46b] Attempting to commit version 0 with 4 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.680249","level":"info","event":"25/07/14 18:04:43 INFO DeltaLog: Creating a new snapshot v0 for commit version 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.680501","level":"info","event":"25/07/14 18:04:43 INFO DeltaLog: Loading version 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.699522","level":"info","event":"25/07/14 18:04:43 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1995)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.809234","level":"info","event":"25/07/14 18:04:43 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.810836","level":"info","event":"25/07/14 18:04:43 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.811395","level":"info","event":"25/07/14 18:04:43 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#325.minReaderVersion) OR isnotnull(metaData#324.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.853319","level":"info","event":"25/07/14 18:04:43 INFO CodeGenerator: Code generated in 22.979954 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.859471","level":"info","event":"25/07/14 18:04:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 206.2 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.867590","level":"info","event":"25/07/14 18:04:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.868389","level":"info","event":"25/07/14 18:04:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 69f798aefb29:33609 (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.869489","level":"info","event":"25/07/14 18:04:43 INFO SparkContext: Created broadcast 3 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.886597","level":"info","event":"25/07/14 18:04:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.956303","level":"info","event":"25/07/14 18:04:43 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.957785","level":"info","event":"25/07/14 18:04:43 INFO DAGScheduler: Got job 3 (toString at String.java:4220) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.957960","level":"info","event":"25/07/14 18:04:43 INFO DAGScheduler: Final stage: ResultStage 2 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.958033","level":"info","event":"25/07/14 18:04:43 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.958088","level":"info","event":"25/07/14 18:04:43 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.958940","level":"info","event":"25/07/14 18:04:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.961776","level":"info","event":"25/07/14 18:04:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 40.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.969787","level":"info","event":"25/07/14 18:04:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.971613","level":"info","event":"25/07/14 18:04:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 69f798aefb29:33609 (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.972749","level":"info","event":"25/07/14 18:04:43 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.973709","level":"info","event":"25/07/14 18:04:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.973828","level":"info","event":"25/07/14 18:04:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:43.976250","level":"info","event":"25/07/14 18:04:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.25.0.8, executor 0, partition 0, PROCESS_LOCAL, 11166 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.003213","level":"info","event":"25/07/14 18:04:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.25.0.8:38685 (size: 13.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.158870","level":"info","event":"25/07/14 18:04:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.25.0.8:38685 (size: 36.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.254539","level":"info","event":"25/07/14 18:04:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 278 ms on 172.25.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.254970","level":"info","event":"25/07/14 18:04:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.256002","level":"info","event":"25/07/14 18:04:44 INFO DAGScheduler: ResultStage 2 (toString at String.java:4220) finished in 0.296 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.256321","level":"info","event":"25/07/14 18:04:44 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.256480","level":"info","event":"25/07/14 18:04:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.257023","level":"info","event":"25/07/14 18:04:44 INFO DAGScheduler: Job 3 finished: toString at String.java:4220, took 0.300485 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.335435","level":"info","event":"25/07/14 18:04:44 INFO CodeGenerator: Code generated in 50.054614 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.349787","level":"info","event":"25/07/14 18:04:44 INFO Snapshot: [tableId=c3c015bb-b570-4cbd-a986-654ebcc72db6] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(be432ec5-17cc-4204-8c3d-c06349bc8753,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1752516275572)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1752516283611; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=8af0097a9b3476adfc9309849cef8872 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@4719750d,1752516283611), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.356042","level":"info","event":"25/07/14 18:04:44 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(be432ec5-17cc-4204-8c3d-c06349bc8753,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1752516275572)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1752516283611; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=8af0097a9b3476adfc9309849cef8872 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@4719750d,1752516283611), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.366134","level":"info","event":"25/07/14 18:04:44 INFO Snapshot: [tableId=be432ec5-17cc-4204-8c3d-c06349bc8753] DELTA: Compute snapshot for version: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.381179","level":"info","event":"25/07/14 18:04:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 205.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.389828","level":"info","event":"25/07/14 18:04:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.390501","level":"info","event":"25/07/14 18:04:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 69f798aefb29:33609 (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.391731","level":"info","event":"25/07/14 18:04:44 INFO SparkContext: Created broadcast 5 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.610266","level":"info","event":"25/07/14 18:04:44 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 69f798aefb29:33609 in memory (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.616938","level":"info","event":"25/07/14 18:04:44 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.25.0.8:38685 in memory (size: 13.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.780318","level":"info","event":"25/07/14 18:04:44 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.780550","level":"info","event":"25/07/14 18:04:44 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.780696","level":"info","event":"25/07/14 18:04:44 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.844481","level":"info","event":"25/07/14 18:04:44 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.979873","level":"info","event":"25/07/14 18:04:44 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 69f798aefb29:33609 in memory (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:44.984740","level":"info","event":"25/07/14 18:04:44 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.25.0.8:38685 in memory (size: 36.4 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.025647","level":"info","event":"25/07/14 18:04:45 INFO CodeGenerator: Code generated in 95.839359 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.031523","level":"info","event":"25/07/14 18:04:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 206.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.041731","level":"info","event":"25/07/14 18:04:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.043103","level":"info","event":"25/07/14 18:04:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 69f798aefb29:33609 (size: 36.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.045623","level":"info","event":"25/07/14 18:04:45 INFO SparkContext: Created broadcast 6 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.049632","level":"info","event":"25/07/14 18:04:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.102266","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: Registering RDD 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.108221","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: Got map stage job 4 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.109372","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: Final stage: ShuffleMapStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.109614","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.110126","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.111537","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.123592","level":"info","event":"25/07/14 18:04:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 105.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.125360","level":"info","event":"25/07/14 18:04:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.125955","level":"info","event":"25/07/14 18:04:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 69f798aefb29:33609 (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.126558","level":"info","event":"25/07/14 18:04:45 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.128067","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.128190","level":"info","event":"25/07/14 18:04:45 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.131859","level":"info","event":"25/07/14 18:04:45 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.25.0.8, executor 0, partition 0, PROCESS_LOCAL, 11155 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.152524","level":"info","event":"25/07/14 18:04:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.25.0.8:38685 (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.540768","level":"info","event":"25/07/14 18:04:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.25.0.8:38685 (size: 36.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.663500","level":"info","event":"25/07/14 18:04:45 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 533 ms on 172.25.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.663856","level":"info","event":"25/07/14 18:04:45 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.672127","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: ShuffleMapStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.556 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.673942","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.674763","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.675623","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.676326","level":"info","event":"25/07/14 18:04:45 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.775637","level":"info","event":"25/07/14 18:04:45 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 69f798aefb29:33609 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:45.788049","level":"info","event":"25/07/14 18:04:45 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.25.0.8:38685 in memory (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:46.363690","level":"info","event":"25/07/14 18:04:46 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:46.364100","level":"info","event":"25/07/14 18:04:46 INFO CodeGenerator: Code generated in 473.001808 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:46.541290","level":"info","event":"25/07/14 18:04:46 INFO CodeGenerator: Code generated in 116.656284 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.176853","level":"info","event":"25/07/14 18:04:47 INFO CodeGenerator: Code generated in 132.901657 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.203181","level":"info","event":"25/07/14 18:04:47 INFO DAGScheduler: Registering RDD 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.203512","level":"info","event":"25/07/14 18:04:47 INFO DAGScheduler: Got map stage job 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.203649","level":"info","event":"25/07/14 18:04:47 INFO DAGScheduler: Final stage: ShuffleMapStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.203781","level":"info","event":"25/07/14 18:04:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.209409","level":"info","event":"25/07/14 18:04:47 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.210534","level":"info","event":"25/07/14 18:04:47 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[26] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.292519","level":"info","event":"25/07/14 18:04:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 603.3 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.298582","level":"info","event":"25/07/14 18:04:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.301111","level":"info","event":"25/07/14 18:04:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 69f798aefb29:33609 (size: 138.2 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.302819","level":"info","event":"25/07/14 18:04:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.305447","level":"info","event":"25/07/14 18:04:47 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[26] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.305834","level":"info","event":"25/07/14 18:04:47 INFO TaskSchedulerImpl: Adding task set 5.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.327042","level":"info","event":"25/07/14 18:04:47 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 4) (172.25.0.8, executor 0, partition 26, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.328107","level":"info","event":"25/07/14 18:04:47 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 5) (172.25.0.8, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.365863","level":"info","event":"25/07/14 18:04:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.25.0.8:38685 (size: 138.2 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:47.614752","level":"info","event":"25/07/14 18:04:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.25.0.8:54154","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:48.640033","level":"info","event":"25/07/14 18:04:48 INFO BlockManagerInfo: Added rdd_23_42 in memory on 172.25.0.8:38685 (size: 562.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:48.641716","level":"info","event":"25/07/14 18:04:48 INFO BlockManagerInfo: Added rdd_23_26 in memory on 172.25.0.8:38685 (size: 691.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:48.982947","level":"info","event":"25/07/14 18:04:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (172.25.0.8, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:48.984419","level":"info","event":"25/07/14 18:04:48 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 4) in 1663 ms on 172.25.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:48.986239","level":"info","event":"25/07/14 18:04:48 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7) (172.25.0.8, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:48.987176","level":"info","event":"25/07/14 18:04:48 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 5) in 1659 ms on 172.25.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.115433","level":"info","event":"25/07/14 18:04:49 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.131583","level":"info","event":"25/07/14 18:04:49 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.205469","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 8) (172.25.0.8, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.206922","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 221 ms on 172.25.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.208610","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 9) (172.25.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.209910","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 228 ms on 172.25.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.401954","level":"info","event":"25/07/14 18:04:49 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.415607","level":"info","event":"25/07/14 18:04:49 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.505669","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 10) (172.25.0.8, executor 0, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.507475","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 8) in 303 ms on 172.25.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.512023","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 11) (172.25.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.517312","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 9) in 308 ms on 172.25.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.685991","level":"info","event":"25/07/14 18:04:49 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.687472","level":"info","event":"25/07/14 18:04:49 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.777964","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 12) (172.25.0.8, executor 0, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.779227","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 10) in 275 ms on 172.25.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.782254","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 13) (172.25.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.784544","level":"info","event":"25/07/14 18:04:49 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 11) in 273 ms on 172.25.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.975335","level":"info","event":"25/07/14 18:04:49 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:49.991017","level":"info","event":"25/07/14 18:04:49 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.088946","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 14) (172.25.0.8, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.090759","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 12) in 313 ms on 172.25.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.094041","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 15) (172.25.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.095530","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 13) in 314 ms on 172.25.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.273306","level":"info","event":"25/07/14 18:04:50 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.289732","level":"info","event":"25/07/14 18:04:50 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.350381","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 16) (172.25.0.8, executor 0, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.351527","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 14) in 264 ms on 172.25.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.376567","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 17) (172.25.0.8, executor 0, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.378082","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 15) in 285 ms on 172.25.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.503561","level":"info","event":"25/07/14 18:04:50 INFO BlockManagerInfo: Added rdd_23_10 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.524287","level":"info","event":"25/07/14 18:04:50 INFO BlockManagerInfo: Added rdd_23_11 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.589529","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 18) (172.25.0.8, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.592950","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 16) in 242 ms on 172.25.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.622160","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 19) (172.25.0.8, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.623665","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 17) in 247 ms on 172.25.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.824880","level":"info","event":"25/07/14 18:04:50 INFO BlockManagerInfo: Added rdd_23_12 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.857091","level":"info","event":"25/07/14 18:04:50 INFO BlockManagerInfo: Added rdd_23_13 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.915840","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 20) (172.25.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.918191","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 18) in 330 ms on 172.25.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.959027","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 21) (172.25.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:50.960506","level":"info","event":"25/07/14 18:04:50 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 19) in 339 ms on 172.25.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.065009","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_14 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.096513","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_15 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.124779","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 22) (172.25.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.126191","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 20) in 212 ms on 172.25.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.169309","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 23) (172.25.0.8, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.170675","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 21) in 212 ms on 172.25.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.290746","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_16 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.351312","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_17 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.361393","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 24) (172.25.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.362658","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 22) in 238 ms on 172.25.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.426962","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 25) (172.25.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.433956","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 23) in 265 ms on 172.25.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.494371","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_18 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.555351","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 26) (172.25.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.556984","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 24) in 195 ms on 172.25.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.559276","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_19 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.614270","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 27) (172.25.0.8, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.614901","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 25) in 189 ms on 172.25.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.655543","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_20 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.746578","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 28) (172.25.0.8, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.748033","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 26) in 195 ms on 172.25.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.799808","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_21 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.851573","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 29) (172.25.0.8, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.853811","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 27) in 239 ms on 172.25.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.869588","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_22 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.932203","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 30) (172.25.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.933667","level":"info","event":"25/07/14 18:04:51 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 28) in 188 ms on 172.25.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:51.960294","level":"info","event":"25/07/14 18:04:51 INFO BlockManagerInfo: Added rdd_23_23 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.009380","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 31) (172.25.0.8, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.010143","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 29) in 160 ms on 172.25.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.022630","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_24 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.069590","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 32) (172.25.0.8, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.070229","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 30) in 139 ms on 172.25.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.090280","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_25 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.121115","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 33) (172.25.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.122277","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 31) in 113 ms on 172.25.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.138087","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_27 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.168951","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 34) (172.25.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.170829","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 32) in 102 ms on 172.25.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.197284","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_28 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.232960","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 35) (172.25.0.8, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.233761","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 33) in 114 ms on 172.25.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.245399","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_29 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.279663","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 36) (172.25.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.281010","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 34) in 114 ms on 172.25.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.305578","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_30 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.349297","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 37) (172.25.0.8, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.357308","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 35) in 124 ms on 172.25.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.366756","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_31 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.404048","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 38) (172.25.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.404902","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 36) in 127 ms on 172.25.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.426872","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_32 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.461626","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 39) (172.25.0.8, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.463749","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 37) in 113 ms on 172.25.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.476162","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_33 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.513887","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 40) (172.25.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.515632","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 38) in 112 ms on 172.25.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.532066","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_34 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.568426","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 41) (172.25.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.569800","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 39) in 109 ms on 172.25.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.579549","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_35 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.607903","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 42) (172.25.0.8, executor 0, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.609436","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 40) in 96 ms on 172.25.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.635618","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_36 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.678099","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_37 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.678522","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 43) (172.25.0.8, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.678661","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 41) in 112 ms on 172.25.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.717769","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 44) (172.25.0.8, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.719613","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 42) in 112 ms on 172.25.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.751663","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_38 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.793280","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_39 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.793529","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 45) (172.25.0.8, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.794586","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 43) in 117 ms on 172.25.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.837544","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 46) (172.25.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.839172","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 44) in 122 ms on 172.25.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.873452","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_40 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.905679","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_41 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.908481","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 47) (172.25.0.8, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.910878","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 45) in 117 ms on 172.25.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.948084","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 48) (172.25.0.8, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.949969","level":"info","event":"25/07/14 18:04:52 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 46) in 113 ms on 172.25.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:52.992459","level":"info","event":"25/07/14 18:04:52 INFO BlockManagerInfo: Added rdd_23_43 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.024123","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerInfo: Added rdd_23_44 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.030480","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 49) (172.25.0.8, executor 0, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.031316","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 47) in 124 ms on 172.25.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.063725","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 50) (172.25.0.8, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.064596","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 48) in 117 ms on 172.25.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.116931","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerInfo: Added rdd_23_45 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.153358","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerInfo: Added rdd_23_46 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.160803","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 51) (172.25.0.8, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.161846","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 49) in 132 ms on 172.25.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.194877","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 52) (172.25.0.8, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.196908","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 50) in 133 ms on 172.25.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.241627","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerInfo: Added rdd_23_47 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.268545","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerInfo: Added rdd_23_48 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.283611","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 53) (172.25.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.284874","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 51) in 125 ms on 172.25.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.321737","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 52) in 127 ms on 172.25.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.371974","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerInfo: Added rdd_23_49 in memory on 172.25.0.8:38685 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.400233","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 53) in 118 ms on 172.25.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.400630","level":"info","event":"25/07/14 18:04:53 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.402223","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: ShuffleMapStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 6.167 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.402433","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.402530","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.402609","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.402743","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.455559","level":"info","event":"25/07/14 18:04:53 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.459044","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: Got job 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.459355","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.459481","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.459729","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.460480","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[29] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.474492","level":"info","event":"25/07/14 18:04:53 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 534.7 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.479053","level":"info","event":"25/07/14 18:04:53 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 124.7 KiB, free 432.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.480399","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 69f798aefb29:33609 (size: 124.7 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.481273","level":"info","event":"25/07/14 18:04:53 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.481998","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.482221","level":"info","event":"25/07/14 18:04:53 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.484955","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 54) (172.25.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.504425","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.25.0.8:38685 (size: 124.7 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.534462","level":"info","event":"25/07/14 18:04:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.25.0.8:54154","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.644556","level":"info","event":"25/07/14 18:04:53 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 54) in 161 ms on 172.25.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.644798","level":"info","event":"25/07/14 18:04:53 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.645295","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.183 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.645451","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.645561","level":"info","event":"25/07/14 18:04:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.646002","level":"info","event":"25/07/14 18:04:53 INFO DAGScheduler: Job 6 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.190514 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.735893","level":"info","event":"25/07/14 18:04:53 INFO CodeGenerator: Code generated in 65.756707 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.740372","level":"info","event":"25/07/14 18:04:53 INFO Snapshot: [tableId=be432ec5-17cc-4204-8c3d-c06349bc8753] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.792122","level":"info","event":"25/07/14 18:04:53 INFO OptimisticTransaction: [tableId=c3c015bb,txnId=852df46b] Committed delta #0 to s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.802247","level":"info","event":"INFO:__main__:Data cleaned and loaded to silver layer!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.803970","level":"info","event":"25/07/14 18:04:53 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.823269","level":"info","event":"25/07/14 18:04:53 INFO SparkUI: Stopped Spark web UI at http://69f798aefb29:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.827940","level":"info","event":"25/07/14 18:04:53 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.828539","level":"info","event":"25/07/14 18:04:53 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.864234","level":"info","event":"25/07/14 18:04:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.903530","level":"info","event":"25/07/14 18:04:53 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.904512","level":"info","event":"25/07/14 18:04:53 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.912934","level":"info","event":"25/07/14 18:04:53 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.917546","level":"info","event":"25/07/14 18:04:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:53.939703","level":"info","event":"25/07/14 18:04:53 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.373992","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.374186","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.473453","level":"info","event":"25/07/14 18:04:54 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.473900","level":"info","event":"25/07/14 18:04:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8/pyspark-12d6461a-a38b-4416-88ee-ccde2bd4490d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.479701","level":"info","event":"25/07/14 18:04:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-4f1c05fe-eff4-4775-adeb-32adb4df84c8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.484956","level":"info","event":"25/07/14 18:04:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-2ae2381c-294e-4751-b63e-7e35892a931d","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.493840","level":"info","event":"25/07/14 18:04:54 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.494027","level":"info","event":"25/07/14 18:04:54 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-14T18:04:54.494098","level":"info","event":"25/07/14 18:04:54 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
