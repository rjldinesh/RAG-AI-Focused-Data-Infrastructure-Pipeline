{"timestamp":"2025-07-31T08:26:59.454627","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-31T08:26:59.454933","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-31T08:27:02.011616","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-31T08:27:02.012362","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.721933","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762702","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762790","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762822","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762857","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762879","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762897","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762914","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762932","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762949","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762966","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.762984","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763002","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763020","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763037","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763076","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763115","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763137","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763154","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763170","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763187","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763205","level":"info","event":"primaryResource         file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763222","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763240","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763258","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763275","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763294","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763310","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763327","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763343","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763361","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763377","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763393","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763409","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763426","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763441","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763457","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763473","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763489","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763504","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763538","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763555","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763571","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.763588","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.823648","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.858125","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.858204","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.859859","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.859901","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.859922","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.860029","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.860339","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-9d958c56-36ea-434a-8215-65f9649bc8c4;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.860391","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.937360","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.950303","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.957929","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.972755","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.980916","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.989995","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:02.996157","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.002707","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016126","level":"info","event":":: resolution report :: resolve 148ms :: artifacts dl 7ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016195","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016222","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016248","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016269","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016287","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016305","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016323","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016435","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016492","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016532","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016554","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016572","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016595","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016613","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016629","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016646","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.016661","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.019332","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-9d958c56-36ea-434a-8215-65f9649bc8c4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.019399","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.022608","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/3ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.117496","level":"info","event":"25/07/31 08:27:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.201926","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.202005","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.202039","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.202061","level":"info","event":"file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.202080","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203003","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203054","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203078","level":"info","event":"(spark.app.submitTime,1753950423195)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203097","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203115","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203132","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203149","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203167","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203184","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203201","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203218","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203234","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203250","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203267","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203283","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203300","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203318","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203334","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203353","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203370","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203386","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203402","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203418","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203434","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203450","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203466","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203483","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203501","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.203537","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.753400","level":"info","event":"INFO:__main__:Starting Spark job...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.817167","level":"info","event":"25/07/31 08:27:03 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.817253","level":"info","event":"25/07/31 08:27:03 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.817334","level":"info","event":"25/07/31 08:27:03 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.825367","level":"info","event":"25/07/31 08:27:03 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.825428","level":"info","event":"25/07/31 08:27:03 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.825532","level":"info","event":"25/07/31 08:27:03 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.825663","level":"info","event":"25/07/31 08:27:03 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.834523","level":"info","event":"25/07/31 08:27:03 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.837688","level":"info","event":"25/07/31 08:27:03 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.838346","level":"info","event":"25/07/31 08:27:03 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.863050","level":"info","event":"25/07/31 08:27:03 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.863137","level":"info","event":"25/07/31 08:27:03 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.863234","level":"info","event":"25/07/31 08:27:03 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.863396","level":"info","event":"25/07/31 08:27:03 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.863469","level":"info","event":"25/07/31 08:27:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.965294","level":"info","event":"25/07/31 08:27:03 INFO Utils: Successfully started service 'sparkDriver' on port 43133.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.978499","level":"info","event":"25/07/31 08:27:03 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.992053","level":"info","event":"25/07/31 08:27:03 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.998785","level":"info","event":"25/07/31 08:27:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:03.998923","level":"info","event":"25/07/31 08:27:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.000582","level":"info","event":"25/07/31 08:27:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.009875","level":"info","event":"25/07/31 08:27:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5fc3bd9f-dd58-47a6-a84e-ac16cc1a09dd","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.015091","level":"info","event":"25/07/31 08:27:04 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.021296","level":"info","event":"25/07/31 08:27:04 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.077572","level":"info","event":"25/07/31 08:27:04 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.104118","level":"info","event":"25/07/31 08:27:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.118736","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://05a2169a22bf:43133/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.118827","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://05a2169a22bf:43133/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.118905","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://05a2169a22bf:43133/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.118993","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://05a2169a22bf:43133/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.119079","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://05a2169a22bf:43133/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.119224","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://05a2169a22bf:43133/jars/org.tukaani_xz-1.9.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.119282","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://05a2169a22bf:43133/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.119347","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://05a2169a22bf:43133/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.120351","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://05a2169a22bf:43133/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.120775","level":"info","event":"25/07/31 08:27:04 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/userFiles-e4974371-0efb-4a9e-b1a0-3565de630d1e/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.128722","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://05a2169a22bf:43133/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.128811","level":"info","event":"25/07/31 08:27:04 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/userFiles-e4974371-0efb-4a9e-b1a0-3565de630d1e/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.317107","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://05a2169a22bf:43133/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.317284","level":"info","event":"25/07/31 08:27:04 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/userFiles-e4974371-0efb-4a9e-b1a0-3565de630d1e/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.319267","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://05a2169a22bf:43133/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.319328","level":"info","event":"25/07/31 08:27:04 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/userFiles-e4974371-0efb-4a9e-b1a0-3565de630d1e/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.325336","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://05a2169a22bf:43133/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.325416","level":"info","event":"25/07/31 08:27:04 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/userFiles-e4974371-0efb-4a9e-b1a0-3565de630d1e/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.327943","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://05a2169a22bf:43133/files/org.tukaani_xz-1.9.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.328009","level":"info","event":"25/07/31 08:27:04 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/userFiles-e4974371-0efb-4a9e-b1a0-3565de630d1e/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.330107","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://05a2169a22bf:43133/files/io.delta_delta-storage-3.1.0.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.330162","level":"info","event":"25/07/31 08:27:04 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/userFiles-e4974371-0efb-4a9e-b1a0-3565de630d1e/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.331943","level":"info","event":"25/07/31 08:27:04 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://05a2169a22bf:43133/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1753950423813","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.332047","level":"info","event":"25/07/31 08:27:04 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/userFiles-e4974371-0efb-4a9e-b1a0-3565de630d1e/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.443959","level":"info","event":"25/07/31 08:27:04 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.475074","level":"info","event":"25/07/31 08:27:04 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.6:7077 after 18 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.538939","level":"info","event":"25/07/31 08:27:04 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250731082704-0024","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.539428","level":"info","event":"25/07/31 08:27:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250731082704-0024/0 on worker-20250731074315-172.18.0.8-42239 (172.18.0.8:42239) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.540435","level":"info","event":"25/07/31 08:27:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20250731082704-0024/0 on hostPort 172.18.0.8:42239 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.549966","level":"info","event":"25/07/31 08:27:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44971.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.550049","level":"info","event":"25/07/31 08:27:04 INFO NettyBlockTransferService: Server created on 05a2169a22bf:44971","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.550992","level":"info","event":"25/07/31 08:27:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.558067","level":"info","event":"25/07/31 08:27:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 05a2169a22bf, 44971, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.559652","level":"info","event":"25/07/31 08:27:04 INFO BlockManagerMasterEndpoint: Registering block manager 05a2169a22bf:44971 with 434.4 MiB RAM, BlockManagerId(driver, 05a2169a22bf, 44971, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.560682","level":"info","event":"25/07/31 08:27:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 05a2169a22bf, 44971, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.565413","level":"info","event":"25/07/31 08:27:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 05a2169a22bf, 44971, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.593242","level":"info","event":"25/07/31 08:27:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731082704-0024/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.723487","level":"info","event":"25/07/31 08:27:04 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.861283","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.861372","level":"info","event":"INFO:__main__:Reading parquet data from s3a://activefence-bucket/bbc_tech/bronze","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.865315","level":"info","event":"25/07/31 08:27:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:04.866332","level":"info","event":"25/07/31 08:27:04 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:05.313592","level":"info","event":"25/07/31 08:27:05 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:05.319263","level":"info","event":"25/07/31 08:27:05 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:05.319355","level":"info","event":"25/07/31 08:27:05 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:05.786978","level":"info","event":"25/07/31 08:27:05 INFO InMemoryFileIndex: It took 41 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:05.895492","level":"info","event":"25/07/31 08:27:05 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:48478) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:05.924329","level":"info","event":"25/07/31 08:27:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:38377 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.8, 38377, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:05.994002","level":"info","event":"25/07/31 08:27:05 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.003171","level":"info","event":"25/07/31 08:27:06 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.003452","level":"info","event":"25/07/31 08:27:06 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.003622","level":"info","event":"25/07/31 08:27:06 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.004125","level":"info","event":"25/07/31 08:27:06 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.006677","level":"info","event":"25/07/31 08:27:06 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.036271","level":"info","event":"25/07/31 08:27:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 108.3 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.075898","level":"info","event":"25/07/31 08:27:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.079775","level":"info","event":"25/07/31 08:27:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 05a2169a22bf:44971 (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.082347","level":"info","event":"25/07/31 08:27:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.097683","level":"info","event":"25/07/31 08:27:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:06.098273","level":"info","event":"25/07/31 08:27:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:07.224773","level":"info","event":"25/07/31 08:27:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10672 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:07.442657","level":"info","event":"25/07/31 08:27:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:38377 (size: 39.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.204221","level":"info","event":"25/07/31 08:27:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 991 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.205100","level":"info","event":"25/07/31 08:27:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.208060","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 2.193 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.209014","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.209095","level":"info","event":"25/07/31 08:27:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.209918","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 2.215817 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.449251","level":"info","event":"25/07/31 08:27:08 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 05a2169a22bf:44971 in memory (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.453768","level":"info","event":"25/07/31 08:27:08 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.8:38377 in memory (size: 39.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550328","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550407","level":"info","event":"|-- article_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550435","level":"info","event":"|-- title: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550455","level":"info","event":"|-- pub_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550487","level":"info","event":"|-- summary: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550532","level":"info","event":"|-- load_timestamp: timestamp_ntz (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550553","level":"info","event":"|-- year_month: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550573","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550597","level":"info","event":"INFO:__main__:Input dataframe schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.550614","level":"info","event":"None","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.755152","level":"info","event":"25/07/31 08:27:08 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.755727","level":"info","event":"25/07/31 08:27:08 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.756064","level":"info","event":"25/07/31 08:27:08 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.908901","level":"info","event":"25/07/31 08:27:08 INFO CodeGenerator: Code generated in 78.5465 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.924033","level":"info","event":"25/07/31 08:27:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.930229","level":"info","event":"25/07/31 08:27:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.930547","level":"info","event":"25/07/31 08:27:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 05a2169a22bf:44971 (size: 36.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.931108","level":"info","event":"25/07/31 08:27:08 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.938293","level":"info","event":"25/07/31 08:27:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 33707727 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.962163","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.964373","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.964615","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.964682","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.964919","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.965367","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.978879","level":"info","event":"25/07/31 08:27:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.982025","level":"info","event":"25/07/31 08:27:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.982482","level":"info","event":"25/07/31 08:27:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 05a2169a22bf:44971 (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.982848","level":"info","event":"25/07/31 08:27:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.983714","level":"info","event":"25/07/31 08:27:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.983756","level":"info","event":"25/07/31 08:27:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.987256","level":"info","event":"25/07/31 08:27:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 12350 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:08.987543","level":"info","event":"25/07/31 08:27:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 12350 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.010755","level":"info","event":"25/07/31 08:27:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.8:38377 (size: 7.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.223311","level":"info","event":"25/07/31 08:27:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:38377 (size: 36.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.411473","level":"info","event":"25/07/31 08:27:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 424 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.411836","level":"info","event":"25/07/31 08:27:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 427 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.411903","level":"info","event":"25/07/31 08:27:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.412816","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.446 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.413035","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.413252","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.413585","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.413828","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.430884","level":"info","event":"25/07/31 08:27:09 INFO CodeGenerator: Code generated in 5.204708 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.442052","level":"info","event":"25/07/31 08:27:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.446371","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.446434","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.446460","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.446614","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.446853","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.450218","level":"info","event":"25/07/31 08:27:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.453362","level":"info","event":"25/07/31 08:27:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.453797","level":"info","event":"25/07/31 08:27:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 05a2169a22bf:44971 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.454033","level":"info","event":"25/07/31 08:27:09 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 05a2169a22bf:44971 in memory (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.454163","level":"info","event":"25/07/31 08:27:09 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.454561","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.454615","level":"info","event":"25/07/31 08:27:09 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.455492","level":"info","event":"25/07/31 08:27:09 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.8:38377 in memory (size: 7.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.457009","level":"info","event":"25/07/31 08:27:09 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.466031","level":"info","event":"25/07/31 08:27:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:38377 (size: 5.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.475860","level":"info","event":"25/07/31 08:27:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:48478","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.523502","level":"info","event":"25/07/31 08:27:09 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 67 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.523603","level":"info","event":"25/07/31 08:27:09 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.524235","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.074 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.524302","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.524333","level":"info","event":"25/07/31 08:27:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.524703","level":"info","event":"25/07/31 08:27:09 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.082482 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.528104","level":"info","event":"INFO:__main__:Number of rows read from bronze layer: 8362","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.645808","level":"info","event":"25/07/31 08:27:09 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:09.808729","level":"info","event":"25/07/31 08:27:09 INFO DeltaLog: Loading version 12 starting from checkpoint version 10.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.375451","level":"info","event":"25/07/31 08:27:10 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20494)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.375551","level":"info","event":"25/07/31 08:27:10 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20494)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.397159","level":"info","event":"25/07/31 08:27:10 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 2, totalFileSize: 4816)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.474234","level":"info","event":"25/07/31 08:27:10 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.478469","level":"info","event":"25/07/31 08:27:10 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(checkpointMetadata.version),IsNotNull(sidecar.path))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.478692","level":"info","event":"25/07/31 08:27:10 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(checkpointMetadata#83.version) OR isnotnull(sidecar#84.path))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.480228","level":"info","event":"25/07/31 08:27:10 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.480431","level":"info","event":"25/07/31 08:27:10 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(protocol.minReaderVersion),IsNotNull(metaData.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.480521","level":"info","event":"25/07/31 08:27:10 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#75.minReaderVersion) OR isnotnull(metaData#74.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.481242","level":"info","event":"25/07/31 08:27:10 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.481433","level":"info","event":"25/07/31 08:27:10 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.481533","level":"info","event":"25/07/31 08:27:10 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#108.minReaderVersion) OR isnotnull(metaData#107.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.527378","level":"info","event":"25/07/31 08:27:10 INFO CodeGenerator: Code generated in 30.057042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.531093","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 209.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.539576","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.539960","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 05a2169a22bf:44971 (size: 37.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.540484","level":"info","event":"25/07/31 08:27:10 INFO SparkContext: Created broadcast 4 from $anonfun$submit$1 at FutureTask.java:264","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.540588","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 05a2169a22bf:44971 in memory (size: 5.9 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.542076","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:38377 in memory (size: 5.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.542357","level":"info","event":"25/07/31 08:27:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.551394","level":"info","event":"25/07/31 08:27:10 INFO SparkContext: Starting job: $anonfun$submit$1 at FutureTask.java:264","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.551928","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Got job 3 ($anonfun$submit$1 at FutureTask.java:264) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.551975","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$submit$1 at FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.551998","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.552129","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.552323","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[12] at $anonfun$submit$1 at FutureTask.java:264), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.552578","level":"info","event":"25/07/31 08:27:10 INFO CodeGenerator: Code generated in 54.457916 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.553352","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 25.8 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.553912","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.554202","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 05a2169a22bf:44971 (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.554498","level":"info","event":"25/07/31 08:27:10 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.554759","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[12] at $anonfun$submit$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.554794","level":"info","event":"25/07/31 08:27:10 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.555306","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 210.4 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.555760","level":"info","event":"25/07/31 08:27:10 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11180 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.558934","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.559319","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 05a2169a22bf:44971 (size: 37.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.559862","level":"info","event":"25/07/31 08:27:10 INFO SparkContext: Created broadcast 6 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.560328","level":"info","event":"25/07/31 08:27:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.562657","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:38377 (size: 8.8 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.590654","level":"info","event":"25/07/31 08:27:10 INFO CodeGenerator: Code generated in 24.848834 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.592150","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 206.0 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.595646","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.596125","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 05a2169a22bf:44971 (size: 36.5 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.596603","level":"info","event":"25/07/31 08:27:10 INFO SparkContext: Created broadcast 7 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.603495","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:38377 (size: 37.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.604110","level":"info","event":"25/07/31 08:27:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4196712 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.633146","level":"info","event":"25/07/31 08:27:10 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.634160","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Got job 4 (toString at String.java:4220) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.634221","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Final stage: ResultStage 5 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.634249","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.634328","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.634633","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.636351","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 85.9 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.636999","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.637392","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 05a2169a22bf:44971 (size: 25.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.637721","level":"info","event":"25/07/31 08:27:10 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.637987","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.638026","level":"info","event":"25/07/31 08:27:10 INFO TaskSchedulerImpl: Adding task set 5.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.639304","level":"info","event":"25/07/31 08:27:10 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11289 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.646372","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:38377 (size: 25.0 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.651570","level":"info","event":"25/07/31 08:27:10 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11275 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.652564","level":"info","event":"25/07/31 08:27:10 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 97 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.652685","level":"info","event":"25/07/31 08:27:10 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.653091","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: ResultStage 4 ($anonfun$submit$1 at FutureTask.java:264) finished in 0.100 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.653233","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.653291","level":"info","event":"25/07/31 08:27:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.654055","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Job 3 finished: $anonfun$submit$1 at FutureTask.java:264, took 0.101983 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.727582","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:38377 (size: 37.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.776897","level":"info","event":"25/07/31 08:27:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:38377 (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.808161","level":"info","event":"25/07/31 08:27:10 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 7) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 11275 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.808479","level":"info","event":"25/07/31 08:27:10 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 157 ms on 172.18.0.8 (executor 0) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.830748","level":"info","event":"25/07/31 08:27:10 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 7) in 23 ms on 172.18.0.8 (executor 0) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.872798","level":"info","event":"25/07/31 08:27:10 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 234 ms on 172.18.0.8 (executor 0) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.872886","level":"info","event":"25/07/31 08:27:10 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.873479","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: ResultStage 5 (toString at String.java:4220) finished in 0.238 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.873730","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.873773","level":"info","event":"25/07/31 08:27:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.874044","level":"info","event":"25/07/31 08:27:10 INFO DAGScheduler: Job 4 finished: toString at String.java:4220, took 0.240775 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.905105","level":"info","event":"25/07/31 08:27:10 INFO CodeGenerator: Code generated in 20.830042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.908940","level":"info","event":"25/07/31 08:27:10 INFO Snapshot: [tableId=bb61e43c-61f4-4fd6-a3df-84a77f09476d] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=12, metadata=Metadata(934fe67a-3cdb-4bd9-9244-c2df2ca4d973,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930718246)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,12,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000011.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1753949807621; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=66136d252fe95f1d80e74adc9058826b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000012.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1753950234834; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=1249295f95736346582592cd2ef28df7 versionId=null),UninitializedV1OrV2ParquetCheckpointProvider(10,S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000010.checkpoint.parquet; isDirectory=false; length=20494; replication=1; blocksize=33554432; modification_time=1753949309810; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c5c8a1e77e57133f67f860751c3a8633 versionId=null,s3a://activefence-bucket/bbc_tech/silver/_delta_log,Some(LastCheckpointInfo(10,23,None,Some(20494),Some(2),Some(StructType(StructField(txn,StructType(StructField(appId,StringType,true),StructField(version,LongType,true),StructField(lastUpdated,LongType,true)),true),StructField(add,StructType(StructField(path,StringType,true),StructField(partitionValues,MapType(StringType,StringType,true),true),StructField(size,LongType,true),StructField(modificationTime,LongType,true),StructField(dataChange,BooleanType,true),StructField(tags,MapType(StringType,StringType,true),true),StructField(deletionVector,StructType(StructField(storageType,StringType,true),StructField(pathOrInlineDv,StringType,true),StructField(offset,IntegerType,true),StructField(sizeInBytes,IntegerType,true),StructField(cardinality,LongType,true),StructField(maxRowIndex,LongType,true)),true),StructField(baseRowId,LongType,true),StructField(defaultRowCommitVersion,LongType,true),StructField(clusteringProvider,StringType,true),StructField(stats,StringType,true)),true),StructField(remove,StructType(StructField(path,StringType,true),StructField(deletionTimestamp,LongType,true),StructField(dataChange,BooleanType,true),StructField(extendedFileMetadata,BooleanType,true),StructField(partitionValues,MapType(StringType,StringType,true),true),StructField(size,LongType,true),StructField(deletionVector,StructType(StructField(storageType,StringType,true),StructField(pathOrInlineDv,StringType,true),StructField(offset,IntegerType,true),StructField(sizeInBytes,IntegerType,true),StructField(cardinality,LongType,true),StructField(maxRowIndex,LongType,true)),true),StructField(baseRowId,LongType,true),StructField(defaultRowCommitVersion,LongType,true)),true),StructField(metaData,StructType(StructField(id,StringType,true),StructField(name,StringType,true),StructField(description,StringType,true),StructField(format,StructType(StructField(provider,StringType,true),StructField(options,MapType(StringType,StringType,true),true)),true),StructField(schemaString,StringType,true),StructField(partitionColumns,ArrayType(StringType,true),true),StructField(configuration,MapType(StringType,StringType,true),true),StructField(createdTime,LongType,true)),true),StructField(protocol,StructType(StructField(minReaderVersion,IntegerType,true),StructField(minWriterVersion,IntegerType,true),StructField(readerFeatures,ArrayType(StringType,true),true),StructField(writerFeatures,ArrayType(StringType,true),true)),true),StructField(domainMetadata,StructType(StructField(domain,StringType,true),StructField(configuration,StringType,true),StructField(removed,BooleanType,true)),true))),None,Some(e938afa7d730e475b25c59ce6679c1e1)))),1753950234834), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:10.993332","level":"info","event":"25/07/31 08:27:10 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Compute snapshot for version: 12","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.000114","level":"info","event":"25/07/31 08:27:10 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 205.7 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.003352","level":"info","event":"25/07/31 08:27:11 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.003636","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 05a2169a22bf:44971 (size: 36.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.004021","level":"info","event":"25/07/31 08:27:11 INFO SparkContext: Created broadcast 9 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.010327","level":"info","event":"25/07/31 08:27:11 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20494)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.229585","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 05a2169a22bf:44971 in memory (size: 37.3 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.230914","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.8:38377 in memory (size: 37.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.235059","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 05a2169a22bf:44971 in memory (size: 37.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.236023","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.8:38377 in memory (size: 37.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.239296","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 05a2169a22bf:44971 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.240232","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:38377 in memory (size: 8.8 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.243407","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 05a2169a22bf:44971 in memory (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.244594","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.8:38377 in memory (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.247581","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 05a2169a22bf:44971 in memory (size: 25.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.248424","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.8:38377 in memory (size: 25.0 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.257919","level":"info","event":"25/07/31 08:27:11 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.258010","level":"info","event":"25/07/31 08:27:11 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.258039","level":"info","event":"25/07/31 08:27:11 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.258545","level":"info","event":"25/07/31 08:27:11 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.258733","level":"info","event":"25/07/31 08:27:11 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.258795","level":"info","event":"25/07/31 08:27:11 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.267591","level":"info","event":"25/07/31 08:27:11 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.347848","level":"info","event":"25/07/31 08:27:11 INFO CodeGenerator: Code generated in 53.727959 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.351028","level":"info","event":"25/07/31 08:27:11 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 223.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.354257","level":"info","event":"25/07/31 08:27:11 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 39.4 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.354552","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 05a2169a22bf:44971 (size: 39.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.355030","level":"info","event":"25/07/31 08:27:11 INFO SparkContext: Created broadcast 10 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.355546","level":"info","event":"25/07/31 08:27:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.392164","level":"info","event":"25/07/31 08:27:11 INFO CodeGenerator: Code generated in 20.1815 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.393371","level":"info","event":"25/07/31 08:27:11 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 206.0 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.396318","level":"info","event":"25/07/31 08:27:11 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.396634","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 05a2169a22bf:44971 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.397052","level":"info","event":"25/07/31 08:27:11 INFO SparkContext: Created broadcast 11 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.397494","level":"info","event":"25/07/31 08:27:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4196712 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.400540","level":"info","event":"25/07/31 08:27:11 INFO DAGScheduler: Registering RDD 28 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.400651","level":"info","event":"25/07/31 08:27:11 INFO DAGScheduler: Got map stage job 5 (save at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.400683","level":"info","event":"25/07/31 08:27:11 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.400703","level":"info","event":"25/07/31 08:27:11 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.400793","level":"info","event":"25/07/31 08:27:11 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.400962","level":"info","event":"25/07/31 08:27:11 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.403595","level":"info","event":"25/07/31 08:27:11 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 241.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.404384","level":"info","event":"25/07/31 08:27:11 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.404658","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 05a2169a22bf:44971 (size: 62.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.404920","level":"info","event":"25/07/31 08:27:11 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.405179","level":"info","event":"25/07/31 08:27:11 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.405244","level":"info","event":"25/07/31 08:27:11 INFO TaskSchedulerImpl: Adding task set 6.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.405907","level":"info","event":"25/07/31 08:27:11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.406057","level":"info","event":"25/07/31 08:27:11 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11264 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.414424","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:38377 (size: 62.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.601984","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:38377 (size: 39.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:11.639556","level":"info","event":"25/07/31 08:27:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:38377 (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.089003","level":"info","event":"25/07/31 08:27:12 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 10) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 11264 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.089506","level":"info","event":"25/07/31 08:27:12 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 684 ms on 172.18.0.8 (executor 0) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.094048","level":"info","event":"25/07/31 08:27:12 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 688 ms on 172.18.0.8 (executor 0) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.126878","level":"info","event":"25/07/31 08:27:12 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 10) in 39 ms on 172.18.0.8 (executor 0) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.127048","level":"info","event":"25/07/31 08:27:12 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.128040","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: ShuffleMapStage 6 (save at NativeMethodAccessorImpl.java:0) finished in 0.726 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.128191","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.128277","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.128322","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.128357","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.234049","level":"info","event":"25/07/31 08:27:12 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 05a2169a22bf:44971 in memory (size: 62.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.234180","level":"info","event":"25/07/31 08:27:12 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.8:38377 in memory (size: 62.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.540089","level":"info","event":"25/07/31 08:27:12 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.540444","level":"info","event":"25/07/31 08:27:12 INFO CodeGenerator: Code generated in 279.126042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.641322","level":"info","event":"25/07/31 08:27:12 INFO CodeGenerator: Code generated in 53.425 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.798128","level":"info","event":"25/07/31 08:27:12 INFO CodeGenerator: Code generated in 22.922042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.801426","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: Registering RDD 38 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.801555","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: Got map stage job 6 (save at NativeMethodAccessorImpl.java:0) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.801600","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.801631","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.802842","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.803148","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.820122","level":"info","event":"25/07/31 08:27:12 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 616.4 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.821617","level":"info","event":"25/07/31 08:27:12 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 144.4 KiB, free 432.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.821981","level":"info","event":"25/07/31 08:27:12 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 05a2169a22bf:44971 (size: 144.4 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.822227","level":"info","event":"25/07/31 08:27:12 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.822563","level":"info","event":"25/07/31 08:27:12 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.822621","level":"info","event":"25/07/31 08:27:12 INFO TaskSchedulerImpl: Adding task set 8.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.823602","level":"info","event":"25/07/31 08:27:12 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.823852","level":"info","event":"25/07/31 08:27:12 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 12) (172.18.0.8, executor 0, partition 1, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.835309","level":"info","event":"25/07/31 08:27:12 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:38377 (size: 144.4 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:12.969139","level":"info","event":"25/07/31 08:27:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:48478","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.275893","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_1 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.276104","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_0 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.573398","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 13) (172.18.0.8, executor 0, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.573741","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 750 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.574365","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 14) (172.18.0.8, executor 0, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.574914","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 12) in 751 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.651354","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_2 in memory on 172.18.0.8:38377 (size: 378.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.651565","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_4 in memory on 172.18.0.8:38377 (size: 699.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.688358","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 15) (172.18.0.8, executor 0, partition 6, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.688734","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 13) in 116 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.689130","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 16) (172.18.0.8, executor 0, partition 7, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.689756","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 14) in 115 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.748296","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_6 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.748469","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_7 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.782062","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 17) (172.18.0.8, executor 0, partition 8, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.782689","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 18) (172.18.0.8, executor 0, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.782973","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 15) in 95 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.783401","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 16) in 95 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.840101","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_10 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.840239","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_8 in memory on 172.18.0.8:38377 (size: 305.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.867631","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 19) (172.18.0.8, executor 0, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.867880","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 18) in 85 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.868314","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 20) (172.18.0.8, executor 0, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.868581","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 17) in 87 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.931041","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_11 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.931125","level":"info","event":"25/07/31 08:27:13 INFO BlockManagerInfo: Added rdd_35_12 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.963148","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 21) (172.18.0.8, executor 0, partition 17, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.963455","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 20) in 95 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.963844","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 22) (172.18.0.8, executor 0, partition 21, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:13.964222","level":"info","event":"25/07/31 08:27:13 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 19) in 97 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.014703","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_21 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.014814","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_17 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.034818","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 22.0 in stage 8.0 (TID 23) (172.18.0.8, executor 0, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.035359","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 23.0 in stage 8.0 (TID 24) (172.18.0.8, executor 0, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.035640","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 21) in 73 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.035756","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 22) in 72 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.086285","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_23 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.086374","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_22 in memory on 172.18.0.8:38377 (size: 804.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.110738","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 25.0 in stage 8.0 (TID 25) (172.18.0.8, executor 0, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.110936","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 23.0 in stage 8.0 (TID 24) in 75 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.111338","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 27.0 in stage 8.0 (TID 26) (172.18.0.8, executor 0, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.111609","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 22.0 in stage 8.0 (TID 23) in 77 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.163564","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_27 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.163721","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_25 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.182743","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 30.0 in stage 8.0 (TID 27) (172.18.0.8, executor 0, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.182989","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 27.0 in stage 8.0 (TID 26) in 71 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.183387","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 34.0 in stage 8.0 (TID 28) (172.18.0.8, executor 0, partition 34, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.183725","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 25.0 in stage 8.0 (TID 25) in 73 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.233195","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_30 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.233292","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_34 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.255466","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 37.0 in stage 8.0 (TID 29) (172.18.0.8, executor 0, partition 37, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.255943","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 39.0 in stage 8.0 (TID 30) (172.18.0.8, executor 0, partition 39, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.256126","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 30.0 in stage 8.0 (TID 27) in 73 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.256330","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 34.0 in stage 8.0 (TID 28) in 73 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.301315","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_37 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.301504","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_39 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.320239","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 42.0 in stage 8.0 (TID 31) (172.18.0.8, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.320456","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 37.0 in stage 8.0 (TID 29) in 65 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.320935","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 44.0 in stage 8.0 (TID 32) (172.18.0.8, executor 0, partition 44, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.321250","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 39.0 in stage 8.0 (TID 30) in 66 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.355419","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_44 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.364632","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 45.0 in stage 8.0 (TID 33) (172.18.0.8, executor 0, partition 45, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.364982","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 44.0 in stage 8.0 (TID 32) in 44 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.382338","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_45 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.390128","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 47.0 in stage 8.0 (TID 34) (172.18.0.8, executor 0, partition 47, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.390330","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 45.0 in stage 8.0 (TID 33) in 26 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.407671","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_47 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.420083","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 35) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.420340","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 47.0 in stage 8.0 (TID 34) in 31 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.437288","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_3 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.446576","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 36) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.446907","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 35) in 27 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.466223","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_5 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.472465","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_42 in memory on 172.18.0.8:38377 (size: 562.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.473686","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 37) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.474787","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 36) in 27 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.480388","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 38) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.480683","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 42.0 in stage 8.0 (TID 31) in 161 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.493760","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_9 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.498255","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_13 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.502765","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 39) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.502975","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 37) in 29 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.508297","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 40) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.508498","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 38) in 28 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.521798","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_14 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.523532","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_15 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.530919","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 41) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.531442","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 39) in 29 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.532585","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 42) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.533052","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 40) in 25 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.558585","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_18 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.558678","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_16 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.572612","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 43) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.572880","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 42) in 40 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.573198","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 20.0 in stage 8.0 (TID 44) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.573609","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 41) in 43 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.597643","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_20 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.599113","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_19 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.608992","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 24.0 in stage 8.0 (TID 45) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.609172","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 20.0 in stage 8.0 (TID 44) in 36 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.609647","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 26.0 in stage 8.0 (TID 46) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.609901","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 43) in 37 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.632346","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_26 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.632426","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_24 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.644597","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 28.0 in stage 8.0 (TID 47) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.645133","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 29.0 in stage 8.0 (TID 48) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.645422","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 24.0 in stage 8.0 (TID 45) in 37 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.645788","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 26.0 in stage 8.0 (TID 46) in 36 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.674299","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_28 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.674591","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_29 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.686340","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 31.0 in stage 8.0 (TID 49) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.686562","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 29.0 in stage 8.0 (TID 48) in 42 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.687082","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 32.0 in stage 8.0 (TID 50) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.687185","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 28.0 in stage 8.0 (TID 47) in 43 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.707827","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_31 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.707915","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_32 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.719491","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 33.0 in stage 8.0 (TID 51) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.719690","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 31.0 in stage 8.0 (TID 49) in 33 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.720115","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 35.0 in stage 8.0 (TID 52) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.720272","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 32.0 in stage 8.0 (TID 50) in 34 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.747537","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_35 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.747720","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_33 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.759506","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 36.0 in stage 8.0 (TID 53) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.759755","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 33.0 in stage 8.0 (TID 51) in 40 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.760086","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 38.0 in stage 8.0 (TID 54) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.760276","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 35.0 in stage 8.0 (TID 52) in 41 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.789181","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_36 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.789272","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_38 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.800196","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 40.0 in stage 8.0 (TID 55) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.800441","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 38.0 in stage 8.0 (TID 54) in 41 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.800737","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 41.0 in stage 8.0 (TID 56) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.801052","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 36.0 in stage 8.0 (TID 53) in 41 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.819858","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_40 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.819939","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_41 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.829085","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 43.0 in stage 8.0 (TID 57) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.829313","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 40.0 in stage 8.0 (TID 55) in 30 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.829624","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 46.0 in stage 8.0 (TID 58) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.829994","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 41.0 in stage 8.0 (TID 56) in 29 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.853254","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_43 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.853342","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_46 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.863969","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 48.0 in stage 8.0 (TID 59) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.864218","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 46.0 in stage 8.0 (TID 58) in 35 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.864494","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 49.0 in stage 8.0 (TID 60) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.864772","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 43.0 in stage 8.0 (TID 57) in 36 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.883018","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_48 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.883091","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added rdd_35_49 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.895938","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 49.0 in stage 8.0 (TID 60) in 31 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.896016","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 48.0 in stage 8.0 (TID 59) in 32 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.896041","level":"info","event":"25/07/31 08:27:14 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.896581","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) finished in 2.090 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.896660","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.896710","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.896735","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.896756","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.909393","level":"info","event":"25/07/31 08:27:14 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.909996","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: Got job 7 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.910043","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: Final stage: ResultStage 11 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.910065","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.910136","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.910318","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[41] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.912954","level":"info","event":"25/07/31 08:27:14 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 547.6 KiB, free 432.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.914274","level":"info","event":"25/07/31 08:27:14 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 127.5 KiB, free 432.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.914468","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 05a2169a22bf:44971 (size: 127.5 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.914708","level":"info","event":"25/07/31 08:27:14 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.914844","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.914878","level":"info","event":"25/07/31 08:27:14 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.915504","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 61) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.919911","level":"info","event":"25/07/31 08:27:14 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:38377 (size: 127.5 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.924924","level":"info","event":"25/07/31 08:27:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:48478","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.945783","level":"info","event":"25/07/31 08:27:14 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 61) in 30 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.945853","level":"info","event":"25/07/31 08:27:14 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.946064","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: ResultStage 11 (save at NativeMethodAccessorImpl.java:0) finished in 0.035 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.946174","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.946209","level":"info","event":"25/07/31 08:27:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.946360","level":"info","event":"25/07/31 08:27:14 INFO DAGScheduler: Job 7 finished: save at NativeMethodAccessorImpl.java:0, took 0.036952 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.971684","level":"info","event":"25/07/31 08:27:14 INFO CodeGenerator: Code generated in 19.043917 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:14.973045","level":"info","event":"25/07/31 08:27:14 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.017590","level":"info","event":"25/07/31 08:27:15 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.017654","level":"info","event":"25/07/31 08:27:15 INFO FileSourceStrategy: Pushed Filters: IsNotNull(article_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.017676","level":"info","event":"25/07/31 08:27:15 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(article_id#0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.038919","level":"info","event":"25/07/31 08:27:15 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.054064","level":"info","event":"25/07/31 08:27:15 INFO CodeGenerator: Code generated in 4.295209 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.055691","level":"info","event":"25/07/31 08:27:15 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 208.0 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.059057","level":"info","event":"25/07/31 08:27:15 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.059277","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 05a2169a22bf:44971 (size: 37.1 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.059612","level":"info","event":"25/07/31 08:27:15 INFO SparkContext: Created broadcast 15 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.060187","level":"info","event":"25/07/31 08:27:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 33707727 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.083763","level":"info","event":"25/07/31 08:27:15 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.084172","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Got job 8 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.084234","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Final stage: ResultStage 12 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.084262","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.084283","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.084539","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[44] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.092751","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 05a2169a22bf:44971 in memory (size: 144.4 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.093719","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.8:38377 in memory (size: 144.4 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.097618","level":"info","event":"25/07/31 08:27:15 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 358.2 KiB, free 432.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.098690","level":"info","event":"25/07/31 08:27:15 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 127.9 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.098844","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 05a2169a22bf:44971 (size: 127.9 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.099194","level":"info","event":"25/07/31 08:27:15 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.099388","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[44] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.099430","level":"info","event":"25/07/31 08:27:15 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.100175","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 62) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 12361 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.100213","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 05a2169a22bf:44971 in memory (size: 127.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.100273","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 63) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 12361 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.101355","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.8:38377 in memory (size: 127.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.105309","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.8:38377 (size: 127.9 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.160838","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:38377 (size: 37.1 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.619757","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 62) in 520 ms on 172.18.0.8 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.619843","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 63) in 519 ms on 172.18.0.8 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.619867","level":"info","event":"25/07/31 08:27:15 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.620363","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: ResultStage 12 (save at NativeMethodAccessorImpl.java:0) finished in 0.536 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.620446","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.620468","level":"info","event":"25/07/31 08:27:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.620747","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Job 8 finished: save at NativeMethodAccessorImpl.java:0, took 0.536872 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.621279","level":"info","event":"25/07/31 08:27:15 INFO DeltaFileFormatWriter: Start to commit write Job e8c35654-f67d-478e-9fad-e3eb1016c616.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.621853","level":"info","event":"25/07/31 08:27:15 INFO DeltaFileFormatWriter: Write Job e8c35654-f67d-478e-9fad-e3eb1016c616 committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.622766","level":"info","event":"25/07/31 08:27:15 INFO DeltaFileFormatWriter: Finished processing stats for write job e8c35654-f67d-478e-9fad-e3eb1016c616.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.740481","level":"info","event":"25/07/31 08:27:15 INFO CodeGenerator: Code generated in 29.472542 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.752792","level":"info","event":"25/07/31 08:27:15 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.753421","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Got job 9 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.753481","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Final stage: ResultStage 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.753518","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.753956","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.754111","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[46] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.756374","level":"info","event":"25/07/31 08:27:15 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 697.8 KiB, free 432.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.757473","level":"info","event":"25/07/31 08:27:15 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 160.7 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.757668","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 05a2169a22bf:44971 (size: 160.7 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.757945","level":"info","event":"25/07/31 08:27:15 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.758165","level":"info","event":"25/07/31 08:27:15 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 14 (MapPartitionsRDD[46] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.758217","level":"info","event":"25/07/31 08:27:15 INFO TaskSchedulerImpl: Adding task set 14.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.759088","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 64) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.759204","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 65) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.764596","level":"info","event":"25/07/31 08:27:15 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.8:38377 (size: 160.7 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.851503","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 66) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.851993","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 67) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.852059","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 65) in 92 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.852202","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 64) in 93 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.865481","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 68) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.865712","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 67) in 14 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.865912","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 5.0 in stage 14.0 (TID 69) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.866261","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 66) in 15 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.874178","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 6.0 in stage 14.0 (TID 70) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.874586","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 7.0 in stage 14.0 (TID 71) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.874639","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 5.0 in stage 14.0 (TID 69) in 9 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.874957","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 68) in 9 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.880299","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 8.0 in stage 14.0 (TID 72) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.880388","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 6.0 in stage 14.0 (TID 70) in 7 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.880832","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 9.0 in stage 14.0 (TID 73) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.881126","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 7.0 in stage 14.0 (TID 71) in 6 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.887318","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 10.0 in stage 14.0 (TID 74) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.887624","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 11.0 in stage 14.0 (TID 75) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.887903","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 9.0 in stage 14.0 (TID 73) in 7 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.887966","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 8.0 in stage 14.0 (TID 72) in 8 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.892413","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 12.0 in stage 14.0 (TID 76) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.892794","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 13.0 in stage 14.0 (TID 77) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.892877","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 10.0 in stage 14.0 (TID 74) in 5 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.893048","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 11.0 in stage 14.0 (TID 75) in 5 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.897378","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 14.0 in stage 14.0 (TID 78) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.897749","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 15.0 in stage 14.0 (TID 79) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.897950","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 12.0 in stage 14.0 (TID 76) in 5 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.898097","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 13.0 in stage 14.0 (TID 77) in 5 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.902505","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 16.0 in stage 14.0 (TID 80) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.902821","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 17.0 in stage 14.0 (TID 81) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.902990","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 15.0 in stage 14.0 (TID 79) in 5 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.903121","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 14.0 in stage 14.0 (TID 78) in 5 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.909037","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 18.0 in stage 14.0 (TID 82) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.909216","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 17.0 in stage 14.0 (TID 81) in 7 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.909570","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 19.0 in stage 14.0 (TID 83) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.909777","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 16.0 in stage 14.0 (TID 80) in 7 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.915060","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 20.0 in stage 14.0 (TID 84) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.915233","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 19.0 in stage 14.0 (TID 83) in 6 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.915741","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 21.0 in stage 14.0 (TID 85) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.916120","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 18.0 in stage 14.0 (TID 82) in 7 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.920187","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 22.0 in stage 14.0 (TID 86) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.920368","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 20.0 in stage 14.0 (TID 84) in 6 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.920736","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 23.0 in stage 14.0 (TID 87) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.920956","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 21.0 in stage 14.0 (TID 85) in 5 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.928895","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 24.0 in stage 14.0 (TID 88) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.929027","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 22.0 in stage 14.0 (TID 86) in 9 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.929311","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 25.0 in stage 14.0 (TID 89) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.929563","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 23.0 in stage 14.0 (TID 87) in 9 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.935169","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 26.0 in stage 14.0 (TID 90) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.935499","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 27.0 in stage 14.0 (TID 91) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.935656","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 24.0 in stage 14.0 (TID 88) in 7 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.935831","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 25.0 in stage 14.0 (TID 89) in 6 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.944909","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 28.0 in stage 14.0 (TID 92) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.945240","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 29.0 in stage 14.0 (TID 93) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.945321","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 27.0 in stage 14.0 (TID 91) in 10 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.945447","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 26.0 in stage 14.0 (TID 90) in 11 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.953964","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 30.0 in stage 14.0 (TID 94) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.954135","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 29.0 in stage 14.0 (TID 93) in 9 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.954414","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 31.0 in stage 14.0 (TID 95) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.954756","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 28.0 in stage 14.0 (TID 92) in 10 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.959654","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 32.0 in stage 14.0 (TID 96) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.959903","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 31.0 in stage 14.0 (TID 95) in 5 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.960202","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 33.0 in stage 14.0 (TID 97) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.960396","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 30.0 in stage 14.0 (TID 94) in 7 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.967819","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 34.0 in stage 14.0 (TID 98) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.968090","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 32.0 in stage 14.0 (TID 96) in 8 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.968338","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 35.0 in stage 14.0 (TID 99) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.968574","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 33.0 in stage 14.0 (TID 97) in 9 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.975642","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 36.0 in stage 14.0 (TID 100) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.975775","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 34.0 in stage 14.0 (TID 98) in 8 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.976118","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 37.0 in stage 14.0 (TID 101) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.976349","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 35.0 in stage 14.0 (TID 99) in 8 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.981525","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 38.0 in stage 14.0 (TID 102) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.981665","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 36.0 in stage 14.0 (TID 100) in 6 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.982225","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 39.0 in stage 14.0 (TID 103) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.982459","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 37.0 in stage 14.0 (TID 101) in 7 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.991819","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 40.0 in stage 14.0 (TID 104) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.992134","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Starting task 41.0 in stage 14.0 (TID 105) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.992200","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 38.0 in stage 14.0 (TID 102) in 11 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:15.992365","level":"info","event":"25/07/31 08:27:15 INFO TaskSetManager: Finished task 39.0 in stage 14.0 (TID 103) in 11 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.000461","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 42.0 in stage 14.0 (TID 106) (172.18.0.8, executor 0, partition 42, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.000682","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 40.0 in stage 14.0 (TID 104) in 9 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.001001","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 43.0 in stage 14.0 (TID 107) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.001387","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 41.0 in stage 14.0 (TID 105) in 10 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.008899","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 44.0 in stage 14.0 (TID 108) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.009159","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 42.0 in stage 14.0 (TID 106) in 9 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.009464","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 45.0 in stage 14.0 (TID 109) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.009821","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 43.0 in stage 14.0 (TID 107) in 9 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.016556","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 46.0 in stage 14.0 (TID 110) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.016800","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 44.0 in stage 14.0 (TID 108) in 8 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.017130","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 47.0 in stage 14.0 (TID 111) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.017400","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 45.0 in stage 14.0 (TID 109) in 8 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.024238","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 48.0 in stage 14.0 (TID 112) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.024441","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 46.0 in stage 14.0 (TID 110) in 8 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.024887","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 49.0 in stage 14.0 (TID 113) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.024953","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 47.0 in stage 14.0 (TID 111) in 8 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.034172","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 49.0 in stage 14.0 (TID 113) in 9 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.034249","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 48.0 in stage 14.0 (TID 112) in 11 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.034271","level":"info","event":"25/07/31 08:27:16 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.034592","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: ResultStage 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.280 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.034647","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.034670","level":"info","event":"25/07/31 08:27:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.034846","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Job 9 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.282056 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.043405","level":"info","event":"25/07/31 08:27:16 INFO CodeGenerator: Code generated in 5.123791 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.062110","level":"info","event":"25/07/31 08:27:16 INFO OptimisticTransaction: [tableId=934fe67a,txnId=15a91c0f] Attempting to commit version 13 with 5 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.153608","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 05a2169a22bf:44971 in memory (size: 160.7 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.154474","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.8:38377 in memory (size: 160.7 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.157182","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 05a2169a22bf:44971 in memory (size: 127.9 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.157750","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.8:38377 in memory (size: 127.9 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.179128","level":"info","event":"25/07/31 08:27:16 INFO DeltaLog: Creating a new snapshot v13 for commit version 13","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.179207","level":"info","event":"25/07/31 08:27:16 INFO DeltaLog: Loading version 13 starting from checkpoint version 10.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.183828","level":"info","event":"25/07/31 08:27:16 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 3, totalFileSize: 7224)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.197211","level":"info","event":"25/07/31 08:27:16 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.197289","level":"info","event":"25/07/31 08:27:16 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(protocol.minReaderVersion),IsNotNull(metaData.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.197328","level":"info","event":"25/07/31 08:27:16 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#748.minReaderVersion) OR isnotnull(metaData#747.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.197583","level":"info","event":"25/07/31 08:27:16 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.197614","level":"info","event":"25/07/31 08:27:16 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.197635","level":"info","event":"25/07/31 08:27:16 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#759.minReaderVersion) OR isnotnull(metaData#758.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.204214","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 210.6 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.207367","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.207582","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 05a2169a22bf:44971 (size: 37.5 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.208102","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Created broadcast 18 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.208437","level":"info","event":"25/07/31 08:27:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.215713","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 206.2 KiB, free 432.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.218880","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 432.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.219228","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 05a2169a22bf:44971 (size: 36.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.219744","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Created broadcast 19 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.220351","level":"info","event":"25/07/31 08:27:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6295068 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.226472","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.227124","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Got job 10 (toString at String.java:4220) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.227189","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Final stage: ResultStage 15 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.227217","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.227240","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.227459","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.228337","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 85.9 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.228932","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 432.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.229172","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 05a2169a22bf:44971 (size: 25.0 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.229403","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.229615","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.229667","level":"info","event":"25/07/31 08:27:16 INFO TaskSchedulerImpl: Adding task set 15.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.230188","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 114) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11289 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.230365","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 115) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11434 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.235022","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.8:38377 (size: 25.0 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.239813","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.8:38377 (size: 37.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.241005","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.8:38377 (size: 36.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.266996","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 116) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 11275 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.267254","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 115) in 37 ms on 172.18.0.8 (executor 0) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.277506","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 116) in 11 ms on 172.18.0.8 (executor 0) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.277627","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 114) in 47 ms on 172.18.0.8 (executor 0) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.277656","level":"info","event":"25/07/31 08:27:16 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.277899","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: ResultStage 15 (toString at String.java:4220) finished in 0.050 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.277952","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.277975","level":"info","event":"25/07/31 08:27:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.278101","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Job 10 finished: toString at String.java:4220, took 0.051634 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.280942","level":"info","event":"25/07/31 08:27:16 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=13, metadata=Metadata(934fe67a-3cdb-4bd9-9244-c2df2ca4d973,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930718246)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,13,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000011.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1753949807621; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=66136d252fe95f1d80e74adc9058826b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000012.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1753950234834; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=1249295f95736346582592cd2ef28df7 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000013.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1753950436157; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=06970c32ec0c8289006dc706dfe72d90 versionId=null),org.apache.spark.sql.delta.CheckpointProvider$$anon$2@51676c91,1753950436157), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.281789","level":"info","event":"25/07/31 08:27:16 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=13, metadata=Metadata(934fe67a-3cdb-4bd9-9244-c2df2ca4d973,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1753930718246)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,13,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000011.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1753949807621; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=66136d252fe95f1d80e74adc9058826b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000012.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1753950234834; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=1249295f95736346582592cd2ef28df7 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000013.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1753950436157; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=06970c32ec0c8289006dc706dfe72d90 versionId=null),org.apache.spark.sql.delta.CheckpointProvider$$anon$2@51676c91,1753950436157), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.282167","level":"info","event":"25/07/31 08:27:16 INFO MapPartitionsRDD: Removing RDD 35 from persistence list","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.284975","level":"info","event":"25/07/31 08:27:16 INFO BlockManager: Removing RDD 35","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.291795","level":"info","event":"25/07/31 08:27:16 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Compute snapshot for version: 13","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.292862","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 205.9 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.295691","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.296019","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 05a2169a22bf:44971 (size: 36.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.296420","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Created broadcast 21 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.369984","level":"info","event":"25/07/31 08:27:16 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.370061","level":"info","event":"25/07/31 08:27:16 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.370085","level":"info","event":"25/07/31 08:27:16 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.370362","level":"info","event":"25/07/31 08:27:16 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.370414","level":"info","event":"25/07/31 08:27:16 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.370440","level":"info","event":"25/07/31 08:27:16 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.392449","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 223.3 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.395697","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 39.4 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.395987","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 05a2169a22bf:44971 (size: 39.4 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.396413","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Created broadcast 22 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.396728","level":"info","event":"25/07/31 08:27:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.403796","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 05a2169a22bf:44971 in memory (size: 36.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.404771","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.8:38377 in memory (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.407965","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 05a2169a22bf:44971 in memory (size: 25.0 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.408048","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 206.2 KiB, free 432.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.408501","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.8:38377 in memory (size: 25.0 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.411363","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 05a2169a22bf:44971 in memory (size: 37.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.411442","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 432.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.411769","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 05a2169a22bf:44971 (size: 36.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.412401","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Created broadcast 23 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.412453","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.8:38377 in memory (size: 37.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.412853","level":"info","event":"25/07/31 08:27:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6295068 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.415916","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Registering RDD 62 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.415980","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Got map stage job 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.416005","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Final stage: ShuffleMapStage 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.416025","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.416046","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.416235","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[62] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.417813","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 241.3 KiB, free 432.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.418480","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 432.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.418611","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 05a2169a22bf:44971 (size: 62.1 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.419239","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.419272","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[62] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.419293","level":"info","event":"25/07/31 08:27:16 INFO TaskSchedulerImpl: Adding task set 16.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.419476","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 117) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.419604","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 118) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 11423 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.424266","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.8:38377 (size: 62.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.433716","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.8:38377 (size: 39.4 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.438172","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.8:38377 (size: 36.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.462992","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 119) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 11264 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.463377","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 118) in 44 ms on 172.18.0.8 (executor 0) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.473474","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 117) in 54 ms on 172.18.0.8 (executor 0) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.483954","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 119) in 21 ms on 172.18.0.8 (executor 0) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.484036","level":"info","event":"25/07/31 08:27:16 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.484280","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: ShuffleMapStage 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.068 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.484344","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.484371","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.484391","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.484409","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.552420","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 05a2169a22bf:44971 in memory (size: 62.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.553444","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.8:38377 in memory (size: 62.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.557384","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Registering RDD 72 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 4","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.557457","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Got map stage job 12 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.557487","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Final stage: ShuffleMapStage 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.557526","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.557831","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.558134","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[72] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.561370","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 616.4 KiB, free 431.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.562446","level":"info","event":"25/07/31 08:27:16 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 144.6 KiB, free 431.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.562681","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 05a2169a22bf:44971 (size: 144.6 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.562900","level":"info","event":"25/07/31 08:27:16 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.563129","level":"info","event":"25/07/31 08:27:16 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[72] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.563186","level":"info","event":"25/07/31 08:27:16 INFO TaskSchedulerImpl: Adding task set 18.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.563778","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 120) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.563898","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 121) (172.18.0.8, executor 0, partition 1, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.568304","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.8:38377 (size: 144.6 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.576029","level":"info","event":"25/07/31 08:27:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:48478","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.598389","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_1 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.598479","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_0 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.611155","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 122) (172.18.0.8, executor 0, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.611333","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 120) in 48 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.611768","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 4.0 in stage 18.0 (TID 123) (172.18.0.8, executor 0, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.612006","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 121) in 48 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.646500","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_4 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.648959","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_2 in memory on 172.18.0.8:38377 (size: 378.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.663935","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 6.0 in stage 18.0 (TID 124) (172.18.0.8, executor 0, partition 6, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.664504","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 4.0 in stage 18.0 (TID 123) in 53 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.668345","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 7.0 in stage 18.0 (TID 125) (172.18.0.8, executor 0, partition 7, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.669039","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 122) in 58 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.704849","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_6 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.705200","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_7 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.721489","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 8.0 in stage 18.0 (TID 126) (172.18.0.8, executor 0, partition 8, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.721705","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 6.0 in stage 18.0 (TID 124) in 58 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.722104","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 10.0 in stage 18.0 (TID 127) (172.18.0.8, executor 0, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.722492","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 7.0 in stage 18.0 (TID 125) in 55 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.753768","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_8 in memory on 172.18.0.8:38377 (size: 305.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.754758","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_10 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.767159","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 11.0 in stage 18.0 (TID 128) (172.18.0.8, executor 0, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.767324","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 8.0 in stage 18.0 (TID 126) in 46 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.767856","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 12.0 in stage 18.0 (TID 129) (172.18.0.8, executor 0, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.768118","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 10.0 in stage 18.0 (TID 127) in 46 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.795069","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_11 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.795249","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_12 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.811534","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 14.0 in stage 18.0 (TID 130) (172.18.0.8, executor 0, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.811897","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Starting task 17.0 in stage 18.0 (TID 131) (172.18.0.8, executor 0, partition 17, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.812247","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 12.0 in stage 18.0 (TID 129) in 45 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.812679","level":"info","event":"25/07/31 08:27:16 INFO TaskSetManager: Finished task 11.0 in stage 18.0 (TID 128) in 46 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.910661","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_17 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:16.931134","level":"info","event":"25/07/31 08:27:16 INFO BlockManagerInfo: Added rdd_69_14 in memory on 172.18.0.8:38377 (size: 699.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.384195","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Starting task 21.0 in stage 18.0 (TID 132) (172.18.0.8, executor 0, partition 21, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.409642","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Starting task 22.0 in stage 18.0 (TID 133) (172.18.0.8, executor 0, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.419017","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Finished task 17.0 in stage 18.0 (TID 131) in 574 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.427051","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Finished task 14.0 in stage 18.0 (TID 130) in 577 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.515453","level":"info","event":"25/07/31 08:27:17 INFO BlockManagerInfo: Added rdd_69_22 in memory on 172.18.0.8:38377 (size: 377.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.517124","level":"info","event":"25/07/31 08:27:17 INFO BlockManagerInfo: Added rdd_69_21 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.683888","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Starting task 23.0 in stage 18.0 (TID 134) (172.18.0.8, executor 0, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.686435","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Finished task 22.0 in stage 18.0 (TID 133) in 311 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.710448","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Starting task 25.0 in stage 18.0 (TID 135) (172.18.0.8, executor 0, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.711666","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Finished task 21.0 in stage 18.0 (TID 132) in 347 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.808441","level":"info","event":"25/07/31 08:27:17 INFO BlockManagerInfo: Added rdd_69_25 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.809729","level":"info","event":"25/07/31 08:27:17 INFO BlockManagerInfo: Added rdd_69_23 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.907096","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Starting task 27.0 in stage 18.0 (TID 136) (172.18.0.8, executor 0, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.919144","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Finished task 23.0 in stage 18.0 (TID 134) in 221 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.924688","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Starting task 29.0 in stage 18.0 (TID 137) (172.18.0.8, executor 0, partition 29, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:17.932438","level":"info","event":"25/07/31 08:27:17 INFO TaskSetManager: Finished task 25.0 in stage 18.0 (TID 135) in 199 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.226824","level":"info","event":"25/07/31 08:27:18 INFO BlockManagerInfo: Added rdd_69_29 in memory on 172.18.0.8:38377 (size: 697.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.233893","level":"info","event":"25/07/31 08:27:18 INFO BlockManagerInfo: Added rdd_69_27 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.425720","level":"info","event":"25/07/31 08:27:18 INFO TaskSetManager: Starting task 30.0 in stage 18.0 (TID 138) (172.18.0.8, executor 0, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.428600","level":"info","event":"25/07/31 08:27:18 INFO TaskSetManager: Finished task 27.0 in stage 18.0 (TID 136) in 524 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.429065","level":"info","event":"25/07/31 08:27:18 INFO TaskSetManager: Starting task 34.0 in stage 18.0 (TID 139) (172.18.0.8, executor 0, partition 34, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.429094","level":"info","event":"25/07/31 08:27:18 INFO TaskSetManager: Finished task 29.0 in stage 18.0 (TID 137) in 523 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.792231","level":"info","event":"25/07/31 08:27:18 INFO BlockManagerInfo: Added rdd_69_30 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.804917","level":"info","event":"25/07/31 08:27:18 INFO BlockManagerInfo: Added rdd_69_34 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.964768","level":"info","event":"25/07/31 08:27:18 INFO TaskSetManager: Starting task 37.0 in stage 18.0 (TID 140) (172.18.0.8, executor 0, partition 37, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.980681","level":"info","event":"25/07/31 08:27:18 INFO TaskSetManager: Finished task 34.0 in stage 18.0 (TID 139) in 539 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.981756","level":"info","event":"25/07/31 08:27:18 INFO TaskSetManager: Starting task 39.0 in stage 18.0 (TID 141) (172.18.0.8, executor 0, partition 39, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:18.981798","level":"info","event":"25/07/31 08:27:18 INFO TaskSetManager: Finished task 30.0 in stage 18.0 (TID 138) in 545 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.199220","level":"info","event":"25/07/31 08:27:19 INFO BlockManagerInfo: Added rdd_69_37 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.209613","level":"info","event":"25/07/31 08:27:19 INFO BlockManagerInfo: Added rdd_69_39 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.694133","level":"info","event":"25/07/31 08:27:19 INFO TaskSetManager: Starting task 42.0 in stage 18.0 (TID 142) (172.18.0.8, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.701836","level":"info","event":"25/07/31 08:27:19 INFO TaskSetManager: Finished task 37.0 in stage 18.0 (TID 140) in 740 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.711668","level":"info","event":"25/07/31 08:27:19 INFO TaskSetManager: Starting task 44.0 in stage 18.0 (TID 143) (172.18.0.8, executor 0, partition 44, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.721871","level":"info","event":"25/07/31 08:27:19 INFO TaskSetManager: Finished task 39.0 in stage 18.0 (TID 141) in 752 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.867844","level":"info","event":"25/07/31 08:27:19 INFO BlockManagerInfo: Added rdd_69_44 in memory on 172.18.0.8:38377 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.869335","level":"info","event":"25/07/31 08:27:19 INFO BlockManagerInfo: Added rdd_69_42 in memory on 172.18.0.8:38377 (size: 562.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.949554","level":"info","event":"25/07/31 08:27:19 INFO TaskSetManager: Starting task 45.0 in stage 18.0 (TID 144) (172.18.0.8, executor 0, partition 45, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.950720","level":"info","event":"25/07/31 08:27:19 INFO TaskSetManager: Starting task 47.0 in stage 18.0 (TID 145) (172.18.0.8, executor 0, partition 47, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.950775","level":"info","event":"25/07/31 08:27:19 INFO TaskSetManager: Finished task 42.0 in stage 18.0 (TID 142) in 263 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:19.950801","level":"info","event":"25/07/31 08:27:19 INFO TaskSetManager: Finished task 44.0 in stage 18.0 (TID 143) in 247 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.062685","level":"info","event":"25/07/31 08:27:20 INFO BlockManagerInfo: Added rdd_69_47 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.072533","level":"info","event":"25/07/31 08:27:20 INFO BlockManagerInfo: Added rdd_69_45 in memory on 172.18.0.8:38377 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.151292","level":"info","event":"25/07/31 08:27:20 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 146) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.175534","level":"info","event":"25/07/31 08:27:20 INFO TaskSetManager: Finished task 45.0 in stage 18.0 (TID 144) in 213 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.181154","level":"info","event":"25/07/31 08:27:20 INFO TaskSetManager: Starting task 5.0 in stage 18.0 (TID 147) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.197814","level":"info","event":"25/07/31 08:27:20 INFO TaskSetManager: Finished task 47.0 in stage 18.0 (TID 145) in 226 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.699329","level":"info","event":"25/07/31 08:27:20 INFO BlockManagerInfo: Added rdd_69_5 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.715323","level":"info","event":"25/07/31 08:27:20 INFO BlockManagerInfo: Added rdd_69_3 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.918285","level":"info","event":"25/07/31 08:27:20 INFO TaskSetManager: Starting task 9.0 in stage 18.0 (TID 148) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.922088","level":"info","event":"25/07/31 08:27:20 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 146) in 766 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.934660","level":"info","event":"25/07/31 08:27:20 INFO TaskSetManager: Starting task 13.0 in stage 18.0 (TID 149) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:20.944536","level":"info","event":"25/07/31 08:27:20 INFO TaskSetManager: Finished task 5.0 in stage 18.0 (TID 147) in 772 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.180482","level":"info","event":"25/07/31 08:27:21 INFO BlockManagerInfo: Added rdd_69_13 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.216976","level":"info","event":"25/07/31 08:27:21 INFO BlockManagerInfo: Added rdd_69_9 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.350548","level":"info","event":"25/07/31 08:27:21 INFO TaskSetManager: Starting task 15.0 in stage 18.0 (TID 150) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.363621","level":"info","event":"25/07/31 08:27:21 INFO TaskSetManager: Finished task 13.0 in stage 18.0 (TID 149) in 406 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.408882","level":"info","event":"25/07/31 08:27:21 INFO TaskSetManager: Starting task 16.0 in stage 18.0 (TID 151) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.417693","level":"info","event":"25/07/31 08:27:21 INFO TaskSetManager: Finished task 9.0 in stage 18.0 (TID 148) in 492 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.576663","level":"info","event":"25/07/31 08:27:21 INFO BlockManagerInfo: Added rdd_69_16 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.597976","level":"info","event":"25/07/31 08:27:21 INFO BlockManagerInfo: Added rdd_69_15 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.902027","level":"info","event":"25/07/31 08:27:21 INFO TaskSetManager: Starting task 18.0 in stage 18.0 (TID 152) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.920352","level":"info","event":"25/07/31 08:27:21 INFO TaskSetManager: Finished task 16.0 in stage 18.0 (TID 151) in 502 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.923842","level":"info","event":"25/07/31 08:27:21 INFO TaskSetManager: Starting task 19.0 in stage 18.0 (TID 153) (172.18.0.8, executor 0, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:21.924136","level":"info","event":"25/07/31 08:27:21 INFO TaskSetManager: Finished task 15.0 in stage 18.0 (TID 150) in 582 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:22.208361","level":"info","event":"25/07/31 08:27:22 INFO BlockManagerInfo: Added rdd_69_18 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:22.240913","level":"info","event":"25/07/31 08:27:22 INFO BlockManagerInfo: Added rdd_69_19 in memory on 172.18.0.8:38377 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:22.312625","level":"info","event":"25/07/31 08:27:22 INFO TaskSetManager: Starting task 20.0 in stage 18.0 (TID 154) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:22.315115","level":"info","event":"25/07/31 08:27:22 INFO TaskSetManager: Finished task 19.0 in stage 18.0 (TID 153) in 403 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:22.315829","level":"info","event":"25/07/31 08:27:22 INFO TaskSetManager: Starting task 24.0 in stage 18.0 (TID 155) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:22.327714","level":"info","event":"25/07/31 08:27:22 INFO TaskSetManager: Finished task 18.0 in stage 18.0 (TID 152) in 431 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.849464","level":"info","event":"25/07/31 08:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731082704-0024/0 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.853037","level":"info","event":"25/07/31 08:27:24 INFO StandaloneSchedulerBackend: Executor app-20250731082704-0024/0 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.853177","level":"info","event":"25/07/31 08:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250731082704-0024/1 on worker-20250731074315-172.18.0.8-42239 (172.18.0.8:42239) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.853245","level":"info","event":"25/07/31 08:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20250731082704-0024/1 on hostPort 172.18.0.8:42239 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.856444","level":"info","event":"25/07/31 08:27:24 ERROR TaskSchedulerImpl: Lost executor 0 on 172.18.0.8: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.863016","level":"info","event":"25/07/31 08:27:24 WARN TaskSetManager: Lost task 24.0 in stage 18.0 (TID 155) (172.18.0.8 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.863178","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 3), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.863299","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 29), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.863381","level":"info","event":"25/07/31 08:27:24 WARN TaskSetManager: Lost task 20.0 in stage 18.0 (TID 154) (172.18.0.8 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.863428","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 11), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.863544","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 17), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.863984","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 2), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864025","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 13), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864045","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 37), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864063","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 23), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864081","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 7), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864098","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 16), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864118","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 6), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864150","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 42), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864193","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 22), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864215","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 10), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864232","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 27), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864255","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 47), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864282","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 34), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864300","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 14), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864320","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 9), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.864337","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 1), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865126","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 5), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865208","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 12), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865261","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 0), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865292","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 30), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865323","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 15), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865360","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 21), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865420","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 4), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865443","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 39), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865461","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 19), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865513","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 8), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865552","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 45), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865586","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 25), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865652","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 18), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.865690","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(18, 44), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.869463","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Executor lost: 0 (epoch 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.871706","level":"info","event":"25/07/31 08:27:24 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.871770","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.871794","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_7 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.871814","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_42 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.871926","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_21 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.871951","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_16 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.871967","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.871985","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_37 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872016","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_9 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872048","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_4 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872080","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_29 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872098","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_22 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872123","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872146","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_23 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872163","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872180","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_3 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872195","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872344","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_27 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872378","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_45 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872395","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_15 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872410","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872427","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_30 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872464","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_39 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872495","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_8 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872621","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872661","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_6 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872679","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_17 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872695","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_34 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872711","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872726","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_25 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872742","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_1 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872758","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872887","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_19 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872911","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_47 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872928","level":"info","event":"25/07/31 08:27:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_69_44 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872952","level":"info","event":"25/07/31 08:27:24 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.18.0.8, 38377, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.872986","level":"info","event":"25/07/31 08:27:24 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.873016","level":"info","event":"25/07/31 08:27:24 INFO DAGScheduler: Shuffle files lost for executor: 0 (epoch 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:24.889837","level":"info","event":"25/07/31 08:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250731082704-0024/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:26.309476","level":"info","event":"25/07/31 08:27:26 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:45248) with ID 1,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:26.337245","level":"info","event":"25/07/31 08:27:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:34215 with 1048.8 MiB RAM, BlockManagerId(1, 172.18.0.8, 34215, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:28.468478","level":"info","event":"25/07/31 08:27:28 INFO TaskSetManager: Starting task 44.1 in stage 18.0 (TID 156) (172.18.0.8, executor 1, partition 44, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:28.468990","level":"info","event":"25/07/31 08:27:28 INFO TaskSetManager: Starting task 25.1 in stage 18.0 (TID 157) (172.18.0.8, executor 1, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:28.604516","level":"info","event":"25/07/31 08:27:28 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.8:34215 (size: 144.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.111221","level":"info","event":"25/07/31 08:27:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:45248","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.148612","level":"info","event":"25/07/31 08:27:29 INFO TaskSetManager: Starting task 45.1 in stage 18.0 (TID 158) (172.18.0.8, executor 1, partition 45, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.149060","level":"info","event":"25/07/31 08:27:29 INFO TaskSetManager: Starting task 8.1 in stage 18.0 (TID 159) (172.18.0.8, executor 1, partition 8, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.150724","level":"info","event":"25/07/31 08:27:29 WARN TaskSetManager: Lost task 25.1 in stage 18.0 (TID 157) (172.18.0.8 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=25, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.150807","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.150868","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.150925","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.150987","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151044","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151312","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151414","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151462","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151486","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151511","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151563","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151602","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151656","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151704","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151736","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151764","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151807","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151851","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151886","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151915","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151945","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.151970","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152005","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152034","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152064","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152089","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152124","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152158","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152190","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152210","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152239","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152274","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152316","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152342","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152359","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152393","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152437","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152479","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152529","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152578","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152611","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152802","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152870","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152931","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.152970","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153014","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153049","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153082","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153118","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153166","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153189","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153206","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153223","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153263","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153302","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153339","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153375","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153408","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153429","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153458","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153480","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153498","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153542","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153575","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153604","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153655","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153694","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153745","level":"info","event":"25/07/31 08:27:29 INFO TaskSetManager: task 25.1 in stage 18.0 (TID 157) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153786","level":"info","event":"25/07/31 08:27:29 WARN TaskSetManager: Lost task 44.1 in stage 18.0 (TID 156) (172.18.0.8 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=44, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153829","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 44","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153867","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153902","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153933","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153952","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.153979","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154021","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154061","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154098","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154130","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154161","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154194","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154212","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154236","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154280","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154302","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154319","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154350","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154391","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154420","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154456","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154488","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154507","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154523","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154565","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154608","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154657","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154684","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154731","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154752","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154775","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154820","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154839","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154855","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154872","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154908","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154948","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154968","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.154985","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155001","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155016","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155046","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155082","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155113","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155167","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155213","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155242","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155260","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155298","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155347","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155370","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155386","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155402","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155425","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155461","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155512","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155554","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155597","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155646","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155669","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155686","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155702","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155720","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155748","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155764","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155783","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155821","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155859","level":"info","event":"25/07/31 08:27:29 INFO TaskSetManager: task 44.1 in stage 18.0 (TID 156) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155898","level":"info","event":"25/07/31 08:27:29 INFO DAGScheduler: Marking ShuffleMapStage 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as failed due to a fetch failure from ShuffleMapStage 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155940","level":"info","event":"25/07/31 08:27:29 INFO DAGScheduler: ShuffleMapStage 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) failed in 12.592 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155960","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155976","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.155993","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156010","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156026","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156042","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156058","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156094","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156116","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156132","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156161","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156182","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156210","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156247","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156275","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156292","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156309","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156324","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156340","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156366","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156398","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156418","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156434","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156464","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156481","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156507","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156536","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156569","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156590","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156626","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156665","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156696","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156716","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156731","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156761","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156778","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156794","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156811","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156826","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156842","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156857","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156873","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156888","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156904","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156919","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156935","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156951","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156967","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156982","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.156998","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157013","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157034","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157058","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157074","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157111","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157153","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157183","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157214","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157236","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157252","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157269","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157285","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.157309","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.168419","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.168513","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.168561","level":"info","event":"25/07/31 08:27:29 INFO DAGScheduler: Resubmitting ShuffleMapStage 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) and ShuffleMapStage 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) due to fetch failure","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.171328","level":"info","event":"25/07/31 08:27:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:45248","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.175936","level":"info","event":"25/07/31 08:27:29 WARN TaskSetManager: Lost task 8.1 in stage 18.0 (TID 159) (172.18.0.8 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=8, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176062","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 8","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176144","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176183","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176209","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176231","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176260","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176277","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176296","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176335","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176366","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176408","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176431","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176458","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176479","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176496","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176520","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176544","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176561","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176577","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176593","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176610","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176646","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176663","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176680","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176697","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176713","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176743","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176759","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176775","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176792","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176809","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176825","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176841","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176856","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176872","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176888","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176917","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176936","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176952","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176980","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.176999","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177014","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177030","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177045","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177061","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177077","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177093","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177109","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177125","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177140","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177156","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177172","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177187","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177202","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177219","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177234","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177250","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177266","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177282","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177298","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177314","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177330","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177345","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177361","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177377","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177394","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177411","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177436","level":"info","event":"25/07/31 08:27:29 INFO TaskSetManager: task 8.1 in stage 18.0 (TID 159) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177455","level":"info","event":"25/07/31 08:27:29 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177471","level":"info","event":"25/07/31 08:27:29 WARN TaskSetManager: Lost task 45.1 in stage 18.0 (TID 158) (172.18.0.8 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=45, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177488","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 45","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177504","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177519","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177535","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177552","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177569","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177585","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177601","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177618","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177649","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177666","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177682","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177698","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177714","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177744","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177760","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177776","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177792","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177808","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177824","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177840","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177856","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177871","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177895","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177917","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177934","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177950","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177966","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177983","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.177998","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178014","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178029","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178044","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178059","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178075","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178091","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178107","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178122","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178137","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178158","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178198","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178232","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178252","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178268","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178284","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178316","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178334","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178348","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178364","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178379","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178395","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178410","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178426","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178442","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178458","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178473","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178489","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178505","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178534","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178550","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178566","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178582","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178598","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178614","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178644","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178661","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178678","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178693","level":"info","event":"25/07/31 08:27:29 INFO TaskSetManager: task 45.1 in stage 18.0 (TID 158) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.178721","level":"info","event":"25/07/31 08:27:29 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.361669","level":"info","event":"25/07/31 08:27:29 INFO DAGScheduler: Resubmitting failed stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.362401","level":"info","event":"25/07/31 08:27:29 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[62] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.365343","level":"info","event":"25/07/31 08:27:29 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 241.3 KiB, free 431.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.368022","level":"info","event":"25/07/31 08:27:29 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 431.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.368454","level":"info","event":"25/07/31 08:27:29 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 05a2169a22bf:44971 (size: 62.1 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.369020","level":"info","event":"25/07/31 08:27:29 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.369263","level":"info","event":"25/07/31 08:27:29 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[62] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.369379","level":"info","event":"25/07/31 08:27:29 INFO TaskSchedulerImpl: Adding task set 17.1 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.370224","level":"info","event":"25/07/31 08:27:29 INFO TaskSetManager: Starting task 0.0 in stage 17.1 (TID 160) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 11278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.370370","level":"info","event":"25/07/31 08:27:29 INFO TaskSetManager: Starting task 1.0 in stage 17.1 (TID 161) (172.18.0.8, executor 1, partition 1, PROCESS_LOCAL, 11423 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.381403","level":"info","event":"25/07/31 08:27:29 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.8:34215 (size: 62.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.908614","level":"info","event":"25/07/31 08:27:29 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.8:34215 (size: 39.4 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:29.976811","level":"info","event":"25/07/31 08:27:29 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.8:34215 (size: 36.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.122015","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Starting task 2.0 in stage 17.1 (TID 162) (172.18.0.8, executor 1, partition 2, PROCESS_LOCAL, 11264 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.122591","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Finished task 1.0 in stage 17.1 (TID 161) in 1752 ms on 172.18.0.8 (executor 1) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.123783","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Finished task 0.0 in stage 17.1 (TID 160) in 1754 ms on 172.18.0.8 (executor 1) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.173529","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Finished task 2.0 in stage 17.1 (TID 162) in 59 ms on 172.18.0.8 (executor 1) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.173645","level":"info","event":"25/07/31 08:27:31 INFO TaskSchedulerImpl: Removed TaskSet 17.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.174020","level":"info","event":"25/07/31 08:27:31 INFO DAGScheduler: ShuffleMapStage 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.810 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.174080","level":"info","event":"25/07/31 08:27:31 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.174134","level":"info","event":"25/07/31 08:27:31 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.174185","level":"info","event":"25/07/31 08:27:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 18)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.174242","level":"info","event":"25/07/31 08:27:31 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.174948","level":"info","event":"25/07/31 08:27:31 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[72] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.176014","level":"info","event":"25/07/31 08:27:31 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 18.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.184165","level":"info","event":"25/07/31 08:27:31 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 616.4 KiB, free 430.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.187648","level":"info","event":"25/07/31 08:27:31 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 144.7 KiB, free 430.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.187988","level":"info","event":"25/07/31 08:27:31 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 05a2169a22bf:44971 (size: 144.7 KiB, free: 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.188330","level":"info","event":"25/07/31 08:27:31 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.188747","level":"info","event":"25/07/31 08:27:31 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[72] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.188821","level":"info","event":"25/07/31 08:27:31 INFO TaskSchedulerImpl: Adding task set 18.1 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.189719","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Starting task 0.0 in stage 18.1 (TID 163) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.189878","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Starting task 1.0 in stage 18.1 (TID 164) (172.18.0.8, executor 1, partition 1, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.198610","level":"info","event":"25/07/31 08:27:31 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.8:34215 (size: 144.7 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.212675","level":"info","event":"25/07/31 08:27:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:45248","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.497668","level":"info","event":"25/07/31 08:27:31 INFO BlockManagerInfo: Added rdd_69_1 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.497786","level":"info","event":"25/07/31 08:27:31 INFO BlockManagerInfo: Added rdd_69_0 in memory on 172.18.0.8:34215 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.817177","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Starting task 2.0 in stage 18.1 (TID 165) (172.18.0.8, executor 1, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.817429","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Finished task 1.0 in stage 18.1 (TID 164) in 627 ms on 172.18.0.8 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.817668","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Starting task 4.0 in stage 18.1 (TID 166) (172.18.0.8, executor 1, partition 4, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.818456","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Finished task 0.0 in stage 18.1 (TID 163) in 629 ms on 172.18.0.8 (executor 1) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.925582","level":"info","event":"25/07/31 08:27:31 INFO BlockManagerInfo: Added rdd_69_2 in memory on 172.18.0.8:34215 (size: 378.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.925722","level":"info","event":"25/07/31 08:27:31 INFO BlockManagerInfo: Added rdd_69_4 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.956666","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Starting task 6.0 in stage 18.1 (TID 167) (172.18.0.8, executor 1, partition 6, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.956894","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Finished task 2.0 in stage 18.1 (TID 165) in 140 ms on 172.18.0.8 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.957383","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Starting task 7.0 in stage 18.1 (TID 168) (172.18.0.8, executor 1, partition 7, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:31.957842","level":"info","event":"25/07/31 08:27:31 INFO TaskSetManager: Finished task 4.0 in stage 18.1 (TID 166) in 140 ms on 172.18.0.8 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.037082","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_6 in memory on 172.18.0.8:34215 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.038168","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_7 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.075520","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 8.0 in stage 18.1 (TID 169) (172.18.0.8, executor 1, partition 8, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.075960","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 7.0 in stage 18.1 (TID 168) in 118 ms on 172.18.0.8 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.076589","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 10.0 in stage 18.1 (TID 170) (172.18.0.8, executor 1, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.076690","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 6.0 in stage 18.1 (TID 167) in 120 ms on 172.18.0.8 (executor 1) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.129128","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_8 in memory on 172.18.0.8:34215 (size: 305.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.129226","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_10 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.150763","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 11.0 in stage 18.1 (TID 171) (172.18.0.8, executor 1, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.151256","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 8.0 in stage 18.1 (TID 169) in 77 ms on 172.18.0.8 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.152389","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 12.0 in stage 18.1 (TID 172) (172.18.0.8, executor 1, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.152830","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 10.0 in stage 18.1 (TID 170) in 77 ms on 172.18.0.8 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.200693","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_12 in memory on 172.18.0.8:34215 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.200815","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_11 in memory on 172.18.0.8:34215 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.223064","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 14.0 in stage 18.1 (TID 173) (172.18.0.8, executor 1, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.223335","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 11.0 in stage 18.1 (TID 171) in 73 ms on 172.18.0.8 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.223929","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 17.0 in stage 18.1 (TID 174) (172.18.0.8, executor 1, partition 17, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.224137","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 12.0 in stage 18.1 (TID 172) in 72 ms on 172.18.0.8 (executor 1) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.257660","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_14 in memory on 172.18.0.8:34215 (size: 699.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.257755","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_17 in memory on 172.18.0.8:34215 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.274532","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 21.0 in stage 18.1 (TID 175) (172.18.0.8, executor 1, partition 21, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.274844","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 14.0 in stage 18.1 (TID 173) in 52 ms on 172.18.0.8 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.275339","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 22.0 in stage 18.1 (TID 176) (172.18.0.8, executor 1, partition 22, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.275906","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 17.0 in stage 18.1 (TID 174) in 52 ms on 172.18.0.8 (executor 1) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.303621","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_22 in memory on 172.18.0.8:34215 (size: 377.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.303775","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_21 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.317978","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 23.0 in stage 18.1 (TID 177) (172.18.0.8, executor 1, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.318523","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 25.0 in stage 18.1 (TID 178) (172.18.0.8, executor 1, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.318781","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 21.0 in stage 18.1 (TID 175) in 44 ms on 172.18.0.8 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.319111","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 22.0 in stage 18.1 (TID 176) in 44 ms on 172.18.0.8 (executor 1) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.346045","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_23 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.346155","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_25 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.365829","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 27.0 in stage 18.1 (TID 179) (172.18.0.8, executor 1, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.367078","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 29.0 in stage 18.1 (TID 180) (172.18.0.8, executor 1, partition 29, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.367306","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 23.0 in stage 18.1 (TID 177) in 49 ms on 172.18.0.8 (executor 1) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.367849","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 25.0 in stage 18.1 (TID 178) in 49 ms on 172.18.0.8 (executor 1) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.390720","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_27 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.390851","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_29 in memory on 172.18.0.8:34215 (size: 697.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.407508","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 30.0 in stage 18.1 (TID 181) (172.18.0.8, executor 1, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.408053","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 34.0 in stage 18.1 (TID 182) (172.18.0.8, executor 1, partition 34, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.408199","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 27.0 in stage 18.1 (TID 179) in 42 ms on 172.18.0.8 (executor 1) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.408245","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 29.0 in stage 18.1 (TID 180) in 41 ms on 172.18.0.8 (executor 1) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.440662","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_34 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.440770","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_30 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.454279","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 37.0 in stage 18.1 (TID 183) (172.18.0.8, executor 1, partition 37, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.454952","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 39.0 in stage 18.1 (TID 184) (172.18.0.8, executor 1, partition 39, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.455042","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 34.0 in stage 18.1 (TID 182) in 47 ms on 172.18.0.8 (executor 1) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.455079","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 30.0 in stage 18.1 (TID 181) in 48 ms on 172.18.0.8 (executor 1) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.483682","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_37 in memory on 172.18.0.8:34215 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.483791","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_39 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.493489","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 42.0 in stage 18.1 (TID 185) (172.18.0.8, executor 1, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.493708","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 37.0 in stage 18.1 (TID 183) in 40 ms on 172.18.0.8 (executor 1) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.494181","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 44.0 in stage 18.1 (TID 186) (172.18.0.8, executor 1, partition 44, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.494238","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 39.0 in stage 18.1 (TID 184) in 40 ms on 172.18.0.8 (executor 1) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.515318","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_44 in memory on 172.18.0.8:34215 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.525164","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 45.0 in stage 18.1 (TID 187) (172.18.0.8, executor 1, partition 45, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.525527","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 44.0 in stage 18.1 (TID 186) in 32 ms on 172.18.0.8 (executor 1) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.542295","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_45 in memory on 172.18.0.8:34215 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.561444","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 47.0 in stage 18.1 (TID 188) (172.18.0.8, executor 1, partition 47, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.561859","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 45.0 in stage 18.1 (TID 187) in 37 ms on 172.18.0.8 (executor 1) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.580030","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_47 in memory on 172.18.0.8:34215 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.591207","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 3.0 in stage 18.1 (TID 189) (172.18.0.8, executor 1, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.591607","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 47.0 in stage 18.1 (TID 188) in 30 ms on 172.18.0.8 (executor 1) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.607268","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_3 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.616706","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 5.0 in stage 18.1 (TID 190) (172.18.0.8, executor 1, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.616831","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 3.0 in stage 18.1 (TID 189) in 26 ms on 172.18.0.8 (executor 1) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.632957","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_5 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.641916","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 9.0 in stage 18.1 (TID 191) (172.18.0.8, executor 1, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.642046","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 5.0 in stage 18.1 (TID 190) in 25 ms on 172.18.0.8 (executor 1) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.654122","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_42 in memory on 172.18.0.8:34215 (size: 562.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.657116","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_9 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.664290","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 13.0 in stage 18.1 (TID 192) (172.18.0.8, executor 1, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.664576","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 42.0 in stage 18.1 (TID 185) in 171 ms on 172.18.0.8 (executor 1) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.666478","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 15.0 in stage 18.1 (TID 193) (172.18.0.8, executor 1, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.666907","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 9.0 in stage 18.1 (TID 191) in 25 ms on 172.18.0.8 (executor 1) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.686033","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_13 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.686352","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_15 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.696646","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 16.0 in stage 18.1 (TID 194) (172.18.0.8, executor 1, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.696811","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 15.0 in stage 18.1 (TID 193) in 30 ms on 172.18.0.8 (executor 1) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.697339","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 18.0 in stage 18.1 (TID 195) (172.18.0.8, executor 1, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.697610","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 13.0 in stage 18.1 (TID 192) in 34 ms on 172.18.0.8 (executor 1) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.718403","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_18 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.718491","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_16 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.729326","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 19.0 in stage 18.1 (TID 196) (172.18.0.8, executor 1, partition 19, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.729426","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 16.0 in stage 18.1 (TID 194) in 33 ms on 172.18.0.8 (executor 1) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.729901","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 20.0 in stage 18.1 (TID 197) (172.18.0.8, executor 1, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.730067","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 18.0 in stage 18.1 (TID 195) in 32 ms on 172.18.0.8 (executor 1) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.748733","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_20 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.748842","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_19 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.765003","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 24.0 in stage 18.1 (TID 198) (172.18.0.8, executor 1, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.765283","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 26.0 in stage 18.1 (TID 199) (172.18.0.8, executor 1, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.765499","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 19.0 in stage 18.1 (TID 196) in 36 ms on 172.18.0.8 (executor 1) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.765954","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 20.0 in stage 18.1 (TID 197) in 36 ms on 172.18.0.8 (executor 1) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.787276","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_24 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.787376","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_26 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.799102","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 28.0 in stage 18.1 (TID 200) (172.18.0.8, executor 1, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.799220","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 26.0 in stage 18.1 (TID 199) in 34 ms on 172.18.0.8 (executor 1) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.799481","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 31.0 in stage 18.1 (TID 201) (172.18.0.8, executor 1, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.799820","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 24.0 in stage 18.1 (TID 198) in 35 ms on 172.18.0.8 (executor 1) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.820995","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_31 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.821107","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_28 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.832932","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 32.0 in stage 18.1 (TID 202) (172.18.0.8, executor 1, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.833205","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 28.0 in stage 18.1 (TID 200) in 35 ms on 172.18.0.8 (executor 1) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.833711","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 33.0 in stage 18.1 (TID 203) (172.18.0.8, executor 1, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.833772","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 31.0 in stage 18.1 (TID 201) in 34 ms on 172.18.0.8 (executor 1) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.858994","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_33 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.859108","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_32 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.870293","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 35.0 in stage 18.1 (TID 204) (172.18.0.8, executor 1, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.870806","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 36.0 in stage 18.1 (TID 205) (172.18.0.8, executor 1, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.871043","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 33.0 in stage 18.1 (TID 203) in 37 ms on 172.18.0.8 (executor 1) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.871162","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 32.0 in stage 18.1 (TID 202) in 38 ms on 172.18.0.8 (executor 1) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.891385","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_36 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.891481","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_35 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.900951","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 38.0 in stage 18.1 (TID 206) (172.18.0.8, executor 1, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.901336","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 35.0 in stage 18.1 (TID 204) in 32 ms on 172.18.0.8 (executor 1) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.901436","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 40.0 in stage 18.1 (TID 207) (172.18.0.8, executor 1, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.901996","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 36.0 in stage 18.1 (TID 205) in 31 ms on 172.18.0.8 (executor 1) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.922392","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_38 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.922478","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_40 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.936426","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 41.0 in stage 18.1 (TID 208) (172.18.0.8, executor 1, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.936674","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 43.0 in stage 18.1 (TID 209) (172.18.0.8, executor 1, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.936908","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 40.0 in stage 18.1 (TID 207) in 35 ms on 172.18.0.8 (executor 1) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.937402","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 38.0 in stage 18.1 (TID 206) in 37 ms on 172.18.0.8 (executor 1) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.956810","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_43 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.956898","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_41 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.968077","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 46.0 in stage 18.1 (TID 210) (172.18.0.8, executor 1, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.968423","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 41.0 in stage 18.1 (TID 208) in 33 ms on 172.18.0.8 (executor 1) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.968701","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 48.0 in stage 18.1 (TID 211) (172.18.0.8, executor 1, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.969026","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 43.0 in stage 18.1 (TID 209) in 32 ms on 172.18.0.8 (executor 1) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.984372","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_48 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.984464","level":"info","event":"25/07/31 08:27:32 INFO BlockManagerInfo: Added rdd_69_46 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.993402","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Starting task 49.0 in stage 18.1 (TID 212) (172.18.0.8, executor 1, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.993681","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 46.0 in stage 18.1 (TID 210) in 26 ms on 172.18.0.8 (executor 1) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:32.993905","level":"info","event":"25/07/31 08:27:32 INFO TaskSetManager: Finished task 48.0 in stage 18.1 (TID 211) in 25 ms on 172.18.0.8 (executor 1) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.009133","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Added rdd_69_49 in memory on 172.18.0.8:34215 (size: 46.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.015772","level":"info","event":"25/07/31 08:27:33 INFO TaskSetManager: Finished task 49.0 in stage 18.1 (TID 212) in 22 ms on 172.18.0.8 (executor 1) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.015851","level":"info","event":"25/07/31 08:27:33 INFO TaskSchedulerImpl: Removed TaskSet 18.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.016126","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: ShuffleMapStage 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.837 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.016226","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.016267","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.016306","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.016356","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.037545","level":"info","event":"25/07/31 08:27:33 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.038287","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: Got job 13 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.038347","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: Final stage: ResultStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.038386","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.038420","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.038576","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[75] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.041587","level":"info","event":"25/07/31 08:27:33 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 547.7 KiB, free 430.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.052189","level":"info","event":"25/07/31 08:27:33 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 127.7 KiB, free 430.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.052586","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 05a2169a22bf:44971 (size: 127.7 KiB, free: 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.052884","level":"info","event":"25/07/31 08:27:33 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.053512","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[75] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.053581","level":"info","event":"25/07/31 08:27:33 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.054482","level":"info","event":"25/07/31 08:27:33 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 213) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.055712","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 05a2169a22bf:44971 in memory (size: 144.6 KiB, free: 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.063328","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.8:34215 in memory (size: 144.6 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.063416","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.8:34215 (size: 127.7 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.068131","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 05a2169a22bf:44971 in memory (size: 144.7 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.069420","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.8:34215 in memory (size: 144.7 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.073059","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 05a2169a22bf:44971 in memory (size: 62.1 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.074223","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.8:34215 in memory (size: 62.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.106651","level":"info","event":"25/07/31 08:27:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.8:45248","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.135933","level":"info","event":"25/07/31 08:27:33 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 213) in 81 ms on 172.18.0.8 (executor 1) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.136024","level":"info","event":"25/07/31 08:27:33 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.136460","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: ResultStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.098 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.136587","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.136742","level":"info","event":"25/07/31 08:27:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.136826","level":"info","event":"25/07/31 08:27:33 INFO DAGScheduler: Job 13 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.099027 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.144421","level":"info","event":"25/07/31 08:27:33 INFO Snapshot: [tableId=934fe67a-3cdb-4bd9-9244-c2df2ca4d973] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.163554","level":"info","event":"25/07/31 08:27:33 INFO OptimisticTransaction: [tableId=934fe67a,txnId=15a91c0f] Committed delta #13 to s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.169825","level":"info","event":"INFO:__main__:Data cleaned and loaded to silver layer!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.170812","level":"info","event":"25/07/31 08:27:33 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.181439","level":"info","event":"25/07/31 08:27:33 INFO SparkUI: Stopped Spark web UI at http://05a2169a22bf:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.183402","level":"info","event":"25/07/31 08:27:33 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.183670","level":"info","event":"25/07/31 08:27:33 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.197567","level":"info","event":"25/07/31 08:27:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.228731","level":"info","event":"25/07/31 08:27:33 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.228883","level":"info","event":"25/07/31 08:27:33 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.233187","level":"info","event":"25/07/31 08:27:33 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.236121","level":"info","event":"25/07/31 08:27:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.247116","level":"info","event":"25/07/31 08:27:33 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.403256","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:33.403756","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:34.205435","level":"info","event":"25/07/31 08:27:34 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:34.205602","level":"info","event":"25/07/31 08:27:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:34.207576","level":"info","event":"25/07/31 08:27:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-b440c951-6027-40f1-8c25-44a5052bd741/pyspark-5ca0f7bb-b1f8-4088-ab6e-3ac425ab5f4c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:34.209157","level":"info","event":"25/07/31 08:27:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-8c08eb6b-7bc4-4de2-878c-e9e880ef5352","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:34.213803","level":"info","event":"25/07/31 08:27:34 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:34.213916","level":"info","event":"25/07/31 08:27:34 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-31T08:27:34.213944","level":"info","event":"25/07/31 08:27:34 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
