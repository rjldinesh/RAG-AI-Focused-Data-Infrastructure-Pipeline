{"timestamp":"2025-08-01T09:04:02.536062","level":"warning","event":"\n        OpenLineage support for Airflow version 3.0.2 is REMOVED.\n        For Airflow 2.7 and later, use the native Airflow Openlineage provider package.\n        Documentation can be found at https://airflow.apache.org/docs/apache-airflow-providers-openlineage\n        ","logger":"root"}
{"timestamp":"2025-08-01T09:04:03.084616","level":"warning","event":"No module named 'airflow.providers.dbt'","logger":"openlineage.airflow.utils"}
{"timestamp":"2025-08-01T09:04:03.096247","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-01T09:04:03.097212","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/activefence.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-01T09:04:04.675436","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-01T09:04:04.676937","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.238611","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366168","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366243","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366289","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366314","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366334","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366353","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366371","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366388","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366406","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366423","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366440","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366479","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366496","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366513","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366530","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366546","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366563","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366581","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366596","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366613","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366633","level":"info","event":"primaryResource         file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366652","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366668","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366705","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366724","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366762","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.366783","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.367127","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.367354","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.367839","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.367972","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368067","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368110","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368146","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368181","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368215","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368280","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368316","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368349","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368382","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368415","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368450","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.368483","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.545343","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.677465","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.677565","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.679953","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.682287","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.682368","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.682408","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.682443","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-2664aaff-53b5-4383-8231-052338c8549e;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.682480","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:07.985321","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.018023","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.036476","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.082179","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.120748","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.163293","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.213620","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.240161","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.267443","level":"info","event":":: resolution report :: resolve 565ms :: artifacts dl 23ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.267649","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.267822","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.267925","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.267987","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268088","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268152","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268213","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268270","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268327","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268391","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268452","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268511","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268564","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268610","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268646","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268730","level":"info","event":"|      default     |   9   |   0   |   0   |   1   ||   8   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.268769","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.275734","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-2664aaff-53b5-4383-8231-052338c8549e","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.275852","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.279759","level":"info","event":"0 artifacts copied, 8 already retrieved (0kB/4ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:08.749625","level":"info","event":"25/08/01 09:04:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.134407","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.134564","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.135126","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.135460","level":"info","event":"file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.135505","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138416","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138473","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138509","level":"info","event":"(spark.app.submitTime,1754039049104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138539","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138568","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138589","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138607","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138644","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138664","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138681","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138698","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138713","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138730","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138747","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138764","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138780","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138797","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138814","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138836","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138853","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138870","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138886","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138902","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138918","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138934","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138949","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.138965","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.139785","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:09.139809","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.662681","level":"info","event":"INFO:__main__:Starting Spark job...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.841357","level":"info","event":"25/08/01 09:04:10 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.841607","level":"info","event":"25/08/01 09:04:10 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.841740","level":"info","event":"25/08/01 09:04:10 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.858619","level":"info","event":"25/08/01 09:04:10 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.858698","level":"info","event":"25/08/01 09:04:10 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.859684","level":"info","event":"25/08/01 09:04:10 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.860321","level":"info","event":"25/08/01 09:04:10 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.877985","level":"info","event":"25/08/01 09:04:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.888151","level":"info","event":"25/08/01 09:04:10 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.890945","level":"info","event":"25/08/01 09:04:10 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.948747","level":"info","event":"25/08/01 09:04:10 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.948858","level":"info","event":"25/08/01 09:04:10 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.948889","level":"info","event":"25/08/01 09:04:10 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.948908","level":"info","event":"25/08/01 09:04:10 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:10.948925","level":"info","event":"25/08/01 09:04:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.268237","level":"info","event":"25/08/01 09:04:11 INFO Utils: Successfully started service 'sparkDriver' on port 33581.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.315086","level":"info","event":"25/08/01 09:04:11 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.376316","level":"info","event":"25/08/01 09:04:11 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.403762","level":"info","event":"25/08/01 09:04:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.405662","level":"info","event":"25/08/01 09:04:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.416580","level":"info","event":"25/08/01 09:04:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.465409","level":"info","event":"25/08/01 09:04:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a1ba6905-0bac-41d4-82cd-cc8a394ad318","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.542584","level":"info","event":"25/08/01 09:04:11 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.569446","level":"info","event":"25/08/01 09:04:11 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:11.858416","level":"info","event":"25/08/01 09:04:11 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.064273","level":"info","event":"25/08/01 09:04:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.074475","level":"info","event":"25/08/01 09:04:12 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.100286","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://0baa42e17007:33581/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.100523","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://0baa42e17007:33581/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.100582","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://0baa42e17007:33581/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.100622","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://0baa42e17007:33581/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.100658","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://0baa42e17007:33581/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.100695","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://0baa42e17007:33581/jars/org.tukaani_xz-1.9.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.100789","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://0baa42e17007:33581/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.100836","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://0baa42e17007:33581/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.103095","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://0baa42e17007:33581/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.103686","level":"info","event":"25/08/01 09:04:12 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/userFiles-3400b9c3-ab5e-4d9c-a032-a09b840c0606/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.136526","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://0baa42e17007:33581/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.137059","level":"info","event":"25/08/01 09:04:12 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/userFiles-3400b9c3-ab5e-4d9c-a032-a09b840c0606/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.996940","level":"info","event":"25/08/01 09:04:12 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://0baa42e17007:33581/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:12.997356","level":"info","event":"25/08/01 09:04:12 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/userFiles-3400b9c3-ab5e-4d9c-a032-a09b840c0606/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.002683","level":"info","event":"25/08/01 09:04:13 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://0baa42e17007:33581/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.002740","level":"info","event":"25/08/01 09:04:13 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/userFiles-3400b9c3-ab5e-4d9c-a032-a09b840c0606/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.075387","level":"info","event":"25/08/01 09:04:13 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://0baa42e17007:33581/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.075467","level":"info","event":"25/08/01 09:04:13 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/userFiles-3400b9c3-ab5e-4d9c-a032-a09b840c0606/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.082288","level":"info","event":"25/08/01 09:04:13 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://0baa42e17007:33581/files/org.tukaani_xz-1.9.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.082347","level":"info","event":"25/08/01 09:04:13 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/userFiles-3400b9c3-ab5e-4d9c-a032-a09b840c0606/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.094656","level":"info","event":"25/08/01 09:04:13 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://0baa42e17007:33581/files/io.delta_delta-storage-3.1.0.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.094771","level":"info","event":"25/08/01 09:04:13 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/userFiles-3400b9c3-ab5e-4d9c-a032-a09b840c0606/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.103970","level":"info","event":"25/08/01 09:04:13 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://0baa42e17007:33581/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754039050830","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.104136","level":"info","event":"25/08/01 09:04:13 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/userFiles-3400b9c3-ab5e-4d9c-a032-a09b840c0606/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.323905","level":"info","event":"25/08/01 09:04:13 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.434494","level":"info","event":"25/08/01 09:04:13 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.8:7077 after 66 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.717369","level":"info","event":"25/08/01 09:04:13 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250801090413-0000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.737894","level":"info","event":"25/08/01 09:04:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36885.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.738283","level":"info","event":"25/08/01 09:04:13 INFO NettyBlockTransferService: Server created on 0baa42e17007:36885","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.744895","level":"info","event":"25/08/01 09:04:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.754942","level":"info","event":"25/08/01 09:04:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 0baa42e17007, 36885, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.760400","level":"info","event":"25/08/01 09:04:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801090413-0000/0 on worker-20250801090300-172.18.0.5-36675 (172.18.0.5:36675) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.761204","level":"info","event":"25/08/01 09:04:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801090413-0000/0 on hostPort 172.18.0.5:36675 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.764302","level":"info","event":"25/08/01 09:04:13 INFO BlockManagerMasterEndpoint: Registering block manager 0baa42e17007:36885 with 434.4 MiB RAM, BlockManagerId(driver, 0baa42e17007, 36885, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.773643","level":"info","event":"25/08/01 09:04:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 0baa42e17007, 36885, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:13.778540","level":"info","event":"25/08/01 09:04:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 0baa42e17007, 36885, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:14.019129","level":"info","event":"25/08/01 09:04:14 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:14.071439","level":"info","event":"25/08/01 09:04:14 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:14.633140","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:14.633244","level":"info","event":"INFO:__main__:Reading parquet data from s3a://activefence-bucket/bbc_tech/bronze","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:14.644436","level":"info","event":"25/08/01 09:04:14 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:14.649096","level":"info","event":"25/08/01 09:04:14 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:16.394913","level":"info","event":"25/08/01 09:04:16 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:16.410434","level":"info","event":"25/08/01 09:04:16 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:16.410825","level":"info","event":"25/08/01 09:04:16 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:18.334327","level":"info","event":"25/08/01 09:04:18 INFO InMemoryFileIndex: It took 183 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:19.598816","level":"info","event":"25/08/01 09:04:19 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:60244) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:21.007307","level":"info","event":"25/08/01 09:04:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:43767 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.5, 43767, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:22.241523","level":"info","event":"25/08/01 09:04:22 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:22.869818","level":"info","event":"25/08/01 09:04:22 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:22.873256","level":"info","event":"25/08/01 09:04:22 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:22.876461","level":"info","event":"25/08/01 09:04:22 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:22.876539","level":"info","event":"25/08/01 09:04:22 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:22.891069","level":"info","event":"25/08/01 09:04:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:23.003656","level":"info","event":"25/08/01 09:04:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 108.3 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:23.976103","level":"info","event":"25/08/01 09:04:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:24.213787","level":"info","event":"25/08/01 09:04:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 0baa42e17007:36885 (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:24.399825","level":"info","event":"25/08/01 09:04:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:28.271698","level":"info","event":"25/08/01 09:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:28.286552","level":"info","event":"25/08/01 09:04:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:34.087834","level":"info","event":"25/08/01 09:04:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10672 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:34.552276","level":"info","event":"25/08/01 09:04:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:43767 (size: 39.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:37.633022","level":"info","event":"25/08/01 09:04:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3599 ms on 172.18.0.5 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:37.635707","level":"info","event":"25/08/01 09:04:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:37.647380","level":"info","event":"25/08/01 09:04:37 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 14.714 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:37.647435","level":"info","event":"25/08/01 09:04:37 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:37.647463","level":"info","event":"25/08/01 09:04:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:37.662207","level":"info","event":"25/08/01 09:04:37 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 15.411317 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.529265","level":"info","event":"25/08/01 09:04:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:43767 in memory (size: 39.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.532030","level":"info","event":"25/08/01 09:04:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 0baa42e17007:36885 in memory (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.888934","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889041","level":"info","event":"|-- article_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889091","level":"info","event":"|-- title: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889116","level":"info","event":"|-- pub_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889136","level":"info","event":"|-- summary: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889154","level":"info","event":"|-- load_timestamp: timestamp_ntz (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889172","level":"info","event":"|-- year_month: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889190","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889213","level":"info","event":"INFO:__main__:Input dataframe schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:38.889230","level":"info","event":"None","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:39.537907","level":"info","event":"25/08/01 09:04:39 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:39.539610","level":"info","event":"25/08/01 09:04:39 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:39.542196","level":"info","event":"25/08/01 09:04:39 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.003898","level":"info","event":"25/08/01 09:04:40 INFO CodeGenerator: Code generated in 255.997459 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.048130","level":"info","event":"25/08/01 09:04:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.065918","level":"info","event":"25/08/01 09:04:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.070308","level":"info","event":"25/08/01 09:04:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 0baa42e17007:36885 (size: 36.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.072866","level":"info","event":"25/08/01 09:04:40 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.089931","level":"info","event":"25/08/01 09:04:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 37921409 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.142669","level":"info","event":"25/08/01 09:04:40 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.155789","level":"info","event":"25/08/01 09:04:40 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.155885","level":"info","event":"25/08/01 09:04:40 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.155928","level":"info","event":"25/08/01 09:04:40 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.155964","level":"info","event":"25/08/01 09:04:40 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.157519","level":"info","event":"25/08/01 09:04:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.221981","level":"info","event":"25/08/01 09:04:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.230194","level":"info","event":"25/08/01 09:04:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.235929","level":"info","event":"25/08/01 09:04:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 0baa42e17007:36885 (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.236049","level":"info","event":"25/08/01 09:04:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.237479","level":"info","event":"25/08/01 09:04:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.237945","level":"info","event":"25/08/01 09:04:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.246766","level":"info","event":"25/08/01 09:04:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 12509 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.247445","level":"info","event":"25/08/01 09:04:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 12509 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.297269","level":"info","event":"25/08/01 09:04:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:43767 (size: 7.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:40.818168","level":"info","event":"25/08/01 09:04:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:43767 (size: 36.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.405029","level":"info","event":"25/08/01 09:04:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1163 ms on 172.18.0.5 (executor 0) (1/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.408764","level":"info","event":"25/08/01 09:04:41 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1161 ms on 172.18.0.5 (executor 0) (2/2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.408876","level":"info","event":"25/08/01 09:04:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.411385","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.249 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.411482","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.411695","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.411826","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.411934","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.485427","level":"info","event":"25/08/01 09:04:41 INFO CodeGenerator: Code generated in 23.617375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.525905","level":"info","event":"25/08/01 09:04:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.529877","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.529931","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.530396","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.531769","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.531800","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.550896","level":"info","event":"25/08/01 09:04:41 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.553013","level":"info","event":"25/08/01 09:04:41 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.554154","level":"info","event":"25/08/01 09:04:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 0baa42e17007:36885 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.558800","level":"info","event":"25/08/01 09:04:41 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.559001","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.559050","level":"info","event":"25/08/01 09:04:41 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.560267","level":"info","event":"25/08/01 09:04:41 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.593524","level":"info","event":"25/08/01 09:04:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:43767 (size: 5.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.617082","level":"info","event":"25/08/01 09:04:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.5:60244","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.753930","level":"info","event":"25/08/01 09:04:41 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 195 ms on 172.18.0.5 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.754080","level":"info","event":"25/08/01 09:04:41 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.759476","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.210 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.759850","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.759925","level":"info","event":"25/08/01 09:04:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.759964","level":"info","event":"25/08/01 09:04:41 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.234354 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:41.770323","level":"info","event":"INFO:__main__:Number of rows read from bronze layer: 10158","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:42.173865","level":"info","event":"25/08/01 09:04:42 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:42.557205","level":"info","event":"25/08/01 09:04:42 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 0baa42e17007:36885 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:42.577151","level":"info","event":"25/08/01 09:04:42 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:43767 in memory (size: 5.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:42.591792","level":"info","event":"25/08/01 09:04:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 0baa42e17007:36885 in memory (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:42.596102","level":"info","event":"25/08/01 09:04:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:43767 in memory (size: 7.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:42.748293","level":"info","event":"25/08/01 09:04:42 INFO DeltaLog: Loading version 15 starting from checkpoint version 10.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:43.621144","level":"info","event":"25/08/01 09:04:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 0baa42e17007:36885 in memory (size: 36.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:43.622806","level":"info","event":"25/08/01 09:04:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:43767 in memory (size: 36.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:44.726789","level":"info","event":"25/08/01 09:04:44 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20596)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:44.732016","level":"info","event":"25/08/01 09:04:44 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20596)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:44.758698","level":"info","event":"25/08/01 09:04:44 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 5, totalFileSize: 12040)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.018843","level":"info","event":"25/08/01 09:04:45 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.048202","level":"info","event":"25/08/01 09:04:45 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(checkpointMetadata.version),IsNotNull(sidecar.path))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.048346","level":"info","event":"25/08/01 09:04:45 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.048394","level":"info","event":"25/08/01 09:04:45 INFO FileSourceStrategy: Pushed Filters: Or(IsNotNull(protocol.minReaderVersion),IsNotNull(metaData.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.048431","level":"info","event":"25/08/01 09:04:45 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(checkpointMetadata#80.version) OR isnotnull(sidecar#81.path))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.048466","level":"info","event":"25/08/01 09:04:45 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#86.minReaderVersion) OR isnotnull(metaData#85.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.048499","level":"info","event":"25/08/01 09:04:45 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.048532","level":"info","event":"25/08/01 09:04:45 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.048565","level":"info","event":"25/08/01 09:04:45 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#108.minReaderVersion) OR isnotnull(metaData#107.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.163102","level":"info","event":"25/08/01 09:04:45 INFO CodeGenerator: Code generated in 83.89325 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.170723","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 209.0 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.179343","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.206060","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 0baa42e17007:36885 (size: 37.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.206203","level":"info","event":"25/08/01 09:04:45 INFO SparkContext: Created broadcast 4 from $anonfun$submit$1 at FutureTask.java:264","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.206249","level":"info","event":"25/08/01 09:04:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.234060","level":"info","event":"25/08/01 09:04:45 INFO SparkContext: Starting job: $anonfun$submit$1 at FutureTask.java:264","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.237758","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Got job 3 ($anonfun$submit$1 at FutureTask.java:264) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.237894","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$submit$1 at FutureTask.java:264)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.237945","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.237994","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.238029","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[12] at $anonfun$submit$1 at FutureTask.java:264), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.241121","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 25.8 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.242009","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.245415","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 0baa42e17007:36885 (size: 8.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.246923","level":"info","event":"25/08/01 09:04:45 INFO CodeGenerator: Code generated in 155.545708 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.249376","level":"info","event":"25/08/01 09:04:45 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.249500","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[12] at $anonfun$submit$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.249544","level":"info","event":"25/08/01 09:04:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.252835","level":"info","event":"25/08/01 09:04:45 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 11180 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.262863","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 210.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.270713","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.271305","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 0baa42e17007:36885 (size: 37.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.271716","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:43767 (size: 8.8 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.274659","level":"info","event":"25/08/01 09:04:45 INFO SparkContext: Created broadcast 6 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.274763","level":"info","event":"25/08/01 09:04:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.394701","level":"info","event":"25/08/01 09:04:45 INFO CodeGenerator: Code generated in 79.923833 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.394823","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 206.0 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.394851","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.395611","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 0baa42e17007:36885 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.401810","level":"info","event":"25/08/01 09:04:45 INFO SparkContext: Created broadcast 7 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.416196","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:43767 (size: 37.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.425646","level":"info","event":"25/08/01 09:04:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10491780 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.560126","level":"info","event":"25/08/01 09:04:45 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.567787","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Got job 4 (toString at String.java:4220) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.567924","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Final stage: ResultStage 5 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.567971","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.568010","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.568046","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.570112","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 85.9 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.571880","level":"info","event":"25/08/01 09:04:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.572277","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 0baa42e17007:36885 (size: 25.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.572722","level":"info","event":"25/08/01 09:04:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.573619","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.575570","level":"info","event":"25/08/01 09:04:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.582174","level":"info","event":"25/08/01 09:04:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 11289 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.622868","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:43767 (size: 25.0 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.674884","level":"info","event":"25/08/01 09:04:45 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11593 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.675927","level":"info","event":"25/08/01 09:04:45 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 425 ms on 172.18.0.5 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.675986","level":"info","event":"25/08/01 09:04:45 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.677744","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: ResultStage 4 ($anonfun$submit$1 at FutureTask.java:264) finished in 0.441 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.678608","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.678648","level":"info","event":"25/08/01 09:04:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.678670","level":"info","event":"25/08/01 09:04:45 INFO DAGScheduler: Job 3 finished: $anonfun$submit$1 at FutureTask.java:264, took 0.444359 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:45.893398","level":"info","event":"25/08/01 09:04:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:43767 (size: 37.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.115880","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:43767 (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.263958","level":"info","event":"25/08/01 09:04:46 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 7) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 11434 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.265395","level":"info","event":"25/08/01 09:04:46 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 592 ms on 172.18.0.5 (executor 0) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.354231","level":"info","event":"25/08/01 09:04:46 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 7) in 93 ms on 172.18.0.5 (executor 0) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.370630","level":"info","event":"25/08/01 09:04:46 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 786 ms on 172.18.0.5 (executor 0) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.370719","level":"info","event":"25/08/01 09:04:46 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.370746","level":"info","event":"25/08/01 09:04:46 INFO DAGScheduler: ResultStage 5 (toString at String.java:4220) finished in 0.799 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.370767","level":"info","event":"25/08/01 09:04:46 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.370786","level":"info","event":"25/08/01 09:04:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.370804","level":"info","event":"25/08/01 09:04:46 INFO DAGScheduler: Job 4 finished: toString at String.java:4220, took 0.807842 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.457913","level":"info","event":"25/08/01 09:04:46 INFO CodeGenerator: Code generated in 58.302667 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.479709","level":"info","event":"25/08/01 09:04:46 INFO Snapshot: [tableId=6f562608-da59-4282-9447-d05d9e74f82f] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=15, metadata=Metadata(9ce1f2ed-51b3-4e89-b775-e5382d4313a3,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754033156179)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,15,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000011.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1754037847166; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=1ed8e3b0b3938de4ce510b4a402386fc versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000012.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1754038117776; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=bff9c9a1cdff1e1faca7a63d191a5836 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000013.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1754038392501; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=71aa1a5154a39c27bd44f9b8adb1703b versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000014.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1754038543459; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c827814b720d593427ee9884b1623018 versionId=null, S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000015.json; isDirectory=false; length=2408; replication=1; blocksize=33554432; modification_time=1754038594983; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=ab00655c27dbdb25b6bfb662624c7f29 versionId=null),UninitializedV1OrV2ParquetCheckpointProvider(10,S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000010.checkpoint.parquet; isDirectory=false; length=20596; replication=1; blocksize=33554432; modification_time=1754037702456; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=933170ac49042c72bc2f9694f935c9e2 versionId=null,s3a://activefence-bucket/bbc_tech/silver/_delta_log,Some(LastCheckpointInfo(10,24,None,Some(20596),Some(2),Some(StructType(StructField(txn,StructType(StructField(appId,StringType,true),StructField(version,LongType,true),StructField(lastUpdated,LongType,true)),true),StructField(add,StructType(StructField(path,StringType,true),StructField(partitionValues,MapType(StringType,StringType,true),true),StructField(size,LongType,true),StructField(modificationTime,LongType,true),StructField(dataChange,BooleanType,true),StructField(tags,MapType(StringType,StringType,true),true),StructField(deletionVector,StructType(StructField(storageType,StringType,true),StructField(pathOrInlineDv,StringType,true),StructField(offset,IntegerType,true),StructField(sizeInBytes,IntegerType,true),StructField(cardinality,LongType,true),StructField(maxRowIndex,LongType,true)),true),StructField(baseRowId,LongType,true),StructField(defaultRowCommitVersion,LongType,true),StructField(clusteringProvider,StringType,true),StructField(stats,StringType,true)),true),StructField(remove,StructType(StructField(path,StringType,true),StructField(deletionTimestamp,LongType,true),StructField(dataChange,BooleanType,true),StructField(extendedFileMetadata,BooleanType,true),StructField(partitionValues,MapType(StringType,StringType,true),true),StructField(size,LongType,true),StructField(deletionVector,StructType(StructField(storageType,StringType,true),StructField(pathOrInlineDv,StringType,true),StructField(offset,IntegerType,true),StructField(sizeInBytes,IntegerType,true),StructField(cardinality,LongType,true),StructField(maxRowIndex,LongType,true)),true),StructField(baseRowId,LongType,true),StructField(defaultRowCommitVersion,LongType,true)),true),StructField(metaData,StructType(StructField(id,StringType,true),StructField(name,StringType,true),StructField(description,StringType,true),StructField(format,StructType(StructField(provider,StringType,true),StructField(options,MapType(StringType,StringType,true),true)),true),StructField(schemaString,StringType,true),StructField(partitionColumns,ArrayType(StringType,true),true),StructField(configuration,MapType(StringType,StringType,true),true),StructField(createdTime,LongType,true)),true),StructField(protocol,StructType(StructField(minReaderVersion,IntegerType,true),StructField(minWriterVersion,IntegerType,true),StructField(readerFeatures,ArrayType(StringType,true),true),StructField(writerFeatures,ArrayType(StringType,true),true)),true),StructField(domainMetadata,StructType(StructField(domain,StringType,true),StructField(configuration,StringType,true),StructField(removed,BooleanType,true)),true))),None,Some(b0d0e3870748d57ed039dc9729542328)))),1754038594983), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.644488","level":"info","event":"25/08/01 09:04:46 INFO Snapshot: [tableId=9ce1f2ed-51b3-4e89-b775-e5382d4313a3] DELTA: Compute snapshot for version: 15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.668703","level":"info","event":"25/08/01 09:04:46 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 205.7 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.675040","level":"info","event":"25/08/01 09:04:46 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.675250","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 0baa42e17007:36885 (size: 36.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.681931","level":"info","event":"25/08/01 09:04:46 INFO SparkContext: Created broadcast 9 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.692458","level":"info","event":"25/08/01 09:04:46 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(Parquet, numFilesInSegment: 1, totalFileSize: 20596)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.834270","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 0baa42e17007:36885 in memory (size: 25.0 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.837607","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.5:43767 in memory (size: 25.0 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.904816","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 0baa42e17007:36885 in memory (size: 37.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.919764","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.5:43767 in memory (size: 37.3 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.926382","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 0baa42e17007:36885 in memory (size: 37.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.930081","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.5:43767 in memory (size: 37.5 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.941560","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 0baa42e17007:36885 in memory (size: 8.8 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:46.945746","level":"info","event":"25/08/01 09:04:46 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.5:43767 in memory (size: 8.8 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.401321","level":"info","event":"25/08/01 09:04:47 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.401417","level":"info","event":"25/08/01 09:04:47 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.401480","level":"info","event":"25/08/01 09:04:47 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.402547","level":"info","event":"25/08/01 09:04:47 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.402705","level":"info","event":"25/08/01 09:04:47 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.402754","level":"info","event":"25/08/01 09:04:47 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.424785","level":"info","event":"25/08/01 09:04:47 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.569687","level":"info","event":"25/08/01 09:04:47 INFO CodeGenerator: Code generated in 95.133375 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.583330","level":"info","event":"25/08/01 09:04:47 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 223.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.587170","level":"info","event":"25/08/01 09:04:47 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 39.4 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.590702","level":"info","event":"25/08/01 09:04:47 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 0baa42e17007:36885 (size: 39.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.594713","level":"info","event":"25/08/01 09:04:47 INFO SparkContext: Created broadcast 10 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.594805","level":"info","event":"25/08/01 09:04:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.701775","level":"info","event":"25/08/01 09:04:47 INFO CodeGenerator: Code generated in 61.226333 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.705515","level":"info","event":"25/08/01 09:04:47 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 206.0 KiB, free 433.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.711092","level":"info","event":"25/08/01 09:04:47 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.713630","level":"info","event":"25/08/01 09:04:47 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 0baa42e17007:36885 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.717732","level":"info","event":"25/08/01 09:04:47 INFO SparkContext: Created broadcast 11 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.717823","level":"info","event":"25/08/01 09:04:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10491780 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.726875","level":"info","event":"25/08/01 09:04:47 INFO DAGScheduler: Registering RDD 28 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.727387","level":"info","event":"25/08/01 09:04:47 INFO DAGScheduler: Got map stage job 5 (save at NativeMethodAccessorImpl.java:0) with 3 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.727698","level":"info","event":"25/08/01 09:04:47 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.727884","level":"info","event":"25/08/01 09:04:47 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.728072","level":"info","event":"25/08/01 09:04:47 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.729921","level":"info","event":"25/08/01 09:04:47 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.734309","level":"info","event":"25/08/01 09:04:47 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 241.3 KiB, free 433.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.734434","level":"info","event":"25/08/01 09:04:47 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.736435","level":"info","event":"25/08/01 09:04:47 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 0baa42e17007:36885 (size: 62.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.736521","level":"info","event":"25/08/01 09:04:47 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.736571","level":"info","event":"25/08/01 09:04:47 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.736808","level":"info","event":"25/08/01 09:04:47 INFO TaskSchedulerImpl: Adding task set 6.0 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.736873","level":"info","event":"25/08/01 09:04:47 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 11278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.736917","level":"info","event":"25/08/01 09:04:47 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11582 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:47.753087","level":"info","event":"25/08/01 09:04:47 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.5:43767 (size: 62.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:48.092253","level":"info","event":"25/08/01 09:04:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:43767 (size: 39.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:48.208520","level":"info","event":"25/08/01 09:04:48 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:43767 (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.318763","level":"info","event":"25/08/01 09:04:49 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 10) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 11423 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.318950","level":"info","event":"25/08/01 09:04:49 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 1582 ms on 172.18.0.5 (executor 0) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.322448","level":"info","event":"25/08/01 09:04:49 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 1586 ms on 172.18.0.5 (executor 0) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.500637","level":"info","event":"25/08/01 09:04:49 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 10) in 184 ms on 172.18.0.5 (executor 0) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.500727","level":"info","event":"25/08/01 09:04:49 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.501186","level":"info","event":"25/08/01 09:04:49 INFO DAGScheduler: ShuffleMapStage 6 (save at NativeMethodAccessorImpl.java:0) finished in 1.770 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.501309","level":"info","event":"25/08/01 09:04:49 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.501367","level":"info","event":"25/08/01 09:04:49 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.502730","level":"info","event":"25/08/01 09:04:49 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.502805","level":"info","event":"25/08/01 09:04:49 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.663337","level":"info","event":"25/08/01 09:04:49 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.5:43767 in memory (size: 62.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.665765","level":"info","event":"25/08/01 09:04:49 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 0baa42e17007:36885 in memory (size: 62.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.915029","level":"info","event":"25/08/01 09:04:49 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.915311","level":"info","event":"25/08/01 09:04:49 INFO CodeGenerator: Code generated in 256.42525 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:49.976969","level":"info","event":"25/08/01 09:04:49 INFO CodeGenerator: Code generated in 45.562042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.166113","level":"info","event":"25/08/01 09:04:50 INFO CodeGenerator: Code generated in 26.572667 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.173845","level":"info","event":"25/08/01 09:04:50 INFO DAGScheduler: Registering RDD 38 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.173907","level":"info","event":"25/08/01 09:04:50 INFO DAGScheduler: Got map stage job 6 (save at NativeMethodAccessorImpl.java:0) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.173933","level":"info","event":"25/08/01 09:04:50 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.173953","level":"info","event":"25/08/01 09:04:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.174378","level":"info","event":"25/08/01 09:04:50 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.176933","level":"info","event":"25/08/01 09:04:50 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.194227","level":"info","event":"25/08/01 09:04:50 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 616.4 KiB, free 432.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.199865","level":"info","event":"25/08/01 09:04:50 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 144.4 KiB, free 432.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.199964","level":"info","event":"25/08/01 09:04:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 0baa42e17007:36885 (size: 144.4 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.200479","level":"info","event":"25/08/01 09:04:50 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.201354","level":"info","event":"25/08/01 09:04:50 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.201449","level":"info","event":"25/08/01 09:04:50 INFO TaskSchedulerImpl: Adding task set 8.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.202670","level":"info","event":"25/08/01 09:04:50 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.203108","level":"info","event":"25/08/01 09:04:50 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 12) (172.18.0.5, executor 0, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.218677","level":"info","event":"25/08/01 09:04:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.5:43767 (size: 144.4 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.354144","level":"info","event":"25/08/01 09:04:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:60244","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.849710","level":"info","event":"25/08/01 09:04:50 INFO BlockManagerInfo: Added rdd_35_2 in memory on 172.18.0.5:43767 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:50.852898","level":"info","event":"25/08/01 09:04:50 INFO BlockManagerInfo: Added rdd_35_0 in memory on 172.18.0.5:43767 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.539402","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 13) (172.18.0.5, executor 0, partition 5, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.541252","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 14) (172.18.0.5, executor 0, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.541305","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 12) in 1339 ms on 172.18.0.5 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.541687","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 1339 ms on 172.18.0.5 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.619762","level":"info","event":"25/08/01 09:04:51 INFO BlockManagerInfo: Added rdd_35_10 in memory on 172.18.0.5:43767 (size: 379.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.636291","level":"info","event":"25/08/01 09:04:51 INFO BlockManagerInfo: Added rdd_35_5 in memory on 172.18.0.5:43767 (size: 700.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.644637","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 15) (172.18.0.5, executor 0, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.645518","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 14) in 105 ms on 172.18.0.5 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.661670","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 16) (172.18.0.5, executor 0, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.663465","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 13) in 125 ms on 172.18.0.5 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.724744","level":"info","event":"25/08/01 09:04:51 INFO BlockManagerInfo: Added rdd_35_12 in memory on 172.18.0.5:43767 (size: 378.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.740288","level":"info","event":"25/08/01 09:04:51 INFO BlockManagerInfo: Added rdd_35_11 in memory on 172.18.0.5:43767 (size: 378.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.745891","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 17) (172.18.0.5, executor 0, partition 13, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.745959","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 16) in 85 ms on 172.18.0.5 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.766759","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 18) (172.18.0.5, executor 0, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.767704","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 15) in 126 ms on 172.18.0.5 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.808779","level":"info","event":"25/08/01 09:04:51 INFO BlockManagerInfo: Added rdd_35_13 in memory on 172.18.0.5:43767 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.818313","level":"info","event":"25/08/01 09:04:51 INFO BlockManagerInfo: Added rdd_35_14 in memory on 172.18.0.5:43767 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.839286","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 19) (172.18.0.5, executor 0, partition 18, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.839361","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 17) in 94 ms on 172.18.0.5 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.870557","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 20) (172.18.0.5, executor 0, partition 21, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.870655","level":"info","event":"25/08/01 09:04:51 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 18) in 106 ms on 172.18.0.5 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:51.898993","level":"info","event":"25/08/01 09:04:51 INFO BlockManagerInfo: Added rdd_35_18 in memory on 172.18.0.5:43767 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:52.035894","level":"info","event":"25/08/01 09:04:52 INFO TaskSetManager: Starting task 23.0 in stage 8.0 (TID 21) (172.18.0.5, executor 0, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:52.063470","level":"info","event":"25/08/01 09:04:52 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 19) in 188 ms on 172.18.0.5 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:52.134918","level":"info","event":"25/08/01 09:04:52 INFO BlockManagerInfo: Added rdd_35_21 in memory on 172.18.0.5:43767 (size: 379.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:52.747311","level":"info","event":"25/08/01 09:04:52 INFO TaskSetManager: Starting task 25.0 in stage 8.0 (TID 22) (172.18.0.5, executor 0, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:52.751440","level":"info","event":"25/08/01 09:04:52 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 20) in 881 ms on 172.18.0.5 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:52.884040","level":"info","event":"25/08/01 09:04:52 INFO BlockManagerInfo: Added rdd_35_23 in memory on 172.18.0.5:43767 (size: 695.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:57.610858","level":"info","event":"25/08/01 09:04:57 INFO TaskSetManager: Starting task 26.0 in stage 8.0 (TID 23) (172.18.0.5, executor 0, partition 26, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:04:59.542521","level":"info","event":"25/08/01 09:04:59 INFO TaskSetManager: Finished task 23.0 in stage 8.0 (TID 21) in 7350 ms on 172.18.0.5 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.020651","level":"info","event":"25/08/01 09:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/0 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.036414","level":"info","event":"25/08/01 09:05:03 INFO StandaloneSchedulerBackend: Executor app-20250801090413-0000/0 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.036823","level":"info","event":"25/08/01 09:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801090413-0000/1 on worker-20250801090300-172.18.0.5-36675 (172.18.0.5:36675) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.036883","level":"info","event":"25/08/01 09:05:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801090413-0000/1 on hostPort 172.18.0.5:36675 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.044882","level":"info","event":"25/08/01 09:05:03 ERROR TaskSchedulerImpl: Lost executor 0 on 172.18.0.5: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.075889","level":"info","event":"25/08/01 09:05:03 WARN TaskSetManager: Lost task 26.0 in stage 8.0 (TID 23) (172.18.0.5 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.077515","level":"info","event":"25/08/01 09:05:03 WARN TaskSetManager: Lost task 25.0 in stage 8.0 (TID 22) (172.18.0.5 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.078946","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 13), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.079106","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 0), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.079450","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 21), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.079753","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 10), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.080006","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 5), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.080156","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 12), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.080536","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 18), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.085364","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 14), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.085481","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 2), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.085528","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 23), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.085559","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 11), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.116117","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Executor lost: 0 (epoch 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.118728","level":"info","event":"25/08/01 09:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/1 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.123110","level":"info","event":"25/08/01 09:05:03 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.123733","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.123844","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_23 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.123956","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.124285","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.124377","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.124468","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.125890","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_21 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.131844","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.131910","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.131938","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.131960","level":"info","event":"25/08/01 09:05:03 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.132134","level":"info","event":"25/08/01 09:05:03 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.18.0.5, 43767, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.137136","level":"info","event":"25/08/01 09:05:03 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:03.137199","level":"info","event":"25/08/01 09:05:03 INFO DAGScheduler: Shuffle files lost for executor: 0 (epoch 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:08.145998","level":"info","event":"25/08/01 09:05:08 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:51818) with ID 1,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:08.270075","level":"info","event":"25/08/01 09:05:08 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:40417 with 1048.8 MiB RAM, BlockManagerId(1, 172.18.0.5, 40417, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:12.763295","level":"info","event":"25/08/01 09:05:12 INFO TaskSetManager: Starting task 25.1 in stage 8.0 (TID 24) (172.18.0.5, executor 1, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:12.764079","level":"info","event":"25/08/01 09:05:12 INFO TaskSetManager: Starting task 26.1 in stage 8.0 (TID 25) (172.18.0.5, executor 1, partition 26, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:13.172997","level":"info","event":"25/08/01 09:05:13 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.5:40417 (size: 144.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.249035","level":"info","event":"25/08/01 09:05:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:51818","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.354860","level":"info","event":"25/08/01 09:05:14 INFO TaskSetManager: Starting task 11.1 in stage 8.0 (TID 26) (172.18.0.5, executor 1, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.362061","level":"info","event":"25/08/01 09:05:14 INFO TaskSetManager: Starting task 23.1 in stage 8.0 (TID 27) (172.18.0.5, executor 1, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.362852","level":"info","event":"25/08/01 09:05:14 WARN TaskSetManager: Lost task 25.1 in stage 8.0 (TID 24) (172.18.0.5 executor 1): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=25, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.362922","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.362956","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.362997","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363023","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363042","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363060","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363077","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363094","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363111","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363128","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363143","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363160","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363175","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363192","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363207","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363225","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363241","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363258","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363274","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363290","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363306","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363322","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363339","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363355","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363370","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363387","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363403","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363419","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363435","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363451","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363468","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363483","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363498","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363513","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363540","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363577","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363609","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363650","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363671","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363688","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363705","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363721","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363737","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363752","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363768","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363783","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363799","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363827","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363860","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363879","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363895","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363911","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363927","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363942","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363958","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363973","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.363989","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364004","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364021","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364035","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364052","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364066","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364083","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364098","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364114","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364130","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364148","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364536","level":"info","event":"25/08/01 09:05:14 INFO TaskSetManager: task 25.1 in stage 8.0 (TID 24) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364686","level":"info","event":"25/08/01 09:05:14 WARN TaskSetManager: Lost task 26.1 in stage 8.0 (TID 25) (172.18.0.5 executor 1): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=26, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364734","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 26","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364775","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364796","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364820","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364850","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364871","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364901","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364934","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.364966","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365001","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365036","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365059","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365076","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365091","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365107","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365123","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365153","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365169","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365198","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365222","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365254","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365271","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365286","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365303","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365318","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365334","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365349","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365364","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365379","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365413","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365445","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365493","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365533","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365563","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365594","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365646","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365664","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365680","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365703","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365728","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365753","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365773","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365789","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365829","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365851","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365867","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365890","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365914","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365931","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365947","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365966","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365982","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.365998","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366014","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366030","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366046","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366062","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366078","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366094","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366110","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366124","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366141","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366155","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366171","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366186","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366217","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366234","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366255","level":"info","event":"25/08/01 09:05:14 INFO TaskSetManager: task 26.1 in stage 8.0 (TID 25) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366271","level":"info","event":"25/08/01 09:05:14 INFO DAGScheduler: Marking ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) as failed due to a fetch failure from ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366288","level":"info","event":"25/08/01 09:05:14 INFO DAGScheduler: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) failed in 24.185 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366306","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366322","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366337","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366353","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366368","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366384","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366399","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366415","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366430","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366446","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366460","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366476","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366491","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366507","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366523","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366539","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366555","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366571","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366599","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366655","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366674","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366690","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366706","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366721","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366737","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366751","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366767","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366782","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.366797","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456758","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456819","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456843","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456863","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456882","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456899","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456916","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456935","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456953","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456969","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.456986","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457003","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457019","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457035","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457051","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457066","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457082","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457097","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457113","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457128","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457144","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457159","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457175","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457191","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457207","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457223","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457239","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457256","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457272","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457288","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457304","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457320","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457335","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457351","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457367","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457384","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457400","level":"info","event":"25/08/01 09:05:14 INFO DAGScheduler: Resubmitting ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0) and ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) due to fetch failure","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457441","level":"info","event":"25/08/01 09:05:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:51818","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457460","level":"info","event":"25/08/01 09:05:14 WARN TaskSetManager: Lost task 11.1 in stage 8.0 (TID 26) (172.18.0.5 executor 1): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=11, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457476","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 11","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457492","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457507","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457524","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457539","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457555","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457570","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457586","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457601","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457617","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457663","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457681","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457698","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457714","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457730","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457746","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457763","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457779","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457796","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457812","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457827","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457843","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457857","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457873","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457888","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457904","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457918","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457934","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457948","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457964","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457979","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.457994","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458009","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458025","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458040","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458056","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458092","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458113","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458129","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458145","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458159","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458175","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458190","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458206","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458221","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458237","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458251","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458267","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458281","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458297","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458312","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458327","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458342","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458358","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458373","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458389","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458403","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458420","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458434","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458450","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458465","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458481","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458496","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458512","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458527","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458543","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458558","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458575","level":"info","event":"25/08/01 09:05:14 INFO TaskSetManager: task 11.1 in stage 8.0 (TID 26) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458592","level":"info","event":"25/08/01 09:05:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:51818","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458608","level":"info","event":"25/08/01 09:05:14 WARN TaskSetManager: Lost task 23.1 in stage 8.0 (TID 27) (172.18.0.5 executor 1): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=23, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458693","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 23","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458769","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458799","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458821","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458840","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458857","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458874","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458891","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458906","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458923","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458938","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458955","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458969","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.458985","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459000","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459017","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459031","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459047","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459062","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459078","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459093","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459109","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459124","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459140","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459155","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459171","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459186","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459201","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459216","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459232","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459247","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459273","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459290","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459306","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459322","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459337","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459353","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459368","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459384","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459399","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459415","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459429","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459445","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459460","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459476","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459492","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459508","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459523","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459539","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459554","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459571","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459585","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459601","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459616","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459664","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459680","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459696","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459712","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.459728","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517592","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517669","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517690","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517709","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517727","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517743","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517759","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517776","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517793","level":"info","event":"25/08/01 09:05:14 INFO TaskSetManager: task 23.1 in stage 8.0 (TID 27) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.517811","level":"info","event":"25/08/01 09:05:14 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.573381","level":"info","event":"25/08/01 09:05:14 INFO DAGScheduler: Resubmitting failed stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.573940","level":"info","event":"25/08/01 09:05:14 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.577620","level":"info","event":"25/08/01 09:05:14 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 241.3 KiB, free 432.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.591557","level":"info","event":"25/08/01 09:05:14 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.595617","level":"info","event":"25/08/01 09:05:14 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 0baa42e17007:36885 (size: 62.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.595770","level":"info","event":"25/08/01 09:05:14 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.595799","level":"info","event":"25/08/01 09:05:14 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.595822","level":"info","event":"25/08/01 09:05:14 INFO TaskSchedulerImpl: Adding task set 7.1 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.595903","level":"info","event":"25/08/01 09:05:14 INFO TaskSetManager: Starting task 0.0 in stage 7.1 (TID 28) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 11278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.596099","level":"info","event":"25/08/01 09:05:14 INFO TaskSetManager: Starting task 1.0 in stage 7.1 (TID 29) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11582 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:14.614985","level":"info","event":"25/08/01 09:05:14 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.5:40417 (size: 62.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:15.632299","level":"info","event":"25/08/01 09:05:15 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:40417 (size: 39.4 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:15.795047","level":"info","event":"25/08/01 09:05:15 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:40417 (size: 36.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.672084","level":"info","event":"25/08/01 09:05:19 INFO TaskSetManager: Starting task 2.0 in stage 7.1 (TID 30) (172.18.0.5, executor 1, partition 2, PROCESS_LOCAL, 11423 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.682991","level":"info","event":"25/08/01 09:05:19 INFO TaskSetManager: Finished task 0.0 in stage 7.1 (TID 28) in 5078 ms on 172.18.0.5 (executor 1) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.684025","level":"info","event":"25/08/01 09:05:19 INFO TaskSetManager: Finished task 1.0 in stage 7.1 (TID 29) in 5088 ms on 172.18.0.5 (executor 1) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.855384","level":"info","event":"25/08/01 09:05:19 INFO TaskSetManager: Finished task 2.0 in stage 7.1 (TID 30) in 186 ms on 172.18.0.5 (executor 1) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.855474","level":"info","event":"25/08/01 09:05:19 INFO TaskSchedulerImpl: Removed TaskSet 7.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.857590","level":"info","event":"25/08/01 09:05:19 INFO DAGScheduler: ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0) finished in 5.281 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.857757","level":"info","event":"25/08/01 09:05:19 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.857840","level":"info","event":"25/08/01 09:05:19 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.857896","level":"info","event":"25/08/01 09:05:19 INFO DAGScheduler: waiting: Set(ShuffleMapStage 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.857916","level":"info","event":"25/08/01 09:05:19 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.859820","level":"info","event":"25/08/01 09:05:19 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.885044","level":"info","event":"25/08/01 09:05:19 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 8.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.908863","level":"info","event":"25/08/01 09:05:19 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 616.4 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.949303","level":"info","event":"25/08/01 09:05:19 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 0baa42e17007:36885 in memory (size: 144.4 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.960216","level":"info","event":"25/08/01 09:05:19 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 144.5 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.961825","level":"info","event":"25/08/01 09:05:19 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 0baa42e17007:36885 (size: 144.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.961864","level":"info","event":"25/08/01 09:05:19 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.5:40417 in memory (size: 144.4 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.961887","level":"info","event":"25/08/01 09:05:19 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.961907","level":"info","event":"25/08/01 09:05:19 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.961943","level":"info","event":"25/08/01 09:05:19 INFO TaskSchedulerImpl: Adding task set 8.1 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.963455","level":"info","event":"25/08/01 09:05:19 INFO TaskSetManager: Starting task 0.0 in stage 8.1 (TID 31) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.966561","level":"info","event":"25/08/01 09:05:19 INFO TaskSetManager: Starting task 2.0 in stage 8.1 (TID 32) (172.18.0.5, executor 1, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:19.997667","level":"info","event":"25/08/01 09:05:19 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:40417 (size: 144.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:20.022373","level":"info","event":"25/08/01 09:05:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:51818","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:20.605851","level":"info","event":"25/08/01 09:05:20 INFO BlockManagerInfo: Added rdd_35_0 in memory on 172.18.0.5:40417 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:20.607071","level":"info","event":"25/08/01 09:05:20 INFO BlockManagerInfo: Added rdd_35_2 in memory on 172.18.0.5:40417 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.431157","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 5.0 in stage 8.1 (TID 33) (172.18.0.5, executor 1, partition 5, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.431353","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 10.0 in stage 8.1 (TID 34) (172.18.0.5, executor 1, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.435564","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 2.0 in stage 8.1 (TID 32) in 1467 ms on 172.18.0.5 (executor 1) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.435657","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 0.0 in stage 8.1 (TID 31) in 1471 ms on 172.18.0.5 (executor 1) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.561465","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_10 in memory on 172.18.0.5:40417 (size: 379.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.567146","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_5 in memory on 172.18.0.5:40417 (size: 700.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.589032","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 11.0 in stage 8.1 (TID 35) (172.18.0.5, executor 1, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.590988","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 10.0 in stage 8.1 (TID 34) in 164 ms on 172.18.0.5 (executor 1) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.627261","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_11 in memory on 172.18.0.5:40417 (size: 378.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.628081","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 12.0 in stage 8.1 (TID 36) (172.18.0.5, executor 1, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.628952","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 5.0 in stage 8.1 (TID 33) in 203 ms on 172.18.0.5 (executor 1) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.665277","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 13.0 in stage 8.1 (TID 37) (172.18.0.5, executor 1, partition 13, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.665916","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 11.0 in stage 8.1 (TID 35) in 77 ms on 172.18.0.5 (executor 1) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.727042","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_13 in memory on 172.18.0.5:40417 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.734252","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_12 in memory on 172.18.0.5:40417 (size: 378.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.772943","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 13.0 in stage 8.1 (TID 37) in 108 ms on 172.18.0.5 (executor 1) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.773034","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 14.0 in stage 8.1 (TID 38) (172.18.0.5, executor 1, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.791049","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 12.0 in stage 8.1 (TID 36) in 163 ms on 172.18.0.5 (executor 1) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.793097","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 18.0 in stage 8.1 (TID 39) (172.18.0.5, executor 1, partition 18, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.849695","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_18 in memory on 172.18.0.5:40417 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.857507","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_14 in memory on 172.18.0.5:40417 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.866297","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 21.0 in stage 8.1 (TID 40) (172.18.0.5, executor 1, partition 21, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.867125","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 18.0 in stage 8.1 (TID 39) in 74 ms on 172.18.0.5 (executor 1) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.881897","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Starting task 23.0 in stage 8.1 (TID 41) (172.18.0.5, executor 1, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.882283","level":"info","event":"25/08/01 09:05:21 INFO TaskSetManager: Finished task 14.0 in stage 8.1 (TID 38) in 110 ms on 172.18.0.5 (executor 1) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.903454","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_21 in memory on 172.18.0.5:40417 (size: 379.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:21.958939","level":"info","event":"25/08/01 09:05:21 INFO BlockManagerInfo: Added rdd_35_23 in memory on 172.18.0.5:40417 (size: 695.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:22.014771","level":"info","event":"25/08/01 09:05:22 INFO TaskSetManager: Starting task 25.0 in stage 8.1 (TID 42) (172.18.0.5, executor 1, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:22.020105","level":"info","event":"25/08/01 09:05:22 INFO TaskSetManager: Finished task 21.0 in stage 8.1 (TID 40) in 137 ms on 172.18.0.5 (executor 1) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:22.020243","level":"info","event":"25/08/01 09:05:22 INFO TaskSetManager: Starting task 26.0 in stage 8.1 (TID 43) (172.18.0.5, executor 1, partition 26, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:22.020286","level":"info","event":"25/08/01 09:05:22 INFO TaskSetManager: Finished task 23.0 in stage 8.1 (TID 41) in 135 ms on 172.18.0.5 (executor 1) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:23.498856","level":"info","event":"25/08/01 09:05:23 INFO BlockManagerInfo: Added rdd_35_26 in memory on 172.18.0.5:40417 (size: 306.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:23.541895","level":"info","event":"25/08/01 09:05:23 INFO BlockManagerInfo: Added rdd_35_25 in memory on 172.18.0.5:40417 (size: 307.0 B, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:25.281368","level":"info","event":"25/08/01 09:05:25 INFO TaskSetManager: Starting task 27.0 in stage 8.1 (TID 44) (172.18.0.5, executor 1, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:25.340132","level":"info","event":"25/08/01 09:05:25 INFO TaskSetManager: Finished task 26.0 in stage 8.1 (TID 43) in 3248 ms on 172.18.0.5 (executor 1) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:25.360330","level":"info","event":"25/08/01 09:05:25 INFO TaskSetManager: Starting task 30.0 in stage 8.1 (TID 45) (172.18.0.5, executor 1, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:25.370178","level":"info","event":"25/08/01 09:05:25 INFO TaskSetManager: Finished task 25.0 in stage 8.1 (TID 42) in 3367 ms on 172.18.0.5 (executor 1) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.816568","level":"info","event":"25/08/01 09:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/1 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.822503","level":"info","event":"25/08/01 09:05:36 INFO StandaloneSchedulerBackend: Executor app-20250801090413-0000/1 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.825603","level":"info","event":"25/08/01 09:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801090413-0000/2 on worker-20250801090300-172.18.0.5-36675 (172.18.0.5:36675) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.831537","level":"info","event":"25/08/01 09:05:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801090413-0000/2 on hostPort 172.18.0.5:36675 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.831698","level":"info","event":"25/08/01 09:05:36 ERROR TaskSchedulerImpl: Lost executor 1 on 172.18.0.5: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.831764","level":"info","event":"25/08/01 09:05:36 WARN TaskSetManager: Lost task 27.0 in stage 8.1 (TID 44) (172.18.0.5 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.831823","level":"info","event":"25/08/01 09:05:36 WARN TaskSetManager: Lost task 30.0 in stage 8.1 (TID 45) (172.18.0.5 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.831849","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 2), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.841037","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 23), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.841312","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 11), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.841359","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 14), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.844474","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 21), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.844953","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 0), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.846829","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 26), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.847461","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 10), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.852953","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 13), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.861653","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 12), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.865771","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 18), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.866283","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 5), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.866438","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 25), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.869362","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Executor lost: 1 (epoch 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.873317","level":"info","event":"25/08/01 09:05:36 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.873462","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.873690","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_23 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.873763","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.873925","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_25 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.875023","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.875249","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.876381","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.876591","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_21 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.876713","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.876837","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.876960","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.877700","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_26 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.880312","level":"info","event":"25/08/01 09:05:36 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.884346","level":"info","event":"25/08/01 09:05:36 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 172.18.0.5, 40417, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.885742","level":"info","event":"25/08/01 09:05:36 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.885813","level":"info","event":"25/08/01 09:05:36 INFO DAGScheduler: Shuffle files lost for executor: 1 (epoch 4)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:36.952542","level":"info","event":"25/08/01 09:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/2 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:43.077872","level":"info","event":"25/08/01 09:05:43 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:42696) with ID 2,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:43.156824","level":"info","event":"25/08/01 09:05:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:40779 with 1048.8 MiB RAM, BlockManagerId(2, 172.18.0.5, 40779, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:48.724308","level":"info","event":"25/08/01 09:05:48 INFO TaskSetManager: Starting task 30.1 in stage 8.1 (TID 46) (172.18.0.5, executor 2, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:48.725785","level":"info","event":"25/08/01 09:05:48 INFO TaskSetManager: Starting task 27.1 in stage 8.1 (TID 47) (172.18.0.5, executor 2, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:49.328915","level":"info","event":"25/08/01 09:05:49 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:40779 (size: 144.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.632727","level":"info","event":"25/08/01 09:05:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:42696","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677332","level":"info","event":"25/08/01 09:05:50 INFO TaskSetManager: Starting task 25.1 in stage 8.1 (TID 48) (172.18.0.5, executor 2, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677432","level":"info","event":"25/08/01 09:05:50 WARN TaskSetManager: Lost task 30.1 in stage 8.1 (TID 46) (172.18.0.5 executor 2): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=30, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677489","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 30","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677536","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677575","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677612","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677662","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677703","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677730","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677767","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677789","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677825","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677864","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677887","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677912","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677938","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.677972","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678002","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678048","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678091","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678157","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678184","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678212","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678254","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678276","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678311","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.678335","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679184","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679227","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679259","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679288","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679316","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679349","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679368","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679384","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679400","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679416","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679432","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679449","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679473","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679497","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679527","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679549","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679580","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679598","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679614","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679655","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679678","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679695","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679724","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679757","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679789","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679810","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679840","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679875","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679907","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679926","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679943","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.679980","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680000","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680026","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680067","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680086","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680102","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680147","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680164","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680181","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680200","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680219","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680236","level":"info","event":"25/08/01 09:05:50 INFO TaskSetManager: task 30.1 in stage 8.1 (TID 46) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680305","level":"info","event":"25/08/01 09:05:50 WARN TaskSetManager: Lost task 27.1 in stage 8.1 (TID 47) (172.18.0.5 executor 2): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=27, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680328","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 27","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680359","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680380","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680397","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680414","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680430","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680446","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680462","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680477","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680495","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680511","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680528","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680544","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680558","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680575","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680590","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680606","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680630","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680664","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680694","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680720","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680756","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680791","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680812","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680828","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680844","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680860","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680876","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680891","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680907","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680922","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680952","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680968","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.680984","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681013","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681043","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681060","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681076","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681532","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681700","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681743","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681840","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681891","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681931","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.681967","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.682026","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.682064","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.682097","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.683857","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.683932","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.683991","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684069","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684216","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684267","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684306","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684341","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684375","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684408","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684441","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684473","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684504","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684536","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684568","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684600","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684631","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684664","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684697","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684729","level":"info","event":"25/08/01 09:05:50 INFO TaskSetManager: task 27.1 in stage 8.1 (TID 47) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684764","level":"info","event":"25/08/01 09:05:50 INFO DAGScheduler: Marking ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) as failed due to a fetch failure from ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684797","level":"info","event":"25/08/01 09:05:50 INFO DAGScheduler: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) failed in 30.783 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 30","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684856","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684891","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684922","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684955","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.684986","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.685018","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.685052","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.685086","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688169","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688212","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688234","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688253","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688271","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688288","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688334","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688356","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688372","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688388","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688403","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688419","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688443","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688465","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688482","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688498","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688514","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688530","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688555","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688598","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688620","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688636","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688660","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688690","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688707","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688723","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688739","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688754","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688771","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688786","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688815","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688851","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688872","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688889","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688905","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688921","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688937","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688952","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688968","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688983","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.688999","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689014","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689030","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689044","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689060","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689075","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689091","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689106","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689143","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689160","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689176","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689193","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.689208","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.723650","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.723691","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.723711","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.723742","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.723778","level":"info","event":"25/08/01 09:05:50 INFO DAGScheduler: Resubmitting ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0) and ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) due to fetch failure","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.723808","level":"info","event":"25/08/01 09:05:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:42696","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739564","level":"info","event":"25/08/01 09:05:50 WARN TaskSetManager: Lost task 25.1 in stage 8.1 (TID 48) (172.18.0.5 executor 2): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=25, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739716","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739765","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739803","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739839","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739873","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739907","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739940","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.739974","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740007","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740039","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740073","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740106","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740177","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740211","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740243","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740276","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740308","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740339","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740371","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740402","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740433","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740464","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740509","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740540","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740572","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740603","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740644","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740675","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740706","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740737","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740769","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740845","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740893","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740926","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740959","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.740993","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741025","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741057","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741090","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741140","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741174","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741244","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741389","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741438","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741478","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741515","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741549","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741582","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741616","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741649","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741681","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741736","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741774","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741808","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741840","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741883","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741930","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741963","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.741994","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742026","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742058","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742090","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742144","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742181","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742216","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742251","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742286","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742319","level":"info","event":"25/08/01 09:05:50 INFO TaskSetManager: task 25.1 in stage 8.1 (TID 48) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.742355","level":"info","event":"25/08/01 09:05:50 INFO TaskSchedulerImpl: Removed TaskSet 8.1, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.883241","level":"info","event":"25/08/01 09:05:50 INFO DAGScheduler: Resubmitting failed stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.883320","level":"info","event":"25/08/01 09:05:50 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.885547","level":"info","event":"25/08/01 09:05:50 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 241.3 KiB, free 432.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.900250","level":"info","event":"25/08/01 09:05:50 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 432.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.906327","level":"info","event":"25/08/01 09:05:50 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 0baa42e17007:36885 (size: 62.1 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.909569","level":"info","event":"25/08/01 09:05:50 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.909645","level":"info","event":"25/08/01 09:05:50 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.909691","level":"info","event":"25/08/01 09:05:50 INFO TaskSchedulerImpl: Adding task set 7.2 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.912753","level":"info","event":"25/08/01 09:05:50 INFO TaskSetManager: Starting task 0.0 in stage 7.2 (TID 49) (172.18.0.5, executor 2, partition 0, PROCESS_LOCAL, 11278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.912865","level":"info","event":"25/08/01 09:05:50 INFO TaskSetManager: Starting task 1.0 in stage 7.2 (TID 50) (172.18.0.5, executor 2, partition 1, PROCESS_LOCAL, 11582 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:50.942081","level":"info","event":"25/08/01 09:05:50 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.5:40779 (size: 62.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:52.042393","level":"info","event":"25/08/01 09:05:52 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:40779 (size: 39.4 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:52.235552","level":"info","event":"25/08/01 09:05:52 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:40779 (size: 36.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:55.962424","level":"info","event":"25/08/01 09:05:55 INFO TaskSetManager: Starting task 2.0 in stage 7.2 (TID 51) (172.18.0.5, executor 2, partition 2, PROCESS_LOCAL, 11423 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:55.965299","level":"info","event":"25/08/01 09:05:55 INFO TaskSetManager: Finished task 1.0 in stage 7.2 (TID 50) in 5053 ms on 172.18.0.5 (executor 2) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:55.972354","level":"info","event":"25/08/01 09:05:55 INFO TaskSetManager: Finished task 0.0 in stage 7.2 (TID 49) in 5060 ms on 172.18.0.5 (executor 2) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.138425","level":"info","event":"25/08/01 09:05:56 INFO TaskSetManager: Finished task 2.0 in stage 7.2 (TID 51) in 175 ms on 172.18.0.5 (executor 2) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.138562","level":"info","event":"25/08/01 09:05:56 INFO TaskSchedulerImpl: Removed TaskSet 7.2, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.139916","level":"info","event":"25/08/01 09:05:56 INFO DAGScheduler: ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0) finished in 5.257 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.140230","level":"info","event":"25/08/01 09:05:56 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.141307","level":"info","event":"25/08/01 09:05:56 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.142474","level":"info","event":"25/08/01 09:05:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.142538","level":"info","event":"25/08/01 09:05:56 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.143691","level":"info","event":"25/08/01 09:05:56 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.143787","level":"info","event":"25/08/01 09:05:56 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 8.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.151392","level":"info","event":"25/08/01 09:05:56 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 616.4 KiB, free 431.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.172547","level":"info","event":"25/08/01 09:05:56 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 144.5 KiB, free 431.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.185611","level":"info","event":"25/08/01 09:05:56 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 0baa42e17007:36885 (size: 144.5 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.185697","level":"info","event":"25/08/01 09:05:56 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.185730","level":"info","event":"25/08/01 09:05:56 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.185758","level":"info","event":"25/08/01 09:05:56 INFO TaskSchedulerImpl: Adding task set 8.2 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.194480","level":"info","event":"25/08/01 09:05:56 INFO TaskSetManager: Starting task 0.0 in stage 8.2 (TID 52) (172.18.0.5, executor 2, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.194553","level":"info","event":"25/08/01 09:05:56 INFO TaskSetManager: Starting task 2.0 in stage 8.2 (TID 53) (172.18.0.5, executor 2, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.218088","level":"info","event":"25/08/01 09:05:56 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:40779 (size: 144.5 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.265628","level":"info","event":"25/08/01 09:05:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:42696","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.343975","level":"info","event":"25/08/01 09:05:56 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 0baa42e17007:36885 in memory (size: 62.1 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.385702","level":"info","event":"25/08/01 09:05:56 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.5:40779 in memory (size: 62.1 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.397123","level":"info","event":"25/08/01 09:05:56 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 0baa42e17007:36885 in memory (size: 144.5 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.402900","level":"info","event":"25/08/01 09:05:56 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.5:40779 in memory (size: 144.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:56.433676","level":"info","event":"25/08/01 09:05:56 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 0baa42e17007:36885 in memory (size: 62.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:57.154858","level":"info","event":"25/08/01 09:05:57 INFO BlockManagerInfo: Added rdd_35_0 in memory on 172.18.0.5:40779 (size: 307.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:57.154973","level":"info","event":"25/08/01 09:05:57 INFO BlockManagerInfo: Added rdd_35_2 in memory on 172.18.0.5:40779 (size: 307.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.058184","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 5.0 in stage 8.2 (TID 54) (172.18.0.5, executor 2, partition 5, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.058365","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 0.0 in stage 8.2 (TID 52) in 1865 ms on 172.18.0.5 (executor 2) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.059859","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 10.0 in stage 8.2 (TID 55) (172.18.0.5, executor 2, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.060056","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 2.0 in stage 8.2 (TID 53) in 1866 ms on 172.18.0.5 (executor 2) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.155726","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_5 in memory on 172.18.0.5:40779 (size: 700.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.166229","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_10 in memory on 172.18.0.5:40779 (size: 379.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.176502","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 11.0 in stage 8.2 (TID 56) (172.18.0.5, executor 2, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.176740","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 5.0 in stage 8.2 (TID 54) in 119 ms on 172.18.0.5 (executor 2) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.262468","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 12.0 in stage 8.2 (TID 57) (172.18.0.5, executor 2, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.262684","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 10.0 in stage 8.2 (TID 55) in 202 ms on 172.18.0.5 (executor 2) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.286777","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_11 in memory on 172.18.0.5:40779 (size: 378.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.366646","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 13.0 in stage 8.2 (TID 58) (172.18.0.5, executor 2, partition 13, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.370290","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 11.0 in stage 8.2 (TID 56) in 193 ms on 172.18.0.5 (executor 2) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.372838","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_12 in memory on 172.18.0.5:40779 (size: 378.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.429477","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 14.0 in stage 8.2 (TID 59) (172.18.0.5, executor 2, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.429744","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 12.0 in stage 8.2 (TID 57) in 169 ms on 172.18.0.5 (executor 2) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.435417","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_13 in memory on 172.18.0.5:40779 (size: 307.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.465418","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 18.0 in stage 8.2 (TID 60) (172.18.0.5, executor 2, partition 18, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.468317","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 13.0 in stage 8.2 (TID 58) in 103 ms on 172.18.0.5 (executor 2) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.508846","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_14 in memory on 172.18.0.5:40779 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.530968","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_18 in memory on 172.18.0.5:40779 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.542137","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 21.0 in stage 8.2 (TID 61) (172.18.0.5, executor 2, partition 21, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.542296","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 14.0 in stage 8.2 (TID 59) in 113 ms on 172.18.0.5 (executor 2) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.615475","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_21 in memory on 172.18.0.5:40779 (size: 379.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.623034","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 23.0 in stage 8.2 (TID 62) (172.18.0.5, executor 2, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.624427","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 18.0 in stage 8.2 (TID 60) in 159 ms on 172.18.0.5 (executor 2) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.652779","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 25.0 in stage 8.2 (TID 63) (172.18.0.5, executor 2, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.657654","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 21.0 in stage 8.2 (TID 61) in 113 ms on 172.18.0.5 (executor 2) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.695295","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_23 in memory on 172.18.0.5:40779 (size: 695.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.742388","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 26.0 in stage 8.2 (TID 64) (172.18.0.5, executor 2, partition 26, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.742812","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 23.0 in stage 8.2 (TID 62) in 121 ms on 172.18.0.5 (executor 2) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.743891","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_25 in memory on 172.18.0.5:40779 (size: 307.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.795427","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 27.0 in stage 8.2 (TID 65) (172.18.0.5, executor 2, partition 27, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.795508","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 25.0 in stage 8.2 (TID 63) in 143 ms on 172.18.0.5 (executor 2) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.828932","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_26 in memory on 172.18.0.5:40779 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.870776","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 30.0 in stage 8.2 (TID 66) (172.18.0.5, executor 2, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.870846","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 26.0 in stage 8.2 (TID 64) in 129 ms on 172.18.0.5 (executor 2) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.890773","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_27 in memory on 172.18.0.5:40779 (size: 372.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.923400","level":"info","event":"25/08/01 09:05:58 INFO BlockManagerInfo: Added rdd_35_30 in memory on 172.18.0.5:40779 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.924427","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 32.0 in stage 8.2 (TID 67) (172.18.0.5, executor 2, partition 32, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.925072","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 27.0 in stage 8.2 (TID 65) in 130 ms on 172.18.0.5 (executor 2) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.942230","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Starting task 34.0 in stage 8.2 (TID 68) (172.18.0.5, executor 2, partition 34, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:58.945802","level":"info","event":"25/08/01 09:05:58 INFO TaskSetManager: Finished task 30.0 in stage 8.2 (TID 66) in 73 ms on 172.18.0.5 (executor 2) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.002022","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_32 in memory on 172.18.0.5:40779 (size: 307.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.002265","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_34 in memory on 172.18.0.5:40779 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.037812","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Starting task 37.0 in stage 8.2 (TID 69) (172.18.0.5, executor 2, partition 37, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.038445","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Finished task 32.0 in stage 8.2 (TID 67) in 114 ms on 172.18.0.5 (executor 2) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.040027","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Starting task 38.0 in stage 8.2 (TID 70) (172.18.0.5, executor 2, partition 38, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.040297","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Finished task 34.0 in stage 8.2 (TID 68) in 99 ms on 172.18.0.5 (executor 2) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.091260","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_37 in memory on 172.18.0.5:40779 (size: 307.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.115195","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_38 in memory on 172.18.0.5:40779 (size: 306.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.121005","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Starting task 39.0 in stage 8.2 (TID 71) (172.18.0.5, executor 2, partition 39, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.124102","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Finished task 37.0 in stage 8.2 (TID 69) in 86 ms on 172.18.0.5 (executor 2) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.126769","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Starting task 42.0 in stage 8.2 (TID 72) (172.18.0.5, executor 2, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.129940","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Finished task 38.0 in stage 8.2 (TID 70) in 90 ms on 172.18.0.5 (executor 2) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.210293","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_39 in memory on 172.18.0.5:40779 (size: 377.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.230903","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Starting task 44.0 in stage 8.2 (TID 73) (172.18.0.5, executor 2, partition 44, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.230972","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Finished task 39.0 in stage 8.2 (TID 71) in 110 ms on 172.18.0.5 (executor 2) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.271083","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_44 in memory on 172.18.0.5:40779 (size: 377.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.336539","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Starting task 46.0 in stage 8.2 (TID 74) (172.18.0.5, executor 2, partition 46, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.338724","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Finished task 44.0 in stage 8.2 (TID 73) in 107 ms on 172.18.0.5 (executor 2) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.388230","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_46 in memory on 172.18.0.5:40779 (size: 307.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.453098","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Starting task 49.0 in stage 8.2 (TID 75) (172.18.0.5, executor 2, partition 49, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.453405","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Finished task 46.0 in stage 8.2 (TID 74) in 116 ms on 172.18.0.5 (executor 2) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.589569","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_49 in memory on 172.18.0.5:40779 (size: 439.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.658217","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Starting task 1.0 in stage 8.2 (TID 76) (172.18.0.5, executor 2, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.660012","level":"info","event":"25/08/01 09:05:59 INFO TaskSetManager: Finished task 49.0 in stage 8.2 (TID 75) in 209 ms on 172.18.0.5 (executor 2) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:05:59.798906","level":"info","event":"25/08/01 09:05:59 INFO BlockManagerInfo: Added rdd_35_1 in memory on 172.18.0.5:40779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:00.417535","level":"info","event":"25/08/01 09:06:00 INFO TaskSetManager: Starting task 3.0 in stage 8.2 (TID 77) (172.18.0.5, executor 2, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:00.520878","level":"info","event":"25/08/01 09:06:00 INFO TaskSetManager: Finished task 1.0 in stage 8.2 (TID 76) in 855 ms on 172.18.0.5 (executor 2) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:01.442445","level":"info","event":"25/08/01 09:06:01 INFO BlockManagerInfo: Added rdd_35_3 in memory on 172.18.0.5:40779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:04.406238","level":"info","event":"25/08/01 09:06:04 INFO TaskSetManager: Starting task 4.0 in stage 8.2 (TID 78) (172.18.0.5, executor 2, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:04.418614","level":"info","event":"25/08/01 09:06:04 INFO TaskSetManager: Finished task 3.0 in stage 8.2 (TID 77) in 4005 ms on 172.18.0.5 (executor 2) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.432784","level":"info","event":"25/08/01 09:06:14 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/2 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.433701","level":"info","event":"25/08/01 09:06:14 INFO StandaloneSchedulerBackend: Executor app-20250801090413-0000/2 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.434725","level":"info","event":"25/08/01 09:06:14 ERROR TaskSchedulerImpl: Lost executor 2 on 172.18.0.5: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436196","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 3), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436285","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 14), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436334","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 34), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436375","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 23), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436442","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 2), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436488","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 39), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436540","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 46), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436607","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 11), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436651","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 27), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436693","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 26), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436717","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 10), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436735","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 44), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.436752","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 13), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.437538","level":"info","event":"25/08/01 09:06:14 WARN TaskSetManager: Lost task 4.0 in stage 8.2 (TID 78) (172.18.0.5 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.437668","level":"info","event":"25/08/01 09:06:14 WARN TaskSetManager: Lost task 42.0 in stage 8.2 (TID 72) (172.18.0.5 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.438268","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 32), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.438410","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 1), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.438500","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 0), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.438551","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 38), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.438642","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 21), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.438691","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 18), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.440194","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 37), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.440284","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 25), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.440349","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 5), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.440409","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 12), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.440447","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 49), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.440500","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 30), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.440529","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Executor lost: 2 (epoch 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.458292","level":"info","event":"25/08/01 09:06:14 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.458442","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.458509","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_49 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.458567","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_44 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459171","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459329","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459391","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_21 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459430","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_32 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459475","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_38 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459501","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459540","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_34 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459580","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_37 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459633","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459674","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_30 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459724","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_23 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459770","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459810","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_25 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459848","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_3 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459892","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459941","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.459999","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.460078","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_39 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.460137","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_27 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.460194","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_46 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.460234","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_1 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.460273","level":"info","event":"25/08/01 09:06:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_26 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.460318","level":"info","event":"25/08/01 09:06:14 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, 172.18.0.5, 40779, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.462982","level":"info","event":"25/08/01 09:06:14 INFO BlockManagerMaster: Removed 2 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.463075","level":"info","event":"25/08/01 09:06:14 INFO DAGScheduler: Shuffle files lost for executor: 2 (epoch 6)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.464980","level":"info","event":"25/08/01 09:06:14 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801090413-0000/3 on worker-20250801090300-172.18.0.5-36675 (172.18.0.5:36675) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.465069","level":"info","event":"25/08/01 09:06:14 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801090413-0000/3 on hostPort 172.18.0.5:36675 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:14.551368","level":"info","event":"25/08/01 09:06:14 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/3 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:18.649154","level":"info","event":"25/08/01 09:06:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:53074) with ID 3,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:18.724055","level":"info","event":"25/08/01 09:06:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:39073 with 1048.8 MiB RAM, BlockManagerId(3, 172.18.0.5, 39073, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:24.782295","level":"info","event":"25/08/01 09:06:24 INFO TaskSetManager: Starting task 42.1 in stage 8.2 (TID 79) (172.18.0.5, executor 3, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:24.783710","level":"info","event":"25/08/01 09:06:24 INFO TaskSetManager: Starting task 30.1 in stage 8.2 (TID 80) (172.18.0.5, executor 3, partition 30, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:25.124894","level":"info","event":"25/08/01 09:06:25 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:39073 (size: 144.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.601951","level":"info","event":"25/08/01 09:06:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:53074","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.682178","level":"info","event":"25/08/01 09:06:26 INFO TaskSetManager: Starting task 49.1 in stage 8.2 (TID 81) (172.18.0.5, executor 3, partition 49, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.683522","level":"info","event":"25/08/01 09:06:26 INFO TaskSetManager: Starting task 12.1 in stage 8.2 (TID 82) (172.18.0.5, executor 3, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.685980","level":"info","event":"25/08/01 09:06:26 WARN TaskSetManager: Lost task 42.1 in stage 8.2 (TID 79) (172.18.0.5 executor 3): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=42, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686080","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 42","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686123","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686159","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686193","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686228","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686262","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686301","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686336","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686368","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686401","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686433","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686466","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686498","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686529","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686561","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686594","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686626","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686657","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686796","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686835","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686856","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686875","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686893","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686920","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686944","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686960","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686977","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.686993","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687010","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687026","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687042","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687059","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687075","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687113","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687136","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687153","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687170","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687266","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687315","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687338","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687360","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687379","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687396","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687412","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687430","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687447","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687463","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687480","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687496","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687514","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687530","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687547","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687563","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687579","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687596","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687612","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687631","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687648","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687663","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687680","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687696","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687711","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687767","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687788","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687807","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687826","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687844","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687861","level":"info","event":"25/08/01 09:06:26 INFO TaskSetManager: task 42.1 in stage 8.2 (TID 79) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687920","level":"info","event":"25/08/01 09:06:26 WARN TaskSetManager: Lost task 30.1 in stage 8.2 (TID 80) (172.18.0.5 executor 3): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=30, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.687975","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 30","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688012","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688030","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688056","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688091","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688130","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688150","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688185","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688204","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688221","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688237","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688270","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688302","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688342","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688372","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688393","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688426","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688455","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688471","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688488","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688504","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688519","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688534","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688550","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688566","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688582","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.688598","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.691712","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692010","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692072","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692111","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692147","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692180","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692213","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692245","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692363","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692405","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692437","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692480","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692531","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692577","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692610","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692643","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692674","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.692706","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696120","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696217","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696259","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696297","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696332","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696365","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696398","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696431","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696466","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696499","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696551","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696587","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696678","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696773","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696819","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696866","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696900","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696932","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696965","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.696996","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697029","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697063","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697094","level":"info","event":"25/08/01 09:06:26 INFO TaskSetManager: task 30.1 in stage 8.2 (TID 80) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697132","level":"info","event":"25/08/01 09:06:26 INFO DAGScheduler: Marking ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) as failed due to a fetch failure from ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697195","level":"info","event":"25/08/01 09:06:26 INFO DAGScheduler: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) failed in 30.539 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 42","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697234","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697316","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697611","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697695","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697829","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697870","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697903","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.697935","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698066","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698372","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698598","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698645","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698678","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698710","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698779","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698811","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698842","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698924","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.698969","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699004","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699038","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699070","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699127","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699165","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699198","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699229","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699261","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699292","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699323","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699355","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699389","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699420","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699452","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699483","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699515","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699548","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699665","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.699713","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.700028","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.700079","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.921993","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922160","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922268","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922295","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922315","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922333","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922351","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922380","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922404","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922420","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922438","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922455","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922482","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922502","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922542","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922564","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922581","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922598","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922613","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922629","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922659","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922679","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922697","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922713","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922951","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.922972","level":"info","event":"25/08/01 09:06:26 INFO DAGScheduler: Resubmitting ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0) and ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) due to fetch failure","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923082","level":"info","event":"25/08/01 09:06:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:53074","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923109","level":"info","event":"25/08/01 09:06:26 WARN TaskSetManager: Lost task 12.1 in stage 8.2 (TID 82) (172.18.0.5 executor 3): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=12, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923128","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 12","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923144","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923161","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923177","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923193","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923209","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923225","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923241","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.923257","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.926857","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927002","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927046","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927084","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927118","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927152","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927184","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927218","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927250","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927282","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927315","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927347","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927378","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927410","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927442","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927473","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927504","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927535","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927566","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927597","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927628","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927659","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.927690","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.930791","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.930966","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931017","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931054","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931089","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931123","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931158","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931190","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931221","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931254","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931286","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931318","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931350","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931382","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931463","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931663","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931712","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.931997","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932034","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932056","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932075","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932093","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932110","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932126","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932143","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932159","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932174","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932191","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932207","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932222","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932238","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932255","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932270","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932287","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932305","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932321","level":"info","event":"25/08/01 09:06:26 INFO TaskSetManager: task 12.1 in stage 8.2 (TID 82) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932339","level":"info","event":"25/08/01 09:06:26 WARN TaskSetManager: Lost task 49.1 in stage 8.2 (TID 81) (172.18.0.5 executor 3): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=49, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932357","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 49","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932375","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932391","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932408","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932424","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932441","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932455","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932471","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932488","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932503","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932519","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932535","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932551","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932567","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932583","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932598","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932614","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932630","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932645","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932661","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932677","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932692","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.932707","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933776","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933803","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933820","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933837","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933853","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933868","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933884","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933900","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933915","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933931","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933962","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933979","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.933994","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.934011","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:26.934026","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.147030","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.147249","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.147295","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.147332","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.147849","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.147916","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.147995","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148068","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148124","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148265","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148326","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148353","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148374","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148393","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148412","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148431","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148449","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148466","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148483","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148499","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148516","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148533","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148548","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148564","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148581","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148597","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148613","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148643","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148665","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148682","level":"info","event":"25/08/01 09:06:26 INFO TaskSetManager: task 49.1 in stage 8.2 (TID 81) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148699","level":"info","event":"25/08/01 09:06:26 INFO TaskSchedulerImpl: Removed TaskSet 8.2, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148716","level":"info","event":"25/08/01 09:06:26 INFO DAGScheduler: Resubmitting failed stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148775","level":"info","event":"25/08/01 09:06:26 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148793","level":"info","event":"25/08/01 09:06:26 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 241.3 KiB, free 432.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148825","level":"info","event":"25/08/01 09:06:26 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148841","level":"info","event":"25/08/01 09:06:26 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 0baa42e17007:36885 (size: 62.1 KiB, free: 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148860","level":"info","event":"25/08/01 09:06:26 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148878","level":"info","event":"25/08/01 09:06:26 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148895","level":"info","event":"25/08/01 09:06:26 INFO TaskSchedulerImpl: Adding task set 7.3 with 3 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148912","level":"info","event":"25/08/01 09:06:26 INFO TaskSetManager: Starting task 0.0 in stage 7.3 (TID 83) (172.18.0.5, executor 3, partition 0, PROCESS_LOCAL, 11278 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148927","level":"info","event":"25/08/01 09:06:26 INFO TaskSetManager: Starting task 1.0 in stage 7.3 (TID 84) (172.18.0.5, executor 3, partition 1, PROCESS_LOCAL, 11582 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:27.148944","level":"info","event":"25/08/01 09:06:27 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.5:39073 (size: 62.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:28.822834","level":"info","event":"25/08/01 09:06:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:39073 (size: 39.4 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:28.939133","level":"info","event":"25/08/01 09:06:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:39073 (size: 36.5 KiB, free: 1048.5 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.124080","level":"info","event":"25/08/01 09:06:32 INFO TaskSetManager: Starting task 2.0 in stage 7.3 (TID 85) (172.18.0.5, executor 3, partition 2, PROCESS_LOCAL, 11423 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.126781","level":"info","event":"25/08/01 09:06:32 INFO TaskSetManager: Finished task 1.0 in stage 7.3 (TID 84) in 5151 ms on 172.18.0.5 (executor 3) (1/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.126819","level":"info","event":"25/08/01 09:06:32 INFO TaskSetManager: Finished task 0.0 in stage 7.3 (TID 83) in 5151 ms on 172.18.0.5 (executor 3) (2/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.230435","level":"info","event":"25/08/01 09:06:32 INFO TaskSetManager: Finished task 2.0 in stage 7.3 (TID 85) in 107 ms on 172.18.0.5 (executor 3) (3/3)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.230506","level":"info","event":"25/08/01 09:06:32 INFO TaskSchedulerImpl: Removed TaskSet 7.3, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.230755","level":"info","event":"25/08/01 09:06:32 INFO DAGScheduler: ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0) finished in 5.321 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.230801","level":"info","event":"25/08/01 09:06:32 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.230823","level":"info","event":"25/08/01 09:06:32 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.230841","level":"info","event":"25/08/01 09:06:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.230860","level":"info","event":"25/08/01 09:06:32 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.232078","level":"info","event":"25/08/01 09:06:32 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.232112","level":"info","event":"25/08/01 09:06:32 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 8.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.239085","level":"info","event":"25/08/01 09:06:32 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 616.4 KiB, free 431.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.243240","level":"info","event":"25/08/01 09:06:32 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 144.5 KiB, free 431.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.244256","level":"info","event":"25/08/01 09:06:32 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 0baa42e17007:36885 (size: 144.5 KiB, free: 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.244489","level":"info","event":"25/08/01 09:06:32 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.244823","level":"info","event":"25/08/01 09:06:32 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.244863","level":"info","event":"25/08/01 09:06:32 INFO TaskSchedulerImpl: Adding task set 8.3 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.249821","level":"info","event":"25/08/01 09:06:32 INFO TaskSetManager: Starting task 0.0 in stage 8.3 (TID 86) (172.18.0.5, executor 3, partition 0, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.249870","level":"info","event":"25/08/01 09:06:32 INFO TaskSetManager: Starting task 2.0 in stage 8.3 (TID 87) (172.18.0.5, executor 3, partition 2, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.255327","level":"info","event":"25/08/01 09:06:32 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.5:39073 (size: 144.5 KiB, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.279507","level":"info","event":"25/08/01 09:06:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:53074","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.895421","level":"info","event":"25/08/01 09:06:32 INFO BlockManagerInfo: Added rdd_35_0 in memory on 172.18.0.5:39073 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:32.895538","level":"info","event":"25/08/01 09:06:32 INFO BlockManagerInfo: Added rdd_35_2 in memory on 172.18.0.5:39073 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.708521","level":"info","event":"25/08/01 09:06:33 INFO TaskSetManager: Starting task 5.0 in stage 8.3 (TID 88) (172.18.0.5, executor 3, partition 5, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.709052","level":"info","event":"25/08/01 09:06:33 INFO TaskSetManager: Finished task 0.0 in stage 8.3 (TID 86) in 1462 ms on 172.18.0.5 (executor 3) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.723780","level":"info","event":"25/08/01 09:06:33 INFO TaskSetManager: Starting task 10.0 in stage 8.3 (TID 89) (172.18.0.5, executor 3, partition 10, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.724212","level":"info","event":"25/08/01 09:06:33 INFO TaskSetManager: Finished task 2.0 in stage 8.3 (TID 87) in 1478 ms on 172.18.0.5 (executor 3) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.817548","level":"info","event":"25/08/01 09:06:33 INFO BlockManagerInfo: Added rdd_35_5 in memory on 172.18.0.5:39073 (size: 700.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.845851","level":"info","event":"25/08/01 09:06:33 INFO BlockManagerInfo: Added rdd_35_10 in memory on 172.18.0.5:39073 (size: 379.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.885398","level":"info","event":"25/08/01 09:06:33 INFO TaskSetManager: Starting task 11.0 in stage 8.3 (TID 90) (172.18.0.5, executor 3, partition 11, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.885718","level":"info","event":"25/08/01 09:06:33 INFO TaskSetManager: Starting task 12.0 in stage 8.3 (TID 91) (172.18.0.5, executor 3, partition 12, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.886011","level":"info","event":"25/08/01 09:06:33 INFO TaskSetManager: Finished task 10.0 in stage 8.3 (TID 89) in 162 ms on 172.18.0.5 (executor 3) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.886230","level":"info","event":"25/08/01 09:06:33 INFO TaskSetManager: Finished task 5.0 in stage 8.3 (TID 88) in 179 ms on 172.18.0.5 (executor 3) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.983044","level":"info","event":"25/08/01 09:06:33 INFO BlockManagerInfo: Added rdd_35_11 in memory on 172.18.0.5:39073 (size: 378.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:33.991048","level":"info","event":"25/08/01 09:06:33 INFO BlockManagerInfo: Added rdd_35_12 in memory on 172.18.0.5:39073 (size: 378.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.038415","level":"info","event":"25/08/01 09:06:34 INFO TaskSetManager: Starting task 13.0 in stage 8.3 (TID 92) (172.18.0.5, executor 3, partition 13, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.038860","level":"info","event":"25/08/01 09:06:34 INFO TaskSetManager: Starting task 14.0 in stage 8.3 (TID 93) (172.18.0.5, executor 3, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.039171","level":"info","event":"25/08/01 09:06:34 INFO TaskSetManager: Finished task 12.0 in stage 8.3 (TID 91) in 154 ms on 172.18.0.5 (executor 3) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.041487","level":"info","event":"25/08/01 09:06:34 INFO TaskSetManager: Finished task 11.0 in stage 8.3 (TID 90) in 157 ms on 172.18.0.5 (executor 3) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.226965","level":"info","event":"25/08/01 09:06:34 INFO BlockManagerInfo: Added rdd_35_14 in memory on 172.18.0.5:39073 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.610799","level":"info","event":"25/08/01 09:06:34 INFO BlockManagerInfo: Added rdd_35_13 in memory on 172.18.0.5:39073 (size: 307.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.736771","level":"info","event":"25/08/01 09:06:34 INFO TaskSetManager: Starting task 18.0 in stage 8.3 (TID 94) (172.18.0.5, executor 3, partition 18, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.739311","level":"info","event":"25/08/01 09:06:34 INFO TaskSetManager: Finished task 14.0 in stage 8.3 (TID 93) in 698 ms on 172.18.0.5 (executor 3) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.867878","level":"info","event":"25/08/01 09:06:34 INFO TaskSetManager: Starting task 21.0 in stage 8.3 (TID 95) (172.18.0.5, executor 3, partition 21, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.868686","level":"info","event":"25/08/01 09:06:34 INFO TaskSetManager: Finished task 13.0 in stage 8.3 (TID 92) in 830 ms on 172.18.0.5 (executor 3) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:34.930216","level":"info","event":"25/08/01 09:06:34 INFO BlockManagerInfo: Added rdd_35_18 in memory on 172.18.0.5:39073 (size: 306.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:35.031079","level":"info","event":"25/08/01 09:06:35 INFO TaskSetManager: Starting task 23.0 in stage 8.3 (TID 96) (172.18.0.5, executor 3, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:35.035084","level":"info","event":"25/08/01 09:06:35 INFO BlockManagerInfo: Added rdd_35_21 in memory on 172.18.0.5:39073 (size: 379.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:35.035149","level":"info","event":"25/08/01 09:06:35 INFO TaskSetManager: Finished task 18.0 in stage 8.3 (TID 94) in 302 ms on 172.18.0.5 (executor 3) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:35.392115","level":"info","event":"25/08/01 09:06:35 INFO TaskSetManager: Starting task 25.0 in stage 8.3 (TID 97) (172.18.0.5, executor 3, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:35.402892","level":"info","event":"25/08/01 09:06:35 INFO TaskSetManager: Finished task 21.0 in stage 8.3 (TID 95) in 509 ms on 172.18.0.5 (executor 3) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:36.102935","level":"info","event":"25/08/01 09:06:36 INFO BlockManagerInfo: Added rdd_35_23 in memory on 172.18.0.5:39073 (size: 695.0 B, free: 1048.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.647271","level":"info","event":"25/08/01 09:06:37 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/3 is now EXITED (Command exited with code 137)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.647894","level":"info","event":"25/08/01 09:06:37 INFO StandaloneSchedulerBackend: Executor app-20250801090413-0000/3 removed: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.647940","level":"info","event":"25/08/01 09:06:37 ERROR TaskSchedulerImpl: Lost executor 3 on 172.18.0.5: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.649962","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 13), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651033","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 21), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651250","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 0), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651341","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 10), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651374","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 12), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651405","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 18), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651431","level":"info","event":"25/08/01 09:06:37 WARN TaskSetManager: Lost task 25.0 in stage 8.3 (TID 97) (172.18.0.5 executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651452","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 5), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651470","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 2), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651487","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 11), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651512","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Resubmitted ShuffleMapTask(8, 14), so marking it as still running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651540","level":"info","event":"25/08/01 09:06:37 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250801090413-0000/4 on worker-20250801090300-172.18.0.5-36675 (172.18.0.5:36675) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651564","level":"info","event":"25/08/01 09:06:37 WARN TaskSetManager: Lost task 23.0 in stage 8.3 (TID 96) (172.18.0.5 executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Command exited with code 137","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.651589","level":"info","event":"25/08/01 09:06:37 INFO StandaloneSchedulerBackend: Granted executor ID app-20250801090413-0000/4 on hostPort 172.18.0.5:36675 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.653591","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Executor lost: 3 (epoch 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.657827","level":"info","event":"25/08/01 09:06:37 INFO BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.657875","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_13 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.657898","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_23 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.657917","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_2 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.657935","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_0 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.657952","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_12 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.657969","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_14 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.657986","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_21 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.658004","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_18 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.658021","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_5 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.658038","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_10 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.658055","level":"info","event":"25/08/01 09:06:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_35_11 !","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.658072","level":"info","event":"25/08/01 09:06:37 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, 172.18.0.5, 39073, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.658157","level":"info","event":"25/08/01 09:06:37 INFO BlockManagerMaster: Removed 3 successfully in removeExecutor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.658240","level":"info","event":"25/08/01 09:06:37 INFO DAGScheduler: Shuffle files lost for executor: 3 (epoch 8)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:37.717499","level":"info","event":"25/08/01 09:06:37 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250801090413-0000/4 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:41.171446","level":"info","event":"25/08/01 09:06:41 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:49598) with ID 4,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:41.247711","level":"info","event":"25/08/01 09:06:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:39689 with 1048.8 MiB RAM, BlockManagerId(4, 172.18.0.5, 39689, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:45.209176","level":"info","event":"25/08/01 09:06:45 INFO TaskSetManager: Starting task 23.1 in stage 8.3 (TID 98) (172.18.0.5, executor 4, partition 23, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:45.209439","level":"info","event":"25/08/01 09:06:45 INFO TaskSetManager: Starting task 25.1 in stage 8.3 (TID 99) (172.18.0.5, executor 4, partition 25, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:45.504659","level":"info","event":"25/08/01 09:06:45 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.5:39689 (size: 144.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.584470","level":"info","event":"25/08/01 09:06:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:49598","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.634368","level":"info","event":"25/08/01 09:06:46 INFO TaskSetManager: Starting task 14.1 in stage 8.3 (TID 100) (172.18.0.5, executor 4, partition 14, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.635235","level":"info","event":"25/08/01 09:06:46 WARN TaskSetManager: Lost task 25.1 in stage 8.3 (TID 99) (172.18.0.5 executor 4): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=25, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.635368","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.635540","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.635624","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.635708","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.635826","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.635907","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.635988","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636093","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636151","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636281","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636314","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636346","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636481","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636527","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636551","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636572","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636590","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636609","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636626","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636642","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636659","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636676","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636692","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636709","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636753","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636774","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636791","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636808","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636824","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636863","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636892","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636922","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636956","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.636977","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637004","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637028","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637044","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637086","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637112","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637148","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637181","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637212","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637233","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637252","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637281","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637296","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637312","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637339","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637362","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637377","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637393","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637409","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637424","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637441","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637456","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637472","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637488","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637515","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637534","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637554","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637586","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637622","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637652","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637691","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637776","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637799","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637817","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637834","level":"info","event":"25/08/01 09:06:46 INFO TaskSetManager: task 25.1 in stage 8.3 (TID 99) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637865","level":"info","event":"25/08/01 09:06:46 INFO DAGScheduler: Marking ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) as failed due to a fetch failure from ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637884","level":"info","event":"25/08/01 09:06:46 INFO DAGScheduler: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) failed in 14.402 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637901","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637919","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637948","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637964","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637981","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.637996","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638012","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638029","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638045","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638061","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638077","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638094","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638110","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638126","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638141","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638157","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638186","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638207","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638224","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638239","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638255","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638270","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638287","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638304","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638320","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638356","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638377","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638393","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638409","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638424","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638440","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638456","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638472","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638487","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638503","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638519","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638534","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638550","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638565","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638580","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638596","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638612","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638629","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638643","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638659","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638673","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638689","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638705","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638747","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638765","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638781","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638796","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638812","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638828","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638843","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638859","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638874","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638891","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638906","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638922","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638937","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638952","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638968","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.638993","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639015","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639031","level":"info","event":"25/08/01 09:06:46 WARN TaskSetManager: Lost task 23.1 in stage 8.3 (TID 98) (172.18.0.5 executor 4): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=23, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639049","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 23","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639068","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639089","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639114","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639130","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639146","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639162","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639178","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639194","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639210","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639240","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639257","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639272","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639295","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639318","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639334","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639350","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639366","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639397","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639415","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639430","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639446","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639478","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639495","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639511","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639540","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639562","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639578","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639598","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639626","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639642","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639658","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639691","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639714","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639757","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639774","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639796","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639812","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639827","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639843","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639858","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639873","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639889","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639918","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639939","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639954","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.639969","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698061","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698179","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698213","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698236","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698256","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698273","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698292","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698308","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698325","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698342","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698372","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698388","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698405","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698422","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698438","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698454","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698471","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698488","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698506","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698524","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.698541","level":"info","event":"25/08/01 09:06:46 INFO TaskSetManager: task 23.1 in stage 8.3 (TID 98) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.700379","level":"info","event":"25/08/01 09:06:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:49598","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721203","level":"info","event":"25/08/01 09:06:46 WARN TaskSetManager: Lost task 14.1 in stage 8.3 (TID 100) (172.18.0.5 executor 4): FetchFailed(null, shuffleId=1, mapIndex=-1, mapId=-1, reduceId=14, message=","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721327","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 14","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721370","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721407","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721442","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721476","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721509","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721542","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721574","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721607","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721640","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721672","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721704","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721769","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721804","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721837","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721869","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721901","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721932","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721964","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.721997","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722030","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722062","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722094","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722125","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722156","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722187","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722218","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722346","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722446","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722478","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722500","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722518","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722543","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722567","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722584","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722602","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722619","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722637","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722653","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722670","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722687","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722702","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722718","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722760","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722778","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722795","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722810","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722826","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722843","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722858","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722874","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722890","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722906","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722923","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722939","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722954","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722970","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.722986","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723001","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723017","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723033","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723048","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723064","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723080","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723096","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723113","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723131","level":"info","event":")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723157","level":"info","event":"25/08/01 09:06:46 INFO TaskSetManager: task 14.1 in stage 8.3 (TID 100) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.723175","level":"info","event":"25/08/01 09:06:46 INFO TaskSchedulerImpl: Removed TaskSet 8.3, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.890941","level":"info","event":"ERROR:__main__:Error in Spark job: An error occurred while calling o66.save.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891030","level":"info","event":": org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891064","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891095","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891128","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891168","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891191","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891217","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891248","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891293","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891327","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891373","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891420","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891452","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891484","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891501","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891518","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891535","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891552","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891569","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891586","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891601","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891618","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891634","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891650","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891666","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891682","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891698","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.891715","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892184","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892225","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892250","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892271","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892288","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892306","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892323","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892342","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892359","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892375","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892403","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892432","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892464","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892481","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892498","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892514","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892531","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892561","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892578","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892595","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892621","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892650","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892674","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892690","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892707","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892828","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892881","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892915","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.892956","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893005","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893049","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893080","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893098","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893114","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893140","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893162","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893179","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893195","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893212","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893238","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893259","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893275","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893292","level":"info","event":"at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893308","level":"info","event":"at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893324","level":"info","event":"at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893341","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893356","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2031)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893372","level":"info","event":"at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3054)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893390","level":"info","event":"at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893406","level":"info","event":"at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893422","level":"info","event":"at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893440","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.893456","level":"info","event":"25/08/01 09:06:46 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.924339","level":"info","event":"25/08/01 09:06:46 INFO SparkUI: Stopped Spark web UI at http://0baa42e17007:4041","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.931572","level":"info","event":"25/08/01 09:06:46 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.931670","level":"info","event":"25/08/01 09:06:46 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:46.959593","level":"info","event":"25/08/01 09:06:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.059974","level":"info","event":"25/08/01 09:06:47 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.060050","level":"info","event":"25/08/01 09:06:47 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.077279","level":"info","event":"25/08/01 09:06:47 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.085482","level":"info","event":"25/08/01 09:06:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.102165","level":"info","event":"25/08/01 09:06:47 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.275864","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.275959","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.276002","level":"info","event":"File \"/opt/spark-jobs/bronze_to_silver.py\", line 72, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.276469","level":"info","event":"main()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.276498","level":"info","event":"File \"/opt/spark-jobs/bronze_to_silver.py\", line 59, in main","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.276998","level":"info","event":".save(\"s3a://activefence-bucket/bbc_tech/silver\")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.277058","level":"info","event":"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.277092","level":"info","event":"File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 1463, in save","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.280261","level":"info","event":"File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.280898","level":"info","event":"File \"/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 179, in deco","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.281207","level":"info","event":"File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py\", line 326, in get_return_value","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.285836","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o66.save.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.285887","level":"info","event":": org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 8 (save at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.285943","level":"info","event":"org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1 partition 25","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.285997","level":"info","event":"at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1747)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286047","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1694)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286081","level":"info","event":"at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286107","level":"info","event":"at scala.collection.Iterator.foreach(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286131","level":"info","event":"at scala.collection.Iterator.foreach$(Iterator.scala:943)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286176","level":"info","event":"at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286224","level":"info","event":"at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1693)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286272","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1335)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286319","level":"info","event":"at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1297)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286365","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286404","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286444","level":"info","event":"at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286468","level":"info","event":"at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286485","level":"info","event":"at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:200)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286508","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286539","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286583","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286627","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286667","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286689","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286705","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286733","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286751","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286767","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286783","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286799","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286814","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286830","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286846","level":"info","event":"at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286862","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286896","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286917","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286934","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286949","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:381)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286965","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$getOrElseUpdate$1(BlockManager.scala:1372)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286981","level":"info","event":"at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1614)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.286997","level":"info","event":"at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1524)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287013","level":"info","event":"at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1588)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287029","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287045","level":"info","event":"at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287061","level":"info","event":"at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:379)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287077","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287092","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287120","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287140","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287156","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287172","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287188","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287204","level":"info","event":"at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287219","level":"info","event":"at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287234","level":"info","event":"at org.apache.spark.rdd.RDD.iterator(RDD.scala:331)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287251","level":"info","event":"at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287266","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287282","level":"info","event":"at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287298","level":"info","event":"at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287314","level":"info","event":"at org.apache.spark.scheduler.Task.run(Task.scala:141)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287330","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287346","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287361","level":"info","event":"at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287377","level":"info","event":"at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287393","level":"info","event":"at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287408","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287426","level":"info","event":"at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287442","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287459","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287476","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287492","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287507","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287523","level":"info","event":"at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287539","level":"info","event":"at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287555","level":"info","event":"at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287570","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287586","level":"info","event":"at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2031)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287601","level":"info","event":"at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3054)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287617","level":"info","event":"at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287633","level":"info","event":"at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287652","level":"info","event":"at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287668","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.287684","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.375775","level":"info","event":"25/08/01 09:06:47 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.376707","level":"info","event":"25/08/01 09:06:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.382563","level":"info","event":"25/08/01 09:06:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba77b7ce-e212-49c6-9375-5e7d3344e9c3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.388088","level":"info","event":"25/08/01 09:06:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-723b7b57-2796-4b66-97e7-5267240bf3ec/pyspark-d7c342f4-f633-43e8-97f3-28a6a0e78362","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.411022","level":"info","event":"25/08/01 09:06:47 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.411091","level":"info","event":"25/08/01 09:06:47 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.411118","level":"info","event":"25/08/01 09:06:47 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-01T09:06:47.483365","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":867,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1159,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":570,"name":"submit"}],"is_group":false,"exceptions":[]}]}
