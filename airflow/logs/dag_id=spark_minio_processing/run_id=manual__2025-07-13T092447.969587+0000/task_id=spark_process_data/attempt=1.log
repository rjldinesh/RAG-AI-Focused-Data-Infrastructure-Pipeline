{"timestamp":"2025-07-13T09:24:48.453298","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-13T09:24:48.453939","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/bronze.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-13T09:24:48.586837","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-07-13T09:24:48.587998","level":"info","event":"Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.5,com.amazonaws:aws-java-sdk-bundle:1.12.520 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name minio_processing_job --verbose --deploy-mode client /opt/spark-jobs/spark_job.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:48.651368","level":"info","event":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.424852","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.598165","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.598577","level":"info","event":"master                  spark://spark-master:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.598761","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.598902","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.599010","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.599123","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.599218","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.599315","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.599414","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.599568","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.599725","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.599913","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600052","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600155","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600258","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600350","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600440","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600525","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600618","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600710","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600799","level":"info","event":"primaryResource         file:/opt/spark-jobs/spark_job.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600890","level":"info","event":"name                    minio_processing_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.600982","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601066","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601155","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.5,com.amazonaws:aws-java-sdk-bundle:1.12.520","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601247","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601330","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601410","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601493","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601646","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601730","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601793","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601857","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601923","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.601987","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.602051","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.602113","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.602179","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.602239","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.602298","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.602357","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.602413","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.602472","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.777063","level":"info","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.891708","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.891923","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.895535","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.895689","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.896900","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-ffdc4950-b651-4da7-9ef8-6c9c2d6677ad;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:51.897051","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.122812","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.5 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.179516","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.1.3.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.198817","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.220486","level":"info","event":":: resolution report :: resolve 313ms :: artifacts dl 9ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.220854","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.221157","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.221318","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.5 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.221426","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.1.3.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.221622","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.221739","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.316 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.221901","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.222011","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.222099","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.222184","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.222528","level":"info","event":"|      default     |   4   |   0   |   0   |   1   ||   3   |   0   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.222687","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.236263","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-ffdc4950-b651-4da7-9ef8-6c9c2d6677ad","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.236789","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.260846","level":"info","event":"0 artifacts copied, 3 already retrieved (0kB/23ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.541220","level":"info","event":"25/07/13 09:24:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.762444","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.762601","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.762668","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.762710","level":"info","event":"file:/opt/spark-jobs/spark_job.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.762750","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.765912","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766051","level":"info","event":"(spark.app.name,minio_processing_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766111","level":"info","event":"(spark.app.submitTime,1752398692739)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766157","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766194","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766228","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766263","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766352","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766398","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766435","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://minio:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766470","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766504","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766537","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766571","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766606","level":"info","event":"(spark.master,spark://spark-master:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766640","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766674","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766706","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766779","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766824","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766860","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766895","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766933","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:52.766969","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.595851","level":"info","event":"25/07/13 09:24:54 INFO SparkContext: Running Spark version 3.5.1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.596152","level":"info","event":"25/07/13 09:24:54 INFO SparkContext: OS info Linux, 5.15.153.1-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.596577","level":"info","event":"25/07/13 09:24:54 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.622460","level":"info","event":"25/07/13 09:24:54 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.622730","level":"info","event":"25/07/13 09:24:54 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.623288","level":"info","event":"25/07/13 09:24:54 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.623590","level":"info","event":"25/07/13 09:24:54 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.660413","level":"info","event":"25/07/13 09:24:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.671163","level":"info","event":"25/07/13 09:24:54 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.673591","level":"info","event":"25/07/13 09:24:54 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.750686","level":"info","event":"25/07/13 09:24:54 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.750937","level":"info","event":"25/07/13 09:24:54 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.751504","level":"info","event":"25/07/13 09:24:54 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.752112","level":"info","event":"25/07/13 09:24:54 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:54.752521","level":"info","event":"25/07/13 09:24:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.040932","level":"info","event":"25/07/13 09:24:55 INFO Utils: Successfully started service 'sparkDriver' on port 33461.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.092404","level":"info","event":"25/07/13 09:24:55 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.128046","level":"info","event":"25/07/13 09:24:55 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.158887","level":"info","event":"25/07/13 09:24:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.160417","level":"info","event":"25/07/13 09:24:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.169718","level":"info","event":"25/07/13 09:24:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.220532","level":"info","event":"25/07/13 09:24:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-edb4a03c-4dc7-43bd-977c-96031c277d4a","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.245020","level":"info","event":"25/07/13 09:24:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.261773","level":"info","event":"25/07/13 09:24:55 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.429649","level":"info","event":"25/07/13 09:24:55 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.529397","level":"info","event":"25/07/13 09:24:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.588186","level":"info","event":"25/07/13 09:24:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar at spark://9727d6d0d627:33461/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar with timestamp 1752398694589","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.589175","level":"info","event":"25/07/13 09:24:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://9727d6d0d627:33461/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1752398694589","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.589782","level":"info","event":"25/07/13 09:24:55 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar at spark://9727d6d0d627:33461/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar with timestamp 1752398694589","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.600690","level":"info","event":"25/07/13 09:24:55 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar at spark://9727d6d0d627:33461/files/org.apache.hadoop_hadoop-aws-3.3.5.jar with timestamp 1752398694589","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.602834","level":"info","event":"25/07/13 09:24:55 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.5.jar to /tmp/spark-8c3b67f6-80cd-4f2a-96fc-7bea3c88de6a/userFiles-70a22915-c710-4373-a131-fe2c919cfdf2/org.apache.hadoop_hadoop-aws-3.3.5.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.623115","level":"info","event":"25/07/13 09:24:55 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://9727d6d0d627:33461/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1752398694589","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:55.623355","level":"info","event":"25/07/13 09:24:55 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-8c3b67f6-80cd-4f2a-96fc-7bea3c88de6a/userFiles-70a22915-c710-4373-a131-fe2c919cfdf2/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.097866","level":"info","event":"25/07/13 09:24:56 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar at spark://9727d6d0d627:33461/files/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar with timestamp 1752398694589","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.098121","level":"info","event":"25/07/13 09:24:56 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar to /tmp/spark-8c3b67f6-80cd-4f2a-96fc-7bea3c88de6a/userFiles-70a22915-c710-4373-a131-fe2c919cfdf2/org.wildfly.openssl_wildfly-openssl-1.1.3.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.195406","level":"info","event":"25/07/13 09:24:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.244221","level":"info","event":"25/07/13 09:24:56 INFO TransportClientFactory: Successfully created connection to spark-master/172.23.0.5:7077 after 29 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.348129","level":"info","event":"25/07/13 09:24:56 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250713092456-0001","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.352779","level":"info","event":"25/07/13 09:24:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250713092456-0001/0 on worker-20250713091421-172.23.0.8-45161 (172.23.0.8:45161) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.354602","level":"info","event":"25/07/13 09:24:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250713092456-0001/0 on hostPort 172.23.0.8:45161 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.361767","level":"info","event":"25/07/13 09:24:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40451.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.362071","level":"info","event":"25/07/13 09:24:56 INFO NettyBlockTransferService: Server created on 9727d6d0d627:40451","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.365407","level":"info","event":"25/07/13 09:24:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.373089","level":"info","event":"25/07/13 09:24:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 9727d6d0d627, 40451, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.376259","level":"info","event":"25/07/13 09:24:56 INFO BlockManagerMasterEndpoint: Registering block manager 9727d6d0d627:40451 with 434.4 MiB RAM, BlockManagerId(driver, 9727d6d0d627, 40451, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.378429","level":"info","event":"25/07/13 09:24:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 9727d6d0d627, 40451, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.379715","level":"info","event":"25/07/13 09:24:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 9727d6d0d627, 40451, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.435760","level":"info","event":"25/07/13 09:24:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250713092456-0001/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.582389","level":"info","event":"25/07/13 09:24:56 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.773091","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.780342","level":"info","event":"25/07/13 09:24:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:56.782603","level":"info","event":"25/07/13 09:24:56 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.826330","level":"info","event":"25/07/13 09:24:57 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.839579","level":"info","event":"25/07/13 09:24:57 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.839901","level":"info","event":"25/07/13 09:24:57 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897298","level":"info","event":"ERROR:__main__:Error in Spark job: An error occurred while calling o37.load.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897589","level":"info","event":": java.lang.NoClassDefFoundError: org/apache/hadoop/fs/impl/WeakRefMetricsSource","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897653","level":"info","event":"at org.apache.hadoop.fs.s3a.S3AInstrumentation.registerAsMetricsSource(S3AInstrumentation.java:279)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897699","level":"info","event":"at org.apache.hadoop.fs.s3a.S3AInstrumentation.<init>(S3AInstrumentation.java:229)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897740","level":"info","event":"at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:494)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897777","level":"info","event":"at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897815","level":"info","event":"at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897861","level":"info","event":"at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897904","level":"info","event":"at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897939","level":"info","event":"at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.897973","level":"info","event":"at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898008","level":"info","event":"at org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898042","level":"info","event":"at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898078","level":"info","event":"at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898112","level":"info","event":"at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898147","level":"info","event":"at scala.Option.getOrElse(Option.scala:189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898184","level":"info","event":"at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898369","level":"info","event":"at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898549","level":"info","event":"at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898729","level":"info","event":"at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898881","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.898936","level":"info","event":"at java.base/java.lang.reflect.Method.invoke(Method.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899028","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899109","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899159","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899231","level":"info","event":"at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899278","level":"info","event":"at py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899342","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899688","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899745","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899785","level":"info","event":"Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.impl.WeakRefMetricsSource","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899822","level":"info","event":"at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899860","level":"info","event":"at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899899","level":"info","event":"at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899933","level":"info","event":"... 28 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.899970","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.900037","level":"info","event":"25/07/13 09:24:57 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.912619","level":"info","event":"25/07/13 09:24:57 INFO SparkUI: Stopped Spark web UI at http://9727d6d0d627:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.918094","level":"info","event":"25/07/13 09:24:57 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.921794","level":"info","event":"25/07/13 09:24:57 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.934938","level":"info","event":"25/07/13 09:24:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.949438","level":"info","event":"25/07/13 09:24:57 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.950036","level":"info","event":"25/07/13 09:24:57 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.954940","level":"info","event":"25/07/13 09:24:57 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:57.956600","level":"info","event":"25/07/13 09:24:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.008913","level":"info","event":"25/07/13 09:24:58 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.112235","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.112565","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.112699","level":"info","event":"File \"/opt/spark-jobs/spark_job.py\", line 62, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.126247","level":"info","event":"main()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.126590","level":"info","event":"File \"/opt/spark-jobs/spark_job.py\", line 41, in main","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.140720","level":"info","event":".load(\"s3a://activefence-bucket/bbc_tech/land/*.html\")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.141062","level":"info","event":"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.141204","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 307, in load","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.142745","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.143612","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 179, in deco","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.145283","level":"info","event":"File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py\", line 326, in get_return_value","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.146566","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o37.load.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.146687","level":"info","event":": java.lang.NoClassDefFoundError: org/apache/hadoop/fs/impl/WeakRefMetricsSource","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.146766","level":"info","event":"at org.apache.hadoop.fs.s3a.S3AInstrumentation.registerAsMetricsSource(S3AInstrumentation.java:279)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.146822","level":"info","event":"at org.apache.hadoop.fs.s3a.S3AInstrumentation.<init>(S3AInstrumentation.java:229)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.146872","level":"info","event":"at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:494)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.146943","level":"info","event":"at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147005","level":"info","event":"at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147056","level":"info","event":"at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147105","level":"info","event":"at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147174","level":"info","event":"at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147264","level":"info","event":"at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147356","level":"info","event":"at org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:53)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147445","level":"info","event":"at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147532","level":"info","event":"at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147621","level":"info","event":"at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147709","level":"info","event":"at scala.Option.getOrElse(Option.scala:189)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147796","level":"info","event":"at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147882","level":"info","event":"at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.147967","level":"info","event":"at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148053","level":"info","event":"at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148226","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148345","level":"info","event":"at java.base/java.lang.reflect.Method.invoke(Method.java:569)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148445","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148541","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148635","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148722","level":"info","event":"at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148808","level":"info","event":"at py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148896","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.148984","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.149072","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.149158","level":"info","event":"Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.impl.WeakRefMetricsSource","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.149243","level":"info","event":"at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.149327","level":"info","event":"at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.149409","level":"info","event":"at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.149496","level":"info","event":"... 28 more","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.149593","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.149707","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.226263","level":"info","event":"25/07/13 09:24:58 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.226775","level":"info","event":"25/07/13 09:24:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-284a76a7-0ee5-4770-8c36-280b9cfe41d5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.232110","level":"info","event":"25/07/13 09:24:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-8c3b67f6-80cd-4f2a-96fc-7bea3c88de6a","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.235885","level":"info","event":"25/07/13 09:24:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-8c3b67f6-80cd-4f2a-96fc-7bea3c88de6a/pyspark-87839368-07b9-4bf0-bc09-dc9a0c919f19","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-07-13T09:24:58.279460","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.5,com.amazonaws:aws-java-sdk-bundle:1.12.520 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name minio_processing_job --verbose --deploy-mode client /opt/spark-jobs/spark_job.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":867,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1159,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
