{"timestamp":"2025-08-02T09:16:02.796443","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-02T09:16:02.796676","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/data-pipeline-stage.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-02T09:16:03.234611","level":"warning","event":"Couldn't find any OpenLineage transport configuration; will print events to console.","logger":"openlineage.client.client"}
{"timestamp":"2025-08-02T09:16:03.234887","level":"info","event":"OpenLineageClient will use `console` transport","logger":"openlineage.client.client"}
{"timestamp":"2025-08-02T09:16:03.334913","level":"info","event":"Connection Retrieved 'spark_submit_default'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-02T09:16:03.335476","level":"info","event":"Spark-Submit cmd: /opt/spark/bin/spark-submit --master spark://project-v2-spark-master-1:7077 --conf spark.submit.deployMode=client --conf spark.hadoop.fs.s3a.endpoint=http://project-v2-minio-1:9000 --conf spark.hadoop.fs.s3a.access.key=ZPnglo5gVhmWx1iC0FdY --conf spark.hadoop.fs.s3a.secret.key=****** --conf spark.hadoop.fs.s3a.path.style.access=true --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false --conf spark.executor.memory=2g --conf spark.driver.memory=1g --conf spark.executor.cores=2 --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name bronze_to_silver_job --verbose --deploy-mode client /opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.183086","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.227852","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.227938","level":"info","event":"master                  spark://project-v2-spark-master-1:7077","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.227978","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228008","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228027","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228049","level":"info","event":"executorCores           2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228083","level":"info","event":"totalExecutorCores      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228101","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228118","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228136","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228154","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228172","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228188","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228207","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228229","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228247","level":"info","event":"numExecutors            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228263","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228281","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228297","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228314","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228331","level":"info","event":"primaryResource         file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228348","level":"info","event":"name                    bronze_to_silver_job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228365","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228382","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228398","level":"info","event":"packages                org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.520,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228417","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228434","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228450","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228467","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228484","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228502","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228519","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228535","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228551","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228568","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228585","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228601","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228617","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228648","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228670","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228693","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228710","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.228727","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.294190","level":"info","event":":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.330376","level":"info","event":"Ivy Default Cache set to: /home/airflow/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.330467","level":"info","event":"The jars for the packages stored in: /home/airflow/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.332344","level":"info","event":"org.apache.hadoop#hadoop-aws added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.332388","level":"info","event":"com.amazonaws#aws-java-sdk-bundle added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.332409","level":"info","event":"org.apache.spark#spark-avro_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.332427","level":"info","event":"io.delta#delta-spark_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.332761","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-36c94e81-c5fc-442d-953a-b4586315c7db;1.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:04.332788","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:10.930029","level":"info","event":"found org.apache.hadoop#hadoop-aws;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:14.275102","level":"info","event":"found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:16.638330","level":"info","event":"found com.amazonaws#aws-java-sdk-bundle;1.12.520 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:20.046208","level":"info","event":"found org.apache.spark#spark-avro_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:20.553055","level":"info","event":"found org.tukaani#xz;1.9 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:21.008625","level":"info","event":"found io.delta#delta-spark_2.12;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:21.469071","level":"info","event":"found io.delta#delta-storage;3.1.0 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:25.198538","level":"info","event":"found org.antlr#antlr4-runtime;4.9.3 in central","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:25.434154","level":"info","event":"downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:27.326867","level":"info","event":"[SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.3.4!hadoop-aws.jar (2117ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:16:27.584624","level":"info","event":"downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.520/aws-java-sdk-bundle-1.12.520.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:05.113253","level":"info","event":"[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.12.520!aws-java-sdk-bundle.jar (37785ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:05.338581","level":"info","event":"downloading https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.12/3.5.0/spark-avro_2.12-3.5.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:07.895045","level":"info","event":"[SUCCESSFUL ] org.apache.spark#spark-avro_2.12;3.5.0!spark-avro_2.12.jar (2781ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:08.118758","level":"info","event":"downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.1.0/delta-spark_2.12-3.1.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:09.330260","level":"info","event":"[SUCCESSFUL ] io.delta#delta-spark_2.12;3.1.0!delta-spark_2.12.jar (1434ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:09.553469","level":"info","event":"downloading https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:09.818812","level":"info","event":"[SUCCESSFUL ] org.wildfly.openssl#wildfly-openssl;1.0.7.Final!wildfly-openssl.jar (486ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:10.037791","level":"info","event":"downloading https://repo1.maven.org/maven2/org/tukaani/xz/1.9/xz-1.9.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:10.269592","level":"info","event":"[SUCCESSFUL ] org.tukaani#xz;1.9!xz.jar (450ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:10.588862","level":"info","event":"downloading https://repo1.maven.org/maven2/io/delta/delta-storage/3.1.0/delta-storage-3.1.0.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:11.173674","level":"info","event":"[SUCCESSFUL ] io.delta#delta-storage;3.1.0!delta-storage.jar (903ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:11.396909","level":"info","event":"downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.9.3/antlr4-runtime-4.9.3.jar ...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.956128","level":"info","event":"[SUCCESSFUL ] org.antlr#antlr4-runtime;4.9.3!antlr4-runtime.jar (5780ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.957002","level":"info","event":":: resolution report :: resolve 20876ms :: artifacts dl 51748ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.957298","level":"info","event":":: modules in use:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.957453","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.520 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.957519","level":"info","event":"io.delta#delta-spark_2.12;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.957571","level":"info","event":"io.delta#delta-storage;3.1.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.957619","level":"info","event":"org.antlr#antlr4-runtime;4.9.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.957861","level":"info","event":"org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958135","level":"info","event":"org.apache.spark#spark-avro_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958235","level":"info","event":"org.tukaani#xz;1.9 from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958329","level":"info","event":"org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958455","level":"info","event":":: evicted modules:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958506","level":"info","event":"com.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.520] in [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958614","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958702","level":"info","event":"|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958788","level":"info","event":"|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958866","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.958966","level":"info","event":"|      default     |   9   |   8   |   8   |   1   ||   8   |   8   |","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.959054","level":"info","event":"---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.964490","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-36c94e81-c5fc-442d-953a-b4586315c7db","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:16.964614","level":"info","event":"confs: [default]","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.313259","level":"info","event":"8 artifacts copied, 0 already retrieved (337604kB/348ms)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.434363","level":"info","event":"25/08/02 09:17:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.521042","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.521146","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.521198","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.521245","level":"info","event":"file:/opt/spark-jobs/bronze_to_silver.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.521288","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522418","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522459","level":"info","event":"(spark.app.name,bronze_to_silver_job)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522482","level":"info","event":"(spark.app.submitTime,1754126237514)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522499","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522518","level":"info","event":"(spark.executor.cores,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522535","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522553","level":"info","event":"(spark.files,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522573","level":"info","event":"(spark.hadoop.fs.s3a.access.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522591","level":"info","event":"(spark.hadoop.fs.s3a.connection.ssl.enabled,false)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522607","level":"info","event":"(spark.hadoop.fs.s3a.endpoint,http://project-v2-minio-1:9000)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522626","level":"info","event":"(spark.hadoop.fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522644","level":"info","event":"(spark.hadoop.fs.s3a.path.style.access,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522661","level":"info","event":"(spark.hadoop.fs.s3a.secret.key,*********(redacted))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522677","level":"info","event":"(spark.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522695","level":"info","event":"(spark.master,spark://project-v2-spark-master-1:7077)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522712","level":"info","event":"(spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522730","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522747","level":"info","event":"(spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar,/home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar,/home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar,/home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar,/home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar,/home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar,/home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522795","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522816","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522852","level":"info","event":"file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522888","level":"info","event":"file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522906","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522922","level":"info","event":"file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522939","level":"info","event":"file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522970","level":"info","event":"file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.522990","level":"info","event":"file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.523007","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:17.523025","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.086289","level":"info","event":"INFO:__main__:Starting Spark job...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.141744","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Running Spark version 3.5.3","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.141828","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.141873","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Java version 17.0.15","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.151021","level":"info","event":"25/08/02 09:17:18 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.151096","level":"info","event":"25/08/02 09:17:18 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.151157","level":"info","event":"25/08/02 09:17:18 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.151271","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Submitted application: MinIOProcessingJob","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.161929","level":"info","event":"25/08/02 09:17:18 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.165201","level":"info","event":"25/08/02 09:17:18 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.165667","level":"info","event":"25/08/02 09:17:18 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.209301","level":"info","event":"25/08/02 09:17:18 INFO SecurityManager: Changing view acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.209400","level":"info","event":"25/08/02 09:17:18 INFO SecurityManager: Changing modify acls to: airflow","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.209533","level":"info","event":"25/08/02 09:17:18 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.209661","level":"info","event":"25/08/02 09:17:18 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.209786","level":"info","event":"25/08/02 09:17:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.377401","level":"info","event":"25/08/02 09:17:18 INFO Utils: Successfully started service 'sparkDriver' on port 34641.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.425509","level":"info","event":"25/08/02 09:17:18 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.451186","level":"info","event":"25/08/02 09:17:18 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.465389","level":"info","event":"25/08/02 09:17:18 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.465590","level":"info","event":"25/08/02 09:17:18 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.472098","level":"info","event":"25/08/02 09:17:18 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.496571","level":"info","event":"25/08/02 09:17:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-abb72bf4-81b5-437c-a649-035e339a166c","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.506300","level":"info","event":"25/08/02 09:17:18 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.518998","level":"info","event":"25/08/02 09:17:18 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.609304","level":"info","event":"25/08/02 09:17:18 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.645482","level":"info","event":"25/08/02 09:17:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.665792","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://4a4a2233a16a:34641/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.665902","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://4a4a2233a16a:34641/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.665931","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://4a4a2233a16a:34641/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.665955","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://4a4a2233a16a:34641/jars/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.666050","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://4a4a2233a16a:34641/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.666123","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://4a4a2233a16a:34641/jars/org.tukaani_xz-1.9.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.666202","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://4a4a2233a16a:34641/jars/io.delta_delta-storage-3.1.0.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.666283","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://4a4a2233a16a:34641/jars/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.668242","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://4a4a2233a16a:34641/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.668785","level":"info","event":"25/08/02 09:17:18 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/userFiles-c67da30c-a6ea-41dc-9033-07891a4e066f/org.apache.hadoop_hadoop-aws-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.675922","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar at spark://4a4a2233a16a:34641/files/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.676023","level":"info","event":"25/08/02 09:17:18 INFO Utils: Copying /home/airflow/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar to /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/userFiles-c67da30c-a6ea-41dc-9033-07891a4e066f/com.amazonaws_aws-java-sdk-bundle-1.12.520.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.853372","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://4a4a2233a16a:34641/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.853500","level":"info","event":"25/08/02 09:17:18 INFO Utils: Copying /home/airflow/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/userFiles-c67da30c-a6ea-41dc-9033-07891a4e066f/org.apache.spark_spark-avro_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.856159","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar at spark://4a4a2233a16a:34641/files/io.delta_delta-spark_2.12-3.1.0.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.856307","level":"info","event":"25/08/02 09:17:18 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-spark_2.12-3.1.0.jar to /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/userFiles-c67da30c-a6ea-41dc-9033-07891a4e066f/io.delta_delta-spark_2.12-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.861015","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://4a4a2233a16a:34641/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.861102","level":"info","event":"25/08/02 09:17:18 INFO Utils: Copying /home/airflow/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/userFiles-c67da30c-a6ea-41dc-9033-07891a4e066f/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.863656","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar at spark://4a4a2233a16a:34641/files/org.tukaani_xz-1.9.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.863712","level":"info","event":"25/08/02 09:17:18 INFO Utils: Copying /home/airflow/.ivy2/jars/org.tukaani_xz-1.9.jar to /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/userFiles-c67da30c-a6ea-41dc-9033-07891a4e066f/org.tukaani_xz-1.9.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.865647","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar at spark://4a4a2233a16a:34641/files/io.delta_delta-storage-3.1.0.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.865721","level":"info","event":"25/08/02 09:17:18 INFO Utils: Copying /home/airflow/.ivy2/jars/io.delta_delta-storage-3.1.0.jar to /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/userFiles-c67da30c-a6ea-41dc-9033-07891a4e066f/io.delta_delta-storage-3.1.0.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.867528","level":"info","event":"25/08/02 09:17:18 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar at spark://4a4a2233a16a:34641/files/org.antlr_antlr4-runtime-4.9.3.jar with timestamp 1754126238138","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.867582","level":"info","event":"25/08/02 09:17:18 INFO Utils: Copying /home/airflow/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar to /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/userFiles-c67da30c-a6ea-41dc-9033-07891a4e066f/org.antlr_antlr4-runtime-4.9.3.jar","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.975773","level":"info","event":"25/08/02 09:17:18 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://project-v2-spark-master-1:7077...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:18.999202","level":"info","event":"25/08/02 09:17:18 INFO TransportClientFactory: Successfully created connection to project-v2-spark-master-1/172.18.0.7:7077 after 13 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.136189","level":"info","event":"25/08/02 09:17:19 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250802091719-0000","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.140799","level":"info","event":"25/08/02 09:17:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39333.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.140888","level":"info","event":"25/08/02 09:17:19 INFO NettyBlockTransferService: Server created on 4a4a2233a16a:39333","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.141771","level":"info","event":"25/08/02 09:17:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.144880","level":"info","event":"25/08/02 09:17:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 4a4a2233a16a, 39333, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.146408","level":"info","event":"25/08/02 09:17:19 INFO BlockManagerMasterEndpoint: Registering block manager 4a4a2233a16a:39333 with 434.4 MiB RAM, BlockManagerId(driver, 4a4a2233a16a, 39333, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.147646","level":"info","event":"25/08/02 09:17:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 4a4a2233a16a, 39333, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.148299","level":"info","event":"25/08/02 09:17:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 4a4a2233a16a, 39333, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.151910","level":"info","event":"25/08/02 09:17:19 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250802091719-0000/0 on worker-20250802091409-172.18.0.8-33023 (172.18.0.8:33023) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.152907","level":"info","event":"25/08/02 09:17:19 INFO StandaloneSchedulerBackend: Granted executor ID app-20250802091719-0000/0 on hostPort 172.18.0.8:33023 with 2 core(s), 2.0 GiB RAM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.252013","level":"info","event":"25/08/02 09:17:19 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.271584","level":"info","event":"25/08/02 09:17:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250802091719-0000/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.432232","level":"info","event":"INFO:__main__:Spark session created successfully","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.432320","level":"info","event":"INFO:__main__:Reading parquet data from s3a://activefence-bucket/bbc_tech/bronze","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.435346","level":"info","event":"25/08/02 09:17:19 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.436310","level":"info","event":"25/08/02 09:17:19 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.952131","level":"info","event":"25/08/02 09:17:19 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.959570","level":"info","event":"25/08/02 09:17:19 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:19.959657","level":"info","event":"25/08/02 09:17:19 INFO MetricsSystemImpl: s3a-file-system metrics system started","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.417224","level":"info","event":"25/08/02 09:17:20 INFO InMemoryFileIndex: It took 34 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.630567","level":"info","event":"25/08/02 09:17:20 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.636890","level":"info","event":"25/08/02 09:17:20 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.636967","level":"info","event":"25/08/02 09:17:20 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.637089","level":"info","event":"25/08/02 09:17:20 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.637527","level":"info","event":"25/08/02 09:17:20 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.638713","level":"info","event":"25/08/02 09:17:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.661260","level":"info","event":"25/08/02 09:17:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 108.3 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.679926","level":"info","event":"25/08/02 09:17:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.683145","level":"info","event":"25/08/02 09:17:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 4a4a2233a16a:39333 (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.685583","level":"info","event":"25/08/02 09:17:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.695893","level":"info","event":"25/08/02 09:17:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.696225","level":"info","event":"25/08/02 09:17:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.793680","level":"info","event":"25/08/02 09:17:20 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:47292) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:20.820051","level":"info","event":"25/08/02 09:17:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:41779 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.8, 41779, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:21.874827","level":"info","event":"25/08/02 09:17:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10672 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:22.109818","level":"info","event":"25/08/02 09:17:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:41779 (size: 39.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:22.885171","level":"info","event":"25/08/02 09:17:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1020 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:22.886415","level":"info","event":"25/08/02 09:17:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:22.889683","level":"info","event":"25/08/02 09:17:22 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 2.244 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:22.890625","level":"info","event":"25/08/02 09:17:22 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:22.890744","level":"info","event":"25/08/02 09:17:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:22.891563","level":"info","event":"25/08/02 09:17:22 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 2.260852 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.646549","level":"info","event":"root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.646760","level":"info","event":"|-- article_id: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.646817","level":"info","event":"|-- title: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.646871","level":"info","event":"|-- pub_date: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.646918","level":"info","event":"|-- summary: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.646963","level":"info","event":"|-- load_timestamp: timestamp_ntz (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.646990","level":"info","event":"|-- year_month: string (nullable = true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.647028","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.647084","level":"info","event":"INFO:__main__:Input dataframe schema:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.647124","level":"info","event":"None","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.897529","level":"info","event":"25/08/02 09:17:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 4a4a2233a16a:39333 in memory (size: 39.3 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.902005","level":"info","event":"25/08/02 09:17:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.8:41779 in memory (size: 39.3 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.902399","level":"info","event":"25/08/02 09:17:23 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.903222","level":"info","event":"25/08/02 09:17:23 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:23.903726","level":"info","event":"25/08/02 09:17:23 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.095162","level":"info","event":"25/08/02 09:17:24 INFO CodeGenerator: Code generated in 90.009334 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.112754","level":"info","event":"25/08/02 09:17:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.119530","level":"info","event":"25/08/02 09:17:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.119918","level":"info","event":"25/08/02 09:17:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 4a4a2233a16a:39333 (size: 36.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.120771","level":"info","event":"25/08/02 09:17:24 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.130748","level":"info","event":"25/08/02 09:17:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.160941","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.163921","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.164023","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.164131","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.164425","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.164797","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.180227","level":"info","event":"25/08/02 09:17:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.180882","level":"info","event":"25/08/02 09:17:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.181187","level":"info","event":"25/08/02 09:17:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 4a4a2233a16a:39333 (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.181614","level":"info","event":"25/08/02 09:17:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.182475","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.182514","level":"info","event":"25/08/02 09:17:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.185841","level":"info","event":"25/08/02 09:17:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11237 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.210240","level":"info","event":"25/08/02 09:17:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.8:41779 (size: 7.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.459304","level":"info","event":"25/08/02 09:17:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:41779 (size: 36.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.587905","level":"info","event":"25/08/02 09:17:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 404 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.587996","level":"info","event":"25/08/02 09:17:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.589671","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.424 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.589793","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.589876","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.590061","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.590123","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.611830","level":"info","event":"25/08/02 09:17:24 INFO CodeGenerator: Code generated in 6.667125 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.625605","level":"info","event":"25/08/02 09:17:24 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.626659","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.626729","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.626757","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.626783","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.627220","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.631368","level":"info","event":"25/08/02 09:17:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.632027","level":"info","event":"25/08/02 09:17:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.632357","level":"info","event":"25/08/02 09:17:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 4a4a2233a16a:39333 (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.632665","level":"info","event":"25/08/02 09:17:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.632939","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.632972","level":"info","event":"25/08/02 09:17:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.635244","level":"info","event":"25/08/02 09:17:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.647449","level":"info","event":"25/08/02 09:17:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:41779 (size: 5.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.658888","level":"info","event":"25/08/02 09:17:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:47292","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.720547","level":"info","event":"25/08/02 09:17:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 85 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.721603","level":"info","event":"25/08/02 09:17:24 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.723300","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.091 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.723827","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.723892","level":"info","event":"25/08/02 09:17:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.724185","level":"info","event":"25/08/02 09:17:24 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.098657 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.728697","level":"info","event":"INFO:__main__:Number of rows read from bronze layer: 60","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.863077","level":"info","event":"25/08/02 09:17:24 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:24.873609","level":"info","event":"25/08/02 09:17:24 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.440099","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 4a4a2233a16a:39333 in memory (size: 7.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.441995","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.8:41779 in memory (size: 7.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.446413","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 4a4a2233a16a:39333 in memory (size: 5.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.447313","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.8:41779 in memory (size: 5.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.451255","level":"info","event":"25/08/02 09:17:25 INFO InitialSnapshot: [tableId=dd915067-b600-4a33-bfa0-eb340ff34e25] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(6aca0c7c-0b52-4087-ba26-ca579addfbc1,null,null,Format(parquet,Map()),null,List(),Map(),Some(1754126245446)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@42c9b10e,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.500447","level":"info","event":"25/08/02 09:17:25 INFO DeltaLog: No delta log found for the Delta table at s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.500810","level":"info","event":"25/08/02 09:17:25 INFO InitialSnapshot: [tableId=6aca0c7c-0b52-4087-ba26-ca579addfbc1] Created snapshot InitialSnapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=-1, metadata=Metadata(2f8987a4-02bf-4527-938c-8f5ed1eefce5,null,null,Format(parquet,Map()),null,List(),Map(),Some(1754126245500)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@42c9b10e,-1), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.556119","level":"info","event":"25/08/02 09:17:25 INFO OptimisticTransaction: [tableId=2f8987a4,txnId=e4a39b4d] Updated metadata from - to Metadata(65950ee1-5c70-44fb-be90-0e24a57e5909,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754126245543))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.754294","level":"info","event":"25/08/02 09:17:25 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.757911","level":"info","event":"25/08/02 09:17:25 INFO FileSourceStrategy: Pushed Filters: IsNotNull(article_id)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.758003","level":"info","event":"25/08/02 09:17:25 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(article_id#0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.785026","level":"info","event":"25/08/02 09:17:25 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.824665","level":"info","event":"25/08/02 09:17:25 INFO CodeGenerator: Code generated in 23.375917 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.826787","level":"info","event":"25/08/02 09:17:25 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 208.0 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.832796","level":"info","event":"25/08/02 09:17:25 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.833190","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 4a4a2233a16a:39333 (size: 37.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.833734","level":"info","event":"25/08/02 09:17:25 INFO SparkContext: Created broadcast 4 from save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.834647","level":"info","event":"25/08/02 09:17:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.850270","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 4a4a2233a16a:39333 in memory (size: 36.9 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.850618","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:41779 in memory (size: 36.9 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.878095","level":"info","event":"25/08/02 09:17:25 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.878633","level":"info","event":"25/08/02 09:17:25 INFO DAGScheduler: Got job 3 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.878689","level":"info","event":"25/08/02 09:17:25 INFO DAGScheduler: Final stage: ResultStage 4 (save at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.878716","level":"info","event":"25/08/02 09:17:25 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.878739","level":"info","event":"25/08/02 09:17:25 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.879119","level":"info","event":"25/08/02 09:17:25 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at save at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.889587","level":"info","event":"25/08/02 09:17:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 358.2 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.890610","level":"info","event":"25/08/02 09:17:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 127.8 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.891055","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 4a4a2233a16a:39333 (size: 127.8 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.891405","level":"info","event":"25/08/02 09:17:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.891725","level":"info","event":"25/08/02 09:17:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.891785","level":"info","event":"25/08/02 09:17:25 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.892616","level":"info","event":"25/08/02 09:17:25 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11248 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:25.900847","level":"info","event":"25/08/02 09:17:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:41779 (size: 127.8 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:26.536515","level":"info","event":"25/08/02 09:17:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:41779 (size: 37.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.255888","level":"info","event":"25/08/02 09:17:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 1363 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.255977","level":"info","event":"25/08/02 09:17:27 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.256484","level":"info","event":"25/08/02 09:17:27 INFO DAGScheduler: ResultStage 4 (save at NativeMethodAccessorImpl.java:0) finished in 1.377 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.256577","level":"info","event":"25/08/02 09:17:27 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.256630","level":"info","event":"25/08/02 09:17:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.257285","level":"info","event":"25/08/02 09:17:27 INFO DAGScheduler: Job 3 finished: save at NativeMethodAccessorImpl.java:0, took 1.379085 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.258051","level":"info","event":"25/08/02 09:17:27 INFO DeltaFileFormatWriter: Start to commit write Job 139da350-e105-4143-9b4a-ce0505b61763.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.258712","level":"info","event":"25/08/02 09:17:27 INFO DeltaFileFormatWriter: Write Job 139da350-e105-4143-9b4a-ce0505b61763 committed. Elapsed time: 0 ms.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.260181","level":"info","event":"25/08/02 09:17:27 INFO DeltaFileFormatWriter: Finished processing stats for write job 139da350-e105-4143-9b4a-ce0505b61763.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.607320","level":"info","event":"25/08/02 09:17:27 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 4a4a2233a16a:39333 in memory (size: 127.8 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.608842","level":"info","event":"25/08/02 09:17:27 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.8:41779 in memory (size: 127.8 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.757572","level":"info","event":"25/08/02 09:17:27 INFO CodeGenerator: Code generated in 114.551833 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.779182","level":"info","event":"25/08/02 09:17:27 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.779527","level":"info","event":"25/08/02 09:17:27 INFO DAGScheduler: Job 4 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000164 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.811810","level":"info","event":"25/08/02 09:17:27 INFO OptimisticTransaction: [tableId=2f8987a4,txnId=e4a39b4d] Attempting to commit version 0 with 4 actions with Serializable isolation level","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.923435","level":"info","event":"25/08/02 09:17:27 INFO DeltaLog: Creating a new snapshot v0 for commit version 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.923532","level":"info","event":"25/08/02 09:17:27 INFO DeltaLog: Loading version 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.929143","level":"info","event":"25/08/02 09:17:27 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 1995)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.975851","level":"info","event":"25/08/02 09:17:27 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.976158","level":"info","event":"25/08/02 09:17:27 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.976412","level":"info","event":"25/08/02 09:17:27 INFO FileSourceStrategy: Post-Scan Filters: (isnotnull(protocol#336.minReaderVersion) OR isnotnull(metaData#335.id))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.995899","level":"info","event":"25/08/02 09:17:27 INFO CodeGenerator: Code generated in 12.849 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:27.997531","level":"info","event":"25/08/02 09:17:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 206.2 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.000865","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.001170","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 4a4a2233a16a:39333 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.001652","level":"info","event":"25/08/02 09:17:28 INFO SparkContext: Created broadcast 6 from toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.009114","level":"info","event":"25/08/02 09:17:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.027587","level":"info","event":"25/08/02 09:17:28 INFO SparkContext: Starting job: toString at String.java:4220","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.028024","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Got job 5 (toString at String.java:4220) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.028075","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Final stage: ResultStage 5 (toString at String.java:4220)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.028099","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.028123","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.028335","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[19] at toString at String.java:4220), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.029695","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.030402","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.030679","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 4a4a2233a16a:39333 (size: 13.7 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.030939","level":"info","event":"25/08/02 09:17:28 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.031161","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at toString at String.java:4220) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.031197","level":"info","event":"25/08/02 09:17:28 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.031802","level":"info","event":"25/08/02 09:17:28 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11166 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.038314","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:41779 (size: 13.7 KiB, free: 1048.8 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.098017","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:41779 (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.124510","level":"info","event":"25/08/02 09:17:28 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 93 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.124597","level":"info","event":"25/08/02 09:17:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.125000","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: ResultStage 5 (toString at String.java:4220) finished in 0.096 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.125063","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.125092","level":"info","event":"25/08/02 09:17:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.125294","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Job 5 finished: toString at String.java:4220, took 0.097648 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.147632","level":"info","event":"25/08/02 09:17:28 INFO CodeGenerator: Code generated in 14.305834 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.151370","level":"info","event":"25/08/02 09:17:28 INFO Snapshot: [tableId=2f8987a4-02bf-4527-938c-8f5ed1eefce5] Created snapshot Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(65950ee1-5c70-44fb-be90-0e24a57e5909,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754126245543)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1754126247902; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=e9cb72e191c7fb6a0ea3266a9d14f30e versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@42c9b10e,1754126247902), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.152711","level":"info","event":"25/08/02 09:17:28 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://activefence-bucket/bbc_tech/silver/_delta_log, version=0, metadata=Metadata(65950ee1-5c70-44fb-be90-0e24a57e5909,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"article_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"pub_date\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"summary\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"load_timestamp\",\"type\":\"timestamp_ntz\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_month\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1754126245543)), logSegment=LogSegment(s3a://activefence-bucket/bbc_tech/silver/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://activefence-bucket/bbc_tech/silver/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1754126247902; access_time=0; owner=airflow; group=airflow; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=e9cb72e191c7fb6a0ea3266a9d14f30e versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@42c9b10e,1754126247902), checksumOpt=None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.156391","level":"info","event":"25/08/02 09:17:28 INFO Snapshot: [tableId=65950ee1-5c70-44fb-be90-0e24a57e5909] DELTA: Compute snapshot for version: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.162333","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 205.9 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.165903","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.166271","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 4a4a2233a16a:39333 (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.166747","level":"info","event":"25/08/02 09:17:28 INFO SparkContext: Created broadcast 8 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.308672","level":"info","event":"25/08/02 09:17:28 INFO DataSourceStrategy: Pruning directories with:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.308761","level":"info","event":"25/08/02 09:17:28 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.308787","level":"info","event":"25/08/02 09:17:28 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.315811","level":"info","event":"25/08/02 09:17:28 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.367699","level":"info","event":"25/08/02 09:17:28 INFO CodeGenerator: Code generated in 31.683042 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.368866","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 206.2 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.371990","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.372521","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 4a4a2233a16a:39333 (size: 36.5 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.373018","level":"info","event":"25/08/02 09:17:28 INFO SparkContext: Created broadcast 9 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.373582","level":"info","event":"25/08/02 09:17:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.377985","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Registering RDD 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.378064","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Got map stage job 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.378094","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Final stage: ShuffleMapStage 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.378119","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.378278","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.378429","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.380276","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 105.6 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.380907","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 433.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.381268","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 4a4a2233a16a:39333 (size: 32.6 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.381599","level":"info","event":"25/08/02 09:17:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.381884","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.381937","level":"info","event":"25/08/02 09:17:28 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.382599","level":"info","event":"25/08/02 09:17:28 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 11155 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.390338","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:41779 (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.504207","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:41779 (size: 36.5 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.521887","level":"info","event":"25/08/02 09:17:28 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 139 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.521957","level":"info","event":"25/08/02 09:17:28 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.522369","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: ShuffleMapStage 6 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.144 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.522451","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.522478","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.522498","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.522516","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.545632","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 4a4a2233a16a:39333 in memory (size: 13.7 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.546767","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.8:41779 in memory (size: 13.7 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.551459","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 4a4a2233a16a:39333 in memory (size: 32.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.552464","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.8:41779 in memory (size: 32.6 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.555423","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 4a4a2233a16a:39333 in memory (size: 36.5 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.556290","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.8:41779 in memory (size: 36.5 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.669364","level":"info","event":"25/08/02 09:17:28 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 24899 bytes","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.669467","level":"info","event":"25/08/02 09:17:28 INFO CodeGenerator: Code generated in 98.873542 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.694697","level":"info","event":"25/08/02 09:17:28 INFO CodeGenerator: Code generated in 17.654625 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.792840","level":"info","event":"25/08/02 09:17:28 INFO CodeGenerator: Code generated in 18.848292 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.796149","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Registering RDD 33 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.796218","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Got map stage job 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.796267","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Final stage: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.796305","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.797480","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.797945","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.809974","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 603.4 KiB, free 433.1 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.811039","level":"info","event":"25/08/02 09:17:28 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 138.1 KiB, free 433.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.811329","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 4a4a2233a16a:39333 (size: 138.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.811665","level":"info","event":"25/08/02 09:17:28 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.811979","level":"info","event":"25/08/02 09:17:28 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.812013","level":"info","event":"25/08/02 09:17:28 INFO TaskSchedulerImpl: Adding task set 8.0 with 50 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.812832","level":"info","event":"25/08/02 09:17:28 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 6) (172.18.0.8, executor 0, partition 19, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.812995","level":"info","event":"25/08/02 09:17:28 INFO TaskSetManager: Starting task 42.0 in stage 8.0 (TID 7) (172.18.0.8, executor 0, partition 42, NODE_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.823307","level":"info","event":"25/08/02 09:17:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:41779 (size: 138.1 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:28.896903","level":"info","event":"25/08/02 09:17:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:47292","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.120986","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_19 in memory on 172.18.0.8:41779 (size: 691.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.121137","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_42 in memory on 172.18.0.8:41779 (size: 562.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.213837","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.214425","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 9) (172.18.0.8, executor 0, partition 1, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.214960","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 42.0 in stage 8.0 (TID 7) in 402 ms on 172.18.0.8 (executor 0) (1/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.215430","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 6) in 403 ms on 172.18.0.8 (executor 0) (2/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.267419","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_1 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.270997","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_0 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.297118","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 10) (172.18.0.8, executor 0, partition 2, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.297374","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 84 ms on 172.18.0.8 (executor 0) (3/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.297847","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 11) (172.18.0.8, executor 0, partition 3, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.298208","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 9) in 84 ms on 172.18.0.8 (executor 0) (4/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.360351","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_3 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.360508","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_2 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.386210","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 12) (172.18.0.8, executor 0, partition 4, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.386476","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 11) in 89 ms on 172.18.0.8 (executor 0) (5/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.387024","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 13) (172.18.0.8, executor 0, partition 5, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.387183","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 10) in 91 ms on 172.18.0.8 (executor 0) (6/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.441418","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_4 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.441570","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_5 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.465647","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 14) (172.18.0.8, executor 0, partition 6, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.466189","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 15) (172.18.0.8, executor 0, partition 7, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.466344","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 13) in 80 ms on 172.18.0.8 (executor 0) (7/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.466719","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 12) in 81 ms on 172.18.0.8 (executor 0) (8/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.517980","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_6 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.518164","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_7 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.535793","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 16) (172.18.0.8, executor 0, partition 8, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.536041","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 14) in 70 ms on 172.18.0.8 (executor 0) (9/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.536549","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 17) (172.18.0.8, executor 0, partition 9, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.536726","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 15) in 71 ms on 172.18.0.8 (executor 0) (10/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.583148","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_9 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.583484","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_8 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.604626","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 18) (172.18.0.8, executor 0, partition 10, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.604832","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 16) in 69 ms on 172.18.0.8 (executor 0) (11/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.605123","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 19) (172.18.0.8, executor 0, partition 11, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.605530","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 17) in 69 ms on 172.18.0.8 (executor 0) (12/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.642492","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_11 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.642608","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_10 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.659893","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 20) (172.18.0.8, executor 0, partition 12, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.660144","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 19) in 55 ms on 172.18.0.8 (executor 0) (13/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.660837","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 21) (172.18.0.8, executor 0, partition 13, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.660964","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 18) in 56 ms on 172.18.0.8 (executor 0) (14/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.696045","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_13 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.696177","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_12 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.713213","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 22) (172.18.0.8, executor 0, partition 14, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.714310","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 21) in 54 ms on 172.18.0.8 (executor 0) (15/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.714771","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 23) (172.18.0.8, executor 0, partition 15, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.715069","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 20) in 55 ms on 172.18.0.8 (executor 0) (16/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.746548","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_15 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.746691","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_14 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.764608","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 24) (172.18.0.8, executor 0, partition 16, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.765220","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 25) (172.18.0.8, executor 0, partition 17, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.765308","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 23) in 51 ms on 172.18.0.8 (executor 0) (17/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.765539","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 22) in 53 ms on 172.18.0.8 (executor 0) (18/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.804710","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_17 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.804797","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_16 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.817457","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 26) (172.18.0.8, executor 0, partition 18, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.817624","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 25) in 53 ms on 172.18.0.8 (executor 0) (19/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.817997","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 20.0 in stage 8.0 (TID 27) (172.18.0.8, executor 0, partition 20, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.818300","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 24) in 54 ms on 172.18.0.8 (executor 0) (20/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.853541","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_18 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.853732","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_20 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.876708","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 21.0 in stage 8.0 (TID 28) (172.18.0.8, executor 0, partition 21, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.876945","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 26) in 59 ms on 172.18.0.8 (executor 0) (21/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.877375","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 22.0 in stage 8.0 (TID 29) (172.18.0.8, executor 0, partition 22, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.877650","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 20.0 in stage 8.0 (TID 27) in 60 ms on 172.18.0.8 (executor 0) (22/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.904187","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_22 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.904512","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_21 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.921263","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 23.0 in stage 8.0 (TID 30) (172.18.0.8, executor 0, partition 23, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.921491","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 22.0 in stage 8.0 (TID 29) in 44 ms on 172.18.0.8 (executor 0) (23/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.921978","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 24.0 in stage 8.0 (TID 31) (172.18.0.8, executor 0, partition 24, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.922313","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 21.0 in stage 8.0 (TID 28) in 46 ms on 172.18.0.8 (executor 0) (24/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.945505","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_24 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.945666","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_23 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.961399","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 25.0 in stage 8.0 (TID 32) (172.18.0.8, executor 0, partition 25, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.961562","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 24.0 in stage 8.0 (TID 31) in 40 ms on 172.18.0.8 (executor 0) (25/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.961936","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 26.0 in stage 8.0 (TID 33) (172.18.0.8, executor 0, partition 26, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.962206","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 23.0 in stage 8.0 (TID 30) in 42 ms on 172.18.0.8 (executor 0) (26/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.983703","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_26 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.983788","level":"info","event":"25/08/02 09:17:29 INFO BlockManagerInfo: Added rdd_30_25 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.997952","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 27.0 in stage 8.0 (TID 34) (172.18.0.8, executor 0, partition 27, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.998145","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 26.0 in stage 8.0 (TID 33) in 36 ms on 172.18.0.8 (executor 0) (27/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.998799","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Starting task 28.0 in stage 8.0 (TID 35) (172.18.0.8, executor 0, partition 28, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:29.999051","level":"info","event":"25/08/02 09:17:29 INFO TaskSetManager: Finished task 25.0 in stage 8.0 (TID 32) in 38 ms on 172.18.0.8 (executor 0) (28/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.024011","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_28 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.024157","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_27 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.035636","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 29.0 in stage 8.0 (TID 36) (172.18.0.8, executor 0, partition 29, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.035949","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 27.0 in stage 8.0 (TID 34) in 38 ms on 172.18.0.8 (executor 0) (29/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.036320","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 30.0 in stage 8.0 (TID 37) (172.18.0.8, executor 0, partition 30, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.036561","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 28.0 in stage 8.0 (TID 35) in 38 ms on 172.18.0.8 (executor 0) (30/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.064123","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_30 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.064269","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_29 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.077704","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 31.0 in stage 8.0 (TID 38) (172.18.0.8, executor 0, partition 31, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.078245","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 32.0 in stage 8.0 (TID 39) (172.18.0.8, executor 0, partition 32, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.078371","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 29.0 in stage 8.0 (TID 36) in 43 ms on 172.18.0.8 (executor 0) (31/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.078691","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 30.0 in stage 8.0 (TID 37) in 42 ms on 172.18.0.8 (executor 0) (32/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.104958","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_31 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.106135","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_32 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.113514","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 33.0 in stage 8.0 (TID 40) (172.18.0.8, executor 0, partition 33, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.113770","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 31.0 in stage 8.0 (TID 38) in 36 ms on 172.18.0.8 (executor 0) (33/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.114151","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 34.0 in stage 8.0 (TID 41) (172.18.0.8, executor 0, partition 34, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.114504","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 32.0 in stage 8.0 (TID 39) in 37 ms on 172.18.0.8 (executor 0) (34/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.132660","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_33 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.132748","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_34 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.143451","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 35.0 in stage 8.0 (TID 42) (172.18.0.8, executor 0, partition 35, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.143635","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 34.0 in stage 8.0 (TID 41) in 30 ms on 172.18.0.8 (executor 0) (35/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.143993","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 36.0 in stage 8.0 (TID 43) (172.18.0.8, executor 0, partition 36, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.147040","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 33.0 in stage 8.0 (TID 40) in 33 ms on 172.18.0.8 (executor 0) (36/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.159460","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_35 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.159805","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_36 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.169013","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 37.0 in stage 8.0 (TID 44) (172.18.0.8, executor 0, partition 37, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.169429","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 38.0 in stage 8.0 (TID 45) (172.18.0.8, executor 0, partition 38, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.169805","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 36.0 in stage 8.0 (TID 43) in 26 ms on 172.18.0.8 (executor 0) (37/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.169867","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 35.0 in stage 8.0 (TID 42) in 26 ms on 172.18.0.8 (executor 0) (38/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.186995","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_37 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.187076","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_38 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.194995","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 39.0 in stage 8.0 (TID 46) (172.18.0.8, executor 0, partition 39, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.195398","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 40.0 in stage 8.0 (TID 47) (172.18.0.8, executor 0, partition 40, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.195616","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 37.0 in stage 8.0 (TID 44) in 27 ms on 172.18.0.8 (executor 0) (39/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.195773","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 38.0 in stage 8.0 (TID 45) in 26 ms on 172.18.0.8 (executor 0) (40/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.224028","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_40 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.224222","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_39 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.237361","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 41.0 in stage 8.0 (TID 48) (172.18.0.8, executor 0, partition 41, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.237655","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 40.0 in stage 8.0 (TID 47) in 42 ms on 172.18.0.8 (executor 0) (41/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.238127","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 43.0 in stage 8.0 (TID 49) (172.18.0.8, executor 0, partition 43, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.238424","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 39.0 in stage 8.0 (TID 46) in 44 ms on 172.18.0.8 (executor 0) (42/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.262278","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_41 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.262415","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_43 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.271599","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 44.0 in stage 8.0 (TID 50) (172.18.0.8, executor 0, partition 44, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.271832","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 41.0 in stage 8.0 (TID 48) in 35 ms on 172.18.0.8 (executor 0) (43/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.272272","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 45.0 in stage 8.0 (TID 51) (172.18.0.8, executor 0, partition 45, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.272576","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 43.0 in stage 8.0 (TID 49) in 35 ms on 172.18.0.8 (executor 0) (44/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.288791","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_44 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.288986","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_45 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.299555","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 46.0 in stage 8.0 (TID 52) (172.18.0.8, executor 0, partition 46, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.299650","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 45.0 in stage 8.0 (TID 51) in 27 ms on 172.18.0.8 (executor 0) (45/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.300061","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 47.0 in stage 8.0 (TID 53) (172.18.0.8, executor 0, partition 47, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.300328","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 44.0 in stage 8.0 (TID 50) in 29 ms on 172.18.0.8 (executor 0) (46/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.329135","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_46 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.329252","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_47 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.338106","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 48.0 in stage 8.0 (TID 54) (172.18.0.8, executor 0, partition 48, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.338567","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 46.0 in stage 8.0 (TID 52) in 39 ms on 172.18.0.8 (executor 0) (47/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.339071","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 49.0 in stage 8.0 (TID 55) (172.18.0.8, executor 0, partition 49, PROCESS_LOCAL, 10501 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.339467","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 47.0 in stage 8.0 (TID 53) in 40 ms on 172.18.0.8 (executor 0) (48/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.359346","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_48 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.359460","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added rdd_30_49 in memory on 172.18.0.8:41779 (size: 46.0 B, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.371754","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 48.0 in stage 8.0 (TID 54) in 34 ms on 172.18.0.8 (executor 0) (49/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.371843","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 49.0 in stage 8.0 (TID 55) in 33 ms on 172.18.0.8 (executor 0) (50/50)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.371869","level":"info","event":"25/08/02 09:17:30 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.372256","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: ShuffleMapStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.572 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.372291","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: looking for newly runnable stages","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.372312","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: running: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.372332","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: waiting: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.372349","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: failed: Set()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.389208","level":"info","event":"25/08/02 09:17:30 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.390006","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: Got job 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.390079","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: Final stage: ResultStage 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.390106","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.390129","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.390358","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[36] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.393266","level":"info","event":"25/08/02 09:17:30 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 534.7 KiB, free 432.4 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.394736","level":"info","event":"25/08/02 09:17:30 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 124.7 KiB, free 432.3 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.395099","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 4a4a2233a16a:39333 (size: 124.7 KiB, free: 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.395414","level":"info","event":"25/08/02 09:17:30 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.395637","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[36] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.395671","level":"info","event":"25/08/02 09:17:30 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.396447","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 56) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 10512 bytes)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.403806","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 4a4a2233a16a:39333 in memory (size: 138.1 KiB, free: 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.405197","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.8:41779 in memory (size: 138.1 KiB, free: 1048.7 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.406567","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:41779 (size: 124.7 KiB, free: 1048.6 MiB)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.412195","level":"info","event":"25/08/02 09:17:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:47292","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.436117","level":"info","event":"25/08/02 09:17:30 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 56) in 39 ms on 172.18.0.8 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.436195","level":"info","event":"25/08/02 09:17:30 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.436423","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: ResultStage 11 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.046 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.436563","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.436616","level":"info","event":"25/08/02 09:17:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.436746","level":"info","event":"25/08/02 09:17:30 INFO DAGScheduler: Job 8 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.047510 s","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.462788","level":"info","event":"25/08/02 09:17:30 INFO CodeGenerator: Code generated in 20.2445 ms","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.463947","level":"info","event":"25/08/02 09:17:30 INFO Snapshot: [tableId=65950ee1-5c70-44fb-be90-0e24a57e5909] DELTA: Done","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.473938","level":"info","event":"25/08/02 09:17:30 INFO OptimisticTransaction: [tableId=2f8987a4,txnId=e4a39b4d] Committed delta #0 to s3a://activefence-bucket/bbc_tech/silver/_delta_log","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.476633","level":"info","event":"INFO:__main__:Data cleaned and loaded to silver layer!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.476842","level":"info","event":"25/08/02 09:17:30 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.485280","level":"info","event":"25/08/02 09:17:30 INFO SparkUI: Stopped Spark web UI at http://4a4a2233a16a:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.486665","level":"info","event":"25/08/02 09:17:30 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.486856","level":"info","event":"25/08/02 09:17:30 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.497264","level":"info","event":"25/08/02 09:17:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.509803","level":"info","event":"25/08/02 09:17:30 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.510152","level":"info","event":"25/08/02 09:17:30 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.513171","level":"info","event":"25/08/02 09:17:30 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.515015","level":"info","event":"25/08/02 09:17:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.524114","level":"info","event":"25/08/02 09:17:30 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.799409","level":"info","event":"INFO:__main__:Spark session stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.799483","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.820156","level":"info","event":"25/08/02 09:17:30 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.820285","level":"info","event":"25/08/02 09:17:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-4cde6ea1-b389-4029-9e58-323dad6fb903","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.822248","level":"info","event":"25/08/02 09:17:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae/pyspark-5e094a1e-493a-4e05-9b74-c0e5c835de99","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.823521","level":"info","event":"25/08/02 09:17:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-e60c0a03-8b74-40a9-b46c-181f58de4aae","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.826946","level":"info","event":"25/08/02 09:17:30 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.826995","level":"info","event":"25/08/02 09:17:30 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
{"timestamp":"2025-08-02T09:17:30.827033","level":"info","event":"25/08/02 09:17:30 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook"}
